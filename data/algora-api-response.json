{
  "result": {
    "data": {
      "json": {
        "items": [
          {
            "id": "outerbase#59",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2025-11-09T10:34:56.354Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:34:56.354Z",
            "created_at": "2025-11-09T10:34:56.354Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#59",
              "status": "open",
              "type": "issue",
              "number": 59,
              "title": "Database dumps do not work on large databases",
              "source": {
                "data": {
                  "id": "source-outerbase#59",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Database dumps do not work on large databases",
                  "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/59"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#59",
              "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
              "url": "https://github.com/outerbase/starbasedb/issues/59",
              "tech": [
                "go"
              ],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "outerbase#72",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2025-11-09T10:34:58.612Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:34:58.612Z",
            "created_at": "2025-11-09T10:34:58.612Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#72",
              "status": "open",
              "type": "issue",
              "number": 72,
              "title": "Replicate data from external source to internal source with a Plugin",
              "source": {
                "data": {
                  "id": "source-outerbase#72",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Replicate data from external source to internal source with a Plugin",
                  "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/72"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#72",
              "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
              "url": "https://github.com/outerbase/starbasedb/issues/72",
              "tech": [],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13872",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-09T10:34:56.355Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:34:56.355Z",
            "created_at": "2025-11-09T10:34:56.355Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13872",
              "status": "open",
              "type": "issue",
              "number": 13872,
              "title": "CVE-2021-4374 - WordPress Automatic Plugin - Broken Access Control ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13872",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2021-4374 - WordPress Automatic Plugin - Broken Access Control ðŸ’°",
                  "body": "\n### Description: \n> WordPress Automatic Plugin for WordPress versions up to 3.53.2 contains a broken access control caused by missing authorization and option validation in process_form.php, letting unauthenticated attackers arbitrarily update site settings, exploit requires no authentication.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://blog.nintechnet.com/critical-vulnerability-fixed-in-wordpress-automatic-plugin/\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13872"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13872",
              "body": "\n### Description: \n> WordPress Automatic Plugin for WordPress versions up to 3.53.2 contains a broken access control caused by missing authorization and option validation in process_form.php, letting unauthenticated attackers arbitrarily update site settings, exploit requires no authentication.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://blog.nintechnet.com/critical-vulnerability-fixed-in-wordpress-automatic-plugin/\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13872",
              "tech": [
                "go"
              ],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13865",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-09T10:34:58.612Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:34:58.612Z",
            "created_at": "2025-11-09T10:34:58.612Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13865",
              "status": "open",
              "type": "issue",
              "number": 13865,
              "title": "CVE-2023-26134 - git-commit-info - Command Injection ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13865",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2023-26134 - git-commit-info - Command Injection ðŸ’°",
                  "body": "\n### Description: \n> git-commit-info contains a command injection caused by unsanitized commit parameter in gitCommitInfo(), letting attackers inject malicious commands if they control the hash content, exploit requires control over commit hash.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/JPeer264/node-git-commit-info/issues/24\n- https://security.snyk.io/vuln/SNYK-JS-GITCOMMITINFO-5740174\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13865"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13865",
              "body": "\n### Description: \n> git-commit-info contains a command injection caused by unsanitized commit parameter in gitCommitInfo(), letting attackers inject malicious commands if they control the hash content, exploit requires control over commit hash.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/JPeer264/node-git-commit-info/issues/24\n- https://security.snyk.io/vuln/SNYK-JS-GITCOMMITINFO-5740174\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13865",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13862",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-09T10:35:01.074Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:01.074Z",
            "created_at": "2025-11-09T10:35:01.074Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13862",
              "status": "open",
              "type": "issue",
              "number": 13862,
              "title": "CVE-2023-34478 - Apache Shiro - Authentication Bypass ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13862",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2023-34478 - Apache Shiro - Authentication Bypass ðŸ’°",
                  "body": "\n### Description: \n> Apache Shiro before 1.12.0 or 2.0.0-alpha-3 contains a path traversal caused by request routing issues with non-normalized requests, letting attackers bypass authentication, exploit requires use with specific web frameworks or APIs.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/shoucheng3/apache__shiro_CVE-2023-34478_1-11-0\n\n### KEV: True\n\n### Shodan Query: `http.title:\"apache shiro quickstart\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13862"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13862",
              "body": "\n### Description: \n> Apache Shiro before 1.12.0 or 2.0.0-alpha-3 contains a path traversal caused by request routing issues with non-normalized requests, letting attackers bypass authentication, exploit requires use with specific web frameworks or APIs.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/shoucheng3/apache__shiro_CVE-2023-34478_1-11-0\n\n### KEV: True\n\n### Shodan Query: `http.title:\"apache shiro quickstart\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13862",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13820",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-09T10:35:03.784Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:03.784Z",
            "created_at": "2025-11-09T10:35:03.784Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13820",
              "status": "open",
              "type": "issue",
              "number": 13820,
              "title": "CVE-2025-11833 - Post SMTP WordPress Plugin - Broken Access Control ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13820",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2025-11833 - Post SMTP WordPress Plugin - Broken Access Control ðŸ’°",
                  "body": "\n### Description: \n> Post SMTP WordPress plugin <= 3.6.0 contains an unauthorized data access vulnerability caused by missing capability check in __construct function, letting unauthenticated attackers read arbitrary logged emails, exploit requires no authentication.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/nullstatics/CVE-2025-11833\n- https://github.com/modhopmarrow1973/CVE-2025-11833-LAB\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13820"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13820",
              "body": "\n### Description: \n> Post SMTP WordPress plugin <= 3.6.0 contains an unauthorized data access vulnerability caused by missing capability check in __construct function, letting unauthenticated attackers read arbitrary logged emails, exploit requires no authentication.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/nullstatics/CVE-2025-11833\n- https://github.com/modhopmarrow1973/CVE-2025-11833-LAB\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13820",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13724",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-09T10:35:05.590Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:05.590Z",
            "created_at": "2025-11-09T10:35:05.590Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13724",
              "status": "open",
              "type": "issue",
              "number": 13724,
              "title": "CVE-2025-61932 - Lanscope Endpoint Manager - Remote Code Execution ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13724",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2025-61932 - Lanscope Endpoint Manager - Remote Code Execution ðŸ’°",
                  "body": "\n### Description: \n> Lanscope Endpoint Manager (On-Premises) contains a remote code execution vulnerability caused by improper verification of the origin of incoming requests, letting attackers execute arbitrary code remotely, exploit requires sending specially crafted packets.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/allinsthon/CVE-2025-61932\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13724"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13724",
              "body": "\n### Description: \n> Lanscope Endpoint Manager (On-Premises) contains a remote code execution vulnerability caused by improper verification of the origin of incoming requests, letting attackers execute arbitrary code remotely, exploit requires sending specially crafted packets.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/allinsthon/CVE-2025-61932\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13724",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13435",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-09T10:35:07.307Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:07.307Z",
            "created_at": "2025-11-09T10:35:07.307Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13435",
              "status": "open",
              "type": "issue",
              "number": 13435,
              "title": "CVE-2023-27532 - Veeam Backup & Replication - Credential Disclosure ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13435",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2023-27532 - Veeam Backup & Replication - Credential Disclosure ðŸ’°",
                  "body": "### Description:\n> Veeam Backup & Replication allows encrypted credentials stored in the configuration database to be obtained by attackers who can access backup infrastructure hosts.\n\n#### Severity: `High` (CVSS: 7.5)\n\n#### Vulnerability Details:\n- **CVE ID**: CVE-2023-27532\n- **CWE**: CWE-306 (Missing Authentication for Critical Function)\n- **Affected Versions**: 11.0.1.1261 and 12.0.0.1420\n- **Attack Vector**: Network\n- **Authentication**: Requires access to configuration database\n- **Impact**: Information Disclosure, Privilege Escalation\n\n#### POC:\n- https://github.com/horizon3ai/CVE-2023-27532\n- https://github.com/sfewer-r7/CVE-2023-27532\n- https://github.com/puckiestyle/CVE-2023-27532-RCE-Only\n\n### KEV: True âœ…\n**CISA KEV**: Added 2023-08-22  \n**Known Ransomware Campaign**: Yes (Akira, Qilin, and multiple others)\n\n### EPSS Score: 0.87024 (99.406th percentile) âš ï¸\n\n### Shodan Query: `\"Veeam Backup\" http.title:\"Veeam Backup Enterprise Manager\"`\n\n---\n\n> **Acceptance Criteria:**\n> The template must include a complete POC and should not rely solely on version-based detection. Contributors must share vulnerable setup information or a testable instance by emailing templates@projectdiscovery.io. Providing a testable instance significantly reduces validation time and increases the chance of quicker rewards. Templates that are incomplete, invalid, or non-verifiable will not be accepted. Avoid submitting code templates for CVEs that can be detected using HTTP, TCP, or JavaScript only these are blocked by default and will not produce results. Exceptions may apply for certain cases. Do not submit AI-simulated vulnerable environments. To qualify for the bounty, the team must be able to fully validate the POC. If you have hosted a vulnerable environment for validation, send the details (IP or Docker setup) along with the PR number to templates[at]projectdiscovery.io\n\n> **Note**: This vulnerability has been **actively exploited** in multiple ransomware campaigns including Akira, Qilin, and others. **VERY HIGH PRIORITY** - EPSS score 0.87 (top 1%).\n\n---\n\n### References:\n- https://www.veeam.com/kb4424\n- https://github.com/horizon3ai/CVE-2023-27532\n- https://www.zscaler.com/resources/industry-reports/threatlabz-2025-ransomware-analysis.pdf\n- https://blog.qualys.com/vulnerabilities-threat-research/2025/06/18/qilin-ransomware-explained-threats-risks-defenses\n- https://services.google.com/fh/files/misc/m-trends-2025-en.pdf\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/discussions/9965)",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13435"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13435",
              "body": "### Description:\n> Veeam Backup & Replication allows encrypted credentials stored in the configuration database to be obtained by attackers who can access backup infrastructure hosts.\n\n#### Severity: `High` (CVSS: 7.5)\n\n#### Vulnerability Details:\n- **CVE ID**: CVE-2023-27532\n- **CWE**: CWE-306 (Missing Authentication for Critical Function)\n- **Affected Versions**: 11.0.1.1261 and 12.0.0.1420\n- **Attack Vector**: Network\n- **Authentication**: Requires access to configuration database\n- **Impact**: Information Disclosure, Privilege Escalation\n\n#### POC:\n- https://github.com/horizon3ai/CVE-2023-27532\n- https://github.com/sfewer-r7/CVE-2023-27532\n- https://github.com/puckiestyle/CVE-2023-27532-RCE-Only\n\n### KEV: True âœ…\n**CISA KEV**: Added 2023-08-22  \n**Known Ransomware Campaign**: Yes (Akira, Qilin, and multiple others)\n\n### EPSS Score: 0.87024 (99.406th percentile) âš ï¸\n\n### Shodan Query: `\"Veeam Backup\" http.title:\"Veeam Backup Enterprise Manager\"`\n\n---\n\n> **Acceptance Criteria:**\n> The template must include a complete POC and should not rely solely on version-based detection. Contributors must share vulnerable setup information or a testable instance by emailing templates@projectdiscovery.io. Providing a testable instance significantly reduces validation time and increases the chance of quicker rewards. Templates that are incomplete, invalid, or non-verifiable will not be accepted. Avoid submitting code templates for CVEs that can be detected using HTTP, TCP, or JavaScript only these are blocked by default and will not produce results. Exceptions may apply for certain cases. Do not submit AI-simulated vulnerable environments. To qualify for the bounty, the team must be able to fully validate the POC. If you have hosted a vulnerable environment for validation, send the details (IP or Docker setup) along with the PR number to templates[at]projectdiscovery.io\n\n> **Note**: This vulnerability has been **actively exploited** in multiple ransomware campaigns including Akira, Qilin, and others. **VERY HIGH PRIORITY** - EPSS score 0.87 (top 1%).\n\n---\n\n### References:\n- https://www.veeam.com/kb4424\n- https://github.com/horizon3ai/CVE-2023-27532\n- https://www.zscaler.com/resources/industry-reports/threatlabz-2025-ransomware-analysis.pdf\n- https://blog.qualys.com/vulnerabilities-threat-research/2025/06/18/qilin-ransomware-explained-threats-risks-defenses\n- https://services.google.com/fh/files/misc/m-trends-2025-en.pdf\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/discussions/9965)",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13435",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13434",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-09T10:35:10.465Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:10.465Z",
            "created_at": "2025-11-09T10:35:10.465Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13434",
              "status": "open",
              "type": "issue",
              "number": 13434,
              "title": "CVE-2022-26500 - Veeam Backup & Replication - Unrestricted File Upload ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13434",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2022-26500 - Veeam Backup & Replication - Unrestricted File Upload ðŸ’°",
                  "body": "### Description:\n> Veeam Backup & Replication contains an improper limitation of path names caused by insufficient validation in internal API functions, letting remote authenticated users upload and execute arbitrary code.\n\n#### Severity: `High` (CVSS: 8.8)\n\n#### Vulnerability Details:\n- **CVE ID**: CVE-2022-26500\n- **CWE**: CWE-22 (Improper Limitation of a Pathname to a Restricted Directory)\n- **Affected Versions**: 9.5U3, 9.5U4, 10.x, and 11.x\n- **Attack Vector**: Network\n- **Authentication**: Required (logged_in)\n- **Impact**: Remote Code Execution\n\n#### POC:\n- https://cloudsek.com/threatintelligence/multiple-rce-vulnerabilities-affecting-veeam-backup-replication/\n- https://www.veeam.com/kb4288\n\n### KEV: True âœ…\n**CISA KEV**: Added 2022-12-13  \n**Known Ransomware Campaign**: Yes (Cuba, AvosLocker, LockBit)\n\n### EPSS Score: 0.25477 (96.037th percentile)\n\n### Shodan Query: `\"Veeam Backup\" http.title:\"Veeam Backup Enterprise Manager\"`\n\n---\n\n>  Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors must share vulnerable setup information or a testable instance by emailing templates@projectdiscovery.io. Providing a testable instance significantly reduces validation time and increases the chance of quicker rewards. Templates that are incomplete, invalid, or non-verifiable will not be accepted. Avoid submitting code templates for CVEs that can be detected using HTTP, TCP, or JavaScript only these are blocked by default and will not produce results. Exceptions may apply for certain cases. Do not submit AI-simulated vulnerable environments. To qualify for the bounty, the team must be able to fully validate the POC. If you have hosted a vulnerable environment for validation, send the details (IP or Docker setup) along with the PR number to templates[at]projectdiscovery.io\n\n---\n\n### References:\n- https://veeam.com\n- https://www.veeam.com/kb4288\n- https://securelist.com/cuba-ransomware/110533/\n- https://www.kroll.com/en/insights/publications/cyber/avoslocker-ransomware-update\n- https://blog.qualys.com/vulnerabilities-threat-research/2025/05/08/inside-lockbit-defense-lessons-from-the-leaked-lockbit-negotiations\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/discussions/9965)",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13434"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13434",
              "body": "### Description:\n> Veeam Backup & Replication contains an improper limitation of path names caused by insufficient validation in internal API functions, letting remote authenticated users upload and execute arbitrary code.\n\n#### Severity: `High` (CVSS: 8.8)\n\n#### Vulnerability Details:\n- **CVE ID**: CVE-2022-26500\n- **CWE**: CWE-22 (Improper Limitation of a Pathname to a Restricted Directory)\n- **Affected Versions**: 9.5U3, 9.5U4, 10.x, and 11.x\n- **Attack Vector**: Network\n- **Authentication**: Required (logged_in)\n- **Impact**: Remote Code Execution\n\n#### POC:\n- https://cloudsek.com/threatintelligence/multiple-rce-vulnerabilities-affecting-veeam-backup-replication/\n- https://www.veeam.com/kb4288\n\n### KEV: True âœ…\n**CISA KEV**: Added 2022-12-13  \n**Known Ransomware Campaign**: Yes (Cuba, AvosLocker, LockBit)\n\n### EPSS Score: 0.25477 (96.037th percentile)\n\n### Shodan Query: `\"Veeam Backup\" http.title:\"Veeam Backup Enterprise Manager\"`\n\n---\n\n>  Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors must share vulnerable setup information or a testable instance by emailing templates@projectdiscovery.io. Providing a testable instance significantly reduces validation time and increases the chance of quicker rewards. Templates that are incomplete, invalid, or non-verifiable will not be accepted. Avoid submitting code templates for CVEs that can be detected using HTTP, TCP, or JavaScript only these are blocked by default and will not produce results. Exceptions may apply for certain cases. Do not submit AI-simulated vulnerable environments. To qualify for the bounty, the team must be able to fully validate the POC. If you have hosted a vulnerable environment for validation, send the details (IP or Docker setup) along with the PR number to templates[at]projectdiscovery.io\n\n---\n\n### References:\n- https://veeam.com\n- https://www.veeam.com/kb4288\n- https://securelist.com/cuba-ransomware/110533/\n- https://www.kroll.com/en/insights/publications/cyber/avoslocker-ransomware-update\n- https://blog.qualys.com/vulnerabilities-threat-research/2025/05/08/inside-lockbit-defense-lessons-from-the-leaked-lockbit-negotiations\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/discussions/9965)",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13434",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#315",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-09T10:35:19.514Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:19.514Z",
            "created_at": "2025-11-09T10:35:19.514Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#315",
              "status": "open",
              "type": "issue",
              "number": 315,
              "title": "[bounty] test and showcase the new gemini computer use model with terminator MCP",
              "source": {
                "data": {
                  "id": "source-mediar-ai#315",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] test and showcase the new gemini computer use model with terminator MCP",
                  "body": "basic idea: try the new gemini CU model:\n\nhttps://cloud.google.com/vertex-ai/generative-ai/docs/computer-use\n\nand try to build some workflows like reading PDFs or spreadsheets on file system and doing data entry in another software \n\n\ngoal: evaluate if their model adds worthwhile performance gain by using both vision and accessibility to build workflow compared to claude etc\n\n\nrequirements:\n- record yourself building the workflow \n- use the new model somehow (gemini CLI + terminator MCP + gemini model configured for example, or build a custom MCP client in python/js, high preference for JS)\n- use terminator MCP server\n\n\nbonus:\n- professional video level that can be published on social\n\n\nplease share your plan before building things, one-prompt PRs will be banned \n\n/bounty 200\n",
                  "html_url": "https://github.com/mediar-ai/terminator/issues/315"
                },
                "type": "github"
              },
              "hash": "mediar-ai/terminator#315",
              "body": "basic idea: try the new gemini CU model:\n\nhttps://cloud.google.com/vertex-ai/generative-ai/docs/computer-use\n\nand try to build some workflows like reading PDFs or spreadsheets on file system and doing data entry in another software \n\n\ngoal: evaluate if their model adds worthwhile performance gain by using both vision and accessibility to build workflow compared to claude etc\n\n\nrequirements:\n- record yourself building the workflow \n- use the new model somehow (gemini CLI + terminator MCP + gemini model configured for example, or build a custom MCP client in python/js, high preference for JS)\n- use terminator MCP server\n\n\nbonus:\n- professional video level that can be published on social\n\n\nplease share your plan before building things, one-prompt PRs will be banned \n\n/bounty 200\n",
              "url": "https://github.com/mediar-ai/terminator/issues/315",
              "tech": [
                "go"
              ],
              "repo_name": "terminator",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1626",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-09T10:35:19.650Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:19.650Z",
            "created_at": "2025-11-09T10:35:19.650Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1626",
              "status": "open",
              "type": "issue",
              "number": 1626,
              "title": "[bounty] $400 fix audio device randomly stopping sometimes",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1626",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] $400 fix audio device randomly stopping sometimes",
                  "body": "\ndisplay audio / microphone randomly stops on mac sometimes \n\nhad it running for 48h now and display audio somehow stopped a bit later after 50h\n\n/bounty 400 \n\n@EzraEllette any idea?\n\n\ni suggest finding way to reproduce and then some automated test and a fix ",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1626"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1626",
              "body": "\ndisplay audio / microphone randomly stops on mac sometimes \n\nhad it running for 48h now and display audio somehow stopped a bit later after 50h\n\n/bounty 400 \n\n@EzraEllette any idea?\n\n\ni suggest finding way to reproduce and then some automated test and a fix ",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1626",
              "tech": [
                "go"
              ],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1560",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-09T10:35:19.768Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:19.768Z",
            "created_at": "2025-11-09T10:35:19.768Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1560",
              "status": "open",
              "type": "issue",
              "number": 1560,
              "title": "[feature]  Implement Session Tracking for Application and Window Usage",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1560",
                  "user": {
                    "login": "rodgomesc",
                    "id": 4893591,
                    "node_id": "MDQ6VXNlcjQ4OTM1OTE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/4893591?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/rodgomesc",
                    "html_url": "https://github.com/rodgomesc",
                    "followers_url": "https://api.github.com/users/rodgomesc/followers",
                    "following_url": "https://api.github.com/users/rodgomesc/following{/other_user}",
                    "gists_url": "https://api.github.com/users/rodgomesc/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/rodgomesc/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/rodgomesc/subscriptions",
                    "organizations_url": "https://api.github.com/users/rodgomesc/orgs",
                    "repos_url": "https://api.github.com/users/rodgomesc/repos",
                    "events_url": "https://api.github.com/users/rodgomesc/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/rodgomesc/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[feature]  Implement Session Tracking for Application and Window Usage",
                  "body": "\n## Challenge\n\nI'm working on an application that requires accurate session tracking to analyze user behavior patterns,  and provide meaningful insights across different applications and windows. \n\nIn the existing Screenpipe architecture, OCR data is stored with only timestamp information, lacking precise session boundaries (start/end times) for application usage tracking. This limitation prevents us from properly segmenting user activity into coherent sessions.\n\n## 1. Current Workaround\ninternally I implementing a suboptimal solution that:\n1. Queries all OCR database entries chronologically\n2. Manually identifies session boundaries by analyzing timestamp sequences for each application\n3. Determines session end when detecting a different application in subsequent timestamps\n4. Assumes a session is ongoing if no clear delimiter exists in future timestamps\n\nWith that said I would love to hear any feedbacks that could help solve this problem with a minimal overhead on code changes, and make sure I'm not overthinking the solution: cc @louis030195 , i'm planning to start playing with some day next week\n\n## 2. Requirements\n\n1.  **Session Definition:** A \"session\" should be defined as a continuous period of user interaction with a specific application and window.  A break in activity (e.g., switching to a different application or window) should end the current session and potentially start a new one.  A configurable inactivity timeout (e.g., 5 minutes) should also end a session.\n\n2.  **Data Storage:** The database schema must be modified to store session start and end times, associated with specific applications and windows.  It must maintain links to the relevant OCR and audio data chunks.\n\n3.  **API Endpoint:**  A new or modified API endpoint (e.g., `/sessions`) is needed to query for session data.  This endpoint should support filtering by:\n    *   Date range (start and end timestamps).\n    *   Application name.\n    *   Window name.\n    *   Minimum and maximum session duration.\n    *   Associated tags.\n    *   Pagination (limit and offset).\n\n4.  **Real-time Capability:** The system should be able to detect session boundaries in near real-time as data is being ingested. This implies integration with the existing data capture and processing pipeline.\n\n5. **Configurability:** The inactivity timeout for ending a session should be configurable.\n\n## 3. Proposed Solution\n\n### 3.1. Database Schema Changes\n\nWe'll introduce a new table `sessions` and modify the existing tables.\n\n**New Table: `sessions`**\n\n| Column Name      | Data Type  | Constraints                                  | Description                                                                  |\n| :--------------- | :--------- | :------------------------------------------- | :--------------------------------------------------------------------------- |\n| `id`             | INTEGER    | PRIMARY KEY AUTOINCREMENT                    | Unique identifier for the session.                                       |\n| `app_name`       | TEXT       | NOT NULL                                     | Name of the application.                                                 |\n| `window_name`    | TEXT       |                                               | Title of the window.                                                     |\n| `start_time`     | DATETIME   | NOT NULL                                     | Timestamp of the session start.                                            |\n| `end_time`       | DATETIME   | NOT NULL                                     | Timestamp of the session end.                                              |\n| `duration_secs`  | REAL       | NOT NULL                                     | Duration of the session in seconds.                                        |\n\n**Modified Tables:**\n\n*   **`ocr_text`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`audio_transcriptions`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`ui_monitoring`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n\n**Indexes:**\n\n*   Create indexes on `sessions` table columns (`app_name`, `window_name`, `start_time`, `end_time`) for efficient querying.\n*   Create indexes on the `session_id` columns in `ocr_text`, `audio_transcriptions`, and `ui_monitoring`.\n\n### 3.2. API Enhancements\n\nWe'll modify the existing `/search` endpoint to also support session queries.\n\n**Request:**\n\n```\nGET /search?content_type=session&app_name=Cursor&start_time=2024-11-27T00:00:00Z&end_time=2024-11-28T00:00:00Z&min_duration=60&limit=10&offset=0\n```\n\n*   `content_type=session`: Indicates a session-based search.\n*   `app_name`, `window_name`: Filter by application and window (optional).\n*   `start_time`, `end_time`: Date range for the session (optional, defaults to last 24 hours).\n*   `min_duration`, `max_duration`: Filter by session duration in seconds (optional).\n*   `limit`, `offset`: Pagination parameters.\n\n\nafter discussing with @louis030195 on discord he proposed something like this as the output\n\n**Response:**\n\n```json\n{\n  \"data\": [\n    {\n      \"app_name\": \"Cursor\",\n      \"total_usage_time\": 3600,\n      \"windows\": [\n        {\n          \"window_name\": \"page.tsx\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T12:00:00Z\",\n              \"end_time\": \"2024-07-16T12:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [123, 124, 125],\n              \"tags\": [\"coding\", \"frontend\"]\n            },\n            {\n              \"start_time\": \"2024-07-16T14:00:00Z\",\n              \"end_time\": \"2024-07-16T14:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [223, 224, 225],\n              \"tags\": [\"coding\", \"frontend\"]\n            }\n          ],\n          \"total_usage_time\": 3600\n        }\n      ]\n    },\n    {\n      \"app_name\": \"Arc\",\n      \"total_usage_time\": 1200,\n      \"windows\": [\n        {\n          \"window_name\": \"x.com\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T10:30:00Z\",\n              \"end_time\": \"2024-07-16T10:50:00Z\",\n              \"duration\": 1200,\n              \"content_ids\": [126, 127, 128],\n              \"tags\": [\"browsing\", \"social-media\"]\n            }\n          ],\n          \"total_usage_time\": 1200\n        }\n      ]\n    }\n  ],\n  \"pagination\": {\n    \"limit\": 50,\n    \"offset\": 0,\n    \"total\": 2\n  }\n}\n```\n\n### 3.3. Session Boundary Detection Logic\n\n1.  **Real-time Monitoring:**  The existing event listeners for OCR, audio, and UI events will be leveraged.\n\n2.  **Session Tracking:**  Maintain a data structure (likely in memory, possibly augmented with periodic database writes for persistence) to track active sessions.  This structure should map:\n    *   `(app_name, window_name)` -> `(session_id, last_activity_timestamp)`\n\n3.  **New Event Handling:**\n    *   When a new event (OCR, audio, UI) arrives:\n        *   Extract `app_name` and `window_name`.\n        *   Check if an active session exists for this (app, window) combination.\n        *   If a session exists:\n            *   Check if `now() - last_activity_timestamp` exceeds the inactivity timeout.\n            *   If timeout exceeded, end the existing session and create a new one.\n            *   If not timed out, update `last_activity_timestamp` to the event's timestamp.\n        *   If no session exists:\n            *   Create a new session with `start_time` and `end_time` set to the event's timestamp.\n            *   Generate a new `session_id`.\n            *   Insert a new row into the `sessions` table.\n        *   Insert the new data (OCR, audio, UI) into the relevant table, linking it to the active `session_id`.\n\n4.  **Inactivity Timeout:** A configurable timeout (e.g., 5 minutes) will be used to determine session end due to inactivity.\n\n5.  **Periodic Flushing:** To avoid excessive in-memory state, periodically flush closed sessions (those that have exceeded the inactivity timeout) to the database.\n\n6. **Data Migration:** A migration script will be needed to analyze existing data and create initial session records based on timestamp proximity and app/window changes.\n\n### 3.4. Implementation Details\n\n*   **Language/Framework:** Continue using Rust for core logic and database interaction.\n*   **Database:** Continue using SQLite.\n*   **Concurrency:** Use asynchronous operations with `tokio` for handling concurrent events and database interactions.  Leverage `Arc` and `Mutex` for shared state, and channels for communication between tasks.\n*   **Configuration:** Add a new setting for the inactivity timeout.\n*   **Error Handling:** Implement robust error handling with `anyhow` and propagate errors appropriately. Log errors using `tracing`.\n* **Testing:** Thoroughly test session boundary detection with various scenarios, including rapid switching, long inactivity periods, and concurrent events.\n\n## 4. Diagrams\n\n### 4.1. Current Data Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Database\n    User->>Screen: Interacts with screen\n    Screen->>Screenpipe: Captures screen content (OCR)\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Database: Stores OCR data with timestamps\n    Screenpipe->>Database: Stores audio transcriptions with timestamps\n    User->>Screenpipe: Requests data\n    Screenpipe->>Database: Queries data by time range\n    Database->>Screenpipe: Returns data\n    Screenpipe->>User: Returns data\n```\n\n### 4.2. Proposed Database Schema Changes\n\n```mermaid\nclassDiagram\n    class frames {\n        +id : INTEGER [PK]\n        +video_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +name : TEXT\n    }\n    class video_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +device_name : TEXT\n    }\n    class ocr_text {\n        +frame_id : INTEGER [FK]\n        +text : TEXT\n        +text_json : TEXT\n        +app_name : TEXT\n        +window_name : TEXT\n        +ocr_engine : TEXT\n        +focused : BOOLEAN\n        +session_id : INTEGER [FK]\n    }\n    class audio_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +timestamp : TIMESTAMP\n    }\n    class audio_transcriptions {\n        +id : INTEGER [PK]\n        +audio_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +transcription : TEXT\n        +device : TEXT\n        +is_input_device : BOOLEAN\n        +speaker_id : INTEGER\n        +transcription_engine : TEXT\n        +start_time : REAL\n        +end_time : REAL\n        +text_length : INTEGER\n        +session_id : INTEGER [FK]\n    }\n    class ui_monitoring {\n      +id : INTEGER [PK]\n      +text_output : TEXT\n      +timestamp : DATETIME\n      +app : TEXT\n      +window : TEXT\n      +initial_traversal_at : DATETIME\n      +session_id : INTEGER [FK]\n    }\n  class sessions {\n    +id : INTEGER [PK]\n    +app_name : TEXT\n    +window_name : TEXT\n    +start_time : DATETIME\n    +end_time : DATETIME\n    +duration_secs : REAL\n  }\n  frames --|> video_chunks : video_chunk_id\n  ocr_text --|> frames : frame_id\n  audio_transcriptions --|> audio_chunks : audio_chunk_id\n  ocr_text --|> sessions : session_id\n  audio_transcriptions --|> sessions : session_id\n  ui_monitoring --|> sessions : session_id\n```\n\n### 4.3. Modified Data Flow with Session Tracking\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Session Manager\n    participant Database\n\n    User->>Screen: Interacts with App A, Window 1\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to session_id\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: Active session found (session_id)\n    Screenpipe->>Database: Store audio data, link to session_id\n\n    Note over User,Screenpipe: User switches to App B, Window 2\n    User->>Screen: Interacts with App B, Window 2\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App B, Window 2)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: End previous session (App A, Window 1)\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to new session_id\n\n    Note over User,Screenpipe: Inactivity Timeout\n    Screenpipe->>Session Manager: Check for activity\n    Session Manager->>Database: End current session (App B, Window 2)\n```\n\n### 4.4. New API Endpoint (Modified /search)\n\nThe existing `/search` endpoint will be extended to support session-based queries.  No new endpoint is needed.\n\n## 5. Performance Implications\n\n*   **Database:**  The addition of the `sessions` table and foreign keys will add some overhead to write operations.  Proper indexing is crucial to mitigate this.  Read performance for session-based queries should be good with appropriate indexes.\n*   **Memory:**  The in-memory session tracking will require additional memory.  The size of this will depend on the number of concurrent users and the configured timeout.  This should be monitored and potentially optimized (e.g., using a more efficient data structure than a simple `HashMap`).\n*   **CPU:**  The session boundary detection logic will add some CPU overhead.  This should be minimized by efficient checks and the use of asynchronous operations.\n\n## 6. Migration Path\n\n1.  **Add new `sessions` table.**\n2.  **Add `session_id` columns** to `ocr_text`, `audio_transcriptions`, and `ui_monitoring` tables.\n3.  **Backfill `session_id`:**  A migration script will be needed to analyze existing data and create initial session records.  This script will need to:\n    *   Iterate through existing OCR, audio, and UI data in chronological order.\n    *   Apply the session boundary detection logic (described above) to group data into sessions.\n    *   Insert corresponding rows into the `sessions` table.\n    *   Update the `session_id` foreign key in the existing tables.\n\n\n## 7. Alternative Approaches\n\n1.  **Session Table per Content Type:** Instead of a single `sessions` table, we could have separate session tables for each content type (e.g., `ocr_sessions`, `audio_sessions`, `ui_sessions`).  This might simplify queries for a specific content type but could make cross-content type analysis more complex.\n2.  **No Session Table (Denormalized):** We could add `start_time` and `end_time` directly to the existing tables (`ocr_text`, `audio_transcriptions`, `ui_monitoring`). This would avoid the need for joins when querying for sessions, but could lead to data redundancy and potential inconsistencies.\n3.  any other suggestions ????\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1560"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1560",
              "body": "\n## Challenge\n\nI'm working on an application that requires accurate session tracking to analyze user behavior patterns,  and provide meaningful insights across different applications and windows. \n\nIn the existing Screenpipe architecture, OCR data is stored with only timestamp information, lacking precise session boundaries (start/end times) for application usage tracking. This limitation prevents us from properly segmenting user activity into coherent sessions.\n\n## 1. Current Workaround\ninternally I implementing a suboptimal solution that:\n1. Queries all OCR database entries chronologically\n2. Manually identifies session boundaries by analyzing timestamp sequences for each application\n3. Determines session end when detecting a different application in subsequent timestamps\n4. Assumes a session is ongoing if no clear delimiter exists in future timestamps\n\nWith that said I would love to hear any feedbacks that could help solve this problem with a minimal overhead on code changes, and make sure I'm not overthinking the solution: cc @louis030195 , i'm planning to start playing with some day next week\n\n## 2. Requirements\n\n1.  **Session Definition:** A \"session\" should be defined as a continuous period of user interaction with a specific application and window.  A break in activity (e.g., switching to a different application or window) should end the current session and potentially start a new one.  A configurable inactivity timeout (e.g., 5 minutes) should also end a session.\n\n2.  **Data Storage:** The database schema must be modified to store session start and end times, associated with specific applications and windows.  It must maintain links to the relevant OCR and audio data chunks.\n\n3.  **API Endpoint:**  A new or modified API endpoint (e.g., `/sessions`) is needed to query for session data.  This endpoint should support filtering by:\n    *   Date range (start and end timestamps).\n    *   Application name.\n    *   Window name.\n    *   Minimum and maximum session duration.\n    *   Associated tags.\n    *   Pagination (limit and offset).\n\n4.  **Real-time Capability:** The system should be able to detect session boundaries in near real-time as data is being ingested. This implies integration with the existing data capture and processing pipeline.\n\n5. **Configurability:** The inactivity timeout for ending a session should be configurable.\n\n## 3. Proposed Solution\n\n### 3.1. Database Schema Changes\n\nWe'll introduce a new table `sessions` and modify the existing tables.\n\n**New Table: `sessions`**\n\n| Column Name      | Data Type  | Constraints                                  | Description                                                                  |\n| :--------------- | :--------- | :------------------------------------------- | :--------------------------------------------------------------------------- |\n| `id`             | INTEGER    | PRIMARY KEY AUTOINCREMENT                    | Unique identifier for the session.                                       |\n| `app_name`       | TEXT       | NOT NULL                                     | Name of the application.                                                 |\n| `window_name`    | TEXT       |                                               | Title of the window.                                                     |\n| `start_time`     | DATETIME   | NOT NULL                                     | Timestamp of the session start.                                            |\n| `end_time`       | DATETIME   | NOT NULL                                     | Timestamp of the session end.                                              |\n| `duration_secs`  | REAL       | NOT NULL                                     | Duration of the session in seconds.                                        |\n\n**Modified Tables:**\n\n*   **`ocr_text`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`audio_transcriptions`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`ui_monitoring`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n\n**Indexes:**\n\n*   Create indexes on `sessions` table columns (`app_name`, `window_name`, `start_time`, `end_time`) for efficient querying.\n*   Create indexes on the `session_id` columns in `ocr_text`, `audio_transcriptions`, and `ui_monitoring`.\n\n### 3.2. API Enhancements\n\nWe'll modify the existing `/search` endpoint to also support session queries.\n\n**Request:**\n\n```\nGET /search?content_type=session&app_name=Cursor&start_time=2024-11-27T00:00:00Z&end_time=2024-11-28T00:00:00Z&min_duration=60&limit=10&offset=0\n```\n\n*   `content_type=session`: Indicates a session-based search.\n*   `app_name`, `window_name`: Filter by application and window (optional).\n*   `start_time`, `end_time`: Date range for the session (optional, defaults to last 24 hours).\n*   `min_duration`, `max_duration`: Filter by session duration in seconds (optional).\n*   `limit`, `offset`: Pagination parameters.\n\n\nafter discussing with @louis030195 on discord he proposed something like this as the output\n\n**Response:**\n\n```json\n{\n  \"data\": [\n    {\n      \"app_name\": \"Cursor\",\n      \"total_usage_time\": 3600,\n      \"windows\": [\n        {\n          \"window_name\": \"page.tsx\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T12:00:00Z\",\n              \"end_time\": \"2024-07-16T12:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [123, 124, 125],\n              \"tags\": [\"coding\", \"frontend\"]\n            },\n            {\n              \"start_time\": \"2024-07-16T14:00:00Z\",\n              \"end_time\": \"2024-07-16T14:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [223, 224, 225],\n              \"tags\": [\"coding\", \"frontend\"]\n            }\n          ],\n          \"total_usage_time\": 3600\n        }\n      ]\n    },\n    {\n      \"app_name\": \"Arc\",\n      \"total_usage_time\": 1200,\n      \"windows\": [\n        {\n          \"window_name\": \"x.com\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T10:30:00Z\",\n              \"end_time\": \"2024-07-16T10:50:00Z\",\n              \"duration\": 1200,\n              \"content_ids\": [126, 127, 128],\n              \"tags\": [\"browsing\", \"social-media\"]\n            }\n          ],\n          \"total_usage_time\": 1200\n        }\n      ]\n    }\n  ],\n  \"pagination\": {\n    \"limit\": 50,\n    \"offset\": 0,\n    \"total\": 2\n  }\n}\n```\n\n### 3.3. Session Boundary Detection Logic\n\n1.  **Real-time Monitoring:**  The existing event listeners for OCR, audio, and UI events will be leveraged.\n\n2.  **Session Tracking:**  Maintain a data structure (likely in memory, possibly augmented with periodic database writes for persistence) to track active sessions.  This structure should map:\n    *   `(app_name, window_name)` -> `(session_id, last_activity_timestamp)`\n\n3.  **New Event Handling:**\n    *   When a new event (OCR, audio, UI) arrives:\n        *   Extract `app_name` and `window_name`.\n        *   Check if an active session exists for this (app, window) combination.\n        *   If a session exists:\n            *   Check if `now() - last_activity_timestamp` exceeds the inactivity timeout.\n            *   If timeout exceeded, end the existing session and create a new one.\n            *   If not timed out, update `last_activity_timestamp` to the event's timestamp.\n        *   If no session exists:\n            *   Create a new session with `start_time` and `end_time` set to the event's timestamp.\n            *   Generate a new `session_id`.\n            *   Insert a new row into the `sessions` table.\n        *   Insert the new data (OCR, audio, UI) into the relevant table, linking it to the active `session_id`.\n\n4.  **Inactivity Timeout:** A configurable timeout (e.g., 5 minutes) will be used to determine session end due to inactivity.\n\n5.  **Periodic Flushing:** To avoid excessive in-memory state, periodically flush closed sessions (those that have exceeded the inactivity timeout) to the database.\n\n6. **Data Migration:** A migration script will be needed to analyze existing data and create initial session records based on timestamp proximity and app/window changes.\n\n### 3.4. Implementation Details\n\n*   **Language/Framework:** Continue using Rust for core logic and database interaction.\n*   **Database:** Continue using SQLite.\n*   **Concurrency:** Use asynchronous operations with `tokio` for handling concurrent events and database interactions.  Leverage `Arc` and `Mutex` for shared state, and channels for communication between tasks.\n*   **Configuration:** Add a new setting for the inactivity timeout.\n*   **Error Handling:** Implement robust error handling with `anyhow` and propagate errors appropriately. Log errors using `tracing`.\n* **Testing:** Thoroughly test session boundary detection with various scenarios, including rapid switching, long inactivity periods, and concurrent events.\n\n## 4. Diagrams\n\n### 4.1. Current Data Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Database\n    User->>Screen: Interacts with screen\n    Screen->>Screenpipe: Captures screen content (OCR)\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Database: Stores OCR data with timestamps\n    Screenpipe->>Database: Stores audio transcriptions with timestamps\n    User->>Screenpipe: Requests data\n    Screenpipe->>Database: Queries data by time range\n    Database->>Screenpipe: Returns data\n    Screenpipe->>User: Returns data\n```\n\n### 4.2. Proposed Database Schema Changes\n\n```mermaid\nclassDiagram\n    class frames {\n        +id : INTEGER [PK]\n        +video_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +name : TEXT\n    }\n    class video_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +device_name : TEXT\n    }\n    class ocr_text {\n        +frame_id : INTEGER [FK]\n        +text : TEXT\n        +text_json : TEXT\n        +app_name : TEXT\n        +window_name : TEXT\n        +ocr_engine : TEXT\n        +focused : BOOLEAN\n        +session_id : INTEGER [FK]\n    }\n    class audio_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +timestamp : TIMESTAMP\n    }\n    class audio_transcriptions {\n        +id : INTEGER [PK]\n        +audio_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +transcription : TEXT\n        +device : TEXT\n        +is_input_device : BOOLEAN\n        +speaker_id : INTEGER\n        +transcription_engine : TEXT\n        +start_time : REAL\n        +end_time : REAL\n        +text_length : INTEGER\n        +session_id : INTEGER [FK]\n    }\n    class ui_monitoring {\n      +id : INTEGER [PK]\n      +text_output : TEXT\n      +timestamp : DATETIME\n      +app : TEXT\n      +window : TEXT\n      +initial_traversal_at : DATETIME\n      +session_id : INTEGER [FK]\n    }\n  class sessions {\n    +id : INTEGER [PK]\n    +app_name : TEXT\n    +window_name : TEXT\n    +start_time : DATETIME\n    +end_time : DATETIME\n    +duration_secs : REAL\n  }\n  frames --|> video_chunks : video_chunk_id\n  ocr_text --|> frames : frame_id\n  audio_transcriptions --|> audio_chunks : audio_chunk_id\n  ocr_text --|> sessions : session_id\n  audio_transcriptions --|> sessions : session_id\n  ui_monitoring --|> sessions : session_id\n```\n\n### 4.3. Modified Data Flow with Session Tracking\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Session Manager\n    participant Database\n\n    User->>Screen: Interacts with App A, Window 1\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to session_id\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: Active session found (session_id)\n    Screenpipe->>Database: Store audio data, link to session_id\n\n    Note over User,Screenpipe: User switches to App B, Window 2\n    User->>Screen: Interacts with App B, Window 2\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App B, Window 2)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: End previous session (App A, Window 1)\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to new session_id\n\n    Note over User,Screenpipe: Inactivity Timeout\n    Screenpipe->>Session Manager: Check for activity\n    Session Manager->>Database: End current session (App B, Window 2)\n```\n\n### 4.4. New API Endpoint (Modified /search)\n\nThe existing `/search` endpoint will be extended to support session-based queries.  No new endpoint is needed.\n\n## 5. Performance Implications\n\n*   **Database:**  The addition of the `sessions` table and foreign keys will add some overhead to write operations.  Proper indexing is crucial to mitigate this.  Read performance for session-based queries should be good with appropriate indexes.\n*   **Memory:**  The in-memory session tracking will require additional memory.  The size of this will depend on the number of concurrent users and the configured timeout.  This should be monitored and potentially optimized (e.g., using a more efficient data structure than a simple `HashMap`).\n*   **CPU:**  The session boundary detection logic will add some CPU overhead.  This should be minimized by efficient checks and the use of asynchronous operations.\n\n## 6. Migration Path\n\n1.  **Add new `sessions` table.**\n2.  **Add `session_id` columns** to `ocr_text`, `audio_transcriptions`, and `ui_monitoring` tables.\n3.  **Backfill `session_id`:**  A migration script will be needed to analyze existing data and create initial session records.  This script will need to:\n    *   Iterate through existing OCR, audio, and UI data in chronological order.\n    *   Apply the session boundary detection logic (described above) to group data into sessions.\n    *   Insert corresponding rows into the `sessions` table.\n    *   Update the `session_id` foreign key in the existing tables.\n\n\n## 7. Alternative Approaches\n\n1.  **Session Table per Content Type:** Instead of a single `sessions` table, we could have separate session tables for each content type (e.g., `ocr_sessions`, `audio_sessions`, `ui_sessions`).  This might simplify queries for a specific content type but could make cross-content type analysis more complex.\n2.  **No Session Table (Denormalized):** We could add `start_time` and `end_time` directly to the existing tables (`ocr_text`, `audio_transcriptions`, `ui_monitoring`). This would avoid the need for joins when querying for sessions, but could lead to data redundancy and potential inconsistencies.\n3.  any other suggestions ????\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1560",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1441",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-09T10:35:19.952Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:19.952Z",
            "created_at": "2025-11-09T10:35:19.952Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1441",
              "status": "open",
              "type": "issue",
              "number": 1441,
              "title": "[bounty] general purpose scrapper",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1441",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] general purpose scrapper",
                  "body": "\nv0\n\nshould be able to scrap whatsapp\n\nideally you can use the keyboard / mouse api \n\nhttps://docs.screenpi.pe/docs/sdk-reference#input-control-api\n\n\nbasically many ppl would like to scrap data from desktop app and it's hard, like whatsapp, imessage, or even web but without getting banned or because it's local authentication is already done by user usually and stays local, and much less likely detected \n\n\n\n/bounty 200\n\nplease suggest how you would implement a very simple first version that work for whatsapp and UX\n\n\n\n\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1441"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1441",
              "body": "\nv0\n\nshould be able to scrap whatsapp\n\nideally you can use the keyboard / mouse api \n\nhttps://docs.screenpi.pe/docs/sdk-reference#input-control-api\n\n\nbasically many ppl would like to scrap data from desktop app and it's hard, like whatsapp, imessage, or even web but without getting banned or because it's local authentication is already done by user usually and stays local, and much less likely detected \n\n\n\n/bounty 200\n\nplease suggest how you would implement a very simple first version that work for whatsapp and UX\n\n\n\n\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1441",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1298",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-09T10:35:20.076Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:20.076Z",
            "created_at": "2025-11-09T10:35:20.076Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1298",
              "status": "open",
              "type": "issue",
              "number": 1298,
              "title": "[docs] document env var somewhere somehow ",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1298",
                  "user": {
                    "login": "dassio",
                    "id": 733502,
                    "node_id": "MDQ6VXNlcjczMzUwMg==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/733502?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/dassio",
                    "html_url": "https://github.com/dassio",
                    "followers_url": "https://api.github.com/users/dassio/followers",
                    "following_url": "https://api.github.com/users/dassio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/dassio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/dassio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/dassio/subscriptions",
                    "organizations_url": "https://api.github.com/users/dassio/orgs",
                    "repos_url": "https://api.github.com/users/dassio/repos",
                    "events_url": "https://api.github.com/users/dassio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/dassio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[docs] document env var somewhere somehow ",
                  "body": "**describe the feature**\nin the desktop app, you can configure hugging face mirror, but for the screenpipe server cli ,there is no such option , when try to use whisper for audio transcription, need to download mode from hugging face \n\n**why is this needed?**\nhugging face is banned in China\n\n\n**additional context**\n```\nyou are using local processing. all your data stays on your computer.\n\nwarning: telemetry is enabled. only error-level data will be sent to highlight.io.\nto disable, use the --disable-telemetry flag.\n\ncheck latest changes here: https://github.com/mediar-ai/screenpipe/releases\n2025-02-07T14:15:37.861529Z  INFO screenpipe: starting pipes\nfailed to start pipe timeline: No pipe.js/pipe.ts found in the pipe/dist directory\n2025-02-07T14:15:37.864597Z  INFO screenpipe_server::server: Server starting on 127.0.0.1:3030\n2025-02-07T14:15:45.839709Z  INFO screenpipe_server::video: Starting FFmpeg process for file: C:\\Users\\dassi\\.screenpipe\\data\\monitor_490607759_2025-02-07_14-15-45.mp4\n2025-02-07T14:15:48.283937Z  INFO screenpipe_server::resource_monitor: Runtime: 10s, Total Memory: 2% (0.25 GB / 16.09 GB), Total CPU: 88%\n2025-02-07T14:15:58.322953Z  INFO screenpipe_server::resource_monitor: Runtime: 20s, Total Memory: 2% (0.26 GB / 16.09 GB), Total CPU: 92%\n2025-02-07T14:16:00.374953Z ERROR screenpipe: continuous recording error: request error: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n\nCaused by:\n    0: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n    1: connection timed out\n```\n\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1298"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1298",
              "body": "**describe the feature**\nin the desktop app, you can configure hugging face mirror, but for the screenpipe server cli ,there is no such option , when try to use whisper for audio transcription, need to download mode from hugging face \n\n**why is this needed?**\nhugging face is banned in China\n\n\n**additional context**\n```\nyou are using local processing. all your data stays on your computer.\n\nwarning: telemetry is enabled. only error-level data will be sent to highlight.io.\nto disable, use the --disable-telemetry flag.\n\ncheck latest changes here: https://github.com/mediar-ai/screenpipe/releases\n2025-02-07T14:15:37.861529Z  INFO screenpipe: starting pipes\nfailed to start pipe timeline: No pipe.js/pipe.ts found in the pipe/dist directory\n2025-02-07T14:15:37.864597Z  INFO screenpipe_server::server: Server starting on 127.0.0.1:3030\n2025-02-07T14:15:45.839709Z  INFO screenpipe_server::video: Starting FFmpeg process for file: C:\\Users\\dassi\\.screenpipe\\data\\monitor_490607759_2025-02-07_14-15-45.mp4\n2025-02-07T14:15:48.283937Z  INFO screenpipe_server::resource_monitor: Runtime: 10s, Total Memory: 2% (0.25 GB / 16.09 GB), Total CPU: 88%\n2025-02-07T14:15:58.322953Z  INFO screenpipe_server::resource_monitor: Runtime: 20s, Total Memory: 2% (0.26 GB / 16.09 GB), Total CPU: 92%\n2025-02-07T14:16:00.374953Z ERROR screenpipe: continuous recording error: request error: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n\nCaused by:\n    0: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n    1: connection timed out\n```\n\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1298",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1383",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-09T10:35:20.228Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:20.228Z",
            "created_at": "2025-11-09T10:35:20.228Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1383",
              "status": "open",
              "type": "issue",
              "number": 1383,
              "title": "[bounty] implement deep research in search pipe",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1383",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] implement deep research in search pipe",
                  "body": "\n\ni love perplexity deep research \n\ni think we should have something like this in screenpipe search, which would be something that go beyond surface level, really in depth on your data \n\nnot sure about the UX yet, suggest any design first \n\nshould allow async (eg ask something and come back later to it, stored in some kind of history, maybe related to #1382 check perplexity UI too)\n\n/bounty 200 \n\n\n\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1383"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1383",
              "body": "\n\ni love perplexity deep research \n\ni think we should have something like this in screenpipe search, which would be something that go beyond surface level, really in depth on your data \n\nnot sure about the UX yet, suggest any design first \n\nshould allow async (eg ask something and come back later to it, stored in some kind of history, maybe related to #1382 check perplexity UI too)\n\n/bounty 200 \n\n\n\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1383",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1382",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-09T10:35:20.366Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:20.366Z",
            "created_at": "2025-11-09T10:35:20.366Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1382",
              "status": "open",
              "type": "issue",
              "number": 1382,
              "title": "[bounty] implement history for search pipe",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1382",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] implement history for search pipe",
                  "body": "like chatgpt history a bit \n\nwe had this but did not work well\n\ncheck shadcn sidebar and stuff \n\n\n/bounty 100 ",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1382"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1382",
              "body": "like chatgpt history a bit \n\nwe had this but did not work well\n\ncheck shadcn sidebar and stuff \n\n\n/bounty 100 ",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1382",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1380",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-09T10:35:20.496Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:20.496Z",
            "created_at": "2025-11-09T10:35:20.496Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1380",
              "status": "open",
              "type": "issue",
              "number": 1380,
              "title": "[bounty] implement device control and make --use-all-monitors work",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1380",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] implement device control and make --use-all-monitors work",
                  "body": "\nthis feature is useful to improve the experience for:\n1. people switching audio device and monitor devices regularly (commuting for work etc.) (e.g. `--use-all-monitors` argument to always record all monitors for example)\n2. privacy preserving use cases \n3. control resource usage dynamically \n4. other use cases\n\ndefinition of done:\n- `--use-all-monitors` always record all monitor available, and stop recording when it's unplugged \n- running screenpipe for 3 days, while having meetings, working, etc. and the memory stays under 2.5 gb, and CPU roughly the same (10-30% on my mac book pro m4 max)\n- /vision/start, /vision/stop, /vision/list\n\nmake this work reliably and prove it's not memory leaking \n\n\n\n/bounty 400 \n\n\n\nbonus bounty:\n- `--use-all-default-audio-devices` always record all default audio devices\n- very good tests, good benchmarks of memory over time somehow, idk\n\n\n\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1380"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1380",
              "body": "\nthis feature is useful to improve the experience for:\n1. people switching audio device and monitor devices regularly (commuting for work etc.) (e.g. `--use-all-monitors` argument to always record all monitors for example)\n2. privacy preserving use cases \n3. control resource usage dynamically \n4. other use cases\n\ndefinition of done:\n- `--use-all-monitors` always record all monitor available, and stop recording when it's unplugged \n- running screenpipe for 3 days, while having meetings, working, etc. and the memory stays under 2.5 gb, and CPU roughly the same (10-30% on my mac book pro m4 max)\n- /vision/start, /vision/stop, /vision/list\n\nmake this work reliably and prove it's not memory leaking \n\n\n\n/bounty 400 \n\n\n\nbonus bounty:\n- `--use-all-default-audio-devices` always record all default audio devices\n- very good tests, good benchmarks of memory over time somehow, idk\n\n\n\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1380",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1160",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-09T10:35:20.629Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:20.629Z",
            "created_at": "2025-11-09T10:35:20.629Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1160",
              "status": "open",
              "type": "issue",
              "number": 1160,
              "title": "[bounty] list webcam, iphone, etc. in list-monitors",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1160",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] list webcam, iphone, etc. in list-monitors",
                  "body": "we should be able to record webcam, iphone cameras, etc. easily in the same way than monitor device\n\n```\nlouisbeaumont@MacBook-Pro-9:~/Documents/brain$ ffmpeg -f avfoundation -list_devices true -i \"\"\nffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers\n  built with Apple clang version 16.0.0 (clang-1600.0.26.4)\n  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n  libavutil      59. 39.100 / 59. 39.100\n  libavcodec     61. 19.100 / 61. 19.100\n  libavformat    61.  7.100 / 61.  7.100\n  libavdevice    61.  3.100 / 61.  3.100\n  libavfilter    10.  4.100 / 10.  4.100\n  libswscale      8.  3.100 /  8.  3.100\n  libswresample   5.  3.100 /  5.  3.100\n  libpostproc    58.  3.100 / 58.  3.100\n2025-01-16 09:03:00.993 ffmpeg[23450:7179261] WARNING: Add NSCameraUseContinuityCameraDeviceType to your Info.plist to use AVCaptureDeviceTypeContinuityCamera.\n2025-01-16 09:03:01.177 ffmpeg[23450:7179261] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n[AVFoundation indev @ 0x1426314d0] AVFoundation video devices:\n[AVFoundation indev @ 0x1426314d0] [0] MacBook Pro Camera\n[AVFoundation indev @ 0x1426314d0] [1] louisbeaumont.me iphone Camera\n[AVFoundation indev @ 0x1426314d0] [2] louisbeaumont.me iphone Desk View Camera\n[AVFoundation indev @ 0x1426314d0] [3] MacBook Pro Desk View Camera\n[AVFoundation indev @ 0x1426314d0] [4] louisbeaumont.me iphone Desk View Camera\n[AVFoundation indev @ 0x1426314d0] [5] louisbeaumont.me iphone Camera\n[AVFoundation indev @ 0x1426314d0] [6] Capture screen 0\n[AVFoundation indev @ 0x1426314d0] AVFoundation audio devices:\n[AVFoundation indev @ 0x1426314d0] [0] louisbeaumont.me iphone Microphone\n[AVFoundation indev @ 0x1426314d0] [1] Immersed\n[AVFoundation indev @ 0x1426314d0] [2] BlackHole 2ch\n[AVFoundation indev @ 0x1426314d0] [3] louisbeaumont.me iphone Microphone\n[AVFoundation indev @ 0x1426314d0] [4] MacBook Pro Microphone\n[AVFoundation indev @ 0x1426314d0] [5] BlackHole 16ch\n[AVFoundation indev @ 0x1426314d0] [6] Aggregate Device\n[AVFoundation indev @ 0x1426314d0] [7] input\n[AVFoundation indev @ 0x1426314d0] [8] EpocCam Microphone\n[in#0 @ 0x142630ef0] Error opening input: Input/output error\nError opening input file .\nError opening input files: Input/output error\nlouisbeaumont@MacBook-Pro-9:~/Documents/brain$ \n```\n\n/bounty 120",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1160"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1160",
              "body": "we should be able to record webcam, iphone cameras, etc. easily in the same way than monitor device\n\n```\nlouisbeaumont@MacBook-Pro-9:~/Documents/brain$ ffmpeg -f avfoundation -list_devices true -i \"\"\nffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers\n  built with Apple clang version 16.0.0 (clang-1600.0.26.4)\n  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n  libavutil      59. 39.100 / 59. 39.100\n  libavcodec     61. 19.100 / 61. 19.100\n  libavformat    61.  7.100 / 61.  7.100\n  libavdevice    61.  3.100 / 61.  3.100\n  libavfilter    10.  4.100 / 10.  4.100\n  libswscale      8.  3.100 /  8.  3.100\n  libswresample   5.  3.100 /  5.  3.100\n  libpostproc    58.  3.100 / 58.  3.100\n2025-01-16 09:03:00.993 ffmpeg[23450:7179261] WARNING: Add NSCameraUseContinuityCameraDeviceType to your Info.plist to use AVCaptureDeviceTypeContinuityCamera.\n2025-01-16 09:03:01.177 ffmpeg[23450:7179261] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n[AVFoundation indev @ 0x1426314d0] AVFoundation video devices:\n[AVFoundation indev @ 0x1426314d0] [0] MacBook Pro Camera\n[AVFoundation indev @ 0x1426314d0] [1] louisbeaumont.me iphone Camera\n[AVFoundation indev @ 0x1426314d0] [2] louisbeaumont.me iphone Desk View Camera\n[AVFoundation indev @ 0x1426314d0] [3] MacBook Pro Desk View Camera\n[AVFoundation indev @ 0x1426314d0] [4] louisbeaumont.me iphone Desk View Camera\n[AVFoundation indev @ 0x1426314d0] [5] louisbeaumont.me iphone Camera\n[AVFoundation indev @ 0x1426314d0] [6] Capture screen 0\n[AVFoundation indev @ 0x1426314d0] AVFoundation audio devices:\n[AVFoundation indev @ 0x1426314d0] [0] louisbeaumont.me iphone Microphone\n[AVFoundation indev @ 0x1426314d0] [1] Immersed\n[AVFoundation indev @ 0x1426314d0] [2] BlackHole 2ch\n[AVFoundation indev @ 0x1426314d0] [3] louisbeaumont.me iphone Microphone\n[AVFoundation indev @ 0x1426314d0] [4] MacBook Pro Microphone\n[AVFoundation indev @ 0x1426314d0] [5] BlackHole 16ch\n[AVFoundation indev @ 0x1426314d0] [6] Aggregate Device\n[AVFoundation indev @ 0x1426314d0] [7] input\n[AVFoundation indev @ 0x1426314d0] [8] EpocCam Microphone\n[in#0 @ 0x142630ef0] Error opening input: Input/output error\nError opening input file .\nError opening input files: Input/output error\nlouisbeaumont@MacBook-Pro-9:~/Documents/brain$ \n```\n\n/bounty 120",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1160",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1142",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-09T10:35:20.740Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:20.740Z",
            "created_at": "2025-11-09T10:35:20.740Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1142",
              "status": "open",
              "type": "issue",
              "number": 1142,
              "title": "[bounty] support for video and voice LLM in search, timeline, meeting",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1142",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] support for video and voice LLM in search, timeline, meeting",
                  "body": "likely need to break down in multiple bounties\r\n\r\n\r\n\r\n\r\n/bounty 400 \r\n\r\n\r\neg\r\n- meeting: use voice LLM to transcribe or summarize audio would increase a lot quality - 10x better than granola etc\r\n- search: use video LLM would be much more powerful and different context windows \r\n- timeline: same\r\n\r\n\r\nsuggest rough design, might create other issues \r\n\r\n\r\n\r\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1142"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1142",
              "body": "likely need to break down in multiple bounties\r\n\r\n\r\n\r\n\r\n/bounty 400 \r\n\r\n\r\neg\r\n- meeting: use voice LLM to transcribe or summarize audio would increase a lot quality - 10x better than granola etc\r\n- search: use video LLM would be much more powerful and different context windows \r\n- timeline: same\r\n\r\n\r\nsuggest rough design, might create other issues \r\n\r\n\r\n\r\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1142",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#3697",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2025-11-09T10:35:19.560Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:19.560Z",
            "created_at": "2025-11-09T10:35:19.560Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#3697",
              "status": "open",
              "type": "issue",
              "number": 3697,
              "title": "Datastar requests from Endpoint",
              "source": {
                "data": {
                  "id": "source-zio#3697",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Datastar requests from Endpoint",
                  "body": "Build Datastar expressions for request against an Endpoint from its definition\n",
                  "html_url": "https://github.com/zio/zio-http/issues/3697"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3697",
              "body": "Build Datastar expressions for request against an Endpoint from its definition\n",
              "url": "https://github.com/zio/zio-http/issues/3697",
              "tech": [
                "go"
              ],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#709",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2025-11-09T10:35:19.676Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:19.676Z",
            "created_at": "2025-11-09T10:35:19.676Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#709",
              "status": "open",
              "type": "issue",
              "number": 709,
              "title": "Support Http Range header on request for Files",
              "source": {
                "data": {
                  "id": "source-zio#709",
                  "user": {
                    "login": "ashprakasan",
                    "id": 8946971,
                    "node_id": "MDQ6VXNlcjg5NDY5NzE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/8946971?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ashprakasan",
                    "html_url": "https://github.com/ashprakasan",
                    "followers_url": "https://api.github.com/users/ashprakasan/followers",
                    "following_url": "https://api.github.com/users/ashprakasan/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ashprakasan/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ashprakasan/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ashprakasan/subscriptions",
                    "organizations_url": "https://api.github.com/users/ashprakasan/orgs",
                    "repos_url": "https://api.github.com/users/ashprakasan/repos",
                    "events_url": "https://api.github.com/users/ashprakasan/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ashprakasan/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Support Http Range header on request for Files",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe Range HTTP request header indicates the part of a document that the server should return. Several parts can be requested with one Range header at once, and the server may send back these ranges in a multipart document.\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample requesting 3 ranges from files -\r\n`Range: bytes=200-1000, 2000-6576, 19000-`\r\n\r\nSend only those parts of the document in Response.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCurrently, the range is hardcoded as follows - \r\n` ctx.write(new DefaultFileRegion(raf.getChannel, 0, fileLength))`\r\nManipulate the positions as per request headers instead.\r\n\r\n**Additional context**\r\n\r\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Range\r\n",
                  "html_url": "https://github.com/zio/zio-http/issues/709"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#709",
              "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe Range HTTP request header indicates the part of a document that the server should return. Several parts can be requested with one Range header at once, and the server may send back these ranges in a multipart document.\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample requesting 3 ranges from files -\r\n`Range: bytes=200-1000, 2000-6576, 19000-`\r\n\r\nSend only those parts of the document in Response.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCurrently, the range is hardcoded as follows - \r\n` ctx.write(new DefaultFileRegion(raf.getChannel, 0, fileLength))`\r\nManipulate the positions as per request headers instead.\r\n\r\n**Additional context**\r\n\r\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Range\r\n",
              "url": "https://github.com/zio/zio-http/issues/709",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#595",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2025-11-09T10:35:19.896Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:19.896Z",
            "created_at": "2025-11-09T10:35:19.896Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#595",
              "status": "open",
              "type": "issue",
              "number": 595,
              "title": "STOMP support",
              "source": {
                "data": {
                  "id": "source-zio#595",
                  "user": {
                    "login": "octavz",
                    "id": 23629302,
                    "node_id": "MDQ6VXNlcjIzNjI5MzAy",
                    "avatar_url": "https://avatars.githubusercontent.com/u/23629302?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/octavz",
                    "html_url": "https://github.com/octavz",
                    "followers_url": "https://api.github.com/users/octavz/followers",
                    "following_url": "https://api.github.com/users/octavz/following{/other_user}",
                    "gists_url": "https://api.github.com/users/octavz/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/octavz/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/octavz/subscriptions",
                    "organizations_url": "https://api.github.com/users/octavz/orgs",
                    "repos_url": "https://api.github.com/users/octavz/repos",
                    "events_url": "https://api.github.com/users/octavz/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/octavz/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "STOMP support",
                  "body": "Would be nice to support STOMP, probably not a priority for authors, but I thought about adding it, perhaps someone can contribute.\r\n\r\nNetty already implements support for STOMP,  `zio-http` should \"decode/encode\" frames as proper \"Stomp\" and add a typed API to work with it. \r\n\r\nThanks",
                  "html_url": "https://github.com/zio/zio-http/issues/595"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#595",
              "body": "Would be nice to support STOMP, probably not a priority for authors, but I thought about adding it, perhaps someone can contribute.\r\n\r\nNetty already implements support for STOMP,  `zio-http` should \"decode/encode\" frames as proper \"Stomp\" and add a typed API to work with it. \r\n\r\nThanks",
              "url": "https://github.com/zio/zio-http/issues/595",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#3645",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2025-11-09T10:35:20.037Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:20.037Z",
            "created_at": "2025-11-09T10:35:20.037Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#3645",
              "status": "open",
              "type": "issue",
              "number": 3645,
              "title": "Default 404 page with available routes for dev mode",
              "source": {
                "data": {
                  "id": "source-zio#3645",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Default 404 page with available routes for dev mode",
                  "body": "Depends on dev mode being implemented \n",
                  "html_url": "https://github.com/zio/zio-http/issues/3645"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3645",
              "body": "Depends on dev mode being implemented \n",
              "url": "https://github.com/zio/zio-http/issues/3645",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#3472",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2025-11-09T10:35:20.164Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:20.164Z",
            "created_at": "2025-11-09T10:35:20.164Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#3472",
              "status": "open",
              "type": "issue",
              "number": 3472,
              "title": "Split into multiple modules",
              "source": {
                "data": {
                  "id": "source-zio#3472",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Split into multiple modules",
                  "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
                  "html_url": "https://github.com/zio/zio-http/issues/3472"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3472",
              "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
              "url": "https://github.com/zio/zio-http/issues/3472",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#9810",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2025-11-09T10:35:20.278Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:20.278Z",
            "created_at": "2025-11-09T10:35:20.278Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#9810",
              "status": "open",
              "type": "issue",
              "number": 9810,
              "title": "ZStreams buffer(1) is buffering 2.",
              "source": {
                "data": {
                  "id": "source-zio#9810",
                  "user": {
                    "login": "douglasthomsen",
                    "id": 88000378,
                    "node_id": "MDQ6VXNlcjg4MDAwMzc4",
                    "avatar_url": "https://avatars.githubusercontent.com/u/88000378?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/douglasthomsen",
                    "html_url": "https://github.com/douglasthomsen",
                    "followers_url": "https://api.github.com/users/douglasthomsen/followers",
                    "following_url": "https://api.github.com/users/douglasthomsen/following{/other_user}",
                    "gists_url": "https://api.github.com/users/douglasthomsen/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/douglasthomsen/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/douglasthomsen/subscriptions",
                    "organizations_url": "https://api.github.com/users/douglasthomsen/orgs",
                    "repos_url": "https://api.github.com/users/douglasthomsen/repos",
                    "events_url": "https://api.github.com/users/douglasthomsen/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/douglasthomsen/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZStreams buffer(1) is buffering 2.",
                  "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
                  "html_url": "https://github.com/zio/zio/issues/9810"
                },
                "type": "github"
              },
              "hash": "zio/zio#9810",
              "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
              "url": "https://github.com/zio/zio/issues/9810",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#9844",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2025-11-09T10:35:20.392Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:20.392Z",
            "created_at": "2025-11-09T10:35:20.392Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#9844",
              "status": "open",
              "type": "issue",
              "number": 9844,
              "title": "improved `Queue` shutdown functionality",
              "source": {
                "data": {
                  "id": "source-zio#9844",
                  "user": {
                    "login": "mberndt123",
                    "id": 11650737,
                    "node_id": "MDQ6VXNlcjExNjUwNzM3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/11650737?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/mberndt123",
                    "html_url": "https://github.com/mberndt123",
                    "followers_url": "https://api.github.com/users/mberndt123/followers",
                    "following_url": "https://api.github.com/users/mberndt123/following{/other_user}",
                    "gists_url": "https://api.github.com/users/mberndt123/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/mberndt123/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/mberndt123/subscriptions",
                    "organizations_url": "https://api.github.com/users/mberndt123/orgs",
                    "repos_url": "https://api.github.com/users/mberndt123/repos",
                    "events_url": "https://api.github.com/users/mberndt123/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/mberndt123/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "improved `Queue` shutdown functionality",
                  "body": "Hey, I've recently proposed something on Discord, and since feedback has been rather positive, I'm making a ticket to track the idea.\n\nI've been working with Queues recently, and I've been having some issues around `shutdown` that I would like to address.\n\nSpecifically, I find it a common pattern that I send some kind of request object through a queue because I want another fiber to perform some action on my behalf. Along with the request, I send a `Promise` to have that fiber communicate the outcome of that action to me. By and large this works fine. The issue arises when the fiber that I'm sending requests to fails. In that case, I would like it to communicate the cause of the failure back to the other fibers. This is easy enough for the requests that I've already pulled out of the queue: I simply fail those promises.\nBut I also need to deal with other cases: fibers currently blocked in an `offer` call, future attempts to `offer` to the queue, and I also need to deal with requests that have been submitted to the queue but not yet retrieved.\n\nSo my idea is as follows:\n - add an `E` type parameter to `Queue`\n - add a `shutdownCause` method that takes a type parameter of type `Cause[E]`\n - `shutdownCause` would also return the items currently buffered in the queue in order to dispose of them\n - after `shutdownCause` has been called, any attempt to interact with the queue will fail with the cause\n - methods like `take, offer` etc. should indicate errors of type `E`\n - streams created with `ZStream.fromQueue` would also fail with this cause\n - `shutdownCause` should be atomic: when multiple fibers call it at the same time, one of them wins and the others fail with the cause supplied by the winner\n\nAfaik, adding a new method is a binary compatible change, as is adding a new type parameter. Hence I think this is a source incompatible but binary compatible change. @ghostdogpr therefore suggested it could be added in a ZIO 2.2 release.\n",
                  "html_url": "https://github.com/zio/zio/issues/9844"
                },
                "type": "github"
              },
              "hash": "zio/zio#9844",
              "body": "Hey, I've recently proposed something on Discord, and since feedback has been rather positive, I'm making a ticket to track the idea.\n\nI've been working with Queues recently, and I've been having some issues around `shutdown` that I would like to address.\n\nSpecifically, I find it a common pattern that I send some kind of request object through a queue because I want another fiber to perform some action on my behalf. Along with the request, I send a `Promise` to have that fiber communicate the outcome of that action to me. By and large this works fine. The issue arises when the fiber that I'm sending requests to fails. In that case, I would like it to communicate the cause of the failure back to the other fibers. This is easy enough for the requests that I've already pulled out of the queue: I simply fail those promises.\nBut I also need to deal with other cases: fibers currently blocked in an `offer` call, future attempts to `offer` to the queue, and I also need to deal with requests that have been submitted to the queue but not yet retrieved.\n\nSo my idea is as follows:\n - add an `E` type parameter to `Queue`\n - add a `shutdownCause` method that takes a type parameter of type `Cause[E]`\n - `shutdownCause` would also return the items currently buffered in the queue in order to dispose of them\n - after `shutdownCause` has been called, any attempt to interact with the queue will fail with the cause\n - methods like `take, offer` etc. should indicate errors of type `E`\n - streams created with `ZStream.fromQueue` would also fail with this cause\n - `shutdownCause` should be atomic: when multiple fibers call it at the same time, one of them wins and the others fail with the cause supplied by the winner\n\nAfaik, adding a new method is a binary compatible change, as is adding a new type parameter. Hence I think this is a source incompatible but binary compatible change. @ghostdogpr therefore suggested it could be added in a ZIO 2.2 release.\n",
              "url": "https://github.com/zio/zio/issues/9844",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#9878",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2025-11-09T10:35:20.530Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:20.530Z",
            "created_at": "2025-11-09T10:35:20.530Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#9878",
              "status": "open",
              "type": "issue",
              "number": 9878,
              "title": "ZScheduler parks+unparks workers too frequently",
              "source": {
                "data": {
                  "id": "source-zio#9878",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZScheduler parks+unparks workers too frequently",
                  "body": "Unparking workers is slow and invoked in the hotpath too often. I think we may need to trade some fairness for aggression to avoid excessive cycling.\n\n`maybeUnparkWorker` (obviously `LockSupport.unpark(worker)`) is very expensive: https://github.com/zio/zio/blob/series/2.x/core/jvm-native/src/main/scala/zio/internal/ZScheduler.scala#L443-L454",
                  "html_url": "https://github.com/zio/zio/issues/9878"
                },
                "type": "github"
              },
              "hash": "zio/zio#9878",
              "body": "Unparking workers is slow and invoked in the hotpath too often. I think we may need to trade some fairness for aggression to avoid excessive cycling.\n\n`maybeUnparkWorker` (obviously `LockSupport.unpark(worker)`) is very expensive: https://github.com/zio/zio/blob/series/2.x/core/jvm-native/src/main/scala/zio/internal/ZScheduler.scala#L443-L454",
              "url": "https://github.com/zio/zio/issues/9878",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#9877",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2025-11-09T10:35:20.671Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:20.671Z",
            "created_at": "2025-11-09T10:35:20.671Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#9877",
              "status": "open",
              "type": "issue",
              "number": 9877,
              "title": "Can Fiber(Runtime) and Promise be merged?",
              "source": {
                "data": {
                  "id": "source-zio#9877",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Can Fiber(Runtime) and Promise be merged?",
                  "body": "A Promise awaiting completion is essentially a Fiber parked awaiting an async callback. When a Fiber is forking work (which will eventually complete a promise), then awaiting a Promise, we end up with unnecessary allocations + indirection.\n\nit would be useful to have `Promise.become` or similar to link fibers/promises.",
                  "html_url": "https://github.com/zio/zio/issues/9877"
                },
                "type": "github"
              },
              "hash": "zio/zio#9877",
              "body": "A Promise awaiting completion is essentially a Fiber parked awaiting an async callback. When a Fiber is forking work (which will eventually complete a promise), then awaiting a Promise, we end up with unnecessary allocations + indirection.\n\nit would be useful to have `Promise.become` or similar to link fibers/promises.",
              "url": "https://github.com/zio/zio/issues/9877",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#9874",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2025-11-09T10:35:20.821Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T10:35:20.821Z",
            "created_at": "2025-11-09T10:35:20.821Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#9874",
              "status": "open",
              "type": "issue",
              "number": 9874,
              "title": "Handling errors allows recovering from defects",
              "source": {
                "data": {
                  "id": "source-zio#9874",
                  "user": {
                    "login": "kyri-petrou",
                    "id": 67301607,
                    "node_id": "MDQ6VXNlcjY3MzAxNjA3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/67301607?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kyri-petrou",
                    "html_url": "https://github.com/kyri-petrou",
                    "followers_url": "https://api.github.com/users/kyri-petrou/followers",
                    "following_url": "https://api.github.com/users/kyri-petrou/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kyri-petrou/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kyri-petrou/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kyri-petrou/subscriptions",
                    "organizations_url": "https://api.github.com/users/kyri-petrou/orgs",
                    "repos_url": "https://api.github.com/users/kyri-petrou/repos",
                    "events_url": "https://api.github.com/users/kyri-petrou/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kyri-petrou/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Handling errors allows recovering from defects",
                  "body": "Sigh... Well, this is annoying. When a Cause contains both a failure and a defect (i.e., Fail & Die), failure handling assumes that the Cause does not contain any defects and therefor silently ignores them.\n\nRepro:\n\n```scala\nimport zio.*\n\nobject Foo extends ZIOAppDefault {\n  val dieCause: Cause[String] = Cause.die(new RuntimeException(\"boom\"))\n  val combinedCause = dieCause && Cause.fail(\"boom\")\n\n  def run = ZIO.failCause(combinedCause).catchAll { e =>\n    ZIO.debug(e)\n  } *> ZIO.debug(\"Success\")\n}\n```\nprints:\n```\nhandled: boom\nSuccess\n```\n\nHowever if we substituted `ZIO.failCause(combinedCause)` with `ZIO.failCause(dieCause)`:\n\n```\ntimestamp=2025-05-20T16:31:09.291104Z level=ERROR thread=#zio-fiber-1707930317 message=\"\" cause=\"java.lang.RuntimeException: boom\n\tat Foo$.<clinit>(Foo.scala:4)\n\tat Foo.main(Foo.scala)\n\tat <empty>.Foo.run(Foo.scala:7)\n\tat <empty>.Foo.run(Foo.scala:9)\n\"\n```\n\nWith both of these causes, the outcome should be the same as defects should always be prioritised over failures. This gets even worse when interruption is involved, because the failure handling will be prioritised over it.\n\nHaving said that, this has the potential to massively alter applications so I'm too scared to fix it.\n@ghostdogpr @jdegoes  @hearnadam @guizmaii I summon you all for some wisdom",
                  "html_url": "https://github.com/zio/zio/issues/9874"
                },
                "type": "github"
              },
              "hash": "zio/zio#9874",
              "body": "Sigh... Well, this is annoying. When a Cause contains both a failure and a defect (i.e., Fail & Die), failure handling assumes that the Cause does not contain any defects and therefor silently ignores them.\n\nRepro:\n\n```scala\nimport zio.*\n\nobject Foo extends ZIOAppDefault {\n  val dieCause: Cause[String] = Cause.die(new RuntimeException(\"boom\"))\n  val combinedCause = dieCause && Cause.fail(\"boom\")\n\n  def run = ZIO.failCause(combinedCause).catchAll { e =>\n    ZIO.debug(e)\n  } *> ZIO.debug(\"Success\")\n}\n```\nprints:\n```\nhandled: boom\nSuccess\n```\n\nHowever if we substituted `ZIO.failCause(combinedCause)` with `ZIO.failCause(dieCause)`:\n\n```\ntimestamp=2025-05-20T16:31:09.291104Z level=ERROR thread=#zio-fiber-1707930317 message=\"\" cause=\"java.lang.RuntimeException: boom\n\tat Foo$.<clinit>(Foo.scala:4)\n\tat Foo.main(Foo.scala)\n\tat <empty>.Foo.run(Foo.scala:7)\n\tat <empty>.Foo.run(Foo.scala:9)\n\"\n```\n\nWith both of these causes, the outcome should be the same as defects should always be prioritised over failures. This gets even worse when interruption is involved, because the failure handling will be prioritised over it.\n\nHaving said that, this has the potential to massively alter applications so I'm too scared to fix it.\n@ghostdogpr @jdegoes  @hearnadam @guizmaii I summon you all for some wisdom",
              "url": "https://github.com/zio/zio/issues/9874",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          }
        ],
        "next_cursor": null
      }
    }
  }
}