{
  "result": {
    "data": {
      "json": {
        "items": [
          {
            "id": "triggerdotdev#2654",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "triggerdotdev",
              "id": "generated-triggerdotdev",
              "name": "Triggerdotdev",
              "description": "",
              "members": [],
              "display_name": "Triggerdotdev",
              "created_at": "2025-12-12T07:43:15.205Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/triggerdotdev?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "colinhacks",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:15.205Z",
            "created_at": "2025-12-12T07:43:15.205Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-triggerdotdev#2654",
              "status": "open",
              "type": "issue",
              "number": 2654,
              "title": "Schema in object being inferred differently (and weirdly)",
              "source": {
                "data": {
                  "id": "source-triggerdotdev#2654",
                  "user": {
                    "login": "ericallam",
                    "id": 534,
                    "node_id": "MDQ6VXNlcjUzNA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/534?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ericallam",
                    "html_url": "https://github.com/ericallam",
                    "followers_url": "https://api.github.com/users/ericallam/followers",
                    "following_url": "https://api.github.com/users/ericallam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ericallam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ericallam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ericallam/subscriptions",
                    "organizations_url": "https://api.github.com/users/ericallam/orgs",
                    "repos_url": "https://api.github.com/users/ericallam/repos",
                    "events_url": "https://api.github.com/users/ericallam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ericallam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Schema in object being inferred differently (and weirdly)",
                  "body": "See the following TS snippet:\r\n\r\n```ts\r\nimport { z } from \"zod\";\r\n\r\nconst EventNameSchema = z.string().or(z.array(z.string()));\r\n\r\ntype EventName = z.infer<typeof EventNameSchema>;\r\n// EventName is string | string[]\r\n\r\nconst EventSchema = z.object({\r\n  name: z.string().or(z.array(z.string())) // this is the same as the EventNameSchema\r\n});\r\n\r\ntype EventWithName = z.infer<typeof EventSchema>;\r\ntype EventName2 = EventWithName[\"name\"];\r\n// EventName2 is (string | string[]) & (string | string[] | undefined)\r\n```\r\n\r\nAnd the TS playground: [link](https://www.typescriptlang.org/play?#code/JYWwDg9gTgLgBAbzgLzgXzgMyhEcBEyEAJvgNwBQFAxhAHYDO8AogG4CmdMAcgIYjsAytQAW7ELzgBeFADomUYHQDmACgCUs6KuSzeUKLwCeO+TEUqN69ZQowjYdnDace-JzN1LM7KAB57RwhMZw4uPgFhMQkAPkoAenjQ1winYAY4BSVlOAAfTPNsgG0AXSpaRhYwmCjxSU8tACMAK3ZqGFUECjg4OncALjksy01tXX1DE11htWt1CjQbKkCnFy4AdWAYEVTpOW9fAId2YOSuWtjKFbO3AQAmPbWYTe3Uovw+gXwShKSn1Ie6TgqhmeQKFmUpXUcAAZMDQfkZqUwQBXOjEdiYJTsYjqIA)\r\n\r\nI'm not sure if this is intended or a bug or maybe just a user error. Using zod `3.21.4` and TS `4.8.4`",
                  "html_url": "https://github.com/colinhacks/zod/issues/2654"
                },
                "type": "github"
              },
              "hash": "colinhacks/zod#2654",
              "body": "See the following TS snippet:\r\n\r\n```ts\r\nimport { z } from \"zod\";\r\n\r\nconst EventNameSchema = z.string().or(z.array(z.string()));\r\n\r\ntype EventName = z.infer<typeof EventNameSchema>;\r\n// EventName is string | string[]\r\n\r\nconst EventSchema = z.object({\r\n  name: z.string().or(z.array(z.string())) // this is the same as the EventNameSchema\r\n});\r\n\r\ntype EventWithName = z.infer<typeof EventSchema>;\r\ntype EventName2 = EventWithName[\"name\"];\r\n// EventName2 is (string | string[]) & (string | string[] | undefined)\r\n```\r\n\r\nAnd the TS playground: [link](https://www.typescriptlang.org/play?#code/JYWwDg9gTgLgBAbzgLzgXzgMyhEcBEyEAJvgNwBQFAxhAHYDO8AogG4CmdMAcgIYjsAytQAW7ELzgBeFADomUYHQDmACgCUs6KuSzeUKLwCeO+TEUqN69ZQowjYdnDace-JzN1LM7KAB57RwhMZw4uPgFhMQkAPkoAenjQ1winYAY4BSVlOAAfTPNsgG0AXSpaRhYwmCjxSU8tACMAK3ZqGFUECjg4OncALjksy01tXX1DE11htWt1CjQbKkCnFy4AdWAYEVTpOW9fAId2YOSuWtjKFbO3AQAmPbWYTe3Uovw+gXwShKSn1Ie6TgqhmeQKFmUpXUcAAZMDQfkZqUwQBXOjEdiYJTsYjqIA)\r\n\r\nI'm not sure if this is intended or a bug or maybe just a user error. Using zod `3.21.4` and TS `4.8.4`",
              "url": "https://github.com/colinhacks/zod/issues/2654",
              "tech": [
                "go"
              ],
              "repo_name": "zod",
              "repo_owner": "colinhacks",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#3697",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-12T07:43:16.828Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:16.828Z",
            "created_at": "2025-12-12T07:43:16.828Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#3697",
              "status": "open",
              "type": "issue",
              "number": 3697,
              "title": "Datastar requests from Endpoint",
              "source": {
                "data": {
                  "id": "source-ZIO#3697",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Datastar requests from Endpoint",
                  "body": "Build Datastar expressions for request against an Endpoint from its definition\n",
                  "html_url": "https://github.com/zio/zio-http/issues/3697"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3697",
              "body": "Build Datastar expressions for request against an Endpoint from its definition\n",
              "url": "https://github.com/zio/zio-http/issues/3697",
              "tech": [
                "go"
              ],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#709",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-12T07:43:17.942Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:17.942Z",
            "created_at": "2025-12-12T07:43:17.942Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#709",
              "status": "open",
              "type": "issue",
              "number": 709,
              "title": "Support Http Range header on request for Files",
              "source": {
                "data": {
                  "id": "source-ZIO#709",
                  "user": {
                    "login": "ashprakasan",
                    "id": 8946971,
                    "node_id": "MDQ6VXNlcjg5NDY5NzE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/8946971?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ashprakasan",
                    "html_url": "https://github.com/ashprakasan",
                    "followers_url": "https://api.github.com/users/ashprakasan/followers",
                    "following_url": "https://api.github.com/users/ashprakasan/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ashprakasan/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ashprakasan/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ashprakasan/subscriptions",
                    "organizations_url": "https://api.github.com/users/ashprakasan/orgs",
                    "repos_url": "https://api.github.com/users/ashprakasan/repos",
                    "events_url": "https://api.github.com/users/ashprakasan/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ashprakasan/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Support Http Range header on request for Files",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe Range HTTP request header indicates the part of a document that the server should return. Several parts can be requested with one Range header at once, and the server may send back these ranges in a multipart document.\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample requesting 3 ranges from files -\r\n`Range: bytes=200-1000, 2000-6576, 19000-`\r\n\r\nSend only those parts of the document in Response.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCurrently, the range is hardcoded as follows - \r\n` ctx.write(new DefaultFileRegion(raf.getChannel, 0, fileLength))`\r\nManipulate the positions as per request headers instead.\r\n\r\n**Additional context**\r\n\r\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Range\r\n",
                  "html_url": "https://github.com/zio/zio-http/issues/709"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#709",
              "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe Range HTTP request header indicates the part of a document that the server should return. Several parts can be requested with one Range header at once, and the server may send back these ranges in a multipart document.\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample requesting 3 ranges from files -\r\n`Range: bytes=200-1000, 2000-6576, 19000-`\r\n\r\nSend only those parts of the document in Response.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCurrently, the range is hardcoded as follows - \r\n` ctx.write(new DefaultFileRegion(raf.getChannel, 0, fileLength))`\r\nManipulate the positions as per request headers instead.\r\n\r\n**Additional context**\r\n\r\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Range\r\n",
              "url": "https://github.com/zio/zio-http/issues/709",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#3472",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-12T07:43:20.656Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:20.656Z",
            "created_at": "2025-12-12T07:43:20.656Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#3472",
              "status": "open",
              "type": "issue",
              "number": 3472,
              "title": "Split into multiple modules",
              "source": {
                "data": {
                  "id": "source-ZIO#3472",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Split into multiple modules",
                  "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
                  "html_url": "https://github.com/zio/zio-http/issues/3472"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3472",
              "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
              "url": "https://github.com/zio/zio-http/issues/3472",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9810",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-12T07:43:23.565Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:23.565Z",
            "created_at": "2025-12-12T07:43:23.565Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9810",
              "status": "open",
              "type": "issue",
              "number": 9810,
              "title": "ZStreams buffer(1) is buffering 2.",
              "source": {
                "data": {
                  "id": "source-ZIO#9810",
                  "user": {
                    "login": "douglasthomsen",
                    "id": 88000378,
                    "node_id": "MDQ6VXNlcjg4MDAwMzc4",
                    "avatar_url": "https://avatars.githubusercontent.com/u/88000378?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/douglasthomsen",
                    "html_url": "https://github.com/douglasthomsen",
                    "followers_url": "https://api.github.com/users/douglasthomsen/followers",
                    "following_url": "https://api.github.com/users/douglasthomsen/following{/other_user}",
                    "gists_url": "https://api.github.com/users/douglasthomsen/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/douglasthomsen/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/douglasthomsen/subscriptions",
                    "organizations_url": "https://api.github.com/users/douglasthomsen/orgs",
                    "repos_url": "https://api.github.com/users/douglasthomsen/repos",
                    "events_url": "https://api.github.com/users/douglasthomsen/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/douglasthomsen/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZStreams buffer(1) is buffering 2.",
                  "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
                  "html_url": "https://github.com/zio/zio/issues/9810"
                },
                "type": "github"
              },
              "hash": "zio/zio#9810",
              "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
              "url": "https://github.com/zio/zio/issues/9810",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9844",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-12T07:43:24.040Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:24.040Z",
            "created_at": "2025-12-12T07:43:24.040Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9844",
              "status": "open",
              "type": "issue",
              "number": 9844,
              "title": "improved `Queue` shutdown functionality",
              "source": {
                "data": {
                  "id": "source-ZIO#9844",
                  "user": {
                    "login": "mberndt123",
                    "id": 11650737,
                    "node_id": "MDQ6VXNlcjExNjUwNzM3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/11650737?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/mberndt123",
                    "html_url": "https://github.com/mberndt123",
                    "followers_url": "https://api.github.com/users/mberndt123/followers",
                    "following_url": "https://api.github.com/users/mberndt123/following{/other_user}",
                    "gists_url": "https://api.github.com/users/mberndt123/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/mberndt123/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/mberndt123/subscriptions",
                    "organizations_url": "https://api.github.com/users/mberndt123/orgs",
                    "repos_url": "https://api.github.com/users/mberndt123/repos",
                    "events_url": "https://api.github.com/users/mberndt123/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/mberndt123/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "improved `Queue` shutdown functionality",
                  "body": "Hey, I've recently proposed something on Discord, and since feedback has been rather positive, I'm making a ticket to track the idea.\n\nI've been working with Queues recently, and I've been having some issues around `shutdown` that I would like to address.\n\nSpecifically, I find it a common pattern that I send some kind of request object through a queue because I want another fiber to perform some action on my behalf. Along with the request, I send a `Promise` to have that fiber communicate the outcome of that action to me. By and large this works fine. The issue arises when the fiber that I'm sending requests to fails. In that case, I would like it to communicate the cause of the failure back to the other fibers. This is easy enough for the requests that I've already pulled out of the queue: I simply fail those promises.\nBut I also need to deal with other cases: fibers currently blocked in an `offer` call, future attempts to `offer` to the queue, and I also need to deal with requests that have been submitted to the queue but not yet retrieved.\n\nSo my idea is as follows:\n - add an `E` type parameter to `Queue`\n - add a `shutdownCause` method that takes a type parameter of type `Cause[E]`\n - `shutdownCause` would also return the items currently buffered in the queue in order to dispose of them\n - after `shutdownCause` has been called, any attempt to interact with the queue will fail with the cause\n - methods like `take, offer` etc. should indicate errors of type `E`\n - streams created with `ZStream.fromQueue` would also fail with this cause\n - `shutdownCause` should be atomic: when multiple fibers call it at the same time, one of them wins and the others fail with the cause supplied by the winner\n\nAfaik, adding a new method is a binary compatible change, as is adding a new type parameter. Hence I think this is a source incompatible but binary compatible change. @ghostdogpr therefore suggested it could be added in a ZIO 2.2 release.\n",
                  "html_url": "https://github.com/zio/zio/issues/9844"
                },
                "type": "github"
              },
              "hash": "zio/zio#9844",
              "body": "Hey, I've recently proposed something on Discord, and since feedback has been rather positive, I'm making a ticket to track the idea.\n\nI've been working with Queues recently, and I've been having some issues around `shutdown` that I would like to address.\n\nSpecifically, I find it a common pattern that I send some kind of request object through a queue because I want another fiber to perform some action on my behalf. Along with the request, I send a `Promise` to have that fiber communicate the outcome of that action to me. By and large this works fine. The issue arises when the fiber that I'm sending requests to fails. In that case, I would like it to communicate the cause of the failure back to the other fibers. This is easy enough for the requests that I've already pulled out of the queue: I simply fail those promises.\nBut I also need to deal with other cases: fibers currently blocked in an `offer` call, future attempts to `offer` to the queue, and I also need to deal with requests that have been submitted to the queue but not yet retrieved.\n\nSo my idea is as follows:\n - add an `E` type parameter to `Queue`\n - add a `shutdownCause` method that takes a type parameter of type `Cause[E]`\n - `shutdownCause` would also return the items currently buffered in the queue in order to dispose of them\n - after `shutdownCause` has been called, any attempt to interact with the queue will fail with the cause\n - methods like `take, offer` etc. should indicate errors of type `E`\n - streams created with `ZStream.fromQueue` would also fail with this cause\n - `shutdownCause` should be atomic: when multiple fibers call it at the same time, one of them wins and the others fail with the cause supplied by the winner\n\nAfaik, adding a new method is a binary compatible change, as is adding a new type parameter. Hence I think this is a source incompatible but binary compatible change. @ghostdogpr therefore suggested it could be added in a ZIO 2.2 release.\n",
              "url": "https://github.com/zio/zio/issues/9844",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9878",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-12T07:43:24.403Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:24.403Z",
            "created_at": "2025-12-12T07:43:24.403Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9878",
              "status": "open",
              "type": "issue",
              "number": 9878,
              "title": "ZScheduler parks+unparks workers too frequently",
              "source": {
                "data": {
                  "id": "source-ZIO#9878",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZScheduler parks+unparks workers too frequently",
                  "body": "Unparking workers is slow and invoked in the hotpath too often. I think we may need to trade some fairness for aggression to avoid excessive cycling.\n\n`maybeUnparkWorker` (obviously `LockSupport.unpark(worker)`) is very expensive: https://github.com/zio/zio/blob/series/2.x/core/jvm-native/src/main/scala/zio/internal/ZScheduler.scala#L443-L454",
                  "html_url": "https://github.com/zio/zio/issues/9878"
                },
                "type": "github"
              },
              "hash": "zio/zio#9878",
              "body": "Unparking workers is slow and invoked in the hotpath too often. I think we may need to trade some fairness for aggression to avoid excessive cycling.\n\n`maybeUnparkWorker` (obviously `LockSupport.unpark(worker)`) is very expensive: https://github.com/zio/zio/blob/series/2.x/core/jvm-native/src/main/scala/zio/internal/ZScheduler.scala#L443-L454",
              "url": "https://github.com/zio/zio/issues/9878",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9877",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-12T07:43:24.536Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:24.536Z",
            "created_at": "2025-12-12T07:43:24.536Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9877",
              "status": "open",
              "type": "issue",
              "number": 9877,
              "title": "Can Fiber(Runtime) and Promise be merged?",
              "source": {
                "data": {
                  "id": "source-ZIO#9877",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Can Fiber(Runtime) and Promise be merged?",
                  "body": "A Promise awaiting completion is essentially a Fiber parked awaiting an async callback. When a Fiber is forking work (which will eventually complete a promise), then awaiting a Promise, we end up with unnecessary allocations + indirection.\n\nit would be useful to have `Promise.become` or similar to link fibers/promises.",
                  "html_url": "https://github.com/zio/zio/issues/9877"
                },
                "type": "github"
              },
              "hash": "zio/zio#9877",
              "body": "A Promise awaiting completion is essentially a Fiber parked awaiting an async callback. When a Fiber is forking work (which will eventually complete a promise), then awaiting a Promise, we end up with unnecessary allocations + indirection.\n\nit would be useful to have `Promise.become` or similar to link fibers/promises.",
              "url": "https://github.com/zio/zio/issues/9877",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9874",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-12T07:43:24.704Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:24.704Z",
            "created_at": "2025-12-12T07:43:24.704Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9874",
              "status": "open",
              "type": "issue",
              "number": 9874,
              "title": "Handling errors allows recovering from defects",
              "source": {
                "data": {
                  "id": "source-ZIO#9874",
                  "user": {
                    "login": "kyri-petrou",
                    "id": 67301607,
                    "node_id": "MDQ6VXNlcjY3MzAxNjA3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/67301607?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kyri-petrou",
                    "html_url": "https://github.com/kyri-petrou",
                    "followers_url": "https://api.github.com/users/kyri-petrou/followers",
                    "following_url": "https://api.github.com/users/kyri-petrou/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kyri-petrou/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kyri-petrou/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kyri-petrou/subscriptions",
                    "organizations_url": "https://api.github.com/users/kyri-petrou/orgs",
                    "repos_url": "https://api.github.com/users/kyri-petrou/repos",
                    "events_url": "https://api.github.com/users/kyri-petrou/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kyri-petrou/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Handling errors allows recovering from defects",
                  "body": "Sigh... Well, this is annoying. When a Cause contains both a failure and a defect (i.e., Fail & Die), failure handling assumes that the Cause does not contain any defects and therefor silently ignores them.\n\nRepro:\n\n```scala\nimport zio.*\n\nobject Foo extends ZIOAppDefault {\n  val dieCause: Cause[String] = Cause.die(new RuntimeException(\"boom\"))\n  val combinedCause = dieCause && Cause.fail(\"boom\")\n\n  def run = ZIO.failCause(combinedCause).catchAll { e =>\n    ZIO.debug(e)\n  } *> ZIO.debug(\"Success\")\n}\n```\nprints:\n```\nhandled: boom\nSuccess\n```\n\nHowever if we substituted `ZIO.failCause(combinedCause)` with `ZIO.failCause(dieCause)`:\n\n```\ntimestamp=2025-05-20T16:31:09.291104Z level=ERROR thread=#zio-fiber-1707930317 message=\"\" cause=\"java.lang.RuntimeException: boom\n\tat Foo$.<clinit>(Foo.scala:4)\n\tat Foo.main(Foo.scala)\n\tat <empty>.Foo.run(Foo.scala:7)\n\tat <empty>.Foo.run(Foo.scala:9)\n\"\n```\n\nWith both of these causes, the outcome should be the same as defects should always be prioritised over failures. This gets even worse when interruption is involved, because the failure handling will be prioritised over it.\n\nHaving said that, this has the potential to massively alter applications so I'm too scared to fix it.\n@ghostdogpr @jdegoes  @hearnadam @guizmaii I summon you all for some wisdom",
                  "html_url": "https://github.com/zio/zio/issues/9874"
                },
                "type": "github"
              },
              "hash": "zio/zio#9874",
              "body": "Sigh... Well, this is annoying. When a Cause contains both a failure and a defect (i.e., Fail & Die), failure handling assumes that the Cause does not contain any defects and therefor silently ignores them.\n\nRepro:\n\n```scala\nimport zio.*\n\nobject Foo extends ZIOAppDefault {\n  val dieCause: Cause[String] = Cause.die(new RuntimeException(\"boom\"))\n  val combinedCause = dieCause && Cause.fail(\"boom\")\n\n  def run = ZIO.failCause(combinedCause).catchAll { e =>\n    ZIO.debug(e)\n  } *> ZIO.debug(\"Success\")\n}\n```\nprints:\n```\nhandled: boom\nSuccess\n```\n\nHowever if we substituted `ZIO.failCause(combinedCause)` with `ZIO.failCause(dieCause)`:\n\n```\ntimestamp=2025-05-20T16:31:09.291104Z level=ERROR thread=#zio-fiber-1707930317 message=\"\" cause=\"java.lang.RuntimeException: boom\n\tat Foo$.<clinit>(Foo.scala:4)\n\tat Foo.main(Foo.scala)\n\tat <empty>.Foo.run(Foo.scala:7)\n\tat <empty>.Foo.run(Foo.scala:9)\n\"\n```\n\nWith both of these causes, the outcome should be the same as defects should always be prioritised over failures. This gets even worse when interruption is involved, because the failure handling will be prioritised over it.\n\nHaving said that, this has the potential to massively alter applications so I'm too scared to fix it.\n@ghostdogpr @jdegoes  @hearnadam @guizmaii I summon you all for some wisdom",
              "url": "https://github.com/zio/zio/issues/9874",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9681",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-12T07:43:25.087Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:25.087Z",
            "created_at": "2025-12-12T07:43:25.087Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9681",
              "status": "open",
              "type": "issue",
              "number": 9681,
              "title": "Scala Native `WeakConcurrentBag` NPE when forking 10K fibers",
              "source": {
                "data": {
                  "id": "source-ZIO#9681",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Scala Native `WeakConcurrentBag` NPE when forking 10K fibers",
                  "body": "```\n[info]   - PromiseSpec - waiter stack safety\n[info]     Exception in thread \"zio-fiber-931\" java.lang.NullPointerException: null\n[info]     \tat scala.scalanative.runtime.package$.throwNullPointer(Unknown Source)\n[info]     \tat <none>.(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.treeifyBin(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.putVal(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap$KeySetView.add(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.addToLongTermStorage(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.add(Unknown Source)\n[info]     \tat zio.internal.FiberScope$global$.add(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.makeChildFiber(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.fork(Unknown Source)\n[info]     \tat zio.ZIO.$anonfun$forkWithScopeOverride$2(Unknown Source)\n[info]     \tat zio.ZIO$$Lambda$280.apply(Unknown Source)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:127)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:124)\n```\nI introduced a new test in #9569 which resulted in this strange failure on Native.",
                  "html_url": "https://github.com/zio/zio/issues/9681"
                },
                "type": "github"
              },
              "hash": "zio/zio#9681",
              "body": "```\n[info]   - PromiseSpec - waiter stack safety\n[info]     Exception in thread \"zio-fiber-931\" java.lang.NullPointerException: null\n[info]     \tat scala.scalanative.runtime.package$.throwNullPointer(Unknown Source)\n[info]     \tat <none>.(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.treeifyBin(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.putVal(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap$KeySetView.add(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.addToLongTermStorage(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.add(Unknown Source)\n[info]     \tat zio.internal.FiberScope$global$.add(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.makeChildFiber(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.fork(Unknown Source)\n[info]     \tat zio.ZIO.$anonfun$forkWithScopeOverride$2(Unknown Source)\n[info]     \tat zio.ZIO$$Lambda$280.apply(Unknown Source)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:127)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:124)\n```\nI introduced a new test in #9569 which resulted in this strange failure on Native.",
              "url": "https://github.com/zio/zio/issues/9681",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9922",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-12T07:43:26.737Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:26.737Z",
            "created_at": "2025-12-12T07:43:26.737Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9922",
              "status": "open",
              "type": "issue",
              "number": 9922,
              "title": "Add tests for `ZStreamAspect`",
              "source": {
                "data": {
                  "id": "source-ZIO#9922",
                  "user": {
                    "login": "kyri-petrou",
                    "id": 67301607,
                    "node_id": "MDQ6VXNlcjY3MzAxNjA3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/67301607?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kyri-petrou",
                    "html_url": "https://github.com/kyri-petrou",
                    "followers_url": "https://api.github.com/users/kyri-petrou/followers",
                    "following_url": "https://api.github.com/users/kyri-petrou/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kyri-petrou/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kyri-petrou/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kyri-petrou/subscriptions",
                    "organizations_url": "https://api.github.com/users/kyri-petrou/orgs",
                    "repos_url": "https://api.github.com/users/kyri-petrou/repos",
                    "events_url": "https://api.github.com/users/kyri-petrou/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kyri-petrou/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add tests for `ZStreamAspect`",
                  "body": "Currently there are no tests for `ZStreamAspect`. We should add a suite that tests each of the provided aspects",
                  "html_url": "https://github.com/zio/zio/issues/9922"
                },
                "type": "github"
              },
              "hash": "zio/zio#9922",
              "body": "Currently there are no tests for `ZStreamAspect`. We should add a suite that tests each of the provided aspects",
              "url": "https://github.com/zio/zio/issues/9922",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7596",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T07:43:52.088Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:52.088Z",
            "created_at": "2025-12-12T07:43:52.088Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7596",
              "status": "open",
              "type": "issue",
              "number": 7596,
              "title": "[Enhancement]: new deployment page",
              "source": {
                "data": {
                  "id": "source-coollabsio#7596",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: new deployment page",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n- Add deployments to sidebar\n- Show past deployments (all of them)\n- Add a filter on the top:\n  - Filter by project\n  - Filter by server\n  - Filter by sources\n  - Filter by status (queued, pending, done)\n- Show live updates / refresh?\n- Hide filters if only 1 server / 1 source\n\n## Design inspiration\n\nVercel example:\n\n<img width=\"1362\" height=\"967\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e46d7470-fff1-46c5-8011-63ba82119db2\" />\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7596"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7596",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n- Add deployments to sidebar\n- Show past deployments (all of them)\n- Add a filter on the top:\n  - Filter by project\n  - Filter by server\n  - Filter by sources\n  - Filter by status (queued, pending, done)\n- Show live updates / refresh?\n- Hide filters if only 1 server / 1 source\n\n## Design inspiration\n\nVercel example:\n\n<img width=\"1362\" height=\"967\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e46d7470-fff1-46c5-8011-63ba82119db2\" />\n",
              "url": "https://github.com/coollabsio/coolify/issues/7596",
              "tech": [
                "go"
              ],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7529",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T07:43:52.218Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:52.218Z",
            "created_at": "2025-12-12T07:43:52.218Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7529",
              "status": "open",
              "type": "issue",
              "number": 7529,
              "title": "[Enhancement]: Enable backup restore/import for ServiceDatabase (Docker Compose databases)",
              "source": {
                "data": {
                  "id": "source-coollabsio#7529",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Enable backup restore/import for ServiceDatabase (Docker Compose databases)",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nDatabases created via Docker Compose deployments (`ServiceDatabase`) can create backups but cannot restore/import them through the UI. The import functionality only supports Standalone database types.\n\n### Current Behavior\n\n| Database Type | Backup | Restore/Import |\n|---|---|---|\n| StandalonePostgresql |  |  |\n| StandaloneMysql |  |  |\n| StandaloneMariadb |  |  |\n| StandaloneMongodb |  |  |\n| **ServiceDatabase** (from Docker Compose) |  |  |\n\n### Expected Behavior\n\nServiceDatabase should support restore/import functionality, similar to Standalone databases.\n\n### Technical Details\n\n**File:** `app/Livewire/Project/Database/Import.php`\n\nThe `buildRestoreCommand()` method (line 576-614) only handles Standalone database classes:\n\n```php\nswitch ($this->resource->getMorphClass()) {\n    case \\App\\Models\\StandaloneMariadb::class:\n        // ...\n    case \\App\\Models\\StandaloneMysql::class:\n        // ...\n    case \\App\\Models\\StandalonePostgresql::class:\n        // ...\n    case \\App\\Models\\StandaloneMongodb::class:\n        // ...\n    default:\n        $restoreCommand = ''; // ServiceDatabase falls here\n}\n```\n\n### Proposed Solution\n\nAdd support for `ServiceDatabase` in `Import.php`:\n\n1. In `buildRestoreCommand()`, add a case for `ServiceDatabase`:\n```php\ncase \\App\\Models\\ServiceDatabase::class:\n    $dbType = $this->resource->databaseType(); // Returns 'standalone-postgresql', etc.\n    // Build restore command based on $dbType\n    break;\n```\n\n2. The `ServiceDatabase->databaseType()` method already returns the database type (e.g., `standalone-postgresql`, `standalone-mysql`), which can be used to determine the correct restore command.\n\n3. Update `getContainers()` to properly handle ServiceDatabase container naming:\n```php\n// ServiceDatabase container name format: {service-name}-{service-uuid}\n$this->container = $this->resource->name . '-' . $this->resource->service->uuid;\n```\n\n### Related Code\n\n- `app/Livewire/Project/Database/Import.php` - Import/restore component\n- `app/Models/ServiceDatabase.php` - Has `databaseType()` method\n- `app/Jobs/DatabaseBackupJob.php` - Already supports ServiceDatabase for backups\n\n### Use Case\n\nUsers deploying databases via Docker Compose (e.g., `postgres:17-alpine` in a compose file) need the ability to restore backups through the Coolify UI, just like Standalone database deployments.\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7529"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7529",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nDatabases created via Docker Compose deployments (`ServiceDatabase`) can create backups but cannot restore/import them through the UI. The import functionality only supports Standalone database types.\n\n### Current Behavior\n\n| Database Type | Backup | Restore/Import |\n|---|---|---|\n| StandalonePostgresql |  |  |\n| StandaloneMysql |  |  |\n| StandaloneMariadb |  |  |\n| StandaloneMongodb |  |  |\n| **ServiceDatabase** (from Docker Compose) |  |  |\n\n### Expected Behavior\n\nServiceDatabase should support restore/import functionality, similar to Standalone databases.\n\n### Technical Details\n\n**File:** `app/Livewire/Project/Database/Import.php`\n\nThe `buildRestoreCommand()` method (line 576-614) only handles Standalone database classes:\n\n```php\nswitch ($this->resource->getMorphClass()) {\n    case \\App\\Models\\StandaloneMariadb::class:\n        // ...\n    case \\App\\Models\\StandaloneMysql::class:\n        // ...\n    case \\App\\Models\\StandalonePostgresql::class:\n        // ...\n    case \\App\\Models\\StandaloneMongodb::class:\n        // ...\n    default:\n        $restoreCommand = ''; // ServiceDatabase falls here\n}\n```\n\n### Proposed Solution\n\nAdd support for `ServiceDatabase` in `Import.php`:\n\n1. In `buildRestoreCommand()`, add a case for `ServiceDatabase`:\n```php\ncase \\App\\Models\\ServiceDatabase::class:\n    $dbType = $this->resource->databaseType(); // Returns 'standalone-postgresql', etc.\n    // Build restore command based on $dbType\n    break;\n```\n\n2. The `ServiceDatabase->databaseType()` method already returns the database type (e.g., `standalone-postgresql`, `standalone-mysql`), which can be used to determine the correct restore command.\n\n3. Update `getContainers()` to properly handle ServiceDatabase container naming:\n```php\n// ServiceDatabase container name format: {service-name}-{service-uuid}\n$this->container = $this->resource->name . '-' . $this->resource->service->uuid;\n```\n\n### Related Code\n\n- `app/Livewire/Project/Database/Import.php` - Import/restore component\n- `app/Models/ServiceDatabase.php` - Has `databaseType()` method\n- `app/Jobs/DatabaseBackupJob.php` - Already supports ServiceDatabase for backups\n\n### Use Case\n\nUsers deploying databases via Docker Compose (e.g., `postgres:17-alpine` in a compose file) need the ability to restore backups through the Coolify UI, just like Standalone database deployments.\n",
              "url": "https://github.com/coollabsio/coolify/issues/7529",
              "tech": [
                "go"
              ],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7528",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T07:43:52.351Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:52.351Z",
            "created_at": "2025-12-12T07:43:52.351Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7528",
              "status": "open",
              "type": "issue",
              "number": 7528,
              "title": "[Enhancement]: Enable database detection and backup support for Docker Compose deployments via GitHub App",
              "source": {
                "data": {
                  "id": "source-coollabsio#7528",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Enable database detection and backup support for Docker Compose deployments via GitHub App",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nWhen deploying a Docker Compose file via GitHub App (using the `dockercompose` buildpack), database services are not detected and `ServiceDatabase` records are not created. This means automated backups are not available for databases in these deployments.\n\nHowever, when using \"Empty Docker Compose\" or one-click services (like Supabase), database detection works correctly and backups are available.\n\n### Current Behavior\n\n| Deployment Method | Model | Creates ServiceDatabase | Backups Available |\n|---|---|---|---|\n| Empty Docker Compose | `Service` |  Yes |  Yes |\n| GitHub App (dockercompose buildpack) | `Application` |  No |  No |\n| One-click Services (e.g., Supabase) | `Service` |  Yes |  Yes |\n\n### Expected Behavior\n\nDatabase services in Docker Compose files deployed via GitHub App should be detected and have backup functionality available, similar to Empty Docker Compose deployments.\n\n### Technical Details\n\nThe issue is in `bootstrap/helpers/shared.php` in the `parseDockerComposeFile()` function:\n\n**Service model path (lines 1263-2025):**\n- Calls `isDatabaseImage()` to detect databases\n- Creates `ServiceDatabase` records for detected databases\n- These databases can have scheduled backups\n\n**Application model path (lines 2026-2767):**\n- Does NOT call `isDatabaseImage()`\n- Does NOT create `ServiceDatabase` records\n- All services are treated as application containers\n- No backup support\n\n### Proposed Solution\n\nAdd database detection logic to the Application model parsing path:\n\n1. In `parseDockerComposeFile()` for the Application model (around line 2066), add:\n   ```php\n   $isDatabase = isDatabaseImage($image, $service);\n   data_set($service, 'is_database', $isDatabase);\n   ```\n\n2. Create `ServiceDatabase` records for detected database services, similar to how it's done in the Service model path.\n\n3. Alternatively, consider refactoring to share the database detection logic between both paths.\n\n### Use Case\n\nUsers deploying full-stack applications via GitHub (e.g., Next.js app + PostgreSQL + pgbouncer in a single compose file) expect database backups to work the same way as standalone database deployments or one-click services.\n\n### Related Code\n\n- `bootstrap/helpers/shared.php` - `parseDockerComposeFile()` function\n- `bootstrap/helpers/docker.php` - `isDatabaseImage()` function\n- `app/Models/ServiceDatabase.php` - Database model with backup support\n- `app/Models/ScheduledDatabaseBackup.php` - Backup scheduling\n\n### Environment\n\n- Coolify version: latest\n- Deployment method: GitHub App with dockercompose buildpack\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7528"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7528",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nWhen deploying a Docker Compose file via GitHub App (using the `dockercompose` buildpack), database services are not detected and `ServiceDatabase` records are not created. This means automated backups are not available for databases in these deployments.\n\nHowever, when using \"Empty Docker Compose\" or one-click services (like Supabase), database detection works correctly and backups are available.\n\n### Current Behavior\n\n| Deployment Method | Model | Creates ServiceDatabase | Backups Available |\n|---|---|---|---|\n| Empty Docker Compose | `Service` |  Yes |  Yes |\n| GitHub App (dockercompose buildpack) | `Application` |  No |  No |\n| One-click Services (e.g., Supabase) | `Service` |  Yes |  Yes |\n\n### Expected Behavior\n\nDatabase services in Docker Compose files deployed via GitHub App should be detected and have backup functionality available, similar to Empty Docker Compose deployments.\n\n### Technical Details\n\nThe issue is in `bootstrap/helpers/shared.php` in the `parseDockerComposeFile()` function:\n\n**Service model path (lines 1263-2025):**\n- Calls `isDatabaseImage()` to detect databases\n- Creates `ServiceDatabase` records for detected databases\n- These databases can have scheduled backups\n\n**Application model path (lines 2026-2767):**\n- Does NOT call `isDatabaseImage()`\n- Does NOT create `ServiceDatabase` records\n- All services are treated as application containers\n- No backup support\n\n### Proposed Solution\n\nAdd database detection logic to the Application model parsing path:\n\n1. In `parseDockerComposeFile()` for the Application model (around line 2066), add:\n   ```php\n   $isDatabase = isDatabaseImage($image, $service);\n   data_set($service, 'is_database', $isDatabase);\n   ```\n\n2. Create `ServiceDatabase` records for detected database services, similar to how it's done in the Service model path.\n\n3. Alternatively, consider refactoring to share the database detection logic between both paths.\n\n### Use Case\n\nUsers deploying full-stack applications via GitHub (e.g., Next.js app + PostgreSQL + pgbouncer in a single compose file) expect database backups to work the same way as standalone database deployments or one-click services.\n\n### Related Code\n\n- `bootstrap/helpers/shared.php` - `parseDockerComposeFile()` function\n- `bootstrap/helpers/docker.php` - `isDatabaseImage()` function\n- `app/Models/ServiceDatabase.php` - Database model with backup support\n- `app/Models/ScheduledDatabaseBackup.php` - Backup scheduling\n\n### Environment\n\n- Coolify version: latest\n- Deployment method: GitHub App with dockercompose buildpack\n",
              "url": "https://github.com/coollabsio/coolify/issues/7528",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7473",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T07:43:52.474Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:52.474Z",
            "created_at": "2025-12-12T07:43:52.474Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7473",
              "status": "open",
              "type": "issue",
              "number": 7473,
              "title": "[Bug]: Database Backups won't use the custom timeout in ssh command (regression)",
              "source": {
                "data": {
                  "id": "source-coollabsio#7473",
                  "user": {
                    "login": "isokosan",
                    "id": 1430946,
                    "node_id": "MDQ6VXNlcjE0MzA5NDY=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1430946?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/isokosan",
                    "html_url": "https://github.com/isokosan",
                    "followers_url": "https://api.github.com/users/isokosan/followers",
                    "following_url": "https://api.github.com/users/isokosan/following{/other_user}",
                    "gists_url": "https://api.github.com/users/isokosan/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/isokosan/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/isokosan/subscriptions",
                    "organizations_url": "https://api.github.com/users/isokosan/orgs",
                    "repos_url": "https://api.github.com/users/isokosan/repos",
                    "events_url": "https://api.github.com/users/isokosan/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/isokosan/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Database Backups won't use the custom timeout in ssh command (regression)",
                  "body": "### Error Message and Logs\n\nWe had [this issue](https://github.com/coollabsio/coolify/issues/3325) with backups exceeding timeouts and we made a new feature where we can customize the timeout settings in the backups.\n\nThis was working but seems to have regressed as the timeout setting is not being passed to the backup ssh command, instead the default 3600 is being used I'm afraid:\n\nThe process \"timeout 3600 ssh -i /var/www/html/storage/app/ssh/keys/ssh_key@jgcwgggco80sc0occ88skg0s -o StrictHos... truncated ...FoM2ROejJRRmtjT1M0NXNt\" exceeded the timeout of 3600 seconds.\n\n@Cinzya commented that this is about the SSH command now and not the backup itself:\n> I believe this is actually the SSH process timing out and not the backup itself.\n> The SSH process has a hard timeout of 3600. The backup timeout is not really passed to the SSH process to increase that timeout as well. \n> This is either an oversight or there is a specific reason why a SSH process shouldn't linger more then 3600 seconds. \n> But yes, feel free to open a new issue about it. \n\n\n### Steps to Reproduce\n\n1. Configure a database and then backups.\n2. Use the Timeout option in the dashboard to set a custom timeout, eg 10800 (default 3600 seconds)\n3. Click on Backup Now\n4. Check the command that is run by coolify to see the timeout not being passed to the SSH command\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7473"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7473",
              "body": "### Error Message and Logs\n\nWe had [this issue](https://github.com/coollabsio/coolify/issues/3325) with backups exceeding timeouts and we made a new feature where we can customize the timeout settings in the backups.\n\nThis was working but seems to have regressed as the timeout setting is not being passed to the backup ssh command, instead the default 3600 is being used I'm afraid:\n\nThe process \"timeout 3600 ssh -i /var/www/html/storage/app/ssh/keys/ssh_key@jgcwgggco80sc0occ88skg0s -o StrictHos... truncated ...FoM2ROejJRRmtjT1M0NXNt\" exceeded the timeout of 3600 seconds.\n\n@Cinzya commented that this is about the SSH command now and not the backup itself:\n> I believe this is actually the SSH process timing out and not the backup itself.\n> The SSH process has a hard timeout of 3600. The backup timeout is not really passed to the SSH process to increase that timeout as well. \n> This is either an oversight or there is a specific reason why a SSH process shouldn't linger more then 3600 seconds. \n> But yes, feel free to open a new issue about it. \n\n\n### Steps to Reproduce\n\n1. Configure a database and then backups.\n2. Use the Timeout option in the dashboard to set a custom timeout, eg 10800 (default 3600 seconds)\n3. Click on Backup Now\n4. Check the command that is run by coolify to see the timeout not being passed to the SSH command\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/7473",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7458",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T07:43:52.618Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:52.618Z",
            "created_at": "2025-12-12T07:43:52.618Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7458",
              "status": "open",
              "type": "issue",
              "number": 7458,
              "title": "[Bug + Multiple Bounties]: Official Selfhosted Supabase MCP Setup hindered by Coolify AND Bounty List",
              "source": {
                "data": {
                  "id": "source-coollabsio#7458",
                  "user": {
                    "login": "rootacc3ss",
                    "id": 192549131,
                    "node_id": "U_kgDOC3oRCw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/192549131?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/rootacc3ss",
                    "html_url": "https://github.com/rootacc3ss",
                    "followers_url": "https://api.github.com/users/rootacc3ss/followers",
                    "following_url": "https://api.github.com/users/rootacc3ss/following{/other_user}",
                    "gists_url": "https://api.github.com/users/rootacc3ss/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/rootacc3ss/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/rootacc3ss/subscriptions",
                    "organizations_url": "https://api.github.com/users/rootacc3ss/orgs",
                    "repos_url": "https://api.github.com/users/rootacc3ss/repos",
                    "events_url": "https://api.github.com/users/rootacc3ss/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/rootacc3ss/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug + Multiple Bounties]: Official Selfhosted Supabase MCP Setup hindered by Coolify AND Bounty List",
                  "body": "### Error Message and Logs\n\n**Bounty! $15.00 on Algora.io; will add ASAP, need to figure out how to use it.**\n\nWhen following these documents from Supabase pertaining to the latest selfhosted Supabase docker setup:\nhttps://supabase.com/docs/guides/self-hosting/enable-mcp\n_you will notice the following..._\n\n1. There is no configuration to turn this on or off with ease, or even commented out docker-compose, nor any notes.\n2. With how we expose Kong via URL by default, the approach in the document could be messy or unsafe\n3. It looks like additional configuration may be required if there are multiple Supabase instances on the same server with individual /mcp exposures as Traefik is handling the routing and everything is using the same ports, etc...\n\n**I am looking for a \"work around\" as the resolution for this bounty.** That is acceptable, but I will require **at minimum a tutorial below** that figures out how to get around this bug/issue and properly documents the following:\n\n- How to configure the MCP and use it on local network\n- How to setup Wireguard to properly allow for usage of this MCP\n- How to configure Cursor/Claude Code/Windsurf to use this MCP\n- **MOST IMPORTANTLY, HOW TO CONNECT TO DIFFERENT SUPABASE INSTANCES ON THE SAME COOLIFY INSTANCE (assuming all of them are running the default Service template)**\n\nCreating a fix within the system we have to spin up and manage a Supabase instance may be difficult due to the template system's restraints, but if you want to work on that complaint of mine and **earn much more than $15**, you can see the bottom of this post. I list off the other bounties I will be offering and putting up cash for upon clearing some wires and hopefully seeing someone (or a few people) dedicate time to it.\n\n### Steps to Reproduce\n\n1. Follow docs linked above\n2. Attempt to edit the docker and piece it all together as tutorial says\n3. ???\n\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nUbuntu 24.04.03\n\n### Additional Information\n\nI am starting this bounty small as I have no clue how this system works and if I will be able to add crypto or not. I want to list these other bounties here firstly to see if there is any immediate response for \n\n**If you claim the small bounty for this, I have a few more I am willing to put in to place -- just let me know if you're interested and make sure to clear whichever one you wish to do with me to I can post the bounty for it:**\n\n- **[$35]** Better Cloudflared/Cloudflare management tools (easy exclusions and inclusions by project, IP, etc... manage domains and subdomains via Cloudflare Zero Trust or DNS settings automatically -- or at least though a portal of some sort)\n- **[$15]** Improved Supabase template (easily configure MCP properly using some sort of fix from this thread, configure mail server for automated mail and OTP with ease, set up external S3 with ease, etc -- I can contribute what I have learned from messing with the template)\n- **[$25]** Working MailCow OR Stalwart+Roundcube \"Service\" template... It's time...\n- **[$XXX]** CoolifyAI -- add API key, get AI assistant w/ knowledge-base similar to the Supabase assistant, ideally with GitHub issue lookup and basic research capability  \n- **[$XXX - $X,XXX]** More proper, fleshed out \"Services\" template system WITH ability to add remote repositories outside of the official Coolify templates; setup scripting w/ select-able options, easily modify docker template or automations/commands with checkboxes, dropdowns and input fields and the works. Ideally, a system in which \"addons\" in these same repositories as the whole \"Services\" themselves can be added on to each individual service; I.e. for Cloudflared, my request above. Or for Supabase, an easy tool to help you visualize the parts missing from Selfhosted that are in Supabase SaaS/Cloud and perhaps an API to interface with it. **This would make Coolify the single self-hosted PaaS with scripting for templates, but also an extension system allowing new functionality.**\n\nIf you are interested in discussing, claiming or collaborating on one of these bounties, see the little repo I made to track this here:\nhttps://github.com/rootacc3ss/coolify-bounties/tree/main",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7458"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7458",
              "body": "### Error Message and Logs\n\n**Bounty! $15.00 on Algora.io; will add ASAP, need to figure out how to use it.**\n\nWhen following these documents from Supabase pertaining to the latest selfhosted Supabase docker setup:\nhttps://supabase.com/docs/guides/self-hosting/enable-mcp\n_you will notice the following..._\n\n1. There is no configuration to turn this on or off with ease, or even commented out docker-compose, nor any notes.\n2. With how we expose Kong via URL by default, the approach in the document could be messy or unsafe\n3. It looks like additional configuration may be required if there are multiple Supabase instances on the same server with individual /mcp exposures as Traefik is handling the routing and everything is using the same ports, etc...\n\n**I am looking for a \"work around\" as the resolution for this bounty.** That is acceptable, but I will require **at minimum a tutorial below** that figures out how to get around this bug/issue and properly documents the following:\n\n- How to configure the MCP and use it on local network\n- How to setup Wireguard to properly allow for usage of this MCP\n- How to configure Cursor/Claude Code/Windsurf to use this MCP\n- **MOST IMPORTANTLY, HOW TO CONNECT TO DIFFERENT SUPABASE INSTANCES ON THE SAME COOLIFY INSTANCE (assuming all of them are running the default Service template)**\n\nCreating a fix within the system we have to spin up and manage a Supabase instance may be difficult due to the template system's restraints, but if you want to work on that complaint of mine and **earn much more than $15**, you can see the bottom of this post. I list off the other bounties I will be offering and putting up cash for upon clearing some wires and hopefully seeing someone (or a few people) dedicate time to it.\n\n### Steps to Reproduce\n\n1. Follow docs linked above\n2. Attempt to edit the docker and piece it all together as tutorial says\n3. ???\n\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nUbuntu 24.04.03\n\n### Additional Information\n\nI am starting this bounty small as I have no clue how this system works and if I will be able to add crypto or not. I want to list these other bounties here firstly to see if there is any immediate response for \n\n**If you claim the small bounty for this, I have a few more I am willing to put in to place -- just let me know if you're interested and make sure to clear whichever one you wish to do with me to I can post the bounty for it:**\n\n- **[$35]** Better Cloudflared/Cloudflare management tools (easy exclusions and inclusions by project, IP, etc... manage domains and subdomains via Cloudflare Zero Trust or DNS settings automatically -- or at least though a portal of some sort)\n- **[$15]** Improved Supabase template (easily configure MCP properly using some sort of fix from this thread, configure mail server for automated mail and OTP with ease, set up external S3 with ease, etc -- I can contribute what I have learned from messing with the template)\n- **[$25]** Working MailCow OR Stalwart+Roundcube \"Service\" template... It's time...\n- **[$XXX]** CoolifyAI -- add API key, get AI assistant w/ knowledge-base similar to the Supabase assistant, ideally with GitHub issue lookup and basic research capability  \n- **[$XXX - $X,XXX]** More proper, fleshed out \"Services\" template system WITH ability to add remote repositories outside of the official Coolify templates; setup scripting w/ select-able options, easily modify docker template or automations/commands with checkboxes, dropdowns and input fields and the works. Ideally, a system in which \"addons\" in these same repositories as the whole \"Services\" themselves can be added on to each individual service; I.e. for Cloudflared, my request above. Or for Supabase, an easy tool to help you visualize the parts missing from Selfhosted that are in Supabase SaaS/Cloud and perhaps an API to interface with it. **This would make Coolify the single self-hosted PaaS with scripting for templates, but also an extension system allowing new functionality.**\n\nIf you are interested in discussing, claiming or collaborating on one of these bounties, see the little repo I made to track this here:\nhttps://github.com/rootacc3ss/coolify-bounties/tree/main",
              "url": "https://github.com/coollabsio/coolify/issues/7458",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7423",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T07:43:52.721Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:52.721Z",
            "created_at": "2025-12-12T07:43:52.721Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7423",
              "status": "open",
              "type": "issue",
              "number": 7423,
              "title": "[Enhancement]: Use pgBackRest for Postgres backups",
              "source": {
                "data": {
                  "id": "source-coollabsio#7423",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Use pgBackRest for Postgres backups",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\nImplement support for using pgBackRest for Postgres backups, ideally as the new default for Postgres.\n\nThis will enable incremental backups and make the backup experience 100x better for large DBs using Postgres. The current backup system is good, but starts to have failures for larger DBs. The current backup system also causes huge S3 bills for larger DBs (ex. nightly backups of 100gb DBs start to add up).\n\nThis must also support the backups API.\n\n$1,000 USD bounty once this is merged into https://app.coolify.io's/ instance and I've verified it works on Postgres DBs with 100gb of data in them.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com/), a charity that supports teenagers who love computers and electronics! We previously funded database SSL support and the creation of the backups API.",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7423"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7423",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\nImplement support for using pgBackRest for Postgres backups, ideally as the new default for Postgres.\n\nThis will enable incremental backups and make the backup experience 100x better for large DBs using Postgres. The current backup system is good, but starts to have failures for larger DBs. The current backup system also causes huge S3 bills for larger DBs (ex. nightly backups of 100gb DBs start to add up).\n\nThis must also support the backups API.\n\n$1,000 USD bounty once this is merged into https://app.coolify.io's/ instance and I've verified it works on Postgres DBs with 100gb of data in them.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com/), a charity that supports teenagers who love computers and electronics! We previously funded database SSL support and the creation of the backups API.",
              "url": "https://github.com/coollabsio/coolify/issues/7423",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#6519",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T07:43:52.884Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:52.884Z",
            "created_at": "2025-12-12T07:43:52.884Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#6519",
              "status": "open",
              "type": "issue",
              "number": 6519,
              "title": "[Enhancement]: Filebrowser for Containerlevel",
              "source": {
                "data": {
                  "id": "source-coollabsio#6519",
                  "user": {
                    "login": "swissbyte",
                    "id": 33572050,
                    "node_id": "MDQ6VXNlcjMzNTcyMDUw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/33572050?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/swissbyte",
                    "html_url": "https://github.com/swissbyte",
                    "followers_url": "https://api.github.com/users/swissbyte/followers",
                    "following_url": "https://api.github.com/users/swissbyte/following{/other_user}",
                    "gists_url": "https://api.github.com/users/swissbyte/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/swissbyte/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/swissbyte/subscriptions",
                    "organizations_url": "https://api.github.com/users/swissbyte/orgs",
                    "repos_url": "https://api.github.com/users/swissbyte/repos",
                    "events_url": "https://api.github.com/users/swissbyte/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/swissbyte/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Filebrowser for Containerlevel",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\nI would like to get the ability to have a filebrowser on containerlevel. The idea is, that, for example, one can download or upload config file or images or any other type of files within the scope of the container. This includes mounts and also the overlay fs. Just a filebrowser for everything that you can see inside the container itself. \n\nPrio 1: mapped folders\nPrio 2: everything \"inside\" the container. \n\nIt should support: \n\n- Browsing like windows explorer or nautilus under linux\n- Upload and download single files\n- Upload and download folders\n- Create folders\n- Delete folders / files\n- Check Filesize\n- Check permissions (optional: set them)\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/6519"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#6519",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\nI would like to get the ability to have a filebrowser on containerlevel. The idea is, that, for example, one can download or upload config file or images or any other type of files within the scope of the container. This includes mounts and also the overlay fs. Just a filebrowser for everything that you can see inside the container itself. \n\nPrio 1: mapped folders\nPrio 2: everything \"inside\" the container. \n\nIt should support: \n\n- Browsing like windows explorer or nautilus under linux\n- Upload and download single files\n- Upload and download folders\n- Create folders\n- Delete folders / files\n- Check Filesize\n- Check permissions (optional: set them)\n",
              "url": "https://github.com/coollabsio/coolify/issues/6519",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7110",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T07:43:53.013Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:53.013Z",
            "created_at": "2025-12-12T07:43:53.013Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7110",
              "status": "open",
              "type": "issue",
              "number": 7110,
              "title": "[Enhancement]: Update Clickhouse template",
              "source": {
                "data": {
                  "id": "source-coollabsio#7110",
                  "user": {
                    "login": "ronenteva",
                    "id": 2454954,
                    "node_id": "MDQ6VXNlcjI0NTQ5NTQ=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/2454954?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ronenteva",
                    "html_url": "https://github.com/ronenteva",
                    "followers_url": "https://api.github.com/users/ronenteva/followers",
                    "following_url": "https://api.github.com/users/ronenteva/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ronenteva/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ronenteva/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ronenteva/subscriptions",
                    "organizations_url": "https://api.github.com/users/ronenteva/orgs",
                    "repos_url": "https://api.github.com/users/ronenteva/repos",
                    "events_url": "https://api.github.com/users/ronenteva/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ronenteva/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Update Clickhouse template",
                  "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the Clickhouse template is using `bitnamilegacy/clickhouse` which is not updated anymore.\nI believe the correct image to be used is `clickhouse:lts`.\n\nSimply changing the image doesn't work, probably just different environment variables.\nThere should be a migration path so data won't be lost (written explanation is fine).\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7110"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7110",
              "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the Clickhouse template is using `bitnamilegacy/clickhouse` which is not updated anymore.\nI believe the correct image to be used is `clickhouse:lts`.\n\nSimply changing the image doesn't work, probably just different environment variables.\nThere should be a migration path so data won't be lost (written explanation is fine).\n",
              "url": "https://github.com/coollabsio/coolify/issues/7110",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#6894",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T07:43:53.154Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:53.154Z",
            "created_at": "2025-12-12T07:43:53.154Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#6894",
              "status": "open",
              "type": "issue",
              "number": 6894,
              "title": "[Enhancement]: Project-specific members",
              "source": {
                "data": {
                  "id": "source-coollabsio#6894",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Project-specific members",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n$1,000 USD bounty.\n\nAdd support for project-specific team members.\n\nProblem: I have team members I want to add to a project on Coolify, but I dont want to give them access to the full account and to all projects on the server. Instead, I want to invite them to a specific project on Coolify and for them to only have access to that project.\n\nAdditionally, I want to optionally allow the project-specific member to deploy their own apps on the servers on the account. This will just create a new project in the Team with them as a project-specific member.\n\nI should be able to manage all project-specific members from the main team page in addition to on each projects page.\n\nAny APIs that exist for managing team members should also work for project-specific members.\n\nThe purpose of this bounty is to create a secure way to give people limited access to projects on Coolify. They must not be able to break out of their permissions. For example, if I can SSH into a server as a project member using one of the keys - that would allow me to break out of my permissions.\n\nAcceptance criteria: Once your PR is merged and deployed on Coolify Cloud, I will test the features and award the bounty. Thanks!\n\n[Hack Club](https://hackclub.com) previously awarded bounties to implement database SSL and APIs to manage backups. Were a nonprofit for teenage coders!",
                  "html_url": "https://github.com/coollabsio/coolify/issues/6894"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#6894",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n$1,000 USD bounty.\n\nAdd support for project-specific team members.\n\nProblem: I have team members I want to add to a project on Coolify, but I dont want to give them access to the full account and to all projects on the server. Instead, I want to invite them to a specific project on Coolify and for them to only have access to that project.\n\nAdditionally, I want to optionally allow the project-specific member to deploy their own apps on the servers on the account. This will just create a new project in the Team with them as a project-specific member.\n\nI should be able to manage all project-specific members from the main team page in addition to on each projects page.\n\nAny APIs that exist for managing team members should also work for project-specific members.\n\nThe purpose of this bounty is to create a secure way to give people limited access to projects on Coolify. They must not be able to break out of their permissions. For example, if I can SSH into a server as a project member using one of the keys - that would allow me to break out of my permissions.\n\nAcceptance criteria: Once your PR is merged and deployed on Coolify Cloud, I will test the features and award the bounty. Thanks!\n\n[Hack Club](https://hackclub.com) previously awarded bounties to implement database SSL and APIs to manage backups. Were a nonprofit for teenage coders!",
              "url": "https://github.com/coollabsio/coolify/issues/6894",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#6567",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T07:43:53.290Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T07:43:53.290Z",
            "created_at": "2025-12-12T07:43:53.290Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#6567",
              "status": "open",
              "type": "issue",
              "number": 6567,
              "title": "[Enhancement]: Add Soju IRC bouncer",
              "source": {
                "data": {
                  "id": "source-coollabsio#6567",
                  "user": {
                    "login": "XEJK",
                    "id": 4692876,
                    "node_id": "MDQ6VXNlcjQ2OTI4NzY=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/4692876?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/XEJK",
                    "html_url": "https://github.com/XEJK",
                    "followers_url": "https://api.github.com/users/XEJK/followers",
                    "following_url": "https://api.github.com/users/XEJK/following{/other_user}",
                    "gists_url": "https://api.github.com/users/XEJK/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/XEJK/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/XEJK/subscriptions",
                    "organizations_url": "https://api.github.com/users/XEJK/orgs",
                    "repos_url": "https://api.github.com/users/XEJK/repos",
                    "events_url": "https://api.github.com/users/XEJK/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/XEJK/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Add Soju IRC bouncer",
                  "body": "### Request Type\n\nNew Service\n\n### Description\n\nIt would be nice to add the Soju IRC bouncer to the list of services.\nThe documentation is here: \n1. https://codeberg.org/emersion/soju/src/branch/master/doc/getting-started.md\n2. https://codeberg.org/emersion/soju-containers\n3. https://codeberg.org/emersion/soju/src/branch/master/doc/file-upload.md\n\nIt's based on a docker compose seems to need some extra thought since user creation is done through the command line \n\n\nWhen the template is merged in Coolify and I can spin-up a working instance of soju \nincluding file upload support, secure connections, and full support for the protocols supported by soju wjhich can be tested using an IRCv3 compatible client such as goguma or halloy will the attached bounty be seen as completed.\n\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/6567"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#6567",
              "body": "### Request Type\n\nNew Service\n\n### Description\n\nIt would be nice to add the Soju IRC bouncer to the list of services.\nThe documentation is here: \n1. https://codeberg.org/emersion/soju/src/branch/master/doc/getting-started.md\n2. https://codeberg.org/emersion/soju-containers\n3. https://codeberg.org/emersion/soju/src/branch/master/doc/file-upload.md\n\nIt's based on a docker compose seems to need some extra thought since user creation is done through the command line \n\n\nWhen the template is merged in Coolify and I can spin-up a working instance of soju \nincluding file upload support, secure connections, and full support for the protocols supported by soju wjhich can be tested using an IRCv3 compatible client such as goguma or halloy will the attached bounty be seen as completed.\n\n",
              "url": "https://github.com/coollabsio/coolify/issues/6567",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          }
        ],
        "next_cursor": null
      }
    }
  }
}