{
  "result": {
    "data": {
      "json": {
        "items": [
          {
            "id": "permitio#716",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "permitio",
              "id": "generated-permitio",
              "name": "Permitio",
              "description": "",
              "members": [],
              "display_name": "Permitio",
              "created_at": "2025-12-12T23:33:00.823Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/permitio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "permitio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:00.823Z",
            "created_at": "2025-12-12T23:33:00.823Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-permitio#716",
              "status": "open",
              "type": "issue",
              "number": 716,
              "title": "Error resolving broadcast hostname being swallowed",
              "source": {
                "data": {
                  "id": "source-permitio#716",
                  "user": {
                    "login": "keyz182",
                    "id": 693408,
                    "node_id": "MDQ6VXNlcjY5MzQwOA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/693408?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/keyz182",
                    "html_url": "https://github.com/keyz182",
                    "followers_url": "https://api.github.com/users/keyz182/followers",
                    "following_url": "https://api.github.com/users/keyz182/following{/other_user}",
                    "gists_url": "https://api.github.com/users/keyz182/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/keyz182/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/keyz182/subscriptions",
                    "organizations_url": "https://api.github.com/users/keyz182/orgs",
                    "repos_url": "https://api.github.com/users/keyz182/repos",
                    "events_url": "https://api.github.com/users/keyz182/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/keyz182/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Error resolving broadcast hostname being swallowed",
                  "body": "**Describe the bug**\r\n\r\nWe had a deployment of opal-server that we'd typoed the broadcast URI. We were seeing websockets disconnect errors in the clients, but no errors server side, so no clues it was the broadcast URI. \r\n\r\nAfter turning debug logging on for the server, I spotted the following output:\r\n\r\n```\r\n2024-12-04T15:27:01.018085+0000| fastapi_websocket_rpc.websocket_rpc_e...| INFO  | Client connected\r\n2024-12-04T15:27:01.018500+0000| websockets.legacy.server                | INFO  | connection open\r\n2024-12-04T15:27:01.022749+0000| fastapi_websocket_rpc.rpc_channel       |DEBUG  | Handling RPC request - {'request': RpcRequest(method='_ping_', arguments={}, call_id='5d8d421e3dc94751a035b202644c8e8a'), 'channel': '72c2a547ffc64741bd095079bc778d7d'}\r\n2024-12-04T15:27:01.023420+0000| fastapi_websocket_pubsub.pub_sub_server |DEBUG  | task is done: {<Task finished name='Task-3053' coro=<EventBroadcaster.__read_notifications__() done, defined at /usr/local/lib/python3.10/site-packages/fastapi_websocket_pubsub/event_broadcaster.py:245> exception=gaierror(-2, 'Name or service not known')>}\r\n2024-12-04T15:27:01.023565+0000| fastapi_websocket_pubsub.event_broadc...| INFO  | Cancelling broadcast listen task\r\n2024-12-04T15:27:01.023677+0000| fastapi_websocket_pubsub.event_broadc...|DEBUG  | Unsubscribing from ALL TOPICS\r\n2024-12-04T15:27:01.023790+0000| fastapi_websocket_pubsub.event_notifier |DEBUG  | Removing Subscription of topic='__EventNotifier_ALL_TOPICS__' for subscriber=cc43be7c3ebb41e1b4869ace10d213db\r\n2024-12-04T15:27:01.023948+0000| fastapi_websocket_rpc.websocket_rpc_e...| INFO  | Client connection failed - 42723 :: 72c2a547ffc64741bd095079bc778d7d\r\n2024-12-04T15:27:01.024165+0000| fastapi_websocket_pubsub.pub_sub_server |DEBUG  | Leaving endpoint's main loop\r\n2024-12-04T15:27:01.026785+0000| websockets.legacy.server                | INFO  | connection closed\r\n```\r\n\r\nBased on the 4th line, I went to look at `fastapi_websocket_pubsub/event_broadcaster.py:245` and saw it was referencing the broadcast URI, at which point I double checked ours and saw the typo. \r\n\r\nWhat I believe to be a bug is that the error is being swallowed, and should probably be elevated to an `ERROR` level log for visibility.\r\n\r\n**To Reproduce**\r\nSet the broadcast URI to an invalid value - in our case, a postgres URI with a hostname that didn't resolve.\r\n\r\nLogs: [se616-opal-opal-server-545c454db-hx2nc.log](https://github.com/user-attachments/files/18010731/se616-opal-opal-server-545c454db-hx2nc.log)\r\n\r\n**Expected behavior**\r\nA clear error level log to indicate that the broadcast URI could not be resolved\r\n\r\n**OPAL version**\r\n - Version: Client - 0.7.15, Server - 0.7.8\r\n",
                  "html_url": "https://github.com/permitio/opal/issues/716"
                },
                "type": "github"
              },
              "hash": "permitio/opal#716",
              "body": "**Describe the bug**\r\n\r\nWe had a deployment of opal-server that we'd typoed the broadcast URI. We were seeing websockets disconnect errors in the clients, but no errors server side, so no clues it was the broadcast URI. \r\n\r\nAfter turning debug logging on for the server, I spotted the following output:\r\n\r\n```\r\n2024-12-04T15:27:01.018085+0000| fastapi_websocket_rpc.websocket_rpc_e...| INFO  | Client connected\r\n2024-12-04T15:27:01.018500+0000| websockets.legacy.server                | INFO  | connection open\r\n2024-12-04T15:27:01.022749+0000| fastapi_websocket_rpc.rpc_channel       |DEBUG  | Handling RPC request - {'request': RpcRequest(method='_ping_', arguments={}, call_id='5d8d421e3dc94751a035b202644c8e8a'), 'channel': '72c2a547ffc64741bd095079bc778d7d'}\r\n2024-12-04T15:27:01.023420+0000| fastapi_websocket_pubsub.pub_sub_server |DEBUG  | task is done: {<Task finished name='Task-3053' coro=<EventBroadcaster.__read_notifications__() done, defined at /usr/local/lib/python3.10/site-packages/fastapi_websocket_pubsub/event_broadcaster.py:245> exception=gaierror(-2, 'Name or service not known')>}\r\n2024-12-04T15:27:01.023565+0000| fastapi_websocket_pubsub.event_broadc...| INFO  | Cancelling broadcast listen task\r\n2024-12-04T15:27:01.023677+0000| fastapi_websocket_pubsub.event_broadc...|DEBUG  | Unsubscribing from ALL TOPICS\r\n2024-12-04T15:27:01.023790+0000| fastapi_websocket_pubsub.event_notifier |DEBUG  | Removing Subscription of topic='__EventNotifier_ALL_TOPICS__' for subscriber=cc43be7c3ebb41e1b4869ace10d213db\r\n2024-12-04T15:27:01.023948+0000| fastapi_websocket_rpc.websocket_rpc_e...| INFO  | Client connection failed - 42723 :: 72c2a547ffc64741bd095079bc778d7d\r\n2024-12-04T15:27:01.024165+0000| fastapi_websocket_pubsub.pub_sub_server |DEBUG  | Leaving endpoint's main loop\r\n2024-12-04T15:27:01.026785+0000| websockets.legacy.server                | INFO  | connection closed\r\n```\r\n\r\nBased on the 4th line, I went to look at `fastapi_websocket_pubsub/event_broadcaster.py:245` and saw it was referencing the broadcast URI, at which point I double checked ours and saw the typo. \r\n\r\nWhat I believe to be a bug is that the error is being swallowed, and should probably be elevated to an `ERROR` level log for visibility.\r\n\r\n**To Reproduce**\r\nSet the broadcast URI to an invalid value - in our case, a postgres URI with a hostname that didn't resolve.\r\n\r\nLogs: [se616-opal-opal-server-545c454db-hx2nc.log](https://github.com/user-attachments/files/18010731/se616-opal-opal-server-545c454db-hx2nc.log)\r\n\r\n**Expected behavior**\r\nA clear error level log to indicate that the broadcast URI could not be resolved\r\n\r\n**OPAL version**\r\n - Version: Client - 0.7.15, Server - 0.7.8\r\n",
              "url": "https://github.com/permitio/opal/issues/716",
              "tech": [
                "go"
              ],
              "repo_name": "opal",
              "repo_owner": "permitio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "permitio#677",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "permitio",
              "id": "generated-permitio",
              "name": "Permitio",
              "description": "",
              "members": [],
              "display_name": "Permitio",
              "created_at": "2025-12-12T23:33:01.181Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/permitio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "permitio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:01.181Z",
            "created_at": "2025-12-12T23:33:01.181Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-permitio#677",
              "status": "open",
              "type": "issue",
              "number": 677,
              "title": "Create E2E tests framework using PyTest",
              "source": {
                "data": {
                  "id": "source-permitio#677",
                  "user": {
                    "login": "danyi1212",
                    "id": 12188774,
                    "node_id": "MDQ6VXNlcjEyMTg4Nzc0",
                    "avatar_url": "https://avatars.githubusercontent.com/u/12188774?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/danyi1212",
                    "html_url": "https://github.com/danyi1212",
                    "followers_url": "https://api.github.com/users/danyi1212/followers",
                    "following_url": "https://api.github.com/users/danyi1212/following{/other_user}",
                    "gists_url": "https://api.github.com/users/danyi1212/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/danyi1212/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/danyi1212/subscriptions",
                    "organizations_url": "https://api.github.com/users/danyi1212/orgs",
                    "repos_url": "https://api.github.com/users/danyi1212/repos",
                    "events_url": "https://api.github.com/users/danyi1212/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/danyi1212/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Create E2E tests framework using PyTest",
                  "body": "We want to create a new baseline framework for writing E2E tests for OPAL Client and Server using PyTest\r\n\r\nThe test framework should do the following tasks on its baseline/initial run:\r\n* Run an OPAL Server and Client inside Docker\r\n* Initially test for health check responsivity\r\n* Check logs for errors and critical alerts\r\n* Check the client and server are connected using the [Statistics API](https://opal-v2.permit.io/redoc#tag/Server-Statistics/operation/get_statistics_statistics_get)\r\n\r\nThe acceptance criteria for this issue is the ability to run a single test command that will be based on the framework specified above and run a very basic assertion test on OPAL",
                  "html_url": "https://github.com/permitio/opal/issues/677"
                },
                "type": "github"
              },
              "hash": "permitio/opal#677",
              "body": "We want to create a new baseline framework for writing E2E tests for OPAL Client and Server using PyTest\r\n\r\nThe test framework should do the following tasks on its baseline/initial run:\r\n* Run an OPAL Server and Client inside Docker\r\n* Initially test for health check responsivity\r\n* Check logs for errors and critical alerts\r\n* Check the client and server are connected using the [Statistics API](https://opal-v2.permit.io/redoc#tag/Server-Statistics/operation/get_statistics_statistics_get)\r\n\r\nThe acceptance criteria for this issue is the ability to run a single test command that will be based on the framework specified above and run a very basic assertion test on OPAL",
              "url": "https://github.com/permitio/opal/issues/677",
              "tech": [],
              "repo_name": "opal",
              "repo_owner": "permitio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "permitio#634",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "permitio",
              "id": "generated-permitio",
              "name": "Permitio",
              "description": "",
              "members": [],
              "display_name": "Permitio",
              "created_at": "2025-12-12T23:33:01.437Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/permitio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "permitio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:01.437Z",
            "created_at": "2025-12-12T23:33:01.437Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-permitio#634",
              "status": "open",
              "type": "issue",
              "number": 634,
              "title": "OPAL Server doesn't clean up symbolic links when github is down",
              "source": {
                "data": {
                  "id": "source-permitio#634",
                  "user": {
                    "login": "kreyyser",
                    "id": 8156669,
                    "node_id": "MDQ6VXNlcjgxNTY2Njk=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/8156669?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kreyyser",
                    "html_url": "https://github.com/kreyyser",
                    "followers_url": "https://api.github.com/users/kreyyser/followers",
                    "following_url": "https://api.github.com/users/kreyyser/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kreyyser/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kreyyser/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kreyyser/subscriptions",
                    "organizations_url": "https://api.github.com/users/kreyyser/orgs",
                    "repos_url": "https://api.github.com/users/kreyyser/repos",
                    "events_url": "https://api.github.com/users/kreyyser/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kreyyser/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "OPAL Server doesn't clean up symbolic links when github is down",
                  "body": "When opal server has github policies setup and github is down for some time opal server seems like spawn zombie processes but apparently looks like it is just a list of symbolic links that are not cleaned up.\r\n\r\n**To Reproduce**\r\nrun OPAL with github policies source as a container\r\nmake somehow github return 500\r\nlist processes in opal server container\r\n\r\n**Expected behavior**\r\nNo zombie processes or broken links proc directory\r\n\r\n**Screenshots**\r\n<img width=\"1329\" alt=\"opal-server-proc\" src=\"https://github.com/user-attachments/assets/9f4fa8a5-9867-45d2-a21d-2a7c133ac9c1\">\r\n\r\n**OPAL version**\r\n - Version: 0.7.6\r\n",
                  "html_url": "https://github.com/permitio/opal/issues/634"
                },
                "type": "github"
              },
              "hash": "permitio/opal#634",
              "body": "When opal server has github policies setup and github is down for some time opal server seems like spawn zombie processes but apparently looks like it is just a list of symbolic links that are not cleaned up.\r\n\r\n**To Reproduce**\r\nrun OPAL with github policies source as a container\r\nmake somehow github return 500\r\nlist processes in opal server container\r\n\r\n**Expected behavior**\r\nNo zombie processes or broken links proc directory\r\n\r\n**Screenshots**\r\n<img width=\"1329\" alt=\"opal-server-proc\" src=\"https://github.com/user-attachments/assets/9f4fa8a5-9867-45d2-a21d-2a7c133ac9c1\">\r\n\r\n**OPAL version**\r\n - Version: 0.7.6\r\n",
              "url": "https://github.com/permitio/opal/issues/634",
              "tech": [],
              "repo_name": "opal",
              "repo_owner": "permitio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "outerbase#59",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2025-12-12T23:33:08.588Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:08.588Z",
            "created_at": "2025-12-12T23:33:08.588Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#59",
              "status": "open",
              "type": "issue",
              "number": 59,
              "title": "Database dumps do not work on large databases",
              "source": {
                "data": {
                  "id": "source-outerbase#59",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Database dumps do not work on large databases",
                  "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/59"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#59",
              "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
              "url": "https://github.com/outerbase/starbasedb/issues/59",
              "tech": [
                "go"
              ],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "outerbase#72",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2025-12-12T23:33:09.424Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:09.424Z",
            "created_at": "2025-12-12T23:33:09.424Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#72",
              "status": "open",
              "type": "issue",
              "number": 72,
              "title": "Replicate data from external source to internal source with a Plugin",
              "source": {
                "data": {
                  "id": "source-outerbase#72",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Replicate data from external source to internal source with a Plugin",
                  "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/72"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#72",
              "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
              "url": "https://github.com/outerbase/starbasedb/issues/72",
              "tech": [],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "triggerdotdev#2654",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "triggerdotdev",
              "id": "generated-triggerdotdev",
              "name": "Triggerdotdev",
              "description": "",
              "members": [],
              "display_name": "Triggerdotdev",
              "created_at": "2025-12-12T23:33:09.424Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/triggerdotdev?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "colinhacks",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:09.424Z",
            "created_at": "2025-12-12T23:33:09.424Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-triggerdotdev#2654",
              "status": "open",
              "type": "issue",
              "number": 2654,
              "title": "Schema in object being inferred differently (and weirdly)",
              "source": {
                "data": {
                  "id": "source-triggerdotdev#2654",
                  "user": {
                    "login": "ericallam",
                    "id": 534,
                    "node_id": "MDQ6VXNlcjUzNA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/534?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ericallam",
                    "html_url": "https://github.com/ericallam",
                    "followers_url": "https://api.github.com/users/ericallam/followers",
                    "following_url": "https://api.github.com/users/ericallam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ericallam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ericallam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ericallam/subscriptions",
                    "organizations_url": "https://api.github.com/users/ericallam/orgs",
                    "repos_url": "https://api.github.com/users/ericallam/repos",
                    "events_url": "https://api.github.com/users/ericallam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ericallam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Schema in object being inferred differently (and weirdly)",
                  "body": "See the following TS snippet:\r\n\r\n```ts\r\nimport { z } from \"zod\";\r\n\r\nconst EventNameSchema = z.string().or(z.array(z.string()));\r\n\r\ntype EventName = z.infer<typeof EventNameSchema>;\r\n// EventName is string | string[]\r\n\r\nconst EventSchema = z.object({\r\n  name: z.string().or(z.array(z.string())) // this is the same as the EventNameSchema\r\n});\r\n\r\ntype EventWithName = z.infer<typeof EventSchema>;\r\ntype EventName2 = EventWithName[\"name\"];\r\n// EventName2 is (string | string[]) & (string | string[] | undefined)\r\n```\r\n\r\nAnd the TS playground: [link](https://www.typescriptlang.org/play?#code/JYWwDg9gTgLgBAbzgLzgXzgMyhEcBEyEAJvgNwBQFAxhAHYDO8AogG4CmdMAcgIYjsAytQAW7ELzgBeFADomUYHQDmACgCUs6KuSzeUKLwCeO+TEUqN69ZQowjYdnDace-JzN1LM7KAB57RwhMZw4uPgFhMQkAPkoAenjQ1winYAY4BSVlOAAfTPNsgG0AXSpaRhYwmCjxSU8tACMAK3ZqGFUECjg4OncALjksy01tXX1DE11htWt1CjQbKkCnFy4AdWAYEVTpOW9fAId2YOSuWtjKFbO3AQAmPbWYTe3Uovw+gXwShKSn1Ie6TgqhmeQKFmUpXUcAAZMDQfkZqUwQBXOjEdiYJTsYjqIA)\r\n\r\nI'm not sure if this is intended or a bug or maybe just a user error. Using zod `3.21.4` and TS `4.8.4`",
                  "html_url": "https://github.com/colinhacks/zod/issues/2654"
                },
                "type": "github"
              },
              "hash": "colinhacks/zod#2654",
              "body": "See the following TS snippet:\r\n\r\n```ts\r\nimport { z } from \"zod\";\r\n\r\nconst EventNameSchema = z.string().or(z.array(z.string()));\r\n\r\ntype EventName = z.infer<typeof EventNameSchema>;\r\n// EventName is string | string[]\r\n\r\nconst EventSchema = z.object({\r\n  name: z.string().or(z.array(z.string())) // this is the same as the EventNameSchema\r\n});\r\n\r\ntype EventWithName = z.infer<typeof EventSchema>;\r\ntype EventName2 = EventWithName[\"name\"];\r\n// EventName2 is (string | string[]) & (string | string[] | undefined)\r\n```\r\n\r\nAnd the TS playground: [link](https://www.typescriptlang.org/play?#code/JYWwDg9gTgLgBAbzgLzgXzgMyhEcBEyEAJvgNwBQFAxhAHYDO8AogG4CmdMAcgIYjsAytQAW7ELzgBeFADomUYHQDmACgCUs6KuSzeUKLwCeO+TEUqN69ZQowjYdnDace-JzN1LM7KAB57RwhMZw4uPgFhMQkAPkoAenjQ1winYAY4BSVlOAAfTPNsgG0AXSpaRhYwmCjxSU8tACMAK3ZqGFUECjg4OncALjksy01tXX1DE11htWt1CjQbKkCnFy4AdWAYEVTpOW9fAId2YOSuWtjKFbO3AQAmPbWYTe3Uovw+gXwShKSn1Ie6TgqhmeQKFmUpXUcAAZMDQfkZqUwQBXOjEdiYJTsYjqIA)\r\n\r\nI'm not sure if this is intended or a bug or maybe just a user error. Using zod `3.21.4` and TS `4.8.4`",
              "url": "https://github.com/colinhacks/zod/issues/2654",
              "tech": [
                "go"
              ],
              "repo_name": "zod",
              "repo_owner": "colinhacks",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7596",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T23:33:01.181Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:01.181Z",
            "created_at": "2025-12-12T23:33:01.181Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7596",
              "status": "open",
              "type": "issue",
              "number": 7596,
              "title": "[Enhancement]: new deployment page",
              "source": {
                "data": {
                  "id": "source-coollabsio#7596",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: new deployment page",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n- Add deployments to sidebar\n- Show past deployments (all of them)\n- Add a filter on the top:\n  - Filter by project\n  - Filter by server\n  - Filter by sources\n  - Filter by status (queued, pending, done)\n- Show live updates / refresh?\n- Hide filters if only 1 server / 1 source\n\n## Design inspiration\n\nVercel example:\n\n<img width=\"1362\" height=\"967\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e46d7470-fff1-46c5-8011-63ba82119db2\" />\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7596"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7596",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n- Add deployments to sidebar\n- Show past deployments (all of them)\n- Add a filter on the top:\n  - Filter by project\n  - Filter by server\n  - Filter by sources\n  - Filter by status (queued, pending, done)\n- Show live updates / refresh?\n- Hide filters if only 1 server / 1 source\n\n## Design inspiration\n\nVercel example:\n\n<img width=\"1362\" height=\"967\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e46d7470-fff1-46c5-8011-63ba82119db2\" />\n",
              "url": "https://github.com/coollabsio/coolify/issues/7596",
              "tech": [
                "go"
              ],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7529",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T23:33:01.438Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:01.438Z",
            "created_at": "2025-12-12T23:33:01.438Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7529",
              "status": "open",
              "type": "issue",
              "number": 7529,
              "title": "[Enhancement]: Enable backup restore/import for ServiceDatabase (Docker Compose databases)",
              "source": {
                "data": {
                  "id": "source-coollabsio#7529",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Enable backup restore/import for ServiceDatabase (Docker Compose databases)",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nDatabases created via Docker Compose deployments (`ServiceDatabase`) can create backups but cannot restore/import them through the UI. The import functionality only supports Standalone database types.\n\n### Current Behavior\n\n| Database Type | Backup | Restore/Import |\n|---|---|---|\n| StandalonePostgresql |  |  |\n| StandaloneMysql |  |  |\n| StandaloneMariadb |  |  |\n| StandaloneMongodb |  |  |\n| **ServiceDatabase** (from Docker Compose) |  |  |\n\n### Expected Behavior\n\nServiceDatabase should support restore/import functionality, similar to Standalone databases.\n\n### Technical Details\n\n**File:** `app/Livewire/Project/Database/Import.php`\n\nThe `buildRestoreCommand()` method (line 576-614) only handles Standalone database classes:\n\n```php\nswitch ($this->resource->getMorphClass()) {\n    case \\App\\Models\\StandaloneMariadb::class:\n        // ...\n    case \\App\\Models\\StandaloneMysql::class:\n        // ...\n    case \\App\\Models\\StandalonePostgresql::class:\n        // ...\n    case \\App\\Models\\StandaloneMongodb::class:\n        // ...\n    default:\n        $restoreCommand = ''; // ServiceDatabase falls here\n}\n```\n\n### Proposed Solution\n\nAdd support for `ServiceDatabase` in `Import.php`:\n\n1. In `buildRestoreCommand()`, add a case for `ServiceDatabase`:\n```php\ncase \\App\\Models\\ServiceDatabase::class:\n    $dbType = $this->resource->databaseType(); // Returns 'standalone-postgresql', etc.\n    // Build restore command based on $dbType\n    break;\n```\n\n2. The `ServiceDatabase->databaseType()` method already returns the database type (e.g., `standalone-postgresql`, `standalone-mysql`), which can be used to determine the correct restore command.\n\n3. Update `getContainers()` to properly handle ServiceDatabase container naming:\n```php\n// ServiceDatabase container name format: {service-name}-{service-uuid}\n$this->container = $this->resource->name . '-' . $this->resource->service->uuid;\n```\n\n### Related Code\n\n- `app/Livewire/Project/Database/Import.php` - Import/restore component\n- `app/Models/ServiceDatabase.php` - Has `databaseType()` method\n- `app/Jobs/DatabaseBackupJob.php` - Already supports ServiceDatabase for backups\n\n### Use Case\n\nUsers deploying databases via Docker Compose (e.g., `postgres:17-alpine` in a compose file) need the ability to restore backups through the Coolify UI, just like Standalone database deployments.\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7529"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7529",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nDatabases created via Docker Compose deployments (`ServiceDatabase`) can create backups but cannot restore/import them through the UI. The import functionality only supports Standalone database types.\n\n### Current Behavior\n\n| Database Type | Backup | Restore/Import |\n|---|---|---|\n| StandalonePostgresql |  |  |\n| StandaloneMysql |  |  |\n| StandaloneMariadb |  |  |\n| StandaloneMongodb |  |  |\n| **ServiceDatabase** (from Docker Compose) |  |  |\n\n### Expected Behavior\n\nServiceDatabase should support restore/import functionality, similar to Standalone databases.\n\n### Technical Details\n\n**File:** `app/Livewire/Project/Database/Import.php`\n\nThe `buildRestoreCommand()` method (line 576-614) only handles Standalone database classes:\n\n```php\nswitch ($this->resource->getMorphClass()) {\n    case \\App\\Models\\StandaloneMariadb::class:\n        // ...\n    case \\App\\Models\\StandaloneMysql::class:\n        // ...\n    case \\App\\Models\\StandalonePostgresql::class:\n        // ...\n    case \\App\\Models\\StandaloneMongodb::class:\n        // ...\n    default:\n        $restoreCommand = ''; // ServiceDatabase falls here\n}\n```\n\n### Proposed Solution\n\nAdd support for `ServiceDatabase` in `Import.php`:\n\n1. In `buildRestoreCommand()`, add a case for `ServiceDatabase`:\n```php\ncase \\App\\Models\\ServiceDatabase::class:\n    $dbType = $this->resource->databaseType(); // Returns 'standalone-postgresql', etc.\n    // Build restore command based on $dbType\n    break;\n```\n\n2. The `ServiceDatabase->databaseType()` method already returns the database type (e.g., `standalone-postgresql`, `standalone-mysql`), which can be used to determine the correct restore command.\n\n3. Update `getContainers()` to properly handle ServiceDatabase container naming:\n```php\n// ServiceDatabase container name format: {service-name}-{service-uuid}\n$this->container = $this->resource->name . '-' . $this->resource->service->uuid;\n```\n\n### Related Code\n\n- `app/Livewire/Project/Database/Import.php` - Import/restore component\n- `app/Models/ServiceDatabase.php` - Has `databaseType()` method\n- `app/Jobs/DatabaseBackupJob.php` - Already supports ServiceDatabase for backups\n\n### Use Case\n\nUsers deploying databases via Docker Compose (e.g., `postgres:17-alpine` in a compose file) need the ability to restore backups through the Coolify UI, just like Standalone database deployments.\n",
              "url": "https://github.com/coollabsio/coolify/issues/7529",
              "tech": [
                "go"
              ],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7528",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T23:33:01.896Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:01.896Z",
            "created_at": "2025-12-12T23:33:01.896Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7528",
              "status": "open",
              "type": "issue",
              "number": 7528,
              "title": "[Enhancement]: Enable database detection and backup support for Docker Compose deployments via GitHub App",
              "source": {
                "data": {
                  "id": "source-coollabsio#7528",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Enable database detection and backup support for Docker Compose deployments via GitHub App",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nWhen deploying a Docker Compose file via GitHub App (using the `dockercompose` buildpack), database services are not detected and `ServiceDatabase` records are not created. This means automated backups are not available for databases in these deployments.\n\nHowever, when using \"Empty Docker Compose\" or one-click services (like Supabase), database detection works correctly and backups are available.\n\n### Current Behavior\n\n| Deployment Method | Model | Creates ServiceDatabase | Backups Available |\n|---|---|---|---|\n| Empty Docker Compose | `Service` |  Yes |  Yes |\n| GitHub App (dockercompose buildpack) | `Application` |  No |  No |\n| One-click Services (e.g., Supabase) | `Service` |  Yes |  Yes |\n\n### Expected Behavior\n\nDatabase services in Docker Compose files deployed via GitHub App should be detected and have backup functionality available, similar to Empty Docker Compose deployments.\n\n### Technical Details\n\nThe issue is in `bootstrap/helpers/shared.php` in the `parseDockerComposeFile()` function:\n\n**Service model path (lines 1263-2025):**\n- Calls `isDatabaseImage()` to detect databases\n- Creates `ServiceDatabase` records for detected databases\n- These databases can have scheduled backups\n\n**Application model path (lines 2026-2767):**\n- Does NOT call `isDatabaseImage()`\n- Does NOT create `ServiceDatabase` records\n- All services are treated as application containers\n- No backup support\n\n### Proposed Solution\n\nAdd database detection logic to the Application model parsing path:\n\n1. In `parseDockerComposeFile()` for the Application model (around line 2066), add:\n   ```php\n   $isDatabase = isDatabaseImage($image, $service);\n   data_set($service, 'is_database', $isDatabase);\n   ```\n\n2. Create `ServiceDatabase` records for detected database services, similar to how it's done in the Service model path.\n\n3. Alternatively, consider refactoring to share the database detection logic between both paths.\n\n### Use Case\n\nUsers deploying full-stack applications via GitHub (e.g., Next.js app + PostgreSQL + pgbouncer in a single compose file) expect database backups to work the same way as standalone database deployments or one-click services.\n\n### Related Code\n\n- `bootstrap/helpers/shared.php` - `parseDockerComposeFile()` function\n- `bootstrap/helpers/docker.php` - `isDatabaseImage()` function\n- `app/Models/ServiceDatabase.php` - Database model with backup support\n- `app/Models/ScheduledDatabaseBackup.php` - Backup scheduling\n\n### Environment\n\n- Coolify version: latest\n- Deployment method: GitHub App with dockercompose buildpack\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7528"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7528",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nWhen deploying a Docker Compose file via GitHub App (using the `dockercompose` buildpack), database services are not detected and `ServiceDatabase` records are not created. This means automated backups are not available for databases in these deployments.\n\nHowever, when using \"Empty Docker Compose\" or one-click services (like Supabase), database detection works correctly and backups are available.\n\n### Current Behavior\n\n| Deployment Method | Model | Creates ServiceDatabase | Backups Available |\n|---|---|---|---|\n| Empty Docker Compose | `Service` |  Yes |  Yes |\n| GitHub App (dockercompose buildpack) | `Application` |  No |  No |\n| One-click Services (e.g., Supabase) | `Service` |  Yes |  Yes |\n\n### Expected Behavior\n\nDatabase services in Docker Compose files deployed via GitHub App should be detected and have backup functionality available, similar to Empty Docker Compose deployments.\n\n### Technical Details\n\nThe issue is in `bootstrap/helpers/shared.php` in the `parseDockerComposeFile()` function:\n\n**Service model path (lines 1263-2025):**\n- Calls `isDatabaseImage()` to detect databases\n- Creates `ServiceDatabase` records for detected databases\n- These databases can have scheduled backups\n\n**Application model path (lines 2026-2767):**\n- Does NOT call `isDatabaseImage()`\n- Does NOT create `ServiceDatabase` records\n- All services are treated as application containers\n- No backup support\n\n### Proposed Solution\n\nAdd database detection logic to the Application model parsing path:\n\n1. In `parseDockerComposeFile()` for the Application model (around line 2066), add:\n   ```php\n   $isDatabase = isDatabaseImage($image, $service);\n   data_set($service, 'is_database', $isDatabase);\n   ```\n\n2. Create `ServiceDatabase` records for detected database services, similar to how it's done in the Service model path.\n\n3. Alternatively, consider refactoring to share the database detection logic between both paths.\n\n### Use Case\n\nUsers deploying full-stack applications via GitHub (e.g., Next.js app + PostgreSQL + pgbouncer in a single compose file) expect database backups to work the same way as standalone database deployments or one-click services.\n\n### Related Code\n\n- `bootstrap/helpers/shared.php` - `parseDockerComposeFile()` function\n- `bootstrap/helpers/docker.php` - `isDatabaseImage()` function\n- `app/Models/ServiceDatabase.php` - Database model with backup support\n- `app/Models/ScheduledDatabaseBackup.php` - Backup scheduling\n\n### Environment\n\n- Coolify version: latest\n- Deployment method: GitHub App with dockercompose buildpack\n",
              "url": "https://github.com/coollabsio/coolify/issues/7528",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7473",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T23:33:04.772Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:04.772Z",
            "created_at": "2025-12-12T23:33:04.772Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7473",
              "status": "open",
              "type": "issue",
              "number": 7473,
              "title": "[Bug]: Database Backups won't use the custom timeout in ssh command (regression)",
              "source": {
                "data": {
                  "id": "source-coollabsio#7473",
                  "user": {
                    "login": "isokosan",
                    "id": 1430946,
                    "node_id": "MDQ6VXNlcjE0MzA5NDY=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1430946?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/isokosan",
                    "html_url": "https://github.com/isokosan",
                    "followers_url": "https://api.github.com/users/isokosan/followers",
                    "following_url": "https://api.github.com/users/isokosan/following{/other_user}",
                    "gists_url": "https://api.github.com/users/isokosan/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/isokosan/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/isokosan/subscriptions",
                    "organizations_url": "https://api.github.com/users/isokosan/orgs",
                    "repos_url": "https://api.github.com/users/isokosan/repos",
                    "events_url": "https://api.github.com/users/isokosan/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/isokosan/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Database Backups won't use the custom timeout in ssh command (regression)",
                  "body": "### Error Message and Logs\n\nWe had [this issue](https://github.com/coollabsio/coolify/issues/3325) with backups exceeding timeouts and we made a new feature where we can customize the timeout settings in the backups.\n\nThis was working but seems to have regressed as the timeout setting is not being passed to the backup ssh command, instead the default 3600 is being used I'm afraid:\n\nThe process \"timeout 3600 ssh -i /var/www/html/storage/app/ssh/keys/ssh_key@jgcwgggco80sc0occ88skg0s -o StrictHos... truncated ...FoM2ROejJRRmtjT1M0NXNt\" exceeded the timeout of 3600 seconds.\n\n@Cinzya commented that this is about the SSH command now and not the backup itself:\n> I believe this is actually the SSH process timing out and not the backup itself.\n> The SSH process has a hard timeout of 3600. The backup timeout is not really passed to the SSH process to increase that timeout as well. \n> This is either an oversight or there is a specific reason why a SSH process shouldn't linger more then 3600 seconds. \n> But yes, feel free to open a new issue about it. \n\n\n### Steps to Reproduce\n\n1. Configure a database and then backups.\n2. Use the Timeout option in the dashboard to set a custom timeout, eg 10800 (default 3600 seconds)\n3. Click on Backup Now\n4. Check the command that is run by coolify to see the timeout not being passed to the SSH command\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7473"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7473",
              "body": "### Error Message and Logs\n\nWe had [this issue](https://github.com/coollabsio/coolify/issues/3325) with backups exceeding timeouts and we made a new feature where we can customize the timeout settings in the backups.\n\nThis was working but seems to have regressed as the timeout setting is not being passed to the backup ssh command, instead the default 3600 is being used I'm afraid:\n\nThe process \"timeout 3600 ssh -i /var/www/html/storage/app/ssh/keys/ssh_key@jgcwgggco80sc0occ88skg0s -o StrictHos... truncated ...FoM2ROejJRRmtjT1M0NXNt\" exceeded the timeout of 3600 seconds.\n\n@Cinzya commented that this is about the SSH command now and not the backup itself:\n> I believe this is actually the SSH process timing out and not the backup itself.\n> The SSH process has a hard timeout of 3600. The backup timeout is not really passed to the SSH process to increase that timeout as well. \n> This is either an oversight or there is a specific reason why a SSH process shouldn't linger more then 3600 seconds. \n> But yes, feel free to open a new issue about it. \n\n\n### Steps to Reproduce\n\n1. Configure a database and then backups.\n2. Use the Timeout option in the dashboard to set a custom timeout, eg 10800 (default 3600 seconds)\n3. Click on Backup Now\n4. Check the command that is run by coolify to see the timeout not being passed to the SSH command\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/7473",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7458",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T23:33:06.993Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:06.993Z",
            "created_at": "2025-12-12T23:33:06.993Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7458",
              "status": "open",
              "type": "issue",
              "number": 7458,
              "title": "[Bug + Multiple Bounties]: Official Selfhosted Supabase MCP Setup hindered by Coolify AND Bounty List",
              "source": {
                "data": {
                  "id": "source-coollabsio#7458",
                  "user": {
                    "login": "rootacc3ss",
                    "id": 192549131,
                    "node_id": "U_kgDOC3oRCw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/192549131?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/rootacc3ss",
                    "html_url": "https://github.com/rootacc3ss",
                    "followers_url": "https://api.github.com/users/rootacc3ss/followers",
                    "following_url": "https://api.github.com/users/rootacc3ss/following{/other_user}",
                    "gists_url": "https://api.github.com/users/rootacc3ss/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/rootacc3ss/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/rootacc3ss/subscriptions",
                    "organizations_url": "https://api.github.com/users/rootacc3ss/orgs",
                    "repos_url": "https://api.github.com/users/rootacc3ss/repos",
                    "events_url": "https://api.github.com/users/rootacc3ss/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/rootacc3ss/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug + Multiple Bounties]: Official Selfhosted Supabase MCP Setup hindered by Coolify AND Bounty List",
                  "body": "### Error Message and Logs\n\n**Bounty! $15.00 on Algora.io; will add ASAP, need to figure out how to use it.**\n\nWhen following these documents from Supabase pertaining to the latest selfhosted Supabase docker setup:\nhttps://supabase.com/docs/guides/self-hosting/enable-mcp\n_you will notice the following..._\n\n1. There is no configuration to turn this on or off with ease, or even commented out docker-compose, nor any notes.\n2. With how we expose Kong via URL by default, the approach in the document could be messy or unsafe\n3. It looks like additional configuration may be required if there are multiple Supabase instances on the same server with individual /mcp exposures as Traefik is handling the routing and everything is using the same ports, etc...\n\n**I am looking for a \"work around\" as the resolution for this bounty.** That is acceptable, but I will require **at minimum a tutorial below** that figures out how to get around this bug/issue and properly documents the following:\n\n- How to configure the MCP and use it on local network\n- How to setup Wireguard to properly allow for usage of this MCP\n- How to configure Cursor/Claude Code/Windsurf to use this MCP\n- **MOST IMPORTANTLY, HOW TO CONNECT TO DIFFERENT SUPABASE INSTANCES ON THE SAME COOLIFY INSTANCE (assuming all of them are running the default Service template)**\n\nCreating a fix within the system we have to spin up and manage a Supabase instance may be difficult due to the template system's restraints, but if you want to work on that complaint of mine and **earn much more than $15**, you can see the bottom of this post. I list off the other bounties I will be offering and putting up cash for upon clearing some wires and hopefully seeing someone (or a few people) dedicate time to it.\n\n### Steps to Reproduce\n\n1. Follow docs linked above\n2. Attempt to edit the docker and piece it all together as tutorial says\n3. ???\n\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nUbuntu 24.04.03\n\n### Additional Information\n\nI am starting this bounty small as I have no clue how this system works and if I will be able to add crypto or not. I want to list these other bounties here firstly to see if there is any immediate response for \n\n**If you claim the small bounty for this, I have a few more I am willing to put in to place -- just let me know if you're interested and make sure to clear whichever one you wish to do with me to I can post the bounty for it:**\n\n- **[$35]** Better Cloudflared/Cloudflare management tools (easy exclusions and inclusions by project, IP, etc... manage domains and subdomains via Cloudflare Zero Trust or DNS settings automatically -- or at least though a portal of some sort)\n- **[$15]** Improved Supabase template (easily configure MCP properly using some sort of fix from this thread, configure mail server for automated mail and OTP with ease, set up external S3 with ease, etc -- I can contribute what I have learned from messing with the template)\n- **[$25]** Working MailCow OR Stalwart+Roundcube \"Service\" template... It's time...\n- **[$XXX]** CoolifyAI -- add API key, get AI assistant w/ knowledge-base similar to the Supabase assistant, ideally with GitHub issue lookup and basic research capability  \n- **[$XXX - $X,XXX]** More proper, fleshed out \"Services\" template system WITH ability to add remote repositories outside of the official Coolify templates; setup scripting w/ select-able options, easily modify docker template or automations/commands with checkboxes, dropdowns and input fields and the works. Ideally, a system in which \"addons\" in these same repositories as the whole \"Services\" themselves can be added on to each individual service; I.e. for Cloudflared, my request above. Or for Supabase, an easy tool to help you visualize the parts missing from Selfhosted that are in Supabase SaaS/Cloud and perhaps an API to interface with it. **This would make Coolify the single self-hosted PaaS with scripting for templates, but also an extension system allowing new functionality.**\n\nIf you are interested in discussing, claiming or collaborating on one of these bounties, see the little repo I made to track this here:\nhttps://github.com/rootacc3ss/coolify-bounties/tree/main",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7458"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7458",
              "body": "### Error Message and Logs\n\n**Bounty! $15.00 on Algora.io; will add ASAP, need to figure out how to use it.**\n\nWhen following these documents from Supabase pertaining to the latest selfhosted Supabase docker setup:\nhttps://supabase.com/docs/guides/self-hosting/enable-mcp\n_you will notice the following..._\n\n1. There is no configuration to turn this on or off with ease, or even commented out docker-compose, nor any notes.\n2. With how we expose Kong via URL by default, the approach in the document could be messy or unsafe\n3. It looks like additional configuration may be required if there are multiple Supabase instances on the same server with individual /mcp exposures as Traefik is handling the routing and everything is using the same ports, etc...\n\n**I am looking for a \"work around\" as the resolution for this bounty.** That is acceptable, but I will require **at minimum a tutorial below** that figures out how to get around this bug/issue and properly documents the following:\n\n- How to configure the MCP and use it on local network\n- How to setup Wireguard to properly allow for usage of this MCP\n- How to configure Cursor/Claude Code/Windsurf to use this MCP\n- **MOST IMPORTANTLY, HOW TO CONNECT TO DIFFERENT SUPABASE INSTANCES ON THE SAME COOLIFY INSTANCE (assuming all of them are running the default Service template)**\n\nCreating a fix within the system we have to spin up and manage a Supabase instance may be difficult due to the template system's restraints, but if you want to work on that complaint of mine and **earn much more than $15**, you can see the bottom of this post. I list off the other bounties I will be offering and putting up cash for upon clearing some wires and hopefully seeing someone (or a few people) dedicate time to it.\n\n### Steps to Reproduce\n\n1. Follow docs linked above\n2. Attempt to edit the docker and piece it all together as tutorial says\n3. ???\n\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nUbuntu 24.04.03\n\n### Additional Information\n\nI am starting this bounty small as I have no clue how this system works and if I will be able to add crypto or not. I want to list these other bounties here firstly to see if there is any immediate response for \n\n**If you claim the small bounty for this, I have a few more I am willing to put in to place -- just let me know if you're interested and make sure to clear whichever one you wish to do with me to I can post the bounty for it:**\n\n- **[$35]** Better Cloudflared/Cloudflare management tools (easy exclusions and inclusions by project, IP, etc... manage domains and subdomains via Cloudflare Zero Trust or DNS settings automatically -- or at least though a portal of some sort)\n- **[$15]** Improved Supabase template (easily configure MCP properly using some sort of fix from this thread, configure mail server for automated mail and OTP with ease, set up external S3 with ease, etc -- I can contribute what I have learned from messing with the template)\n- **[$25]** Working MailCow OR Stalwart+Roundcube \"Service\" template... It's time...\n- **[$XXX]** CoolifyAI -- add API key, get AI assistant w/ knowledge-base similar to the Supabase assistant, ideally with GitHub issue lookup and basic research capability  \n- **[$XXX - $X,XXX]** More proper, fleshed out \"Services\" template system WITH ability to add remote repositories outside of the official Coolify templates; setup scripting w/ select-able options, easily modify docker template or automations/commands with checkboxes, dropdowns and input fields and the works. Ideally, a system in which \"addons\" in these same repositories as the whole \"Services\" themselves can be added on to each individual service; I.e. for Cloudflared, my request above. Or for Supabase, an easy tool to help you visualize the parts missing from Selfhosted that are in Supabase SaaS/Cloud and perhaps an API to interface with it. **This would make Coolify the single self-hosted PaaS with scripting for templates, but also an extension system allowing new functionality.**\n\nIf you are interested in discussing, claiming or collaborating on one of these bounties, see the little repo I made to track this here:\nhttps://github.com/rootacc3ss/coolify-bounties/tree/main",
              "url": "https://github.com/coollabsio/coolify/issues/7458",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7423",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T23:33:08.588Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:08.588Z",
            "created_at": "2025-12-12T23:33:08.588Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7423",
              "status": "open",
              "type": "issue",
              "number": 7423,
              "title": "[Enhancement]: Use pgBackRest for Postgres backups",
              "source": {
                "data": {
                  "id": "source-coollabsio#7423",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Use pgBackRest for Postgres backups",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\nImplement support for using pgBackRest for Postgres backups, ideally as the new default for Postgres.\n\nThis will enable incremental backups and make the backup experience 100x better for large DBs using Postgres. The current backup system is good, but starts to have failures for larger DBs. The current backup system also causes huge S3 bills for larger DBs (ex. nightly backups of 100gb DBs start to add up).\n\nThis must also support the backups API.\n\n$1,000 USD bounty once this is merged into https://app.coolify.io's/ instance and I've verified it works on Postgres DBs with 100gb of data in them.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com/), a charity that supports teenagers who love computers and electronics! We previously funded database SSL support and the creation of the backups API.",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7423"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7423",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\nImplement support for using pgBackRest for Postgres backups, ideally as the new default for Postgres.\n\nThis will enable incremental backups and make the backup experience 100x better for large DBs using Postgres. The current backup system is good, but starts to have failures for larger DBs. The current backup system also causes huge S3 bills for larger DBs (ex. nightly backups of 100gb DBs start to add up).\n\nThis must also support the backups API.\n\n$1,000 USD bounty once this is merged into https://app.coolify.io's/ instance and I've verified it works on Postgres DBs with 100gb of data in them.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com/), a charity that supports teenagers who love computers and electronics! We previously funded database SSL support and the creation of the backups API.",
              "url": "https://github.com/coollabsio/coolify/issues/7423",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#6519",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T23:33:09.424Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:09.424Z",
            "created_at": "2025-12-12T23:33:09.424Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#6519",
              "status": "open",
              "type": "issue",
              "number": 6519,
              "title": "[Enhancement]: Filebrowser for Containerlevel",
              "source": {
                "data": {
                  "id": "source-coollabsio#6519",
                  "user": {
                    "login": "swissbyte",
                    "id": 33572050,
                    "node_id": "MDQ6VXNlcjMzNTcyMDUw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/33572050?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/swissbyte",
                    "html_url": "https://github.com/swissbyte",
                    "followers_url": "https://api.github.com/users/swissbyte/followers",
                    "following_url": "https://api.github.com/users/swissbyte/following{/other_user}",
                    "gists_url": "https://api.github.com/users/swissbyte/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/swissbyte/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/swissbyte/subscriptions",
                    "organizations_url": "https://api.github.com/users/swissbyte/orgs",
                    "repos_url": "https://api.github.com/users/swissbyte/repos",
                    "events_url": "https://api.github.com/users/swissbyte/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/swissbyte/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Filebrowser for Containerlevel",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\nI would like to get the ability to have a filebrowser on containerlevel. The idea is, that, for example, one can download or upload config file or images or any other type of files within the scope of the container. This includes mounts and also the overlay fs. Just a filebrowser for everything that you can see inside the container itself. \n\nPrio 1: mapped folders\nPrio 2: everything \"inside\" the container. \n\nIt should support: \n\n- Browsing like windows explorer or nautilus under linux\n- Upload and download single files\n- Upload and download folders\n- Create folders\n- Delete folders / files\n- Check Filesize\n- Check permissions (optional: set them)\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/6519"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#6519",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\nI would like to get the ability to have a filebrowser on containerlevel. The idea is, that, for example, one can download or upload config file or images or any other type of files within the scope of the container. This includes mounts and also the overlay fs. Just a filebrowser for everything that you can see inside the container itself. \n\nPrio 1: mapped folders\nPrio 2: everything \"inside\" the container. \n\nIt should support: \n\n- Browsing like windows explorer or nautilus under linux\n- Upload and download single files\n- Upload and download folders\n- Create folders\n- Delete folders / files\n- Check Filesize\n- Check permissions (optional: set them)\n",
              "url": "https://github.com/coollabsio/coolify/issues/6519",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7110",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T23:33:09.541Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:09.541Z",
            "created_at": "2025-12-12T23:33:09.541Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7110",
              "status": "open",
              "type": "issue",
              "number": 7110,
              "title": "[Enhancement]: Update Clickhouse template",
              "source": {
                "data": {
                  "id": "source-coollabsio#7110",
                  "user": {
                    "login": "ronenteva",
                    "id": 2454954,
                    "node_id": "MDQ6VXNlcjI0NTQ5NTQ=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/2454954?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ronenteva",
                    "html_url": "https://github.com/ronenteva",
                    "followers_url": "https://api.github.com/users/ronenteva/followers",
                    "following_url": "https://api.github.com/users/ronenteva/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ronenteva/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ronenteva/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ronenteva/subscriptions",
                    "organizations_url": "https://api.github.com/users/ronenteva/orgs",
                    "repos_url": "https://api.github.com/users/ronenteva/repos",
                    "events_url": "https://api.github.com/users/ronenteva/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ronenteva/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Update Clickhouse template",
                  "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the Clickhouse template is using `bitnamilegacy/clickhouse` which is not updated anymore.\nI believe the correct image to be used is `clickhouse:lts`.\n\nSimply changing the image doesn't work, probably just different environment variables.\nThere should be a migration path so data won't be lost (written explanation is fine).\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7110"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7110",
              "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the Clickhouse template is using `bitnamilegacy/clickhouse` which is not updated anymore.\nI believe the correct image to be used is `clickhouse:lts`.\n\nSimply changing the image doesn't work, probably just different environment variables.\nThere should be a migration path so data won't be lost (written explanation is fine).\n",
              "url": "https://github.com/coollabsio/coolify/issues/7110",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#6894",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T23:33:09.819Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:09.819Z",
            "created_at": "2025-12-12T23:33:09.819Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#6894",
              "status": "open",
              "type": "issue",
              "number": 6894,
              "title": "[Enhancement]: Project-specific members",
              "source": {
                "data": {
                  "id": "source-coollabsio#6894",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Project-specific members",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n$1,000 USD bounty.\n\nAdd support for project-specific team members.\n\nProblem: I have team members I want to add to a project on Coolify, but I dont want to give them access to the full account and to all projects on the server. Instead, I want to invite them to a specific project on Coolify and for them to only have access to that project.\n\nAdditionally, I want to optionally allow the project-specific member to deploy their own apps on the servers on the account. This will just create a new project in the Team with them as a project-specific member.\n\nI should be able to manage all project-specific members from the main team page in addition to on each projects page.\n\nAny APIs that exist for managing team members should also work for project-specific members.\n\nThe purpose of this bounty is to create a secure way to give people limited access to projects on Coolify. They must not be able to break out of their permissions. For example, if I can SSH into a server as a project member using one of the keys - that would allow me to break out of my permissions.\n\nAcceptance criteria: Once your PR is merged and deployed on Coolify Cloud, I will test the features and award the bounty. Thanks!\n\n[Hack Club](https://hackclub.com) previously awarded bounties to implement database SSL and APIs to manage backups. Were a nonprofit for teenage coders!",
                  "html_url": "https://github.com/coollabsio/coolify/issues/6894"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#6894",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n$1,000 USD bounty.\n\nAdd support for project-specific team members.\n\nProblem: I have team members I want to add to a project on Coolify, but I dont want to give them access to the full account and to all projects on the server. Instead, I want to invite them to a specific project on Coolify and for them to only have access to that project.\n\nAdditionally, I want to optionally allow the project-specific member to deploy their own apps on the servers on the account. This will just create a new project in the Team with them as a project-specific member.\n\nI should be able to manage all project-specific members from the main team page in addition to on each projects page.\n\nAny APIs that exist for managing team members should also work for project-specific members.\n\nThe purpose of this bounty is to create a secure way to give people limited access to projects on Coolify. They must not be able to break out of their permissions. For example, if I can SSH into a server as a project member using one of the keys - that would allow me to break out of my permissions.\n\nAcceptance criteria: Once your PR is merged and deployed on Coolify Cloud, I will test the features and award the bounty. Thanks!\n\n[Hack Club](https://hackclub.com) previously awarded bounties to implement database SSL and APIs to manage backups. Were a nonprofit for teenage coders!",
              "url": "https://github.com/coollabsio/coolify/issues/6894",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#6567",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-12T23:33:10.054Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:10.054Z",
            "created_at": "2025-12-12T23:33:10.054Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#6567",
              "status": "open",
              "type": "issue",
              "number": 6567,
              "title": "[Enhancement]: Add Soju IRC bouncer",
              "source": {
                "data": {
                  "id": "source-coollabsio#6567",
                  "user": {
                    "login": "XEJK",
                    "id": 4692876,
                    "node_id": "MDQ6VXNlcjQ2OTI4NzY=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/4692876?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/XEJK",
                    "html_url": "https://github.com/XEJK",
                    "followers_url": "https://api.github.com/users/XEJK/followers",
                    "following_url": "https://api.github.com/users/XEJK/following{/other_user}",
                    "gists_url": "https://api.github.com/users/XEJK/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/XEJK/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/XEJK/subscriptions",
                    "organizations_url": "https://api.github.com/users/XEJK/orgs",
                    "repos_url": "https://api.github.com/users/XEJK/repos",
                    "events_url": "https://api.github.com/users/XEJK/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/XEJK/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Add Soju IRC bouncer",
                  "body": "### Request Type\n\nNew Service\n\n### Description\n\nIt would be nice to add the Soju IRC bouncer to the list of services.\nThe documentation is here: \n1. https://codeberg.org/emersion/soju/src/branch/master/doc/getting-started.md\n2. https://codeberg.org/emersion/soju-containers\n3. https://codeberg.org/emersion/soju/src/branch/master/doc/file-upload.md\n\nIt's based on a docker compose seems to need some extra thought since user creation is done through the command line \n\n\nWhen the template is merged in Coolify and I can spin-up a working instance of soju \nincluding file upload support, secure connections, and full support for the protocols supported by soju wjhich can be tested using an IRCv3 compatible client such as goguma or halloy will the attached bounty be seen as completed.\n\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/6567"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#6567",
              "body": "### Request Type\n\nNew Service\n\n### Description\n\nIt would be nice to add the Soju IRC bouncer to the list of services.\nThe documentation is here: \n1. https://codeberg.org/emersion/soju/src/branch/master/doc/getting-started.md\n2. https://codeberg.org/emersion/soju-containers\n3. https://codeberg.org/emersion/soju/src/branch/master/doc/file-upload.md\n\nIt's based on a docker compose seems to need some extra thought since user creation is done through the command line \n\n\nWhen the template is merged in Coolify and I can spin-up a working instance of soju \nincluding file upload support, secure connections, and full support for the protocols supported by soju wjhich can be tested using an IRCv3 compatible client such as goguma or halloy will the attached bounty be seen as completed.\n\n",
              "url": "https://github.com/coollabsio/coolify/issues/6567",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "tscircuit#1130",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "tscircuit",
              "id": "generated-tscircuit",
              "name": "Tscircuit",
              "description": "",
              "members": [],
              "display_name": "Tscircuit",
              "created_at": "2025-12-12T23:33:01.035Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/tscircuit?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "tscircuit",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:01.035Z",
            "created_at": "2025-12-12T23:33:01.035Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-tscircuit#1130",
              "status": "open",
              "type": "issue",
              "number": 1130,
              "title": "Change of color on hover for traces are missing",
              "source": {
                "data": {
                  "id": "source-tscircuit#1130",
                  "user": {
                    "login": "imrishabh18",
                    "id": 38923768,
                    "node_id": "MDQ6VXNlcjM4OTIzNzY4",
                    "avatar_url": "https://avatars.githubusercontent.com/u/38923768?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/imrishabh18",
                    "html_url": "https://github.com/imrishabh18",
                    "followers_url": "https://api.github.com/users/imrishabh18/followers",
                    "following_url": "https://api.github.com/users/imrishabh18/following{/other_user}",
                    "gists_url": "https://api.github.com/users/imrishabh18/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/imrishabh18/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/imrishabh18/subscriptions",
                    "organizations_url": "https://api.github.com/users/imrishabh18/orgs",
                    "repos_url": "https://api.github.com/users/imrishabh18/repos",
                    "events_url": "https://api.github.com/users/imrishabh18/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/imrishabh18/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Change of color on hover for traces are missing",
                  "body": "<img width=\"1190\" height=\"1192\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b8cab314-dd61-48f0-b608-8865300bd28d\" />\n\nAll the traces which connect and are under the same net should be shown on hover\n\n\nRef circuit - https://tscircuit.com/MrPicklePinosaur/tscircuit_demo#schematic",
                  "html_url": "https://github.com/tscircuit/tscircuit/issues/1130"
                },
                "type": "github"
              },
              "hash": "tscircuit/tscircuit#1130",
              "body": "<img width=\"1190\" height=\"1192\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b8cab314-dd61-48f0-b608-8865300bd28d\" />\n\nAll the traces which connect and are under the same net should be shown on hover\n\n\nRef circuit - https://tscircuit.com/MrPicklePinosaur/tscircuit_demo#schematic",
              "url": "https://github.com/tscircuit/tscircuit/issues/1130",
              "tech": [
                "go"
              ],
              "repo_name": "tscircuit",
              "repo_owner": "tscircuit",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "tscircuit#534",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "tscircuit",
              "id": "generated-tscircuit",
              "name": "Tscircuit",
              "description": "",
              "members": [],
              "display_name": "Tscircuit",
              "created_at": "2025-12-12T23:33:01.437Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/tscircuit?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "tscircuit",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:01.437Z",
            "created_at": "2025-12-12T23:33:01.437Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-tscircuit#534",
              "status": "open",
              "type": "issue",
              "number": 534,
              "title": "Texture Support (PCB should have texture on box)",
              "source": {
                "data": {
                  "id": "source-tscircuit#534",
                  "user": {
                    "login": "seveibar",
                    "id": 1910070,
                    "node_id": "MDQ6VXNlcjE5MTAwNzA=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1910070?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/seveibar",
                    "html_url": "https://github.com/seveibar",
                    "followers_url": "https://api.github.com/users/seveibar/followers",
                    "following_url": "https://api.github.com/users/seveibar/following{/other_user}",
                    "gists_url": "https://api.github.com/users/seveibar/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/seveibar/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/seveibar/subscriptions",
                    "organizations_url": "https://api.github.com/users/seveibar/orgs",
                    "repos_url": "https://api.github.com/users/seveibar/repos",
                    "events_url": "https://api.github.com/users/seveibar/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/seveibar/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Texture Support (PCB should have texture on box)",
                  "body": "- use circuit-to-svg with resvg-wasm to create the png texture from circuit json\n- apply the texture to the box\n\n<img width=\"948\" height=\"716\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/cdfb9fd9-fc5f-4dad-b5c1-041e60f26c0d\" />\n\n/bounty $150",
                  "html_url": "https://github.com/tscircuit/3d-viewer/issues/534"
                },
                "type": "github"
              },
              "hash": "tscircuit/3d-viewer#534",
              "body": "- use circuit-to-svg with resvg-wasm to create the png texture from circuit json\n- apply the texture to the box\n\n<img width=\"948\" height=\"716\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/cdfb9fd9-fc5f-4dad-b5c1-041e60f26c0d\" />\n\n/bounty $150",
              "url": "https://github.com/tscircuit/3d-viewer/issues/534",
              "tech": [],
              "repo_name": "3d-viewer",
              "repo_owner": "tscircuit",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "tscircuit#419",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "tscircuit",
              "id": "generated-tscircuit",
              "name": "Tscircuit",
              "description": "",
              "members": [],
              "display_name": "Tscircuit",
              "created_at": "2025-12-12T23:33:04.847Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/tscircuit?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "tscircuit",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:04.847Z",
            "created_at": "2025-12-12T23:33:04.847Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-tscircuit#419",
              "status": "open",
              "type": "issue",
              "number": 419,
              "title": "Texture Support (PCB should have texture on box)",
              "source": {
                "data": {
                  "id": "source-tscircuit#419",
                  "user": {
                    "login": "seveibar",
                    "id": 1910070,
                    "node_id": "MDQ6VXNlcjE5MTAwNzA=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1910070?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/seveibar",
                    "html_url": "https://github.com/seveibar",
                    "followers_url": "https://api.github.com/users/seveibar/followers",
                    "following_url": "https://api.github.com/users/seveibar/following{/other_user}",
                    "gists_url": "https://api.github.com/users/seveibar/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/seveibar/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/seveibar/subscriptions",
                    "organizations_url": "https://api.github.com/users/seveibar/orgs",
                    "repos_url": "https://api.github.com/users/seveibar/repos",
                    "events_url": "https://api.github.com/users/seveibar/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/seveibar/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Texture Support (PCB should have texture on box)",
                  "body": "- use circuit-to-svg with resvg-wasm to create the png texture from circuit json\n- apply the texture to the box\n\n<img width=\"948\" height=\"716\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/cdfb9fd9-fc5f-4dad-b5c1-041e60f26c0d\" />\n\n/bounty $150",
                  "html_url": "https://github.com/tscircuit/3d-viewer/issues/534"
                },
                "type": "github"
              },
              "hash": "tscircuit/pcb-viewer#419",
              "body": "- use circuit-to-svg with resvg-wasm to create the png texture from circuit json\n- apply the texture to the box\n\n<img width=\"948\" height=\"716\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/cdfb9fd9-fc5f-4dad-b5c1-041e60f26c0d\" />\n\n/bounty $150",
              "url": "https://github.com/tscircuit/3d-viewer/issues/534",
              "tech": [],
              "repo_name": "pcb-viewer",
              "repo_owner": "tscircuit",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "tscircuit#1081",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "tscircuit",
              "id": "generated-tscircuit",
              "name": "Tscircuit",
              "description": "",
              "members": [],
              "display_name": "Tscircuit",
              "created_at": "2025-12-12T23:33:06.994Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/tscircuit?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "tscircuit",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:06.994Z",
            "created_at": "2025-12-12T23:33:06.994Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-tscircuit#1081",
              "status": "open",
              "type": "issue",
              "number": 1081,
              "title": "Make sure kicad component components create courtyards",
              "source": {
                "data": {
                  "id": "source-tscircuit#1081",
                  "user": {
                    "login": "seveibar",
                    "id": 1910070,
                    "node_id": "MDQ6VXNlcjE5MTAwNzA=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1910070?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/seveibar",
                    "html_url": "https://github.com/seveibar",
                    "followers_url": "https://api.github.com/users/seveibar/followers",
                    "following_url": "https://api.github.com/users/seveibar/following{/other_user}",
                    "gists_url": "https://api.github.com/users/seveibar/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/seveibar/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/seveibar/subscriptions",
                    "organizations_url": "https://api.github.com/users/seveibar/orgs",
                    "repos_url": "https://api.github.com/users/seveibar/repos",
                    "events_url": "https://api.github.com/users/seveibar/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/seveibar/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Make sure kicad component components create courtyards",
                  "body": "In https://kicad-component.tscircuit.com / https://github.com/tscircuit/kicad-component-converter\n\nWe need to load the kicad_mod file and produce `<courtyardrect />` elements\n\n- [ ] Find a kicad_mod file to test with that has a courtyard defined\n- [ ] Make sure courtyards are drawn in circuit-to-svg\n- [ ] Modify kicad-component-converter\n- [ ] Modify circuit-json-to-tscircuit\n\n\n/bounty $75",
                  "html_url": "https://github.com/tscircuit/tscircuit/issues/1081"
                },
                "type": "github"
              },
              "hash": "tscircuit/tscircuit#1081",
              "body": "In https://kicad-component.tscircuit.com / https://github.com/tscircuit/kicad-component-converter\n\nWe need to load the kicad_mod file and produce `<courtyardrect />` elements\n\n- [ ] Find a kicad_mod file to test with that has a courtyard defined\n- [ ] Make sure courtyards are drawn in circuit-to-svg\n- [ ] Modify kicad-component-converter\n- [ ] Modify circuit-json-to-tscircuit\n\n\n/bounty $75",
              "url": "https://github.com/tscircuit/tscircuit/issues/1081",
              "tech": [],
              "repo_name": "tscircuit",
              "repo_owner": "tscircuit",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "tscircuit#386",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "tscircuit",
              "id": "generated-tscircuit",
              "name": "Tscircuit",
              "description": "",
              "members": [],
              "display_name": "Tscircuit",
              "created_at": "2025-12-12T23:33:09.424Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/tscircuit?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "tscircuit",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:09.424Z",
            "created_at": "2025-12-12T23:33:09.424Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-tscircuit#386",
              "status": "open",
              "type": "issue",
              "number": 386,
              "title": "Add support for qfn32",
              "source": {
                "data": {
                  "id": "source-tscircuit#386",
                  "user": {
                    "login": "seveibar",
                    "id": 1910070,
                    "node_id": "MDQ6VXNlcjE5MTAwNzA=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1910070?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/seveibar",
                    "html_url": "https://github.com/seveibar",
                    "followers_url": "https://api.github.com/users/seveibar/followers",
                    "following_url": "https://api.github.com/users/seveibar/following{/other_user}",
                    "gists_url": "https://api.github.com/users/seveibar/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/seveibar/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/seveibar/subscriptions",
                    "organizations_url": "https://api.github.com/users/seveibar/orgs",
                    "repos_url": "https://api.github.com/users/seveibar/repos",
                    "events_url": "https://api.github.com/users/seveibar/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/seveibar/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add support for qfn32",
                  "body": "/bounty $25",
                  "html_url": "https://github.com/tscircuit/jscad-electronics/issues/139"
                },
                "type": "github"
              },
              "hash": "tscircuit/footprinter#386",
              "body": "/bounty $25",
              "url": "https://github.com/tscircuit/jscad-electronics/issues/139",
              "tech": [],
              "repo_name": "footprinter",
              "repo_owner": "tscircuit",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "tscircuit#1498",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "tscircuit",
              "id": "generated-tscircuit",
              "name": "Tscircuit",
              "description": "",
              "members": [],
              "display_name": "Tscircuit",
              "created_at": "2025-12-12T23:33:09.542Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/tscircuit?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "tscircuit",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:09.542Z",
            "created_at": "2025-12-12T23:33:09.542Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-tscircuit#1498",
              "status": "open",
              "type": "issue",
              "number": 1498,
              "title": "Bug schematic traces with the same net name jumpeing to eachother ",
              "source": {
                "data": {
                  "id": "source-tscircuit#1498",
                  "user": {
                    "login": "Abse2001",
                    "id": 54582525,
                    "node_id": "MDQ6VXNlcjU0NTgyNTI1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/54582525?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Abse2001",
                    "html_url": "https://github.com/Abse2001",
                    "followers_url": "https://api.github.com/users/Abse2001/followers",
                    "following_url": "https://api.github.com/users/Abse2001/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Abse2001/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Abse2001/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Abse2001/subscriptions",
                    "organizations_url": "https://api.github.com/users/Abse2001/orgs",
                    "repos_url": "https://api.github.com/users/Abse2001/repos",
                    "events_url": "https://api.github.com/users/Abse2001/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Abse2001/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Bug schematic traces with the same net name jumpeing to eachother ",
                  "body": "<img width=\"477\" height=\"450\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a71254f3-b7a3-4575-9856-0997f856fd1d\" />\n\n\n<img width=\"463\" height=\"449\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3d24332a-05c8-4aca-a1e3-dff06b7b50f1\" />",
                  "html_url": "https://github.com/tscircuit/core/issues/1498"
                },
                "type": "github"
              },
              "hash": "tscircuit/core#1498",
              "body": "<img width=\"477\" height=\"450\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a71254f3-b7a3-4575-9856-0997f856fd1d\" />\n\n\n<img width=\"463\" height=\"449\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3d24332a-05c8-4aca-a1e3-dff06b7b50f1\" />",
              "url": "https://github.com/tscircuit/core/issues/1498",
              "tech": [],
              "repo_name": "core",
              "repo_owner": "tscircuit",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "tscircuit#79",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "tscircuit",
              "id": "generated-tscircuit",
              "name": "Tscircuit",
              "description": "",
              "members": [],
              "display_name": "Tscircuit",
              "created_at": "2025-12-12T23:33:09.819Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/tscircuit?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "tscircuit",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:09.819Z",
            "created_at": "2025-12-12T23:33:09.819Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-tscircuit#79",
              "status": "open",
              "type": "issue",
              "number": 79,
              "title": "Fix extra net label in repro61, or remove trace",
              "source": {
                "data": {
                  "id": "source-tscircuit#79",
                  "user": {
                    "login": "seveibar",
                    "id": 1910070,
                    "node_id": "MDQ6VXNlcjE5MTAwNzA=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1910070?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/seveibar",
                    "html_url": "https://github.com/seveibar",
                    "followers_url": "https://api.github.com/users/seveibar/followers",
                    "following_url": "https://api.github.com/users/seveibar/following{/other_user}",
                    "gists_url": "https://api.github.com/users/seveibar/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/seveibar/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/seveibar/subscriptions",
                    "organizations_url": "https://api.github.com/users/seveibar/orgs",
                    "repos_url": "https://api.github.com/users/seveibar/repos",
                    "events_url": "https://api.github.com/users/seveibar/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/seveibar/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Fix extra net label in repro61, or remove trace",
                  "body": "See [#1503](https://github.com/tscircuit/core/pull/1503/files)\n\nCC @0hmX @Abse2001 \n\n<img width=\"854\" height=\"534\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/90cda586-2e2b-4937-a392-0ed549cd2eca\" />\n\n/bounty $75",
                  "html_url": "https://github.com/tscircuit/schematic-trace-solver/issues/79"
                },
                "type": "github"
              },
              "hash": "tscircuit/schematic-trace-solver#79",
              "body": "See [#1503](https://github.com/tscircuit/core/pull/1503/files)\n\nCC @0hmX @Abse2001 \n\n<img width=\"854\" height=\"534\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/90cda586-2e2b-4937-a392-0ed549cd2eca\" />\n\n/bounty $75",
              "url": "https://github.com/tscircuit/schematic-trace-solver/issues/79",
              "tech": [],
              "repo_name": "schematic-trace-solver",
              "repo_owner": "tscircuit",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "tscircuit#78",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "tscircuit",
              "id": "generated-tscircuit",
              "name": "Tscircuit",
              "description": "",
              "members": [],
              "display_name": "Tscircuit",
              "created_at": "2025-12-12T23:33:10.054Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/tscircuit?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "tscircuit",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:10.054Z",
            "created_at": "2025-12-12T23:33:10.054Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-tscircuit#78",
              "status": "open",
              "type": "issue",
              "number": 78,
              "title": "Fix extra trace lines in post-processing step",
              "source": {
                "data": {
                  "id": "source-tscircuit#78",
                  "user": {
                    "login": "seveibar",
                    "id": 1910070,
                    "node_id": "MDQ6VXNlcjE5MTAwNzA=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1910070?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/seveibar",
                    "html_url": "https://github.com/seveibar",
                    "followers_url": "https://api.github.com/users/seveibar/followers",
                    "following_url": "https://api.github.com/users/seveibar/following{/other_user}",
                    "gists_url": "https://api.github.com/users/seveibar/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/seveibar/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/seveibar/subscriptions",
                    "organizations_url": "https://api.github.com/users/seveibar/orgs",
                    "repos_url": "https://api.github.com/users/seveibar/repos",
                    "events_url": "https://api.github.com/users/seveibar/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/seveibar/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Fix extra trace lines in post-processing step",
                  "body": "<img width=\"1156\" height=\"812\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e14c1b6b-975b-4c07-9632-3ada99461ac9\" />\n\n/bounty $75",
                  "html_url": "https://github.com/tscircuit/schematic-trace-solver/issues/78"
                },
                "type": "github"
              },
              "hash": "tscircuit/schematic-trace-solver#78",
              "body": "<img width=\"1156\" height=\"812\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e14c1b6b-975b-4c07-9632-3ada99461ac9\" />\n\n/bounty $75",
              "url": "https://github.com/tscircuit/schematic-trace-solver/issues/78",
              "tech": [],
              "repo_name": "schematic-trace-solver",
              "repo_owner": "tscircuit",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "tscircuit#176",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "tscircuit",
              "id": "generated-tscircuit",
              "name": "Tscircuit",
              "description": "",
              "members": [],
              "display_name": "Tscircuit",
              "created_at": "2025-12-12T23:33:10.248Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/tscircuit?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "tscircuit",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:10.248Z",
            "created_at": "2025-12-12T23:33:10.248Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-tscircuit#176",
              "status": "open",
              "type": "issue",
              "number": 176,
              "title": "Proposal: Add SparkFun MicroMod STM32 Processor (STM32F405)",
              "source": {
                "data": {
                  "id": "source-tscircuit#176",
                  "user": {
                    "login": "1914Jegx",
                    "id": 153167921,
                    "node_id": "U_kgDOCSEoMQ",
                    "avatar_url": "https://avatars.githubusercontent.com/u/153167921?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/1914Jegx",
                    "html_url": "https://github.com/1914Jegx",
                    "followers_url": "https://api.github.com/users/1914Jegx/followers",
                    "following_url": "https://api.github.com/users/1914Jegx/following{/other_user}",
                    "gists_url": "https://api.github.com/users/1914Jegx/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/1914Jegx/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/1914Jegx/subscriptions",
                    "organizations_url": "https://api.github.com/users/1914Jegx/orgs",
                    "repos_url": "https://api.github.com/users/1914Jegx/repos",
                    "events_url": "https://api.github.com/users/1914Jegx/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/1914Jegx/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Proposal: Add SparkFun MicroMod STM32 Processor (STM32F405)",
                  "body": "Title\nProposal: Add SparkFun MicroMod STM32 Processor (STM32F405)\n\nBody\nHi TSCircuit team! Id like to propose adding the SparkFun MicroMod STM32 Processor to the funboards catalog.\n\n- Board: SparkFun MicroMod STM32 Processor (STM32F405RGT6)\n- Product page: https://www.sparkfun.com/products/21326\n- Hardware repo: https://github.com/sparkfun/MicroMod_STM32_Processor\n- Hookup guide: https://learn.sparkfun.com/tutorials/micromod-stm32-processor-hookup-guide\n- Schematic (PDF): https://cdn.sparkfun.com/assets/8/a/a/7/3/MicroMod_STM32_Processor.pdf\n\nWhy this board\n- Expands MicroMod coverage (M.2 E-class 22mm edge) and brings STM32F4 (Cortex-M4) into the catalog.\n- Reusable mapping: once the MicroMod edge connector + STM32F405 pins are modeled, other MicroMod processors benefit.\n- Complexity: moderate/advanced (MCU, HSE/LSE clocks, boot/reset gating, SPI flash, SDIO, USB, SWD). Seems like a mid-tier bounty candidate.\n\nDuplication check\n- I checked the public boards list in `tscircuit/sparkfun-boards/boards/` and did not find this board at time of filing.\n- Also glanced at the org project board (https://github.com/orgs/tscircuit/projects/6) and didnt see it in progress. Please correct me if I missed it.\n\nPlanned implementation (TSX; no XY tooling)\n- Schematic (TSX):\n  - `STM32F405RG` (LQFP-64) with VDDx/VDDA/VSSA, `VCAP1/2` decoupling, `PH0/PH1` 12MHz HSE, `PC14/PC15` 32.768kHz LSE.\n  - SPI flash W25Qxx (WSON-8 6x5) on SPI1 (PA5/PA6/PA7) + `PC4` CS#; HOLD#/WP# as per schematic.\n  - MicroMod edge symbol with named pins: 3.3V, GNDs, `USB_D`, `USB_VIN`, `RTC_3V`, `3.3V_EN`, `!RESET!`, `!BOOT!`, SWDIO/SWCLK, SDIO, SPI, I2C, UART, BUS/GPIO.\n  - Boot/reset: `BOOT0` gating via PMOSFET (DMG2305UX7), RC on `NRST`, `PB2` (BOOT1) strapped.\n- PCB (TSX):\n  - 22mm MicroMod card outline with chamfer; custom edge pad footprint (pads 175) per MicroMod spec.\n  - Place LQFP64, crystals (3225/3215), WSON8 flash, decoupling; indicative routing for visuals.\n- Artifacts: snapshots/renders via `tsci snapshot`.\n\nAcceptance/questions\n- Can you confirm its green to proceed and eligible for a bounty? If so, please attach a bounty and assign.\n- Any preference for edge connector footprint naming or a canonical MicroMod footprint I should reuse?\n- Any constraints (e.g., minimum visual fidelity for the edge connector, keepout notches, silk expectations)?\n- Any components/modules to avoid for funboards? (Ive avoided relying on XY import.)\n\nEstimated effort\n- 12 days for faithful schematic + functional PCB visualization (including custom edge footprint) and snapshots.\n\nThanks! Happy to adapt to preferred structure or scope.\n",
                  "html_url": "https://github.com/tscircuit/sparkfun-boards/issues/176"
                },
                "type": "github"
              },
              "hash": "tscircuit/sparkfun-boards#176",
              "body": "Title\nProposal: Add SparkFun MicroMod STM32 Processor (STM32F405)\n\nBody\nHi TSCircuit team! Id like to propose adding the SparkFun MicroMod STM32 Processor to the funboards catalog.\n\n- Board: SparkFun MicroMod STM32 Processor (STM32F405RGT6)\n- Product page: https://www.sparkfun.com/products/21326\n- Hardware repo: https://github.com/sparkfun/MicroMod_STM32_Processor\n- Hookup guide: https://learn.sparkfun.com/tutorials/micromod-stm32-processor-hookup-guide\n- Schematic (PDF): https://cdn.sparkfun.com/assets/8/a/a/7/3/MicroMod_STM32_Processor.pdf\n\nWhy this board\n- Expands MicroMod coverage (M.2 E-class 22mm edge) and brings STM32F4 (Cortex-M4) into the catalog.\n- Reusable mapping: once the MicroMod edge connector + STM32F405 pins are modeled, other MicroMod processors benefit.\n- Complexity: moderate/advanced (MCU, HSE/LSE clocks, boot/reset gating, SPI flash, SDIO, USB, SWD). Seems like a mid-tier bounty candidate.\n\nDuplication check\n- I checked the public boards list in `tscircuit/sparkfun-boards/boards/` and did not find this board at time of filing.\n- Also glanced at the org project board (https://github.com/orgs/tscircuit/projects/6) and didnt see it in progress. Please correct me if I missed it.\n\nPlanned implementation (TSX; no XY tooling)\n- Schematic (TSX):\n  - `STM32F405RG` (LQFP-64) with VDDx/VDDA/VSSA, `VCAP1/2` decoupling, `PH0/PH1` 12MHz HSE, `PC14/PC15` 32.768kHz LSE.\n  - SPI flash W25Qxx (WSON-8 6x5) on SPI1 (PA5/PA6/PA7) + `PC4` CS#; HOLD#/WP# as per schematic.\n  - MicroMod edge symbol with named pins: 3.3V, GNDs, `USB_D`, `USB_VIN`, `RTC_3V`, `3.3V_EN`, `!RESET!`, `!BOOT!`, SWDIO/SWCLK, SDIO, SPI, I2C, UART, BUS/GPIO.\n  - Boot/reset: `BOOT0` gating via PMOSFET (DMG2305UX7), RC on `NRST`, `PB2` (BOOT1) strapped.\n- PCB (TSX):\n  - 22mm MicroMod card outline with chamfer; custom edge pad footprint (pads 175) per MicroMod spec.\n  - Place LQFP64, crystals (3225/3215), WSON8 flash, decoupling; indicative routing for visuals.\n- Artifacts: snapshots/renders via `tsci snapshot`.\n\nAcceptance/questions\n- Can you confirm its green to proceed and eligible for a bounty? If so, please attach a bounty and assign.\n- Any preference for edge connector footprint naming or a canonical MicroMod footprint I should reuse?\n- Any constraints (e.g., minimum visual fidelity for the edge connector, keepout notches, silk expectations)?\n- Any components/modules to avoid for funboards? (Ive avoided relying on XY import.)\n\nEstimated effort\n- 12 days for faithful schematic + functional PCB visualization (including custom edge footprint) and snapshots.\n\nThanks! Happy to adapt to preferred structure or scope.\n",
              "url": "https://github.com/tscircuit/sparkfun-boards/issues/176",
              "tech": [],
              "repo_name": "sparkfun-boards",
              "repo_owner": "tscircuit",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "tscircuit#939",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "tscircuit",
              "id": "generated-tscircuit",
              "name": "Tscircuit",
              "description": "",
              "members": [],
              "display_name": "Tscircuit",
              "created_at": "2025-12-12T23:33:10.453Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/tscircuit?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "tscircuit",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:10.453Z",
            "created_at": "2025-12-12T23:33:10.453Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-tscircuit#939",
              "status": "open",
              "type": "issue",
              "number": 939,
              "title": "Figure out why documentation isn't rendering reference designators (Vercel renders with box fonts)",
              "source": {
                "data": {
                  "id": "source-tscircuit#939",
                  "user": {
                    "login": "seveibar",
                    "id": 1910070,
                    "node_id": "MDQ6VXNlcjE5MTAwNzA=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1910070?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/seveibar",
                    "html_url": "https://github.com/seveibar",
                    "followers_url": "https://api.github.com/users/seveibar/followers",
                    "following_url": "https://api.github.com/users/seveibar/following{/other_user}",
                    "gists_url": "https://api.github.com/users/seveibar/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/seveibar/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/seveibar/subscriptions",
                    "organizations_url": "https://api.github.com/users/seveibar/orgs",
                    "repos_url": "https://api.github.com/users/seveibar/repos",
                    "events_url": "https://api.github.com/users/seveibar/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/seveibar/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Figure out why documentation isn't rendering reference designators (Vercel renders with box fonts)",
                  "body": "To reproduce:\n\n1. Deploy to vercel\n2. Go to `${YOUR_SERVER_URL}?svg_type=schematic&format=png&code=H4sIAJmi92gAA0WOQQ6CMBBFrzKZFWykGFcGOITrbqodbKNtSTvGJsa7SyHIbt78l5%2F%2FQes15QOnjGekPIXIoGlUrydDVUM%2FQCU9QHcNKmp4W82ml9gK5ySCIXs3%2FOehmLMbKdnEIa4IsLLyNyrqQ%2BIWjCHwFK0vFeIkjnvilSvypd1ezVLeNcuO%2Ba7x%2BwPTyw6evAAAAA%3D%3D`\n\n<img width=\"1494\" height=\"702\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/628bd14b-edd9-4a43-931a-5da5141085b4\" />\n\n/bounty $100",
                  "html_url": "https://github.com/tscircuit/svg.tscircuit.com/issues/427"
                },
                "type": "github"
              },
              "hash": "tscircuit/tscircuit#939",
              "body": "To reproduce:\n\n1. Deploy to vercel\n2. Go to `${YOUR_SERVER_URL}?svg_type=schematic&format=png&code=H4sIAJmi92gAA0WOQQ6CMBBFrzKZFWykGFcGOITrbqodbKNtSTvGJsa7SyHIbt78l5%2F%2FQes15QOnjGekPIXIoGlUrydDVUM%2FQCU9QHcNKmp4W82ml9gK5ySCIXs3%2FOehmLMbKdnEIa4IsLLyNyrqQ%2BIWjCHwFK0vFeIkjnvilSvypd1ezVLeNcuO%2Ba7x%2BwPTyw6evAAAAA%3D%3D`\n\n<img width=\"1494\" height=\"702\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/628bd14b-edd9-4a43-931a-5da5141085b4\" />\n\n/bounty $100",
              "url": "https://github.com/tscircuit/svg.tscircuit.com/issues/427",
              "tech": [],
              "repo_name": "tscircuit",
              "repo_owner": "tscircuit",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14310",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-12-12T23:33:31.444Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:31.444Z",
            "created_at": "2025-12-12T23:33:31.444Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14310",
              "status": "open",
              "type": "issue",
              "number": 14310,
              "title": "CVE-2024-44902 - Thinkphp - Insecure Deserialization ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14310",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2024-44902 - Thinkphp - Insecure Deserialization ",
                  "body": "\n### Description: \n> Thinkphp v6.1.3 to v8.0.4 contain an insecure deserialization caused by improper handling of serialized data, letting attackers execute arbitrary code, exploit requires sending malicious serialized data.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/fru1ts/CVE-2024-44902\n- https///github.com:fru1ts/CVE-2024-44902.git\n\n### KEV: True\n\n### Shodan Query: `http.title:\"thinkphp\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14310"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14310",
              "body": "\n### Description: \n> Thinkphp v6.1.3 to v8.0.4 contain an insecure deserialization caused by improper handling of serialized data, letting attackers execute arbitrary code, exploit requires sending malicious serialized data.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/fru1ts/CVE-2024-44902\n- https///github.com:fru1ts/CVE-2024-44902.git\n\n### KEV: True\n\n### Shodan Query: `http.title:\"thinkphp\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14310",
              "tech": [
                "go"
              ],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14297",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-12-12T23:33:31.569Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:31.569Z",
            "created_at": "2025-12-12T23:33:31.569Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14297",
              "status": "open",
              "type": "issue",
              "number": 14297,
              "title": "CVE-2019-3980 - Solarwinds Dameware Mini Remote Client - Remote Code Execution ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14297",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2019-3980 - Solarwinds Dameware Mini Remote Client - Remote Code Execution ",
                  "body": "\n### Description: \n> Solarwinds Dameware Mini Remote Client agent v12.1.0.89 contains a remote code execution caused by support for smart card authentication allowing upload and execution of arbitrary executables on the host, letting unauthenticated attackers execute code under the Local System account, exploit requires requesting smart card login.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://www.tenable.com/security/research/tra-227-43\n- https://github.com/CyberQuestor-infosec/CVE-2019-3980-Open_Net_Admin_v18.1.1_RCE\n- https///github.com:CyberQuestor-infosec/CVE-2019-3980-Open_Net_Admin_v18.1.1_RCE.git\n- https://github.com/Barbarisch/CVE-2019-3980\n- https://vulncheck.com/xdb/b2d525559d87\n- https///github.com:Barbarisch/CVE-2019-3980.git\n- https://github.com/warferik/CVE-2019-3980\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14297"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14297",
              "body": "\n### Description: \n> Solarwinds Dameware Mini Remote Client agent v12.1.0.89 contains a remote code execution caused by support for smart card authentication allowing upload and execution of arbitrary executables on the host, letting unauthenticated attackers execute code under the Local System account, exploit requires requesting smart card login.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://www.tenable.com/security/research/tra-227-43\n- https://github.com/CyberQuestor-infosec/CVE-2019-3980-Open_Net_Admin_v18.1.1_RCE\n- https///github.com:CyberQuestor-infosec/CVE-2019-3980-Open_Net_Admin_v18.1.1_RCE.git\n- https://github.com/Barbarisch/CVE-2019-3980\n- https://vulncheck.com/xdb/b2d525559d87\n- https///github.com:Barbarisch/CVE-2019-3980.git\n- https://github.com/warferik/CVE-2019-3980\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14297",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14278",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-12-12T23:33:31.683Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:31.683Z",
            "created_at": "2025-12-12T23:33:31.683Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14278",
              "status": "open",
              "type": "issue",
              "number": 14278,
              "title": "CVE-2019-18935 - Progress Telerik UI for ASP.NET AJAX - Insecure Deserialization ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14278",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2019-18935 - Progress Telerik UI for ASP.NET AJAX - Insecure Deserialization ",
                  "body": "\n### Description: \n> Progress Telerik UI for ASP.NET AJAX <= 2019.3.1023 contains a .NET deserialization caused by insecure RadAsyncUpload function, letting attackers with known encryption keys execute remote code, exploit requires known encryption keys or specific settings.\n\n#### Severity: `Critical`\n\n#### POC: \n- http://packetstormsecurity.com/files/159653/Telerik-UI-ASP.NET-AJAX-RadAsyncUpload-Deserialization.html\n- https://github.com/bao7uo/RAU_crypto\n- https://github.com/noperator/CVE-2019-18935\n- https://know.bishopfox.com/research/cve-2019-18935-remote-code-execution-in-telerik-ui\n- https://github.com/rapid7/metasploit-framework/blob/master/modules/exploits/windows/http/telerik_rau_deserialization.rb\n- https://github.com/menashe12346/CVE-2019-18935\n- https///github.com:menashe12346/CVE-2019-18935.git\n- https://github.com/quyt0/CVE-2019-18935-exploit-study\n- https///github.com:quyt0/CVE-2019-18935-exploit-study.git\n- https///github.com:hnytgl/TelerikUI-RCE.git\n- https://github.com/0xsharz/telerik-scanner-CVE-2019-18935\n- https://github.com/ekkoo-z/CVE-2019-18935-bypasswaf\n- https///github.com:ekkoo-z/CVE-2019-18935-bypasswaf.git\n- https://vulncheck.com/xdb/c621c71a9bf3\n- https://github.com/clarkvoss/telerik\n- https///github.com:clarkvoss/telerik.git\n- https://github.com/dust-life/CVE-2019-18935-memShell\n- https://github.com/KasunPriyashan/Telerik-UI-ASP.NET-AJAX-Exploitation\n- https://vulncheck.com/xdb/dffdf06b5f8a\n- https://github.com/0xAgun/CVE-2019-18935-checker\n- https///github.com:0xAgun/CVE-2019-18935-checker.git\n- https://github.com/random-robbie/CVE-2019-18935\n- https://vulncheck.com/xdb/dd4d5145d7fd\n- https://github.com/appliedi/Telerik_CVE-2019-18935\n- https///github.com:appliedi/Telerik_CVE-2019-18935.git\n- https://vulncheck.com/xdb/8dc793fec147\n- https://github.com/murataydemir/CVE-2019-18935\n- https///github.com:murataydemir/CVE-2019-18935.git\n- https://vulncheck.com/xdb/569e3fec38c8\n- https://github.com/ThanHuuTuan/CVE_2019_18935\n- https///github.com:ThanHuuTuan/CVE_2019_18935.git\n- https://vulncheck.com/xdb/48d2eb3dee46\n- https://github.com/ThanHuuTuan/Telerik_CVE-2019-18935\n- https///github.com:ThanHuuTuan/Telerik_CVE-2019-18935.git\n- https://vulncheck.com/xdb/6733f1b67fb2\n- https://github.com/becrevex/Telerik_CVE-2019-18935\n- https///github.com:becrevex/Telerik_CVE-2019-18935.git\n- https://vulncheck.com/xdb/de3ebe4e8ea8\n- https///github.com:noperator/CVE-2019-18935.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14278"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14278",
              "body": "\n### Description: \n> Progress Telerik UI for ASP.NET AJAX <= 2019.3.1023 contains a .NET deserialization caused by insecure RadAsyncUpload function, letting attackers with known encryption keys execute remote code, exploit requires known encryption keys or specific settings.\n\n#### Severity: `Critical`\n\n#### POC: \n- http://packetstormsecurity.com/files/159653/Telerik-UI-ASP.NET-AJAX-RadAsyncUpload-Deserialization.html\n- https://github.com/bao7uo/RAU_crypto\n- https://github.com/noperator/CVE-2019-18935\n- https://know.bishopfox.com/research/cve-2019-18935-remote-code-execution-in-telerik-ui\n- https://github.com/rapid7/metasploit-framework/blob/master/modules/exploits/windows/http/telerik_rau_deserialization.rb\n- https://github.com/menashe12346/CVE-2019-18935\n- https///github.com:menashe12346/CVE-2019-18935.git\n- https://github.com/quyt0/CVE-2019-18935-exploit-study\n- https///github.com:quyt0/CVE-2019-18935-exploit-study.git\n- https///github.com:hnytgl/TelerikUI-RCE.git\n- https://github.com/0xsharz/telerik-scanner-CVE-2019-18935\n- https://github.com/ekkoo-z/CVE-2019-18935-bypasswaf\n- https///github.com:ekkoo-z/CVE-2019-18935-bypasswaf.git\n- https://vulncheck.com/xdb/c621c71a9bf3\n- https://github.com/clarkvoss/telerik\n- https///github.com:clarkvoss/telerik.git\n- https://github.com/dust-life/CVE-2019-18935-memShell\n- https://github.com/KasunPriyashan/Telerik-UI-ASP.NET-AJAX-Exploitation\n- https://vulncheck.com/xdb/dffdf06b5f8a\n- https://github.com/0xAgun/CVE-2019-18935-checker\n- https///github.com:0xAgun/CVE-2019-18935-checker.git\n- https://github.com/random-robbie/CVE-2019-18935\n- https://vulncheck.com/xdb/dd4d5145d7fd\n- https://github.com/appliedi/Telerik_CVE-2019-18935\n- https///github.com:appliedi/Telerik_CVE-2019-18935.git\n- https://vulncheck.com/xdb/8dc793fec147\n- https://github.com/murataydemir/CVE-2019-18935\n- https///github.com:murataydemir/CVE-2019-18935.git\n- https://vulncheck.com/xdb/569e3fec38c8\n- https://github.com/ThanHuuTuan/CVE_2019_18935\n- https///github.com:ThanHuuTuan/CVE_2019_18935.git\n- https://vulncheck.com/xdb/48d2eb3dee46\n- https://github.com/ThanHuuTuan/Telerik_CVE-2019-18935\n- https///github.com:ThanHuuTuan/Telerik_CVE-2019-18935.git\n- https://vulncheck.com/xdb/6733f1b67fb2\n- https://github.com/becrevex/Telerik_CVE-2019-18935\n- https///github.com:becrevex/Telerik_CVE-2019-18935.git\n- https://vulncheck.com/xdb/de3ebe4e8ea8\n- https///github.com:noperator/CVE-2019-18935.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14278",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14236",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-12-12T23:33:31.791Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:31.791Z",
            "created_at": "2025-12-12T23:33:31.791Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14236",
              "status": "open",
              "type": "issue",
              "number": 14236,
              "title": "CVE-2021-3007 - Laminas Project laminas-http - Insecure Deserialization ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14236",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2021-3007 - Laminas Project laminas-http - Insecure Deserialization ",
                  "body": "\n### Description: \n> Laminas Project laminas-http < 2.14.2 and Zend Framework 3.0.0 contain a deserialization vulnerability caused by __destruct method in Zend\\Http\\Response\\Stream, letting attackers control content lead to remote code execution, exploit requires attacker-controlled serialized data.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/Ling-Yizhou/zendframework3-/blob/main/zend%20framework3%20%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%20rce.md\n- https://research.checkpoint.com/2021/freakout-leveraging-newest-vulnerabilities-for-creating-a-botnet/\n- https://vulncheck.com/xdb/697fc8c15292\n- https://github.com/Vulnmachines/ZF3_CVE-2021-3007\n- https///github.com:Vulnmachines/ZF3_CVE-2021-3007.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14236"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14236",
              "body": "\n### Description: \n> Laminas Project laminas-http < 2.14.2 and Zend Framework 3.0.0 contain a deserialization vulnerability caused by __destruct method in Zend\\Http\\Response\\Stream, letting attackers control content lead to remote code execution, exploit requires attacker-controlled serialized data.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/Ling-Yizhou/zendframework3-/blob/main/zend%20framework3%20%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%20rce.md\n- https://research.checkpoint.com/2021/freakout-leveraging-newest-vulnerabilities-for-creating-a-botnet/\n- https://vulncheck.com/xdb/697fc8c15292\n- https://github.com/Vulnmachines/ZF3_CVE-2021-3007\n- https///github.com:Vulnmachines/ZF3_CVE-2021-3007.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14236",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14212",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-12-12T23:33:31.911Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:31.911Z",
            "created_at": "2025-12-12T23:33:31.911Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14212",
              "status": "open",
              "type": "issue",
              "number": 14212,
              "title": "CVE-2025-13486 - Advanced Custom Fields: Extended - Remote Code Execution ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14212",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2025-13486 - Advanced Custom Fields: Extended - Remote Code Execution ",
                  "body": "\n### Description: \n> Advanced Custom Fields: Extended WordPress plugin 0.9.0.5 through 0.9.1.1 contains a remote code execution caused by unsafe use of call_user_func_array() in prepare_form() function, letting unauthenticated attackers execute arbitrary code remotely.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/lasthero-887/CVE-2025-13486---Poc\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14212"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14212",
              "body": "\n### Description: \n> Advanced Custom Fields: Extended WordPress plugin 0.9.0.5 through 0.9.1.1 contains a remote code execution caused by unsafe use of call_user_func_array() in prepare_form() function, letting unauthenticated attackers execute arbitrary code remotely.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/lasthero-887/CVE-2025-13486---Poc\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14212",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#1471",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-12-12T23:33:32.058Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:32.058Z",
            "created_at": "2025-12-12T23:33:32.058Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#1471",
              "status": "open",
              "type": "issue",
              "number": 1471,
              "title": "release katana v1.3.0",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#1471",
                  "user": {
                    "login": "dogancanbakir",
                    "id": 65292895,
                    "node_id": "MDQ6VXNlcjY1MjkyODk1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/65292895?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/dogancanbakir",
                    "html_url": "https://github.com/dogancanbakir",
                    "followers_url": "https://api.github.com/users/dogancanbakir/followers",
                    "following_url": "https://api.github.com/users/dogancanbakir/following{/other_user}",
                    "gists_url": "https://api.github.com/users/dogancanbakir/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/dogancanbakir/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/dogancanbakir/subscriptions",
                    "organizations_url": "https://api.github.com/users/dogancanbakir/orgs",
                    "repos_url": "https://api.github.com/users/dogancanbakir/repos",
                    "events_url": "https://api.github.com/users/dogancanbakir/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/dogancanbakir/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "release katana v1.3.0",
                  "body": "https://github.com/projectdiscovery/nuclei-templates/pull/14338 https://github.com/projectdiscovery/nuclei-templates/pull/14330 https://github.com/projectdiscovery/nuclei-templates/pull/14214 https://",
                  "html_url": "https://github.com/projectdiscovery/katana/issues/1471"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/katana#1471",
              "body": "https://github.com/projectdiscovery/nuclei-templates/pull/14338 https://github.com/projectdiscovery/nuclei-templates/pull/14330 https://github.com/projectdiscovery/nuclei-templates/pull/14214 https://",
              "url": "https://github.com/projectdiscovery/katana/issues/1471",
              "tech": [],
              "repo_name": "katana",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14152",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-12-12T23:33:32.160Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:32.160Z",
            "created_at": "2025-12-12T23:33:32.160Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14152",
              "status": "open",
              "type": "issue",
              "number": 14152,
              "title": "CVE-2020-14756 - Oracle Coherence - Remote Code Execution ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14152",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2020-14756 - Oracle Coherence - Remote Code Execution ",
                  "body": "\n### Description: \n> Oracle Coherence of Oracle Fusion Middleware (versions 3.7.1.0, 12.1.3.0.0, 12.2.1.3.0, 12.2.1.4.0, 14.1.1.0.0) contains a remote code execution caused by unauthenticated network access via IIOP and T3, letting attackers compromise the system, exploit requires network access.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/somatrasss/weblogic2021\n- https://vulncheck.com/xdb/d5d4e15a3fd1\n- https://github.com/Y4er/CVE-2020-14756\n- https///github.com:Y4er/CVE-2020-14756.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14152"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14152",
              "body": "\n### Description: \n> Oracle Coherence of Oracle Fusion Middleware (versions 3.7.1.0, 12.1.3.0.0, 12.2.1.3.0, 12.2.1.4.0, 14.1.1.0.0) contains a remote code execution caused by unauthenticated network access via IIOP and T3, letting attackers compromise the system, exploit requires network access.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/somatrasss/weblogic2021\n- https://vulncheck.com/xdb/d5d4e15a3fd1\n- https://github.com/Y4er/CVE-2020-14756\n- https///github.com:Y4er/CVE-2020-14756.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14152",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14077",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-12-12T23:33:32.248Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:32.248Z",
            "created_at": "2025-12-12T23:33:32.248Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14077",
              "status": "open",
              "type": "issue",
              "number": 14077,
              "title": "CVE-2021-21980 - vSphere Web Client - Path Traversal ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14077",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2021-21980 - vSphere Web Client - Path Traversal ",
                  "body": "\n### Description: \n> vSphere Web Client (FLEX/Flash) contains an unauthorized arbitrary file read caused by insecure file access in the web client, letting attackers with network access to port 443 on vCenter Server access sensitive information, exploit requires network access to port 443.\n\n#### Severity: `High`\n\n#### POC: \n- https://github.com/Osyanina/westone-CVE-2022-1388-scanner\n- https://github.com/Osyanina/westone-CVE-2021-21980-scanner\n\n### KEV: True\n\n### Shodan Query: `http.title:\"vmware cloud\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14077"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14077",
              "body": "\n### Description: \n> vSphere Web Client (FLEX/Flash) contains an unauthorized arbitrary file read caused by insecure file access in the web client, letting attackers with network access to port 443 on vCenter Server access sensitive information, exploit requires network access to port 443.\n\n#### Severity: `High`\n\n#### POC: \n- https://github.com/Osyanina/westone-CVE-2022-1388-scanner\n- https://github.com/Osyanina/westone-CVE-2021-21980-scanner\n\n### KEV: True\n\n### Shodan Query: `http.title:\"vmware cloud\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14077",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14092",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-12-12T23:33:32.370Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:32.370Z",
            "created_at": "2025-12-12T23:33:32.370Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14092",
              "status": "open",
              "type": "issue",
              "number": 14092,
              "title": "CVE-2021-22941 - Citrix ShareFile - Broken Access Control ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14092",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2021-22941 - Citrix ShareFile - Broken Access Control ",
                  "body": "\n### Description: \n> Citrix ShareFile Storage Zones Controller before 5.11.20 contains a broken access control vulnerability caused by improper access restrictions, letting unauthenticated attackers remotely compromise the system, exploit requires no authentication.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/hoavt18/CVE-2021-22941\n- https://github.com/hoav18/CVE-2021-22941\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14092"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14092",
              "body": "\n### Description: \n> Citrix ShareFile Storage Zones Controller before 5.11.20 contains a broken access control vulnerability caused by improper access restrictions, letting unauthenticated attackers remotely compromise the system, exploit requires no authentication.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/hoavt18/CVE-2021-22941\n- https://github.com/hoav18/CVE-2021-22941\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14092",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14077",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-12-12T23:33:32.376Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:32.376Z",
            "created_at": "2025-12-12T23:33:32.376Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14077",
              "status": "open",
              "type": "issue",
              "number": 14077,
              "title": "CVE-2021-21980 - vSphere Web Client - Path Traversal ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14077",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2021-21980 - vSphere Web Client - Path Traversal ",
                  "body": "\n### Description: \n> vSphere Web Client (FLEX/Flash) contains an unauthorized arbitrary file read caused by insecure file access in the web client, letting attackers with network access to port 443 on vCenter Server access sensitive information, exploit requires network access to port 443.\n\n#### Severity: `High`\n\n#### POC: \n- https://github.com/Osyanina/westone-CVE-2022-1388-scanner\n- https://github.com/Osyanina/westone-CVE-2021-21980-scanner\n\n### KEV: True\n\n### Shodan Query: `http.title:\"vmware cloud\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14077"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14077",
              "body": "\n### Description: \n> vSphere Web Client (FLEX/Flash) contains an unauthorized arbitrary file read caused by insecure file access in the web client, letting attackers with network access to port 443 on vCenter Server access sensitive information, exploit requires network access to port 443.\n\n#### Severity: `High`\n\n#### POC: \n- https://github.com/Osyanina/westone-CVE-2022-1388-scanner\n- https://github.com/Osyanina/westone-CVE-2021-21980-scanner\n\n### KEV: True\n\n### Shodan Query: `http.title:\"vmware cloud\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14077",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "highlight#8635",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "highlight",
              "id": "generated-highlight",
              "name": "Highlight",
              "description": "",
              "members": [],
              "display_name": "Highlight",
              "created_at": "2025-12-12T23:33:34.861Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/highlight?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "highlight",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:34.861Z",
            "created_at": "2025-12-12T23:33:34.861Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-highlight#8635",
              "status": "open",
              "type": "issue",
              "number": 8635,
              "title": "Update workspace and project settings to not use antd components",
              "source": {
                "data": {
                  "id": "source-highlight#8635",
                  "user": {
                    "login": "ccschmitz",
                    "id": 308182,
                    "node_id": "MDQ6VXNlcjMwODE4Mg==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/308182?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ccschmitz",
                    "html_url": "https://github.com/ccschmitz",
                    "followers_url": "https://api.github.com/users/ccschmitz/followers",
                    "following_url": "https://api.github.com/users/ccschmitz/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ccschmitz/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ccschmitz/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ccschmitz/subscriptions",
                    "organizations_url": "https://api.github.com/users/ccschmitz/orgs",
                    "repos_url": "https://api.github.com/users/ccschmitz/repos",
                    "events_url": "https://api.github.com/users/ccschmitz/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ccschmitz/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Update workspace and project settings to not use antd components",
                  "body": "Whoever implements should feel free to break this up into multiple tickets, perhaps one per page.",
                  "html_url": "https://github.com/highlight/highlight/issues/8635"
                },
                "type": "github"
              },
              "hash": "highlight/highlight#8635",
              "body": "Whoever implements should feel free to break this up into multiple tickets, perhaps one per page.",
              "url": "https://github.com/highlight/highlight/issues/8635",
              "tech": [
                "go"
              ],
              "repo_name": "highlight",
              "repo_owner": "highlight",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "highlight#8614",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "highlight",
              "id": "generated-highlight",
              "name": "Highlight",
              "description": "",
              "members": [],
              "display_name": "Highlight",
              "created_at": "2025-12-12T23:33:34.993Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/highlight?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "highlight",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:34.993Z",
            "created_at": "2025-12-12T23:33:34.993Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-highlight#8614",
              "status": "open",
              "type": "issue",
              "number": 8614,
              "title": "update design of integrations page",
              "source": {
                "data": {
                  "id": "source-highlight#8614",
                  "user": {
                    "login": "Vadman97",
                    "id": 1351531,
                    "node_id": "MDQ6VXNlcjEzNTE1MzE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1351531?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Vadman97",
                    "html_url": "https://github.com/Vadman97",
                    "followers_url": "https://api.github.com/users/Vadman97/followers",
                    "following_url": "https://api.github.com/users/Vadman97/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Vadman97/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Vadman97/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Vadman97/subscriptions",
                    "organizations_url": "https://api.github.com/users/Vadman97/orgs",
                    "repos_url": "https://api.github.com/users/Vadman97/repos",
                    "events_url": "https://api.github.com/users/Vadman97/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Vadman97/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "update design of integrations page",
                  "body": "Call us +1 (650) 420-2207  https://github.com/highlight/highlight/issues/8635 https://github.com/highlight/highlight/pull/9716 https://github.com/highlight/highlight/issues/8614 https://github.com/hig",
                  "html_url": "https://github.com/highlight/highlight/issues/8614"
                },
                "type": "github"
              },
              "hash": "highlight/highlight#8614",
              "body": "Call us +1 (650) 420-2207  https://github.com/highlight/highlight/issues/8635 https://github.com/highlight/highlight/pull/9716 https://github.com/highlight/highlight/issues/8614 https://github.com/hig",
              "url": "https://github.com/highlight/highlight/issues/8614",
              "tech": [],
              "repo_name": "highlight",
              "repo_owner": "highlight",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "highlight#8032",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "highlight",
              "id": "generated-highlight",
              "name": "Highlight",
              "description": "",
              "members": [],
              "display_name": "Highlight",
              "created_at": "2025-12-12T23:33:35.092Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/highlight?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "highlight",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:35.092Z",
            "created_at": "2025-12-12T23:33:35.092Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-highlight#8032",
              "status": "open",
              "type": "issue",
              "number": 8032,
              "title": "document sveltekit backend instrumentation",
              "source": {
                "data": {
                  "id": "source-highlight#8032",
                  "user": {
                    "login": "Vadman97",
                    "id": 1351531,
                    "node_id": "MDQ6VXNlcjEzNTE1MzE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1351531?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Vadman97",
                    "html_url": "https://github.com/Vadman97",
                    "followers_url": "https://api.github.com/users/Vadman97/followers",
                    "following_url": "https://api.github.com/users/Vadman97/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Vadman97/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Vadman97/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Vadman97/subscriptions",
                    "organizations_url": "https://api.github.com/users/Vadman97/orgs",
                    "repos_url": "https://api.github.com/users/Vadman97/repos",
                    "events_url": "https://api.github.com/users/Vadman97/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Vadman97/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "document sveltekit backend instrumentation",
                  "body": "see linear thread linked for starting point\n\n[https://discord.com/channels/1026884757667188757/1217184768001839225/1218189516041621524](https://discord.com/channels/1026884757667188757/1217184768001839225/1218189516041621524)",
                  "html_url": "https://github.com/highlight/highlight/issues/8032"
                },
                "type": "github"
              },
              "hash": "highlight/highlight#8032",
              "body": "see linear thread linked for starting point\n\n[https://discord.com/channels/1026884757667188757/1217184768001839225/1218189516041621524](https://discord.com/channels/1026884757667188757/1217184768001839225/1218189516041621524)",
              "url": "https://github.com/highlight/highlight/issues/8032",
              "tech": [],
              "repo_name": "highlight",
              "repo_owner": "highlight",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "highlight#6775",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "highlight",
              "id": "generated-highlight",
              "name": "Highlight",
              "description": "",
              "members": [],
              "display_name": "Highlight",
              "created_at": "2025-12-12T23:33:35.200Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/highlight?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "highlight",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:35.200Z",
            "created_at": "2025-12-12T23:33:35.200Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-highlight#6775",
              "status": "open",
              "type": "issue",
              "number": 6775,
              "title": "Performance of canvas snapshotting on Safari is poor",
              "source": {
                "data": {
                  "id": "source-highlight#6775",
                  "user": {
                    "login": "Pinpickle",
                    "id": 3238878,
                    "node_id": "MDQ6VXNlcjMyMzg4Nzg=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/3238878?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Pinpickle",
                    "html_url": "https://github.com/Pinpickle",
                    "followers_url": "https://api.github.com/users/Pinpickle/followers",
                    "following_url": "https://api.github.com/users/Pinpickle/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Pinpickle/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Pinpickle/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Pinpickle/subscriptions",
                    "organizations_url": "https://api.github.com/users/Pinpickle/orgs",
                    "repos_url": "https://api.github.com/users/Pinpickle/repos",
                    "events_url": "https://api.github.com/users/Pinpickle/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Pinpickle/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Performance of canvas snapshotting on Safari is poor",
                  "body": "**Describe the bug**\r\n\r\nSnapshotting a canvas element in Safari 16.x takes a long time (>20ms). This leads to a frame drop every time the canvas is snapshotted.\r\n\r\n**To Reproduce**\r\n\r\nGo to the Codsandbox full-screen here https://jqgtld.csb.app/ \r\n\r\nLook at the \"Snapshot\" stat in the top right corner (or in the console). On my computer it is ~20ms on Safari 16.5. On Chrome, it is between 0 and 0.3ms.\r\n\r\nThe window size is 1057 x 734 (retina display, so double the dimensions for the canvas)\r\n\r\nHere's the codesandbox with the editor: https://codesandbox.io/s/dazzling-roentgen-jqgtld?file=/src/App.js\r\n\r\n**Expected behavior**\r\n\r\nOverhead for snapshotting to be near 0\r\n\r\n**Screenshots**\r\n\r\n## Safari\r\n\r\n![CleanShot 2023-10-02 at 15 23 03 png](https://github.com/highlight/highlight/assets/3238878/1bc6d193-ea1f-4fda-ae03-7ea9c9cf9143)\r\n\r\n## Chrome\r\n\r\n![CleanShot 2023-10-02 at 15 23 55 png](https://github.com/highlight/highlight/assets/3238878/7a3767f7-94a0-467b-9c23-bac305507d66)\r\n\r\n## iOS\r\n\r\n![CleanShot 2023-10-02 at 15 27 57 png](https://github.com/highlight/highlight/assets/3238878/664fc6c4-27b8-43ce-be71-b35b7553716f)\r\n\r\n\r\n**Additional context**\r\n\r\nEnvironment:\r\n\r\n```\r\nSystem:\r\n    OS: macOS 13.4\r\n    CPU: (8) arm64 Apple M1\r\n    Memory: 51.78 MB / 8.00 GB\r\nBrowsers:\r\n    Chrome: 117.0.5938.92\r\n    Safari: 16.5\r\n```\r\n\r\nProvided this also affects Safari 17 (I don't know if it does), this affects _every_ Safari-based browser (including everything on iOS). This performance drop means we had to disable canvas recording for Safari on our app which really limits its usefulness.\r\n\r\nThe larger the canvas, the longer the snapshot time, from what I can tell. Changing `canvasMaxSnapshotDimension` does not appear to make a difference. Safari doesn't even respect the options parameter for `createBitmapImage`: https://developer.mozilla.org/en-US/docs/Web/API/createImageBitmap\r\n\r\nI'm reasonably confident this comes from the call to `createBitmapImage` here:\r\n\r\nhttps://github.com/highlight/highlight/blob/ed2ea183d0d11781736e2001b01e24e55c33e8cb/frontend/src/__generated/rr/rr.js#L4266-L4269\r\n\r\nIt's supposed to be asynchronous but it looks like it is blocking in Safari. I wonder if there are other ways to get the image data out of a canvas? I understand there are efforts to use WebRTC for canvas recording? I imagine this could help.\r\n",
                  "html_url": "https://github.com/highlight/highlight/issues/6775"
                },
                "type": "github"
              },
              "hash": "highlight/highlight#6775",
              "body": "**Describe the bug**\r\n\r\nSnapshotting a canvas element in Safari 16.x takes a long time (>20ms). This leads to a frame drop every time the canvas is snapshotted.\r\n\r\n**To Reproduce**\r\n\r\nGo to the Codsandbox full-screen here https://jqgtld.csb.app/ \r\n\r\nLook at the \"Snapshot\" stat in the top right corner (or in the console). On my computer it is ~20ms on Safari 16.5. On Chrome, it is between 0 and 0.3ms.\r\n\r\nThe window size is 1057 x 734 (retina display, so double the dimensions for the canvas)\r\n\r\nHere's the codesandbox with the editor: https://codesandbox.io/s/dazzling-roentgen-jqgtld?file=/src/App.js\r\n\r\n**Expected behavior**\r\n\r\nOverhead for snapshotting to be near 0\r\n\r\n**Screenshots**\r\n\r\n## Safari\r\n\r\n![CleanShot 2023-10-02 at 15 23 03 png](https://github.com/highlight/highlight/assets/3238878/1bc6d193-ea1f-4fda-ae03-7ea9c9cf9143)\r\n\r\n## Chrome\r\n\r\n![CleanShot 2023-10-02 at 15 23 55 png](https://github.com/highlight/highlight/assets/3238878/7a3767f7-94a0-467b-9c23-bac305507d66)\r\n\r\n## iOS\r\n\r\n![CleanShot 2023-10-02 at 15 27 57 png](https://github.com/highlight/highlight/assets/3238878/664fc6c4-27b8-43ce-be71-b35b7553716f)\r\n\r\n\r\n**Additional context**\r\n\r\nEnvironment:\r\n\r\n```\r\nSystem:\r\n    OS: macOS 13.4\r\n    CPU: (8) arm64 Apple M1\r\n    Memory: 51.78 MB / 8.00 GB\r\nBrowsers:\r\n    Chrome: 117.0.5938.92\r\n    Safari: 16.5\r\n```\r\n\r\nProvided this also affects Safari 17 (I don't know if it does), this affects _every_ Safari-based browser (including everything on iOS). This performance drop means we had to disable canvas recording for Safari on our app which really limits its usefulness.\r\n\r\nThe larger the canvas, the longer the snapshot time, from what I can tell. Changing `canvasMaxSnapshotDimension` does not appear to make a difference. Safari doesn't even respect the options parameter for `createBitmapImage`: https://developer.mozilla.org/en-US/docs/Web/API/createImageBitmap\r\n\r\nI'm reasonably confident this comes from the call to `createBitmapImage` here:\r\n\r\nhttps://github.com/highlight/highlight/blob/ed2ea183d0d11781736e2001b01e24e55c33e8cb/frontend/src/__generated/rr/rr.js#L4266-L4269\r\n\r\nIt's supposed to be asynchronous but it looks like it is blocking in Safari. I wonder if there are other ways to get the image data out of a canvas? I understand there are efforts to use WebRTC for canvas recording? I imagine this could help.\r\n",
              "url": "https://github.com/highlight/highlight/issues/6775",
              "tech": [],
              "repo_name": "highlight",
              "repo_owner": "highlight",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#3960",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2025-12-12T23:33:34.856Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:34.856Z",
            "created_at": "2025-12-12T23:33:34.856Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3960",
              "status": "open",
              "type": "issue",
              "number": 3960,
              "title": "[ Provider]: Nagios Provider",
              "source": {
                "data": {
                  "id": "source-keephq#3960",
                  "user": {
                    "login": "talboren",
                    "id": 68807791,
                    "node_id": "MDQ6VXNlcjY4ODA3Nzkx",
                    "avatar_url": "https://avatars.githubusercontent.com/u/68807791?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/talboren",
                    "html_url": "https://github.com/talboren",
                    "followers_url": "https://api.github.com/users/talboren/followers",
                    "following_url": "https://api.github.com/users/talboren/following{/other_user}",
                    "gists_url": "https://api.github.com/users/talboren/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/talboren/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/talboren/subscriptions",
                    "organizations_url": "https://api.github.com/users/talboren/orgs",
                    "repos_url": "https://api.github.com/users/talboren/repos",
                    "events_url": "https://api.github.com/users/talboren/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/talboren/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[ Provider]: Nagios Provider",
                  "body": "https://www.nagios.org/",
                  "html_url": "https://github.com/keephq/keep/issues/3960"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3960",
              "body": "https://www.nagios.org/",
              "url": "https://github.com/keephq/keep/issues/3960",
              "tech": [
                "go"
              ],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#3526",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2025-12-12T23:33:34.950Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:34.950Z",
            "created_at": "2025-12-12T23:33:34.950Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3526",
              "status": "open",
              "type": "issue",
              "number": 3526,
              "title": "[ Provider]: Solarwinds",
              "source": {
                "data": {
                  "id": "source-keephq#3526",
                  "user": {
                    "login": "Matvey-Kuk",
                    "id": 3284841,
                    "node_id": "MDQ6VXNlcjMyODQ4NDE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/3284841?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Matvey-Kuk",
                    "html_url": "https://github.com/Matvey-Kuk",
                    "followers_url": "https://api.github.com/users/Matvey-Kuk/followers",
                    "following_url": "https://api.github.com/users/Matvey-Kuk/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Matvey-Kuk/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Matvey-Kuk/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Matvey-Kuk/subscriptions",
                    "organizations_url": "https://api.github.com/users/Matvey-Kuk/orgs",
                    "repos_url": "https://api.github.com/users/Matvey-Kuk/repos",
                    "events_url": "https://api.github.com/users/Matvey-Kuk/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Matvey-Kuk/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[ Provider]: Solarwinds",
                  "body": "We're looking for a https://www.solarwinds.com/ provider for Keep.",
                  "html_url": "https://github.com/keephq/keep/issues/3526"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3526",
              "body": "We're looking for a https://www.solarwinds.com/ provider for Keep.",
              "url": "https://github.com/keephq/keep/issues/3526",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#3376",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2025-12-12T23:33:35.043Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:35.043Z",
            "created_at": "2025-12-12T23:33:35.043Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3376",
              "status": "open",
              "type": "issue",
              "number": 3376,
              "title": "[ Feature]: Add a way to validate Keep workflows from CI",
              "source": {
                "data": {
                  "id": "source-keephq#3376",
                  "user": {
                    "login": "shahargl",
                    "id": 12069200,
                    "node_id": "MDQ6VXNlcjEyMDY5MjAw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/12069200?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/shahargl",
                    "html_url": "https://github.com/shahargl",
                    "followers_url": "https://api.github.com/users/shahargl/followers",
                    "following_url": "https://api.github.com/users/shahargl/following{/other_user}",
                    "gists_url": "https://api.github.com/users/shahargl/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/shahargl/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/shahargl/subscriptions",
                    "organizations_url": "https://api.github.com/users/shahargl/orgs",
                    "repos_url": "https://api.github.com/users/shahargl/repos",
                    "events_url": "https://api.github.com/users/shahargl/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/shahargl/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[ Feature]: Add a way to validate Keep workflows from CI",
                  "body": " https://github.com/keephq/keep/issues/3960 https://github.com/keephq/keep/pull/5149 https://github.com/keephq/keep/pull/4517 https://github.com/keephq/keep/issues/3526 https://github.com/keephq/keep/",
                  "html_url": "https://github.com/keephq/keep/issues/3376"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3376",
              "body": " https://github.com/keephq/keep/issues/3960 https://github.com/keephq/keep/pull/5149 https://github.com/keephq/keep/pull/4517 https://github.com/keephq/keep/issues/3526 https://github.com/keephq/keep/",
              "url": "https://github.com/keephq/keep/issues/3376",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#3379",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2025-12-12T23:33:35.185Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:35.185Z",
            "created_at": "2025-12-12T23:33:35.185Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3379",
              "status": "open",
              "type": "issue",
              "number": 3379,
              "title": "[ Provider]: ServiceNow pull activity from incidents into incidents",
              "source": {
                "data": {
                  "id": "source-keephq#3379",
                  "user": {
                    "login": "talboren",
                    "id": 68807791,
                    "node_id": "MDQ6VXNlcjY4ODA3Nzkx",
                    "avatar_url": "https://avatars.githubusercontent.com/u/68807791?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/talboren",
                    "html_url": "https://github.com/talboren",
                    "followers_url": "https://api.github.com/users/talboren/followers",
                    "following_url": "https://api.github.com/users/talboren/following{/other_user}",
                    "gists_url": "https://api.github.com/users/talboren/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/talboren/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/talboren/subscriptions",
                    "organizations_url": "https://api.github.com/users/talboren/orgs",
                    "repos_url": "https://api.github.com/users/talboren/repos",
                    "events_url": "https://api.github.com/users/talboren/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/talboren/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[ Provider]: ServiceNow pull activity from incidents into incidents",
                  "body": "As a user, I would like to pull activity from ServiceNow incident into my Keep incident and the other way around.",
                  "html_url": "https://github.com/keephq/keep/issues/3379"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3379",
              "body": "As a user, I would like to pull activity from ServiceNow incident into my Keep incident and the other way around.",
              "url": "https://github.com/keephq/keep/issues/3379",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#2112",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2025-12-12T23:33:35.288Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:35.288Z",
            "created_at": "2025-12-12T23:33:35.288Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#2112",
              "status": "open",
              "type": "issue",
              "number": 2112,
              "title": "[ Provider]: SNMP provider",
              "source": {
                "data": {
                  "id": "source-keephq#2112",
                  "user": {
                    "login": "shahargl",
                    "id": 12069200,
                    "node_id": "MDQ6VXNlcjEyMDY5MjAw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/12069200?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/shahargl",
                    "html_url": "https://github.com/shahargl",
                    "followers_url": "https://api.github.com/users/shahargl/followers",
                    "following_url": "https://api.github.com/users/shahargl/following{/other_user}",
                    "gists_url": "https://api.github.com/users/shahargl/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/shahargl/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/shahargl/subscriptions",
                    "organizations_url": "https://api.github.com/users/shahargl/orgs",
                    "repos_url": "https://api.github.com/users/shahargl/repos",
                    "events_url": "https://api.github.com/users/shahargl/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/shahargl/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[ Provider]: SNMP provider",
                  "body": "Send SNMP traps/events into Keep as alerts",
                  "html_url": "https://github.com/keephq/keep/issues/2112"
                },
                "type": "github"
              },
              "hash": "keephq/keep#2112",
              "body": "Send SNMP traps/events into Keep as alerts",
              "url": "https://github.com/keephq/keep/issues/2112",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "golemcloud#275",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "golemcloud",
              "id": "generated-golemcloud",
              "name": "Golemcloud",
              "description": "",
              "members": [],
              "display_name": "Golemcloud",
              "created_at": "2025-12-12T23:33:39.053Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/golemcloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:39.053Z",
            "created_at": "2025-12-12T23:33:39.053Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-golemcloud#275",
              "status": "open",
              "type": "issue",
              "number": 275,
              "title": "Incorporate MCP Server into Golem CLI",
              "source": {
                "data": {
                  "id": "source-golemcloud#275",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Incorporate MCP Server into Golem CLI",
                  "body": "With a new command, Golem CLI enters serve mode:\n\n```bash\n%> golem-cli --serve --serve-port 1232\n%> golem-cli running MCP Server at port 1232\n```\n\nIn this mode, Golem CLI creates an MCP Server that exposes different commands as different tools, and exposes relevant resources (the manifest file in the current, ancestor, and children directories) as resources.\n\nWhen this ticket is completed, it should be possible to use an agent such as Claude Code to perform anything that Golem CLI can do. Moreover, all individual tools and resources must be end-to-end tested with an MCP Client that interacts with the MCP Server.\n\n[This library](https://github.com/rust-mcp-stack/rust-mcp-sdk) looks like the one to use for Rust, but perhaps there are better options available.",
                  "html_url": "https://github.com/golemcloud/golem/issues/1926"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem-cli#275",
              "body": "With a new command, Golem CLI enters serve mode:\n\n```bash\n%> golem-cli --serve --serve-port 1232\n%> golem-cli running MCP Server at port 1232\n```\n\nIn this mode, Golem CLI creates an MCP Server that exposes different commands as different tools, and exposes relevant resources (the manifest file in the current, ancestor, and children directories) as resources.\n\nWhen this ticket is completed, it should be possible to use an agent such as Claude Code to perform anything that Golem CLI can do. Moreover, all individual tools and resources must be end-to-end tested with an MCP Client that interacts with the MCP Server.\n\n[This library](https://github.com/rust-mcp-stack/rust-mcp-sdk) looks like the one to use for Rust, but perhaps there are better options available.",
              "url": "https://github.com/golemcloud/golem/issues/1926",
              "tech": [
                "go"
              ],
              "repo_name": "golem-cli",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "golemcloud#23",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "golemcloud",
              "id": "generated-golemcloud",
              "name": "Golemcloud",
              "description": "",
              "members": [],
              "display_name": "Golemcloud",
              "created_at": "2025-12-12T23:33:39.166Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/golemcloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:39.166Z",
            "created_at": "2025-12-12T23:33:39.166Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-golemcloud#23",
              "status": "open",
              "type": "issue",
              "number": 23,
              "title": "Implement Durable Text-to-Speech Provider Components for golem:tts WIT Interface",
              "source": {
                "data": {
                  "id": "source-golemcloud#23",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Implement Durable Text-to-Speech Provider Components for golem:tts WIT Interface",
                  "body": "I have attached to this ticket a WIT file that describes a generic interface for text-to-speech operations. This interface can be implemented by various providers, either by emulating features not present in a given provider, utilizing the provider's native support for a feature, or indicating an error if a particular combination is not natively supported by a provider.\n\nThe intent of this WIT specification is to allow developers of WASM components (on wasmCloud, Spin, or Golem) to leverage text-to-speech capabilities to build voice-powered applications, accessibility services, and audio content generation systems in a portable and provider-agnostic fashion.\n\nThis ticket involves constructing implementations of this WIT interface for the following providers:\n\n- **ElevenLabs**: The leading AI voice synthesis platform with comprehensive voice cloning, real-time streaming, voice conversion, and sound effects generation capabilities.\n- **AWS Polly**: Amazon's enterprise text-to-speech service with extensive language support, custom lexicons, speech marks, and asynchronous synthesis for long-form content.\n- **Google Cloud Text-to-Speech**: Google's neural voice synthesis service with WaveNet and Neural2 voices, device optimization profiles, and streaming synthesis capabilities.\n- **Deepgram Aura**: High-performance real-time TTS with session-based streaming, low-latency neural voices, and conversational AI optimization.\n\nThese implementations must be written in Rust and compilable to WASM Components (WASI 0.23 only, since Golem does not yet support WASI 0.3). The standard Rust toolchain for WASM component development can be employed (see cargo component and the Rust examples of components in this and other Golem repositories).\n\nAdditionally, these implementations should incorporate custom durability semantics using the Golem durability API and the Golem host API. This approach ensures that durability is managed at the level of individual TTS operations (voice synthesis, streaming session creation, voice cloning, batch processing), providing a higher-level and clearer operation log, which aids in debugging and monitoring. See golem:llm and golem:embed for more details and durable implementations in this same repository.\n\nThe final deliverables associated with this ticket are:\n\n- **ElevenLabs implementation**: A WASM Component (WASI 0.23), named `tts-elevenlabs.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **AWS Polly implementation**: A WASM Component (WASI 0.23), named `tts-polly.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Google Cloud TTS implementation**: A WASM Component (WASI 0.23), named `tts-google.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Deepgram Aura implementation**: A WASM Component (WASI 0.23), named `tts-deepgram.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n\n**Note**: If you have a strong recommendation to swap out one or two of these with other popular / common TTS providers (such as Azure Cognitive Services Speech, IBM Watson Text to Speech, or OpenAI TTS), then as long as you get permission beforehand, that's okay with me. However, we definitely need ElevenLabs and AWS Polly.\n\nThese components will require runtime configuration, notably API keys, endpoint URLs, authentication credentials, and provider-specific settings. For configuring this information, the components can use environment variables for now (in the future, they will use wasi-runtime-config, but Golem does not support this yet, whereas Golem has good support for environment variables).\n\nMoreover, the Rust components need to be tested within Golem to ensure compatibility with Golem 1.2.x.\n\nThis WIT has been designed by examining and comparing the APIs of ElevenLabs, AWS Polly, Google Cloud TTS, Azure Speech Services, OpenAI TTS, and Deepgram Aura. However, given there are no implementations, it is possible the provided WIT is not the optimal abstraction across all these providers. Therefore, deviations from the proposed design can be made. However, to be accepted, any deviation must be fully justified and deemed by Golem core contributors to be an improvement from the original specification.\n\n## Implementation Guidelines\n\nEach provider implementation should handle the following key mapping considerations:\n\n- **Voice Management**: Map the unified voice resource to provider-specific voice identifiers, handle voice discovery and metadata appropriately for each provider's voice catalog structure\n- **Audio Format Conversion**: Implement native audio format support where available, or provide format conversion for unsupported output formats using audio processing libraries\n- **Streaming Implementation**: Utilize native streaming APIs where supported (ElevenLabs, Deepgram), or implement chunk-based synthesis for providers without native streaming support\n- **Authentication Handling**: Implement appropriate authentication mechanisms (API keys, OAuth, service accounts) per provider requirements\n- **Feature Availability**: Route advanced features (voice cloning, sound effects, speech marks) through provider-native APIs where supported, or return `unsupported-operation` errors for unavailable features\n- **Error Mapping**: Map provider-specific HTTP errors and API responses to the unified `tts-error` enumeration with appropriate context preservation\n- **Rate Limiting**: Handle provider-specific rate limits and quota management, implementing appropriate retry logic and error reporting\n- **Long-form Content**: Implement efficient handling of long-form synthesis using provider-native async operations (AWS Polly) or intelligent chunking strategies\n\n## Testing Requirements\n\nEach implementation must include comprehensive test suites covering:\n- Basic synthesis operations (text-to-speech with various voices and configurations)\n- Voice discovery and metadata retrieval\n- Streaming synthesis lifecycle (session creation, chunk processing, cleanup)\n- Advanced feature testing (voice cloning, sound effects, custom pronunciations where supported)\n- Audio format validation and quality verification\n- Authentication and authorization scenarios\n- Error handling for unsupported operations and malformed inputs\n- Rate limiting and quota management behavior\n- Connection management and retry logic\n- Long-form content synthesis (>5000 characters)\n- Durability semantics verification across operation boundaries\n- Provider-specific feature utilization (lexicons for Polly, voice settings for ElevenLabs, etc.)\n\n## Configuration Requirements\n\nEach implementation should support the following environment variables:\n\n### Common Configuration\n- `TTS_PROVIDER_ENDPOINT`: Custom endpoint URL (for enterprise/regional deployments)\n- `TTS_PROVIDER_TIMEOUT`: Request timeout in seconds (default: 30)\n- `TTS_PROVIDER_MAX_RETRIES`: Maximum retry attempts (default: 3)\n- `TTS_PROVIDER_LOG_LEVEL`: Logging verbosity (debug, info, warn, error)\n\n### Provider-Specific Configuration\n- **ElevenLabs**: `ELEVENLABS_API_KEY`, `ELEVENLABS_MODEL_VERSION`\n- **AWS Polly**: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `AWS_SESSION_TOKEN`\n- **Google Cloud**: `GOOGLE_APPLICATION_CREDENTIALS`, `GOOGLE_CLOUD_PROJECT`\n- **Deepgram**: `DEEPGRAM_API_KEY`, `DEEPGRAM_API_VERSION`\n\n```wit\npackage golem:tts@1.0.0;\n\n/// Core types and error handling for universal text-to-speech\ninterface types {\n    /// Comprehensive error types covering all TTS operations\n    variant tts-error {\n        /// Input validation errors\n        invalid-text(string),\n        text-too-long(u32),\n        invalid-ssml(string),\n        unsupported-language(string),\n        \n        /// Voice and model errors\n        voice-not-found(string),\n        model-not-found(string),\n        voice-unavailable(string),\n        \n        /// Authentication and authorization\n        unauthorized(string),\n        access-denied(string),\n        \n        /// Resource and quota limits\n        quota-exceeded(quota-info),\n        rate-limited(u32),\n        insufficient-credits,\n        \n        /// Operation errors\n        synthesis-failed(string),\n        unsupported-operation(string),\n        invalid-configuration(string),\n        \n        /// Service errors\n        service-unavailable(string),\n        network-error(string),\n        internal-error(string),\n        \n        /// Storage errors (for async operations)\n        invalid-storage-location(string),\n        storage-access-denied(string),\n    }\n\n    record quota-info {\n        used: u32,\n        limit: u32,\n        reset-time: u64,\n        unit: quota-unit,\n    }\n\n    enum quota-unit {\n        characters,\n        requests,\n        seconds,\n        credits,\n    }\n\n    /// Language identification using BCP 47 codes\n    type language-code = string;\n\n    /// Voice gender classification\n    enum voice-gender {\n        male,\n        female,\n        neutral,\n    }\n\n    /// Voice quality tiers\n    enum voice-quality {\n        standard,\n        premium,\n        neural,\n        studio,\n    }\n\n    /// Text input types\n    enum text-type {\n        plain,\n        ssml,\n    }\n\n    /// Audio output formats\n    enum audio-format {\n        mp3,\n        wav,\n        pcm,\n        ogg-opus,\n        aac,\n        flac,\n        mulaw,\n        alaw,\n    }\n\n    /// Audio quality settings\n    record audio-config {\n        format: audio-format,\n        sample-rate: option<u32>,\n        bit-rate: option<u32>,\n        channels: option<u8>,\n    }\n\n    /// Voice synthesis parameters\n    record voice-settings {\n        /// Speaking rate (0.25 to 4.0, default 1.0)\n        speed: option<f32>,\n        /// Pitch adjustment in semitones (-20.0 to 20.0, default 0.0)\n        pitch: option<f32>,\n        /// Volume gain in dB (-96.0 to 16.0, default 0.0)\n        volume: option<f32>,\n        /// Voice stability (0.0 to 1.0, provider-specific)\n        stability: option<f32>,\n        /// Similarity to original (0.0 to 1.0, provider-specific)\n        similarity: option<f32>,\n        /// Style exaggeration (0.0 to 1.0, provider-specific)\n        style: option<f32>,\n    }\n\n    /// Audio effects and device optimization\n    flags audio-effects {\n        telephone-quality,\n        headphone-optimized,\n        speaker-optimized,\n        car-audio-optimized,\n        noise-reduction,\n        bass-boost,\n        treble-boost,\n    }\n\n    /// Input text with metadata\n    record text-input {\n        content: string,\n        text-type: text-type,\n        language: option<language-code>,\n    }\n\n    /// Complete synthesis result\n    record synthesis-result {\n        audio-data: list<u8>,\n        metadata: synthesis-metadata,\n    }\n\n    /// Metadata about synthesized audio\n    record synthesis-metadata {\n        duration-seconds: f32,\n        character-count: u32,\n        word-count: u32,\n        audio-size-bytes: u32,\n        request-id: string,\n        provider-info: option<string>,\n    }\n\n    /// Streaming audio chunk\n    record audio-chunk {\n        data: list<u8>,\n        sequence-number: u32,\n        is-final: bool,\n        timing-info: option<timing-info>,\n    }\n\n    /// Timing and synchronization information\n    record timing-info {\n        start-time-seconds: f32,\n        end-time-seconds: option<f32>,\n        text-offset: option<u32>,\n        mark-type: option<timing-mark-type>,\n    }\n\n    enum timing-mark-type {\n        word,\n        sentence,\n        paragraph,\n        ssml-mark,\n        viseme,\n    }\n\n\n}\n\n/// Voice discovery and management\ninterface voices {\n    use types.{tts-error, language-code, voice-gender, voice-quality};\n\n    /// Represents a voice that can be used for speech synthesis\n    resource voice {\n        /// Get voice identification\n        get-id: func() -> string;\n        get-name: func() -> string;\n        get-provider-id: func() -> option<string>;\n        \n        /// Get voice characteristics\n        get-language: func() -> language-code;\n        get-additional-languages: func() -> list<language-code>;\n        get-gender: func() -> voice-gender;\n        get-quality: func() -> voice-quality;\n        get-description: func() -> option<string>;\n        \n        /// Voice capabilities\n        supports-ssml: func() -> bool;\n        get-sample-rates: func() -> list<u32>;\n        get-supported-formats: func() -> list<types.audio-format>;\n        \n        /// Voice management (may return unsupported-operation)\n        update-settings: func(settings: types.voice-settings) -> result<_, tts-error>;\n        delete: func() -> result<_, tts-error>;\n        clone: func() -> result<voice, tts-error>;\n        \n        /// Preview voice with sample text\n        preview: func(text: string) -> result<list<u8>, tts-error>;\n    }\n\n    /// Voice search and filtering\n    record voice-filter {\n        language: option<language-code>,\n        gender: option<voice-gender>,\n        quality: option<voice-quality>,\n        supports-ssml: option<bool>,\n        provider: option<string>,\n        search-query: option<string>,\n    }\n\n    /// Detailed voice information\n    record voice-info {\n        id: string,\n        name: string,\n        language: language-code,\n        additional-languages: list<language-code>,\n        gender: voice-gender,\n        quality: voice-quality,\n        description: option<string>,\n        provider: string,\n        sample-rate: u32,\n        is-custom: bool,\n        is-cloned: bool,\n        preview-url: option<string>,\n        use-cases: list<string>,\n    }\n\n    /// Resource-based iterator for voice results\n    resource voice-results {\n        /// Check if more voices are available\n        has-more: func() -> bool;\n        \n        /// Get next batch of voices\n        get-next: func() -> result<list<voice-info>, tts-error>;\n        \n        /// Get total count if available\n        get-total-count: func() -> option<u32>;\n    }\n\n    /// List available voices with filtering and pagination\n    list-voices: func(\n        filter: option<voice-filter>\n    ) -> result<voice-results, tts-error>;\n\n    /// Get specific voice by ID\n    get-voice: func(voice-id: string) -> result<voice, tts-error>;\n\n    /// Search voices by characteristics\n    search-voices: func(\n        query: string,\n        filter: option<voice-filter>\n    ) -> result<list<voice-info>, tts-error>;\n\n    /// Get supported languages\n    list-languages: func() -> result<list<language-info>, tts-error>;\n\n    record language-info {\n        code: language-code,\n        name: string,\n        native-name: string,\n        voice-count: u32,\n    }\n}\n\n/// Core text-to-speech synthesis operations\ninterface synthesis {\n    use types.{\n        text-input, audio-config, voice-settings, audio-effects,\n        synthesis-result, tts-error, timing-info\n    };\n    use voices.{voice};\n\n    /// Synthesis configuration options\n    record synthesis-options {\n        audio-config: option<audio-config>,\n        voice-settings: option<voice-settings>,\n        audio-effects: option<audio-effects>,\n        enable-timing: option<bool>,\n        enable-word-timing: option<bool>,\n        seed: option<u32>,\n        model-version: option<string>,\n        context: option<synthesis-context>,\n    }\n\n    /// Context for better synthesis quality\n    record synthesis-context {\n        previous-text: option<string>,\n        next-text: option<string>,\n        topic: option<string>,\n        emotion: option<string>,\n        speaking-style: option<string>,\n    }\n\n    /// Convert text to speech (removed async)\n    synthesize: func(\n        input: text-input,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-result, tts-error>;\n\n    /// Batch synthesis for multiple inputs (removed async)\n    synthesize-batch: func(\n        inputs: list<text-input>,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<list<synthesis-result>, tts-error>;\n\n    /// Get timing information without audio synthesis\n    get-timing-marks: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<list<timing-info>, tts-error>;\n\n    /// Validate text before synthesis\n    validate-input: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<validation-result, tts-error>;\n\n    record validation-result {\n        is-valid: bool,\n        character-count: u32,\n        estimated-duration: option<f32>,\n        warnings: list<string>,\n        errors: list<string>,\n    }\n}\n\n/// Real-time streaming synthesis\ninterface streaming {\n    use types.{\n        text-input, audio-config, voice-settings, audio-chunk,\n        tts-error, timing-info\n    };\n    use voices.{voice};\n    use synthesis.{synthesis-options};\n\n    /// Streaming synthesis session\n    resource synthesis-stream {\n        /// Send text for synthesis (can be called multiple times)\n        send-text: func(input: text-input) -> result<_, tts-error>;\n        \n        /// Signal end of input and flush remaining audio\n        finish: func() -> result<_, tts-error>;\n        \n        /// Receive next audio chunk (non-blocking)\n        receive-chunk: func() -> result<option<audio-chunk>, tts-error>;\n        \n        /// Check if more chunks are available\n        has-pending-audio: func() -> bool;\n        \n        /// Get current stream status\n        get-status: func() -> stream-status;\n        \n        /// Close stream and clean up resources\n        close: func();\n    }\n\n    enum stream-status {\n        ready,\n        processing,\n        finished,\n        error,\n        closed,\n    }\n\n    /// Create streaming synthesis session\n    create-stream: func(\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-stream, tts-error>;\n\n    /// Real-time voice conversion streaming\n    create-voice-conversion-stream: func(\n        target-voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<voice-conversion-stream, tts-error>;\n\n    resource voice-conversion-stream {\n        /// Send input audio chunks\n        send-audio: func(audio-data: list<u8>) -> result<_, tts-error>;\n        \n        /// Receive converted audio chunks\n        receive-converted: func() -> result<option<audio-chunk>, tts-error>;\n        \n        finish: func() -> result<_, tts-error>;\n        close: func();\n    }\n}\n\n/// Advanced TTS features and voice manipulation\ninterface advanced {\n    use types.{tts-error, audio-config, language-code};\n    use voices.{voice};\n\n    /// Voice cloning and creation (removed async)\n    create-voice-clone: func(\n        name: string,\n        audio-samples: list<audio-sample>,\n        description: option<string>\n    ) -> result<voice, tts-error>;\n\n    record audio-sample {\n        data: list<u8>,\n        transcript: option<string>,\n        quality-rating: option<u8>,\n    }\n\n    /// Design synthetic voice (removed async)\n    design-voice: func(\n        name: string,\n        characteristics: voice-design-params\n    ) -> result<voice, tts-error>;\n\n    record voice-design-params {\n        gender: types.voice-gender,\n        age-category: age-category,\n        accent: string,\n        personality-traits: list<string>,\n        reference-voice: option<string>,\n    }\n\n    enum age-category {\n        child,\n        young-adult,\n        middle-aged,\n        elderly,\n    }\n\n    /// Voice-to-voice conversion (removed async)\n    convert-voice: func(\n        input-audio: list<u8>,\n        target-voice: borrow<voice>,\n        preserve-timing: option<bool>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Generate sound effects from text description (removed async)\n    generate-sound-effect: func(\n        description: string,\n        duration-seconds: option<f32>,\n        style-influence: option<f32>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Custom pronunciation management\n    resource pronunciation-lexicon {\n        get-name: func() -> string;\n        get-language: func() -> language-code;\n        get-entry-count: func() -> u32;\n        \n        /// Add pronunciation rule\n        add-entry: func(word: string, pronunciation: string) -> result<_, tts-error>;\n        \n        /// Remove pronunciation rule\n        remove-entry: func(word: string) -> result<_, tts-error>;\n        \n        /// Export lexicon content\n        export-content: func() -> result<string, tts-error>;\n    }\n\n    /// Create custom pronunciation lexicon\n    create-lexicon: func(\n        name: string,\n        language: language-code,\n        entries: option<list<pronunciation-entry>>\n    ) -> result<pronunciation-lexicon, tts-error>;\n\n    record pronunciation-entry {\n        word: string,\n        pronunciation: string,\n        part-of-speech: option<string>,\n    }\n\n    /// Long-form content synthesis with optimization (removed async)\n    synthesize-long-form: func(\n        content: string,\n        voice: borrow<voice>,\n        output-location: string,\n        chapter-breaks: option<list<u32>>\n    ) -> result<long-form-operation, tts-error>;\n\n    resource long-form-operation {\n        get-status: func() -> operation-status;\n        get-progress: func() -> f32;\n        cancel: func() -> result<_, tts-error>;\n        get-result: func() -> result<long-form-result, tts-error>;\n    }\n\n    enum operation-status {\n        pending,\n        processing,\n        completed,\n        failed,\n        cancelled,\n    }\n\n    record long-form-result {\n        output-location: string,\n        total-duration: f32,\n        chapter-durations: option<list<f32>>,\n        metadata: types.synthesis-metadata,\n    }\n}\n```",
                  "html_url": "https://github.com/golemcloud/golem-ai/issues/23"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem-ai#23",
              "body": "I have attached to this ticket a WIT file that describes a generic interface for text-to-speech operations. This interface can be implemented by various providers, either by emulating features not present in a given provider, utilizing the provider's native support for a feature, or indicating an error if a particular combination is not natively supported by a provider.\n\nThe intent of this WIT specification is to allow developers of WASM components (on wasmCloud, Spin, or Golem) to leverage text-to-speech capabilities to build voice-powered applications, accessibility services, and audio content generation systems in a portable and provider-agnostic fashion.\n\nThis ticket involves constructing implementations of this WIT interface for the following providers:\n\n- **ElevenLabs**: The leading AI voice synthesis platform with comprehensive voice cloning, real-time streaming, voice conversion, and sound effects generation capabilities.\n- **AWS Polly**: Amazon's enterprise text-to-speech service with extensive language support, custom lexicons, speech marks, and asynchronous synthesis for long-form content.\n- **Google Cloud Text-to-Speech**: Google's neural voice synthesis service with WaveNet and Neural2 voices, device optimization profiles, and streaming synthesis capabilities.\n- **Deepgram Aura**: High-performance real-time TTS with session-based streaming, low-latency neural voices, and conversational AI optimization.\n\nThese implementations must be written in Rust and compilable to WASM Components (WASI 0.23 only, since Golem does not yet support WASI 0.3). The standard Rust toolchain for WASM component development can be employed (see cargo component and the Rust examples of components in this and other Golem repositories).\n\nAdditionally, these implementations should incorporate custom durability semantics using the Golem durability API and the Golem host API. This approach ensures that durability is managed at the level of individual TTS operations (voice synthesis, streaming session creation, voice cloning, batch processing), providing a higher-level and clearer operation log, which aids in debugging and monitoring. See golem:llm and golem:embed for more details and durable implementations in this same repository.\n\nThe final deliverables associated with this ticket are:\n\n- **ElevenLabs implementation**: A WASM Component (WASI 0.23), named `tts-elevenlabs.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **AWS Polly implementation**: A WASM Component (WASI 0.23), named `tts-polly.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Google Cloud TTS implementation**: A WASM Component (WASI 0.23), named `tts-google.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Deepgram Aura implementation**: A WASM Component (WASI 0.23), named `tts-deepgram.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n\n**Note**: If you have a strong recommendation to swap out one or two of these with other popular / common TTS providers (such as Azure Cognitive Services Speech, IBM Watson Text to Speech, or OpenAI TTS), then as long as you get permission beforehand, that's okay with me. However, we definitely need ElevenLabs and AWS Polly.\n\nThese components will require runtime configuration, notably API keys, endpoint URLs, authentication credentials, and provider-specific settings. For configuring this information, the components can use environment variables for now (in the future, they will use wasi-runtime-config, but Golem does not support this yet, whereas Golem has good support for environment variables).\n\nMoreover, the Rust components need to be tested within Golem to ensure compatibility with Golem 1.2.x.\n\nThis WIT has been designed by examining and comparing the APIs of ElevenLabs, AWS Polly, Google Cloud TTS, Azure Speech Services, OpenAI TTS, and Deepgram Aura. However, given there are no implementations, it is possible the provided WIT is not the optimal abstraction across all these providers. Therefore, deviations from the proposed design can be made. However, to be accepted, any deviation must be fully justified and deemed by Golem core contributors to be an improvement from the original specification.\n\n## Implementation Guidelines\n\nEach provider implementation should handle the following key mapping considerations:\n\n- **Voice Management**: Map the unified voice resource to provider-specific voice identifiers, handle voice discovery and metadata appropriately for each provider's voice catalog structure\n- **Audio Format Conversion**: Implement native audio format support where available, or provide format conversion for unsupported output formats using audio processing libraries\n- **Streaming Implementation**: Utilize native streaming APIs where supported (ElevenLabs, Deepgram), or implement chunk-based synthesis for providers without native streaming support\n- **Authentication Handling**: Implement appropriate authentication mechanisms (API keys, OAuth, service accounts) per provider requirements\n- **Feature Availability**: Route advanced features (voice cloning, sound effects, speech marks) through provider-native APIs where supported, or return `unsupported-operation` errors for unavailable features\n- **Error Mapping**: Map provider-specific HTTP errors and API responses to the unified `tts-error` enumeration with appropriate context preservation\n- **Rate Limiting**: Handle provider-specific rate limits and quota management, implementing appropriate retry logic and error reporting\n- **Long-form Content**: Implement efficient handling of long-form synthesis using provider-native async operations (AWS Polly) or intelligent chunking strategies\n\n## Testing Requirements\n\nEach implementation must include comprehensive test suites covering:\n- Basic synthesis operations (text-to-speech with various voices and configurations)\n- Voice discovery and metadata retrieval\n- Streaming synthesis lifecycle (session creation, chunk processing, cleanup)\n- Advanced feature testing (voice cloning, sound effects, custom pronunciations where supported)\n- Audio format validation and quality verification\n- Authentication and authorization scenarios\n- Error handling for unsupported operations and malformed inputs\n- Rate limiting and quota management behavior\n- Connection management and retry logic\n- Long-form content synthesis (>5000 characters)\n- Durability semantics verification across operation boundaries\n- Provider-specific feature utilization (lexicons for Polly, voice settings for ElevenLabs, etc.)\n\n## Configuration Requirements\n\nEach implementation should support the following environment variables:\n\n### Common Configuration\n- `TTS_PROVIDER_ENDPOINT`: Custom endpoint URL (for enterprise/regional deployments)\n- `TTS_PROVIDER_TIMEOUT`: Request timeout in seconds (default: 30)\n- `TTS_PROVIDER_MAX_RETRIES`: Maximum retry attempts (default: 3)\n- `TTS_PROVIDER_LOG_LEVEL`: Logging verbosity (debug, info, warn, error)\n\n### Provider-Specific Configuration\n- **ElevenLabs**: `ELEVENLABS_API_KEY`, `ELEVENLABS_MODEL_VERSION`\n- **AWS Polly**: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `AWS_SESSION_TOKEN`\n- **Google Cloud**: `GOOGLE_APPLICATION_CREDENTIALS`, `GOOGLE_CLOUD_PROJECT`\n- **Deepgram**: `DEEPGRAM_API_KEY`, `DEEPGRAM_API_VERSION`\n\n```wit\npackage golem:tts@1.0.0;\n\n/// Core types and error handling for universal text-to-speech\ninterface types {\n    /// Comprehensive error types covering all TTS operations\n    variant tts-error {\n        /// Input validation errors\n        invalid-text(string),\n        text-too-long(u32),\n        invalid-ssml(string),\n        unsupported-language(string),\n        \n        /// Voice and model errors\n        voice-not-found(string),\n        model-not-found(string),\n        voice-unavailable(string),\n        \n        /// Authentication and authorization\n        unauthorized(string),\n        access-denied(string),\n        \n        /// Resource and quota limits\n        quota-exceeded(quota-info),\n        rate-limited(u32),\n        insufficient-credits,\n        \n        /// Operation errors\n        synthesis-failed(string),\n        unsupported-operation(string),\n        invalid-configuration(string),\n        \n        /// Service errors\n        service-unavailable(string),\n        network-error(string),\n        internal-error(string),\n        \n        /// Storage errors (for async operations)\n        invalid-storage-location(string),\n        storage-access-denied(string),\n    }\n\n    record quota-info {\n        used: u32,\n        limit: u32,\n        reset-time: u64,\n        unit: quota-unit,\n    }\n\n    enum quota-unit {\n        characters,\n        requests,\n        seconds,\n        credits,\n    }\n\n    /// Language identification using BCP 47 codes\n    type language-code = string;\n\n    /// Voice gender classification\n    enum voice-gender {\n        male,\n        female,\n        neutral,\n    }\n\n    /// Voice quality tiers\n    enum voice-quality {\n        standard,\n        premium,\n        neural,\n        studio,\n    }\n\n    /// Text input types\n    enum text-type {\n        plain,\n        ssml,\n    }\n\n    /// Audio output formats\n    enum audio-format {\n        mp3,\n        wav,\n        pcm,\n        ogg-opus,\n        aac,\n        flac,\n        mulaw,\n        alaw,\n    }\n\n    /// Audio quality settings\n    record audio-config {\n        format: audio-format,\n        sample-rate: option<u32>,\n        bit-rate: option<u32>,\n        channels: option<u8>,\n    }\n\n    /// Voice synthesis parameters\n    record voice-settings {\n        /// Speaking rate (0.25 to 4.0, default 1.0)\n        speed: option<f32>,\n        /// Pitch adjustment in semitones (-20.0 to 20.0, default 0.0)\n        pitch: option<f32>,\n        /// Volume gain in dB (-96.0 to 16.0, default 0.0)\n        volume: option<f32>,\n        /// Voice stability (0.0 to 1.0, provider-specific)\n        stability: option<f32>,\n        /// Similarity to original (0.0 to 1.0, provider-specific)\n        similarity: option<f32>,\n        /// Style exaggeration (0.0 to 1.0, provider-specific)\n        style: option<f32>,\n    }\n\n    /// Audio effects and device optimization\n    flags audio-effects {\n        telephone-quality,\n        headphone-optimized,\n        speaker-optimized,\n        car-audio-optimized,\n        noise-reduction,\n        bass-boost,\n        treble-boost,\n    }\n\n    /// Input text with metadata\n    record text-input {\n        content: string,\n        text-type: text-type,\n        language: option<language-code>,\n    }\n\n    /// Complete synthesis result\n    record synthesis-result {\n        audio-data: list<u8>,\n        metadata: synthesis-metadata,\n    }\n\n    /// Metadata about synthesized audio\n    record synthesis-metadata {\n        duration-seconds: f32,\n        character-count: u32,\n        word-count: u32,\n        audio-size-bytes: u32,\n        request-id: string,\n        provider-info: option<string>,\n    }\n\n    /// Streaming audio chunk\n    record audio-chunk {\n        data: list<u8>,\n        sequence-number: u32,\n        is-final: bool,\n        timing-info: option<timing-info>,\n    }\n\n    /// Timing and synchronization information\n    record timing-info {\n        start-time-seconds: f32,\n        end-time-seconds: option<f32>,\n        text-offset: option<u32>,\n        mark-type: option<timing-mark-type>,\n    }\n\n    enum timing-mark-type {\n        word,\n        sentence,\n        paragraph,\n        ssml-mark,\n        viseme,\n    }\n\n\n}\n\n/// Voice discovery and management\ninterface voices {\n    use types.{tts-error, language-code, voice-gender, voice-quality};\n\n    /// Represents a voice that can be used for speech synthesis\n    resource voice {\n        /// Get voice identification\n        get-id: func() -> string;\n        get-name: func() -> string;\n        get-provider-id: func() -> option<string>;\n        \n        /// Get voice characteristics\n        get-language: func() -> language-code;\n        get-additional-languages: func() -> list<language-code>;\n        get-gender: func() -> voice-gender;\n        get-quality: func() -> voice-quality;\n        get-description: func() -> option<string>;\n        \n        /// Voice capabilities\n        supports-ssml: func() -> bool;\n        get-sample-rates: func() -> list<u32>;\n        get-supported-formats: func() -> list<types.audio-format>;\n        \n        /// Voice management (may return unsupported-operation)\n        update-settings: func(settings: types.voice-settings) -> result<_, tts-error>;\n        delete: func() -> result<_, tts-error>;\n        clone: func() -> result<voice, tts-error>;\n        \n        /// Preview voice with sample text\n        preview: func(text: string) -> result<list<u8>, tts-error>;\n    }\n\n    /// Voice search and filtering\n    record voice-filter {\n        language: option<language-code>,\n        gender: option<voice-gender>,\n        quality: option<voice-quality>,\n        supports-ssml: option<bool>,\n        provider: option<string>,\n        search-query: option<string>,\n    }\n\n    /// Detailed voice information\n    record voice-info {\n        id: string,\n        name: string,\n        language: language-code,\n        additional-languages: list<language-code>,\n        gender: voice-gender,\n        quality: voice-quality,\n        description: option<string>,\n        provider: string,\n        sample-rate: u32,\n        is-custom: bool,\n        is-cloned: bool,\n        preview-url: option<string>,\n        use-cases: list<string>,\n    }\n\n    /// Resource-based iterator for voice results\n    resource voice-results {\n        /// Check if more voices are available\n        has-more: func() -> bool;\n        \n        /// Get next batch of voices\n        get-next: func() -> result<list<voice-info>, tts-error>;\n        \n        /// Get total count if available\n        get-total-count: func() -> option<u32>;\n    }\n\n    /// List available voices with filtering and pagination\n    list-voices: func(\n        filter: option<voice-filter>\n    ) -> result<voice-results, tts-error>;\n\n    /// Get specific voice by ID\n    get-voice: func(voice-id: string) -> result<voice, tts-error>;\n\n    /// Search voices by characteristics\n    search-voices: func(\n        query: string,\n        filter: option<voice-filter>\n    ) -> result<list<voice-info>, tts-error>;\n\n    /// Get supported languages\n    list-languages: func() -> result<list<language-info>, tts-error>;\n\n    record language-info {\n        code: language-code,\n        name: string,\n        native-name: string,\n        voice-count: u32,\n    }\n}\n\n/// Core text-to-speech synthesis operations\ninterface synthesis {\n    use types.{\n        text-input, audio-config, voice-settings, audio-effects,\n        synthesis-result, tts-error, timing-info\n    };\n    use voices.{voice};\n\n    /// Synthesis configuration options\n    record synthesis-options {\n        audio-config: option<audio-config>,\n        voice-settings: option<voice-settings>,\n        audio-effects: option<audio-effects>,\n        enable-timing: option<bool>,\n        enable-word-timing: option<bool>,\n        seed: option<u32>,\n        model-version: option<string>,\n        context: option<synthesis-context>,\n    }\n\n    /// Context for better synthesis quality\n    record synthesis-context {\n        previous-text: option<string>,\n        next-text: option<string>,\n        topic: option<string>,\n        emotion: option<string>,\n        speaking-style: option<string>,\n    }\n\n    /// Convert text to speech (removed async)\n    synthesize: func(\n        input: text-input,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-result, tts-error>;\n\n    /// Batch synthesis for multiple inputs (removed async)\n    synthesize-batch: func(\n        inputs: list<text-input>,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<list<synthesis-result>, tts-error>;\n\n    /// Get timing information without audio synthesis\n    get-timing-marks: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<list<timing-info>, tts-error>;\n\n    /// Validate text before synthesis\n    validate-input: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<validation-result, tts-error>;\n\n    record validation-result {\n        is-valid: bool,\n        character-count: u32,\n        estimated-duration: option<f32>,\n        warnings: list<string>,\n        errors: list<string>,\n    }\n}\n\n/// Real-time streaming synthesis\ninterface streaming {\n    use types.{\n        text-input, audio-config, voice-settings, audio-chunk,\n        tts-error, timing-info\n    };\n    use voices.{voice};\n    use synthesis.{synthesis-options};\n\n    /// Streaming synthesis session\n    resource synthesis-stream {\n        /// Send text for synthesis (can be called multiple times)\n        send-text: func(input: text-input) -> result<_, tts-error>;\n        \n        /// Signal end of input and flush remaining audio\n        finish: func() -> result<_, tts-error>;\n        \n        /// Receive next audio chunk (non-blocking)\n        receive-chunk: func() -> result<option<audio-chunk>, tts-error>;\n        \n        /// Check if more chunks are available\n        has-pending-audio: func() -> bool;\n        \n        /// Get current stream status\n        get-status: func() -> stream-status;\n        \n        /// Close stream and clean up resources\n        close: func();\n    }\n\n    enum stream-status {\n        ready,\n        processing,\n        finished,\n        error,\n        closed,\n    }\n\n    /// Create streaming synthesis session\n    create-stream: func(\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-stream, tts-error>;\n\n    /// Real-time voice conversion streaming\n    create-voice-conversion-stream: func(\n        target-voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<voice-conversion-stream, tts-error>;\n\n    resource voice-conversion-stream {\n        /// Send input audio chunks\n        send-audio: func(audio-data: list<u8>) -> result<_, tts-error>;\n        \n        /// Receive converted audio chunks\n        receive-converted: func() -> result<option<audio-chunk>, tts-error>;\n        \n        finish: func() -> result<_, tts-error>;\n        close: func();\n    }\n}\n\n/// Advanced TTS features and voice manipulation\ninterface advanced {\n    use types.{tts-error, audio-config, language-code};\n    use voices.{voice};\n\n    /// Voice cloning and creation (removed async)\n    create-voice-clone: func(\n        name: string,\n        audio-samples: list<audio-sample>,\n        description: option<string>\n    ) -> result<voice, tts-error>;\n\n    record audio-sample {\n        data: list<u8>,\n        transcript: option<string>,\n        quality-rating: option<u8>,\n    }\n\n    /// Design synthetic voice (removed async)\n    design-voice: func(\n        name: string,\n        characteristics: voice-design-params\n    ) -> result<voice, tts-error>;\n\n    record voice-design-params {\n        gender: types.voice-gender,\n        age-category: age-category,\n        accent: string,\n        personality-traits: list<string>,\n        reference-voice: option<string>,\n    }\n\n    enum age-category {\n        child,\n        young-adult,\n        middle-aged,\n        elderly,\n    }\n\n    /// Voice-to-voice conversion (removed async)\n    convert-voice: func(\n        input-audio: list<u8>,\n        target-voice: borrow<voice>,\n        preserve-timing: option<bool>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Generate sound effects from text description (removed async)\n    generate-sound-effect: func(\n        description: string,\n        duration-seconds: option<f32>,\n        style-influence: option<f32>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Custom pronunciation management\n    resource pronunciation-lexicon {\n        get-name: func() -> string;\n        get-language: func() -> language-code;\n        get-entry-count: func() -> u32;\n        \n        /// Add pronunciation rule\n        add-entry: func(word: string, pronunciation: string) -> result<_, tts-error>;\n        \n        /// Remove pronunciation rule\n        remove-entry: func(word: string) -> result<_, tts-error>;\n        \n        /// Export lexicon content\n        export-content: func() -> result<string, tts-error>;\n    }\n\n    /// Create custom pronunciation lexicon\n    create-lexicon: func(\n        name: string,\n        language: language-code,\n        entries: option<list<pronunciation-entry>>\n    ) -> result<pronunciation-lexicon, tts-error>;\n\n    record pronunciation-entry {\n        word: string,\n        pronunciation: string,\n        part-of-speech: option<string>,\n    }\n\n    /// Long-form content synthesis with optimization (removed async)\n    synthesize-long-form: func(\n        content: string,\n        voice: borrow<voice>,\n        output-location: string,\n        chapter-breaks: option<list<u32>>\n    ) -> result<long-form-operation, tts-error>;\n\n    resource long-form-operation {\n        get-status: func() -> operation-status;\n        get-progress: func() -> f32;\n        cancel: func() -> result<_, tts-error>;\n        get-result: func() -> result<long-form-result, tts-error>;\n    }\n\n    enum operation-status {\n        pending,\n        processing,\n        completed,\n        failed,\n        cancelled,\n    }\n\n    record long-form-result {\n        output-location: string,\n        total-duration: f32,\n        chapter-durations: option<list<f32>>,\n        metadata: types.synthesis-metadata,\n    }\n}\n```",
              "url": "https://github.com/golemcloud/golem-ai/issues/23",
              "tech": [
                "go"
              ],
              "repo_name": "golem-ai",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#1911",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2025-12-12T23:33:39.032Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:39.032Z",
            "created_at": "2025-12-12T23:33:39.032Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#1911",
              "status": "open",
              "type": "issue",
              "number": 1911,
              "title": "Warn on mismatch between global `prisma` and local `prisma` or `@prisma/client`",
              "source": {
                "data": {
                  "id": "source-prisma#1911",
                  "user": {
                    "login": "janpio",
                    "id": 183673,
                    "node_id": "MDQ6VXNlcjE4MzY3Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/183673?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/janpio",
                    "html_url": "https://github.com/janpio",
                    "followers_url": "https://api.github.com/users/janpio/followers",
                    "following_url": "https://api.github.com/users/janpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/janpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/janpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/janpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/janpio/orgs",
                    "repos_url": "https://api.github.com/users/janpio/repos",
                    "events_url": "https://api.github.com/users/janpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/janpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Warn on mismatch between global `prisma` and local `prisma` or `@prisma/client`",
                  "body": "Using a global `prisma generate` with a different local `prisma` or `@prisma/client` might lead to problems. It might be a good idea to warn users if they are doing that and ask for explicit confirmation.",
                  "html_url": "https://github.com/prisma/prisma/issues/1911"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#1911",
              "body": "Using a global `prisma generate` with a different local `prisma` or `@prisma/client` might lead to problems. It might be a good idea to warn users if they are doing that and ask for explicit confirmation.",
              "url": "https://github.com/prisma/prisma/issues/1911",
              "tech": [
                "go"
              ],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#8548",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2025-12-12T23:33:39.177Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:39.177Z",
            "created_at": "2025-12-12T23:33:39.177Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#8548",
              "status": "open",
              "type": "issue",
              "number": 8548,
              "title": "`prisma format` ends the file with a single CRLF on windows",
              "source": {
                "data": {
                  "id": "source-prisma#8548",
                  "user": {
                    "login": "binary64",
                    "id": 1680627,
                    "node_id": "MDQ6VXNlcjE2ODA2Mjc=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1680627?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/binary64",
                    "html_url": "https://github.com/binary64",
                    "followers_url": "https://api.github.com/users/binary64/followers",
                    "following_url": "https://api.github.com/users/binary64/following{/other_user}",
                    "gists_url": "https://api.github.com/users/binary64/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/binary64/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/binary64/subscriptions",
                    "organizations_url": "https://api.github.com/users/binary64/orgs",
                    "repos_url": "https://api.github.com/users/binary64/repos",
                    "events_url": "https://api.github.com/users/binary64/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/binary64/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "`prisma format` ends the file with a single CRLF on windows",
                  "body": "### Bug description\n\nOn windows, I run `prisma format` and note the unusual file ending. The lines are all LF, but the very last line is CRLF.\r\n\r\nThis causes issue on my Linux CI where it formats it ending in LF's only, causing a diff to occur and the build to fail.\n\n### How to reproduce\n\n1. On windows do prisma format\r\n2. Open in HxD or similar\r\n3. See attached:\r\n \r\n![image](https://user-images.githubusercontent.com/1680627/127931864-fcd66391-9b31-4914-8553-f6c71b3a6fad.png)\r\n\n\n### Expected behavior\n\nLF's only - no CR's to exist at all\n\n### Prisma information\n\n<!-- Do not include your database credentials when sharing your Prisma schema! -->\r\n\n\n### Environment & setup\n\nNode 16\r\nWindows/Linux\n\n### Prisma Version\n\n```\r\n$ C:\\p\\pab\\monorepo\\node_modules\\.bin\\prisma -v\r\nprisma               : 2.26.0\r\n@prisma/client       : 2.28.0\r\nCurrent platform     : windows\r\nQuery Engine         : query-engine 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\query-engine-windows.exe)\r\nMigration Engine     : migration-engine-cli 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\migration-engine-windows.exe)\r\nIntrospection Engine : introspection-core 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\introspection-engine-windows.exe)\r\nFormat Binary        : prisma-fmt 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\prisma-fmt-windows.exe)\r\nDefault Engines Hash : 9b816b3aa13cc270074f172f30d6eda8a8ce867d\r\nStudio               : 0.408.0\r\n```",
                  "html_url": "https://github.com/prisma/prisma/issues/8548"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#8548",
              "body": "### Bug description\n\nOn windows, I run `prisma format` and note the unusual file ending. The lines are all LF, but the very last line is CRLF.\r\n\r\nThis causes issue on my Linux CI where it formats it ending in LF's only, causing a diff to occur and the build to fail.\n\n### How to reproduce\n\n1. On windows do prisma format\r\n2. Open in HxD or similar\r\n3. See attached:\r\n \r\n![image](https://user-images.githubusercontent.com/1680627/127931864-fcd66391-9b31-4914-8553-f6c71b3a6fad.png)\r\n\n\n### Expected behavior\n\nLF's only - no CR's to exist at all\n\n### Prisma information\n\n<!-- Do not include your database credentials when sharing your Prisma schema! -->\r\n\n\n### Environment & setup\n\nNode 16\r\nWindows/Linux\n\n### Prisma Version\n\n```\r\n$ C:\\p\\pab\\monorepo\\node_modules\\.bin\\prisma -v\r\nprisma               : 2.26.0\r\n@prisma/client       : 2.28.0\r\nCurrent platform     : windows\r\nQuery Engine         : query-engine 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\query-engine-windows.exe)\r\nMigration Engine     : migration-engine-cli 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\migration-engine-windows.exe)\r\nIntrospection Engine : introspection-core 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\introspection-engine-windows.exe)\r\nFormat Binary        : prisma-fmt 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\prisma-fmt-windows.exe)\r\nDefault Engines Hash : 9b816b3aa13cc270074f172f30d6eda8a8ce867d\r\nStudio               : 0.408.0\r\n```",
              "url": "https://github.com/prisma/prisma/issues/8548",
              "tech": [],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#7771",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2025-12-12T23:33:39.290Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-12T23:33:39.290Z",
            "created_at": "2025-12-12T23:33:39.290Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#7771",
              "status": "open",
              "type": "issue",
              "number": 7771,
              "title": "Output path of current Prisma in `-v` ",
              "source": {
                "data": {
                  "id": "source-prisma#7771",
                  "user": {
                    "login": "janpio",
                    "id": 183673,
                    "node_id": "MDQ6VXNlcjE4MzY3Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/183673?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/janpio",
                    "html_url": "https://github.com/janpio",
                    "followers_url": "https://api.github.com/users/janpio/followers",
                    "following_url": "https://api.github.com/users/janpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/janpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/janpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/janpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/janpio/orgs",
                    "repos_url": "https://api.github.com/users/janpio/repos",
                    "events_url": "https://api.github.com/users/janpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/janpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Output path of current Prisma in `-v` ",
                  "body": "## Problem\r\n\r\nThis is a situation that can happen:\r\n```\r\n--- yarn prisma -v ---\r\nwarning package.json: No license field\r\nprisma               : 2.26.0-dev.7\r\n@prisma/client       : 2.26.0-dev.7\r\nCurrent platform     : debian-openssl-1.1.x\r\nQuery Engine         : query-engine c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/query-engine-debian-openssl-1.1.x)\r\nMigration Engine     : migration-engine-cli c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/migration-engine-debian-openssl-1.1.x)\r\nIntrospection Engine : introspection-core c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/introspection-engine-debian-openssl-1.1.x)\r\nFormat Binary        : prisma-fmt c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/prisma-fmt-debian-openssl-1.1.x)\r\nDefault Engines Hash : c838e79f39885bc8e1611849b1eb28b5bb5bc922\r\nStudio               : 0.402.0\r\n--- ls node_modules/@prisma/engines/ ---\r\nls: cannot access 'node_modules/@prisma/engines/': No such file or directory\r\n```\r\n\r\nAs you can see `yarn prisma -v` tells us the engines comes from `node_modules/@prisma/engines`, but when you try to list that directory, it is actually not present.\r\n\r\nWhat is happening here is that `yarn prisma` is actually from a few folders _above_ our project. This is kinda visible when you look to not run `yarn -s` but just `yarn`:\r\n```\r\ncodespace  /workspaces/e2e-tests/platforms-serverless/firebase-functions (janpio-patch-5 ) $ yarn prisma -v\r\nyarn run v1.22.10\r\nwarning package.json: No license field\r\n$ /workspaces/e2e-tests/node_modules/.bin/prisma -v\r\nprisma               : 2.25.0-dev.36\r\n@prisma/client       : 2.25.0-dev.36\r\n...\r\n```\r\n\r\n## Suggested solution\r\n\r\nOutput the directory of where the executed `prisma` is from, either similar to Yarn the absolute path to the binary in `node_modules`, or the folder where the `package.json` that is responsible for the installation of Prisma comes from.\r\n\r\n## Alternatives\r\n\r\nRely on `yarn` itself to give that information. Will not work with `npx` unfortunately for example.",
                  "html_url": "https://github.com/prisma/prisma/issues/7771"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#7771",
              "body": "## Problem\r\n\r\nThis is a situation that can happen:\r\n```\r\n--- yarn prisma -v ---\r\nwarning package.json: No license field\r\nprisma               : 2.26.0-dev.7\r\n@prisma/client       : 2.26.0-dev.7\r\nCurrent platform     : debian-openssl-1.1.x\r\nQuery Engine         : query-engine c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/query-engine-debian-openssl-1.1.x)\r\nMigration Engine     : migration-engine-cli c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/migration-engine-debian-openssl-1.1.x)\r\nIntrospection Engine : introspection-core c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/introspection-engine-debian-openssl-1.1.x)\r\nFormat Binary        : prisma-fmt c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/prisma-fmt-debian-openssl-1.1.x)\r\nDefault Engines Hash : c838e79f39885bc8e1611849b1eb28b5bb5bc922\r\nStudio               : 0.402.0\r\n--- ls node_modules/@prisma/engines/ ---\r\nls: cannot access 'node_modules/@prisma/engines/': No such file or directory\r\n```\r\n\r\nAs you can see `yarn prisma -v` tells us the engines comes from `node_modules/@prisma/engines`, but when you try to list that directory, it is actually not present.\r\n\r\nWhat is happening here is that `yarn prisma` is actually from a few folders _above_ our project. This is kinda visible when you look to not run `yarn -s` but just `yarn`:\r\n```\r\ncodespace  /workspaces/e2e-tests/platforms-serverless/firebase-functions (janpio-patch-5 ) $ yarn prisma -v\r\nyarn run v1.22.10\r\nwarning package.json: No license field\r\n$ /workspaces/e2e-tests/node_modules/.bin/prisma -v\r\nprisma               : 2.25.0-dev.36\r\n@prisma/client       : 2.25.0-dev.36\r\n...\r\n```\r\n\r\n## Suggested solution\r\n\r\nOutput the directory of where the executed `prisma` is from, either similar to Yarn the absolute path to the binary in `node_modules`, or the folder where the `package.json` that is responsible for the installation of Prisma comes from.\r\n\r\n## Alternatives\r\n\r\nRely on `yarn` itself to give that information. Will not work with `npx` unfortunately for example.",
              "url": "https://github.com/prisma/prisma/issues/7771",
              "tech": [],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          }
        ],
        "next_cursor": null
      }
    }
  }
}