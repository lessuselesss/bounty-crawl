{
  "result": {
    "data": {
      "json": {
        "items": [
          {
            "id": "triggerdotdev#2654",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "triggerdotdev",
              "id": "generated-triggerdotdev",
              "name": "Triggerdotdev",
              "description": "",
              "members": [],
              "display_name": "Triggerdotdev",
              "created_at": "2025-12-27T17:49:37.302Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/triggerdotdev?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "colinhacks",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:49:37.302Z",
            "created_at": "2025-12-27T17:49:37.302Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-triggerdotdev#2654",
              "status": "open",
              "type": "issue",
              "number": 2654,
              "title": "Schema in object being inferred differently (and weirdly)",
              "source": {
                "data": {
                  "id": "source-triggerdotdev#2654",
                  "user": {
                    "login": "ericallam",
                    "id": 534,
                    "node_id": "MDQ6VXNlcjUzNA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/534?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ericallam",
                    "html_url": "https://github.com/ericallam",
                    "followers_url": "https://api.github.com/users/ericallam/followers",
                    "following_url": "https://api.github.com/users/ericallam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ericallam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ericallam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ericallam/subscriptions",
                    "organizations_url": "https://api.github.com/users/ericallam/orgs",
                    "repos_url": "https://api.github.com/users/ericallam/repos",
                    "events_url": "https://api.github.com/users/ericallam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ericallam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Schema in object being inferred differently (and weirdly)",
                  "body": "See the following TS snippet:\r\n\r\n```ts\r\nimport { z } from \"zod\";\r\n\r\nconst EventNameSchema = z.string().or(z.array(z.string()));\r\n\r\ntype EventName = z.infer<typeof EventNameSchema>;\r\n// EventName is string | string[]\r\n\r\nconst EventSchema = z.object({\r\n  name: z.string().or(z.array(z.string())) // this is the same as the EventNameSchema\r\n});\r\n\r\ntype EventWithName = z.infer<typeof EventSchema>;\r\ntype EventName2 = EventWithName[\"name\"];\r\n// EventName2 is (string | string[]) & (string | string[] | undefined)\r\n```\r\n\r\nAnd the TS playground: [link](https://www.typescriptlang.org/play?#code/JYWwDg9gTgLgBAbzgLzgXzgMyhEcBEyEAJvgNwBQFAxhAHYDO8AogG4CmdMAcgIYjsAytQAW7ELzgBeFADomUYHQDmACgCUs6KuSzeUKLwCeO+TEUqN69ZQowjYdnDace-JzN1LM7KAB57RwhMZw4uPgFhMQkAPkoAenjQ1winYAY4BSVlOAAfTPNsgG0AXSpaRhYwmCjxSU8tACMAK3ZqGFUECjg4OncALjksy01tXX1DE11htWt1CjQbKkCnFy4AdWAYEVTpOW9fAId2YOSuWtjKFbO3AQAmPbWYTe3Uovw+gXwShKSn1Ie6TgqhmeQKFmUpXUcAAZMDQfkZqUwQBXOjEdiYJTsYjqIA)\r\n\r\nI'm not sure if this is intended or a bug or maybe just a user error. Using zod `3.21.4` and TS `4.8.4`",
                  "html_url": "https://github.com/colinhacks/zod/issues/2654"
                },
                "type": "github"
              },
              "hash": "colinhacks/zod#2654",
              "body": "See the following TS snippet:\r\n\r\n```ts\r\nimport { z } from \"zod\";\r\n\r\nconst EventNameSchema = z.string().or(z.array(z.string()));\r\n\r\ntype EventName = z.infer<typeof EventNameSchema>;\r\n// EventName is string | string[]\r\n\r\nconst EventSchema = z.object({\r\n  name: z.string().or(z.array(z.string())) // this is the same as the EventNameSchema\r\n});\r\n\r\ntype EventWithName = z.infer<typeof EventSchema>;\r\ntype EventName2 = EventWithName[\"name\"];\r\n// EventName2 is (string | string[]) & (string | string[] | undefined)\r\n```\r\n\r\nAnd the TS playground: [link](https://www.typescriptlang.org/play?#code/JYWwDg9gTgLgBAbzgLzgXzgMyhEcBEyEAJvgNwBQFAxhAHYDO8AogG4CmdMAcgIYjsAytQAW7ELzgBeFADomUYHQDmACgCUs6KuSzeUKLwCeO+TEUqN69ZQowjYdnDace-JzN1LM7KAB57RwhMZw4uPgFhMQkAPkoAenjQ1winYAY4BSVlOAAfTPNsgG0AXSpaRhYwmCjxSU8tACMAK3ZqGFUECjg4OncALjksy01tXX1DE11htWt1CjQbKkCnFy4AdWAYEVTpOW9fAId2YOSuWtjKFbO3AQAmPbWYTe3Uovw+gXwShKSn1Ie6TgqhmeQKFmUpXUcAAZMDQfkZqUwQBXOjEdiYJTsYjqIA)\r\n\r\nI'm not sure if this is intended or a bug or maybe just a user error. Using zod `3.21.4` and TS `4.8.4`",
              "url": "https://github.com/colinhacks/zod/issues/2654",
              "tech": [],
              "repo_name": "zod",
              "repo_owner": "colinhacks",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "onyx-dot-app#2281",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "onyx-dot-app",
              "id": "generated-onyx-dot-app",
              "name": "Onyx-dot-app",
              "description": "",
              "members": [],
              "display_name": "Onyx-dot-app",
              "created_at": "2025-12-27T17:49:46.860Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/onyx-dot-app?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "danswer-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:49:46.860Z",
            "created_at": "2025-12-27T17:49:46.860Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-onyx-dot-app#2281",
              "status": "open",
              "type": "issue",
              "number": 2281,
              "title": "Jira Service Management Connector",
              "source": {
                "data": {
                  "id": "source-onyx-dot-app#2281",
                  "user": {
                    "login": "Weves",
                    "id": 25087905,
                    "node_id": "MDQ6VXNlcjI1MDg3OTA1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25087905?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Weves",
                    "html_url": "https://github.com/Weves",
                    "followers_url": "https://api.github.com/users/Weves/followers",
                    "following_url": "https://api.github.com/users/Weves/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Weves/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Weves/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Weves/subscriptions",
                    "organizations_url": "https://api.github.com/users/Weves/orgs",
                    "repos_url": "https://api.github.com/users/Weves/repos",
                    "events_url": "https://api.github.com/users/Weves/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Weves/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Jira Service Management Connector",
                  "body": "Pull in all tickets from a specified [Jira Service Management](https://www.atlassian.com/software/jira/service-management) project. \r\n\r\nCheckout the connector creation README here for more details on the best way to add new connectors: https://github.com/danswer-ai/danswer/blob/main/backend/danswer/connectors/README.md. ",
                  "html_url": "https://github.com/onyx-dot-app/onyx/issues/2281"
                },
                "type": "github"
              },
              "hash": "danswer-ai/danswer#2281",
              "body": "Pull in all tickets from a specified [Jira Service Management](https://www.atlassian.com/software/jira/service-management) project. \r\n\r\nCheckout the connector creation README here for more details on the best way to add new connectors: https://github.com/danswer-ai/danswer/blob/main/backend/danswer/connectors/README.md. ",
              "url": "https://github.com/onyx-dot-app/onyx/issues/2281",
              "tech": [],
              "repo_name": "danswer",
              "repo_owner": "danswer-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "PX4#21902",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "PX4",
              "id": "generated-PX4",
              "name": "PX4",
              "description": "",
              "members": [],
              "display_name": "PX4",
              "created_at": "2025-12-27T17:49:47.156Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/PX4?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "PX4",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:49:47.156Z",
            "created_at": "2025-12-27T17:49:47.156Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-PX4#21902",
              "status": "open",
              "type": "issue",
              "number": 21902,
              "title": "Support EKF2_GPS_POS_* for Multiple GPS",
              "source": {
                "data": {
                  "id": "source-PX4#21902",
                  "user": {
                    "login": "AlexKlimaj",
                    "id": 2019539,
                    "node_id": "MDQ6VXNlcjIwMTk1Mzk=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/2019539?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/AlexKlimaj",
                    "html_url": "https://github.com/AlexKlimaj",
                    "followers_url": "https://api.github.com/users/AlexKlimaj/followers",
                    "following_url": "https://api.github.com/users/AlexKlimaj/following{/other_user}",
                    "gists_url": "https://api.github.com/users/AlexKlimaj/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/AlexKlimaj/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/AlexKlimaj/subscriptions",
                    "organizations_url": "https://api.github.com/users/AlexKlimaj/orgs",
                    "repos_url": "https://api.github.com/users/AlexKlimaj/repos",
                    "events_url": "https://api.github.com/users/AlexKlimaj/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/AlexKlimaj/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Support EKF2_GPS_POS_* for Multiple GPS",
                  "body": "### Describe problem solved by the proposed feature\n\nCurrently the EKF2_GPS_POS_* params only apply to vehicle_gps when it gets used in the EKF.\n\n### Describe your preferred solution\n\nI propose we move these params to an offset in the GPS driver.\n\n### Describe possible alternatives\n\nDo we need these offsets at all?\n\n### Additional context\n\n_No response_",
                  "html_url": "https://github.com/PX4/PX4-Autopilot/issues/21902"
                },
                "type": "github"
              },
              "hash": "PX4/PX4-Autopilot#21902",
              "body": "### Describe problem solved by the proposed feature\n\nCurrently the EKF2_GPS_POS_* params only apply to vehicle_gps when it gets used in the EKF.\n\n### Describe your preferred solution\n\nI propose we move these params to an offset in the GPS driver.\n\n### Describe possible alternatives\n\nDo we need these offsets at all?\n\n### Additional context\n\n_No response_",
              "url": "https://github.com/PX4/PX4-Autopilot/issues/21902",
              "tech": [],
              "repo_name": "PX4-Autopilot",
              "repo_owner": "PX4",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "PX4#19970",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "PX4",
              "id": "generated-PX4",
              "name": "PX4",
              "description": "",
              "members": [],
              "display_name": "PX4",
              "created_at": "2025-12-27T17:49:47.295Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/PX4?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "PX4",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:49:47.295Z",
            "created_at": "2025-12-27T17:49:47.295Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-PX4#19970",
              "status": "open",
              "type": "issue",
              "number": 19970,
              "title": "[Project Tracker] Sensor configuration display UI",
              "source": {
                "data": {
                  "id": "source-PX4#19970",
                  "user": {
                    "login": "junwoo091400",
                    "id": 23277211,
                    "node_id": "MDQ6VXNlcjIzMjc3MjEx",
                    "avatar_url": "https://avatars.githubusercontent.com/u/23277211?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/junwoo091400",
                    "html_url": "https://github.com/junwoo091400",
                    "followers_url": "https://api.github.com/users/junwoo091400/followers",
                    "following_url": "https://api.github.com/users/junwoo091400/following{/other_user}",
                    "gists_url": "https://api.github.com/users/junwoo091400/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/junwoo091400/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/junwoo091400/subscriptions",
                    "organizations_url": "https://api.github.com/users/junwoo091400/orgs",
                    "repos_url": "https://api.github.com/users/junwoo091400/repos",
                    "events_url": "https://api.github.com/users/junwoo091400/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/junwoo091400/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Project Tracker] Sensor configuration display UI",
                  "body": "## Describe problem solved by the proposed feature\r\nCurrently it is hard to figure out which sensors are connected where, with which configuration and which priority (e.g. `CAL_MAG0_PRIO`) in a single view. For example during my [boat project](https://discuss.px4.io/t/rc-speed-boat-with-px4-episode-1-using-px4-to-control-the-boat/28429#things-that-are-still-ambiguous-to-me-22) build, I wasn't sure if I needed to set the priority of magnetometer manually or not.\r\n\r\nThis is also quite related to the calibration pain addressed in the issue #19459. What can we do to improve user experience for setting up the sensors? If so, which part should be addressed and how?\r\n\r\nWhat could be great (in my opinion) could be something like this in QGC (it won't be a literal text output like this, but just for giving some idea):\r\n\r\n```\r\n<mag-type> | <mag-orientation> | <mag-priority> | <mag-protocol?> # First mag sensor\r\n<mag-type> | <mag-orientation> | <mag-priority> | <mag-protocol?> # One for the second mag\r\n<baro-type> |              | <baro-priority> | <baro-protocol>\r\n<gyro-type> | <gyro-orientation> | <gyro-priority> | <gyro-protocol>\r\n```\r\n\r\nBut I am also not sure what others expectation / needs are, so any feedback would be appreciated!\r\n\r\n## Describe your preferred solution\r\n* @davids5 pointed out that transferring device tree information over to QGC could be a solution. Could you elaborate on that?\r\n* @dagar pointed out that having a unified view in general would be good. Could you let me know if a view I suggested above is similar to what you have imagined?\r\n",
                  "html_url": "https://github.com/PX4/PX4-Autopilot/issues/19970"
                },
                "type": "github"
              },
              "hash": "PX4/PX4-Autopilot#19970",
              "body": "## Describe problem solved by the proposed feature\r\nCurrently it is hard to figure out which sensors are connected where, with which configuration and which priority (e.g. `CAL_MAG0_PRIO`) in a single view. For example during my [boat project](https://discuss.px4.io/t/rc-speed-boat-with-px4-episode-1-using-px4-to-control-the-boat/28429#things-that-are-still-ambiguous-to-me-22) build, I wasn't sure if I needed to set the priority of magnetometer manually or not.\r\n\r\nThis is also quite related to the calibration pain addressed in the issue #19459. What can we do to improve user experience for setting up the sensors? If so, which part should be addressed and how?\r\n\r\nWhat could be great (in my opinion) could be something like this in QGC (it won't be a literal text output like this, but just for giving some idea):\r\n\r\n```\r\n<mag-type> | <mag-orientation> | <mag-priority> | <mag-protocol?> # First mag sensor\r\n<mag-type> | <mag-orientation> | <mag-priority> | <mag-protocol?> # One for the second mag\r\n<baro-type> |              | <baro-priority> | <baro-protocol>\r\n<gyro-type> | <gyro-orientation> | <gyro-priority> | <gyro-protocol>\r\n```\r\n\r\nBut I am also not sure what others expectation / needs are, so any feedback would be appreciated!\r\n\r\n## Describe your preferred solution\r\n* @davids5 pointed out that transferring device tree information over to QGC could be a solution. Could you elaborate on that?\r\n* @dagar pointed out that having a unified view in general would be good. Could you let me know if a view I suggested above is similar to what you have imagined?\r\n",
              "url": "https://github.com/PX4/PX4-Autopilot/issues/19970",
              "tech": [],
              "repo_name": "PX4-Autopilot",
              "repo_owner": "PX4",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#3531",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2025-12-27T17:50:09.496Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:09.496Z",
            "created_at": "2025-12-27T17:50:09.496Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3531",
              "status": "open",
              "type": "issue",
              "number": 3531,
              "title": "Better error response for wrong datetime format in REST filter",
              "source": {
                "data": {
                  "id": "source-qdrant#3531",
                  "user": {
                    "login": "timvisee",
                    "id": 856222,
                    "node_id": "MDQ6VXNlcjg1NjIyMg==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/856222?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/timvisee",
                    "html_url": "https://github.com/timvisee",
                    "followers_url": "https://api.github.com/users/timvisee/followers",
                    "following_url": "https://api.github.com/users/timvisee/following{/other_user}",
                    "gists_url": "https://api.github.com/users/timvisee/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/timvisee/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/timvisee/subscriptions",
                    "organizations_url": "https://api.github.com/users/timvisee/orgs",
                    "repos_url": "https://api.github.com/users/timvisee/repos",
                    "events_url": "https://api.github.com/users/timvisee/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/timvisee/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Better error response for wrong datetime format in REST filter",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\nWe recently merged <https://github.com/qdrant/qdrant/pull/3395> which adds a datetime payload index.\r\n\r\nCurrently, the datetime parser is very strict, only allowing [RFC 3339](https://www.rfc-editor.org/rfc/rfc3339) formats in our REST API. A common format such as `YYYY-MM-DD HH:MM:SS` is currently not accepted.\r\n\r\nIf you'd send the following request:\r\n\r\n```json\r\nPOST collections/test_collection/points/scroll\r\n{\r\n  \"limit\": 10,\r\n  \"filter\": {\r\n    \"must\": [\r\n      {\r\n        \"key\": \"updated\",\r\n        \"datetime_range\": {\r\n          \"gt\": \"2014-01-01T00:00:00\"\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nYou'd receive the following error:\r\n\r\n```\r\nFormat error in JSON body: data did not match any variant of untagged enum Condition at line 1 column 96\r\n```\r\n\r\nThis error is very confusing.\r\n\r\n**Describe the solution you'd like**\r\nWe'd strongly prefer a more descriptive error message instead.\r\n\r\nSomething like this would be a lot better:\r\n\r\n```\r\nFormat error in JSON body: '2014-01-01T00:00:00' does not match any accepted datetime format\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n_None_\r\n\r\n**Additional context**\r\nRelated issue: <https://github.com/qdrant/qdrant/issues/3529>",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3531"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3531",
              "body": "**Is your feature request related to a problem? Please describe.**\r\nWe recently merged <https://github.com/qdrant/qdrant/pull/3395> which adds a datetime payload index.\r\n\r\nCurrently, the datetime parser is very strict, only allowing [RFC 3339](https://www.rfc-editor.org/rfc/rfc3339) formats in our REST API. A common format such as `YYYY-MM-DD HH:MM:SS` is currently not accepted.\r\n\r\nIf you'd send the following request:\r\n\r\n```json\r\nPOST collections/test_collection/points/scroll\r\n{\r\n  \"limit\": 10,\r\n  \"filter\": {\r\n    \"must\": [\r\n      {\r\n        \"key\": \"updated\",\r\n        \"datetime_range\": {\r\n          \"gt\": \"2014-01-01T00:00:00\"\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nYou'd receive the following error:\r\n\r\n```\r\nFormat error in JSON body: data did not match any variant of untagged enum Condition at line 1 column 96\r\n```\r\n\r\nThis error is very confusing.\r\n\r\n**Describe the solution you'd like**\r\nWe'd strongly prefer a more descriptive error message instead.\r\n\r\nSomething like this would be a lot better:\r\n\r\n```\r\nFormat error in JSON body: '2014-01-01T00:00:00' does not match any accepted datetime format\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n_None_\r\n\r\n**Additional context**\r\nRelated issue: <https://github.com/qdrant/qdrant/issues/3529>",
              "url": "https://github.com/qdrant/qdrant/issues/3531",
              "tech": [],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#3322",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2025-12-27T17:50:09.595Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:09.595Z",
            "created_at": "2025-12-27T17:50:09.595Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3322",
              "status": "open",
              "type": "issue",
              "number": 3322,
              "title": "Per-collection metrics for Prometheus",
              "source": {
                "data": {
                  "id": "source-qdrant#3322",
                  "user": {
                    "login": "generall",
                    "id": 1935623,
                    "node_id": "MDQ6VXNlcjE5MzU2MjM=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1935623?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/generall",
                    "html_url": "https://github.com/generall",
                    "followers_url": "https://api.github.com/users/generall/followers",
                    "following_url": "https://api.github.com/users/generall/following{/other_user}",
                    "gists_url": "https://api.github.com/users/generall/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/generall/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/generall/subscriptions",
                    "organizations_url": "https://api.github.com/users/generall/orgs",
                    "repos_url": "https://api.github.com/users/generall/repos",
                    "events_url": "https://api.github.com/users/generall/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/generall/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Per-collection metrics for Prometheus",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, all metrics in `/metrics` are global, meaning that it‚Äôs impossible to see differences per collection.\r\n\r\nIn addition to that, all our metrics should have per-collection granularity to allow better aggregation in Prometheus, including:\r\n\r\n- point/vector counts\r\n- REST/gRPC requests\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample:\r\n```\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\"} 0.000046\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection\"} 0.000049\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection-2\"} 0.000046\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreate dedicated endpoint for each collection `/collections/my-collecton/metrics`\r\nbut feedback from DevOps on this idea was negative.\r\n\r\n**Additional context**\r\n\r\nIt might be beneficial to allow users to disable per-collection output. It is especially relevant if there are a lot of collections and metric response could become huge. But this is a nice-to-have requirement.\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently\r\n\r\n",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3322"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3322",
              "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, all metrics in `/metrics` are global, meaning that it‚Äôs impossible to see differences per collection.\r\n\r\nIn addition to that, all our metrics should have per-collection granularity to allow better aggregation in Prometheus, including:\r\n\r\n- point/vector counts\r\n- REST/gRPC requests\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample:\r\n```\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\"} 0.000046\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection\"} 0.000049\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection-2\"} 0.000046\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreate dedicated endpoint for each collection `/collections/my-collecton/metrics`\r\nbut feedback from DevOps on this idea was negative.\r\n\r\n**Additional context**\r\n\r\nIt might be beneficial to allow users to disable per-collection output. It is especially relevant if there are a lot of collections and metric response could become huge. But this is a nice-to-have requirement.\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently\r\n\r\n",
              "url": "https://github.com/qdrant/qdrant/issues/3322",
              "tech": [],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "activepieces#10618",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "activepieces",
              "id": "generated-activepieces",
              "name": "Activepieces",
              "description": "",
              "members": [],
              "display_name": "Activepieces",
              "created_at": "2025-12-27T17:50:13.137Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/activepieces?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "activepieces",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.137Z",
            "created_at": "2025-12-27T17:50:13.137Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-activepieces#10618",
              "status": "open",
              "type": "issue",
              "number": 10618,
              "title": "Native AI Selector",
              "source": {
                "data": {
                  "id": "source-activepieces#10618",
                  "user": {
                    "login": "abuaboud",
                    "id": 1812998,
                    "node_id": "MDQ6VXNlcjE4MTI5OTg=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1812998?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/abuaboud",
                    "html_url": "https://github.com/abuaboud",
                    "followers_url": "https://api.github.com/users/abuaboud/followers",
                    "following_url": "https://api.github.com/users/abuaboud/following{/other_user}",
                    "gists_url": "https://api.github.com/users/abuaboud/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/abuaboud/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/abuaboud/subscriptions",
                    "organizations_url": "https://api.github.com/users/abuaboud/orgs",
                    "repos_url": "https://api.github.com/users/abuaboud/repos",
                    "events_url": "https://api.github.com/users/abuaboud/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/abuaboud/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Native AI Selector",
                  "body": "<br>In the Flow Builder, the current shape design looks very basic. We would like to revamp it to improve the visual quality and match the new design.<br>\n\n## Current State\n\nThe shape is simple and lacks visual polish.\n\n<img src=\"https://uploads.linear.app/31a22bcc-cf6d-4d14-99c3-7f5b856dd10f/c2c9f1ef-1aa1-4c5d-a502-aec7fc20f5f1/d547bade-f286-4591-9d65-3fcd3f3d8420?signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiLzMxYTIyYmNjLWNmNmQtNGQxNC05OWMzLTdmNWI4NTZkZDEwZi9jMmM5ZjFlZi0xYWExLTRjNWQtYTUwMi1hZWM3ZmMyMGY1ZjEvZDU0N2JhZGUtZjI4Ni00NTkxLTlkNjUtM2ZjZDNmM2Q4NDIwIiwiaWF0IjoxNzY2NjUzMTgxLCJleHAiOjE3OTgyMjM3NDF9.bn08HPH8t8hcuSIG-23eYe0zvBG3MLifX8Bh3eUSZYc \" alt=\"image.png\" width=\"725\" data-linear-height=\"556\" />\n\n## New State\n\n<br>Update the shape to match the new design shown in the Figma prototype:<br><br>[https://www.figma.com/proto/MvGDWYULNEs3c3UVwhg9G5/AI-Pieces-Selector?page-id=102%3A11175&node-id=176-548&p=f&t=OT6EYu3U3akLXB1z-1&scaling=min-zoom&content-scaling=fixed&starting-point-node-id=176%3A548](https://www.figma.com/proto/MvGDWYULNEs3c3UVwhg9G5/AI-Pieces-Selector?page-id=102%3A11175&node-id=176-548&p=f&t=OT6EYu3U3akLXB1z-1&scaling=min-zoom&content-scaling=fixed&starting-point-node-id=176%3A548)<br>\n\n## **Implementation Details**\n\n* **Code location:**<br>`packages/react-ui/src/app/builder/pieces-selector/ai-tab-content`\n* Ensure the **height stays the same for both tabs**.\n* Only the visual design should change; behavior should remain unchanged.\n* The text for each action is inside the action metadata (description field)\n* Here is videos link\n  * [https://cdn.activepieces.com/pieces/ai/native/ai-agents.mp4](https://cdn.activepieces.com/pieces/ai/native/ai-agents.mp4)\n  * [https://cdn.activepieces.com/pieces/ai/native/ask-ai.mp4](https://cdn.activepieces.com/pieces/ai/native/ask-ai.mp4)\n  * [https://cdn.activepieces.com/pieces/ai/native/classify-text.mp4](https://cdn.activepieces.com/pieces/ai/native/classify-text.mp4)\n  * [https://cdn.activepieces.com/pieces/ai/native/generate-images.mp4](https://cdn.activepieces.com/pieces/ai/native/generate-images.mp4)\n  * [https://cdn.activepieces.com/pieces/ai/native/ocr.mp4](https://cdn.activepieces.com/pieces/ai/native/ocr.mp4)\n  * [https://cdn.activepieces.com/pieces/ai/native/summarize-text.mp4](https://cdn.activepieces.com/pieces/ai/native/summarize-text.mp4)",
                  "html_url": "https://github.com/activepieces/activepieces/issues/10618"
                },
                "type": "github"
              },
              "hash": "activepieces/activepieces#10618",
              "body": "<br>In the Flow Builder, the current shape design looks very basic. We would like to revamp it to improve the visual quality and match the new design.<br>\n\n## Current State\n\nThe shape is simple and lacks visual polish.\n\n<img src=\"https://uploads.linear.app/31a22bcc-cf6d-4d14-99c3-7f5b856dd10f/c2c9f1ef-1aa1-4c5d-a502-aec7fc20f5f1/d547bade-f286-4591-9d65-3fcd3f3d8420?signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiLzMxYTIyYmNjLWNmNmQtNGQxNC05OWMzLTdmNWI4NTZkZDEwZi9jMmM5ZjFlZi0xYWExLTRjNWQtYTUwMi1hZWM3ZmMyMGY1ZjEvZDU0N2JhZGUtZjI4Ni00NTkxLTlkNjUtM2ZjZDNmM2Q4NDIwIiwiaWF0IjoxNzY2NjUzMTgxLCJleHAiOjE3OTgyMjM3NDF9.bn08HPH8t8hcuSIG-23eYe0zvBG3MLifX8Bh3eUSZYc \" alt=\"image.png\" width=\"725\" data-linear-height=\"556\" />\n\n## New State\n\n<br>Update the shape to match the new design shown in the Figma prototype:<br><br>[https://www.figma.com/proto/MvGDWYULNEs3c3UVwhg9G5/AI-Pieces-Selector?page-id=102%3A11175&node-id=176-548&p=f&t=OT6EYu3U3akLXB1z-1&scaling=min-zoom&content-scaling=fixed&starting-point-node-id=176%3A548](https://www.figma.com/proto/MvGDWYULNEs3c3UVwhg9G5/AI-Pieces-Selector?page-id=102%3A11175&node-id=176-548&p=f&t=OT6EYu3U3akLXB1z-1&scaling=min-zoom&content-scaling=fixed&starting-point-node-id=176%3A548)<br>\n\n## **Implementation Details**\n\n* **Code location:**<br>`packages/react-ui/src/app/builder/pieces-selector/ai-tab-content`\n* Ensure the **height stays the same for both tabs**.\n* Only the visual design should change; behavior should remain unchanged.\n* The text for each action is inside the action metadata (description field)\n* Here is videos link\n  * [https://cdn.activepieces.com/pieces/ai/native/ai-agents.mp4](https://cdn.activepieces.com/pieces/ai/native/ai-agents.mp4)\n  * [https://cdn.activepieces.com/pieces/ai/native/ask-ai.mp4](https://cdn.activepieces.com/pieces/ai/native/ask-ai.mp4)\n  * [https://cdn.activepieces.com/pieces/ai/native/classify-text.mp4](https://cdn.activepieces.com/pieces/ai/native/classify-text.mp4)\n  * [https://cdn.activepieces.com/pieces/ai/native/generate-images.mp4](https://cdn.activepieces.com/pieces/ai/native/generate-images.mp4)\n  * [https://cdn.activepieces.com/pieces/ai/native/ocr.mp4](https://cdn.activepieces.com/pieces/ai/native/ocr.mp4)\n  * [https://cdn.activepieces.com/pieces/ai/native/summarize-text.mp4](https://cdn.activepieces.com/pieces/ai/native/summarize-text.mp4)",
              "url": "https://github.com/activepieces/activepieces/issues/10618",
              "tech": [],
              "repo_name": "activepieces",
              "repo_owner": "activepieces",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "activepieces#9703",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "activepieces",
              "id": "generated-activepieces",
              "name": "Activepieces",
              "description": "",
              "members": [],
              "display_name": "Activepieces",
              "created_at": "2025-12-27T17:50:13.361Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/activepieces?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "activepieces",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.361Z",
            "created_at": "2025-12-27T17:50:13.361Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-activepieces#9703",
              "status": "open",
              "type": "issue",
              "number": 9703,
              "title": "[MCP] Oracle Fusion Cloud ERP",
              "source": {
                "data": {
                  "id": "source-activepieces#9703",
                  "user": {
                    "login": "kishanprmr",
                    "id": 135701940,
                    "node_id": "U_kgDOCBaltA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/135701940?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kishanprmr",
                    "html_url": "https://github.com/kishanprmr",
                    "followers_url": "https://api.github.com/users/kishanprmr/followers",
                    "following_url": "https://api.github.com/users/kishanprmr/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kishanprmr/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kishanprmr/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kishanprmr/subscriptions",
                    "organizations_url": "https://api.github.com/users/kishanprmr/orgs",
                    "repos_url": "https://api.github.com/users/kishanprmr/repos",
                    "events_url": "https://api.github.com/users/kishanprmr/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kishanprmr/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[MCP] Oracle Fusion Cloud ERP",
                  "body": "## ‚Äã üß© Product Overview\n\nOracle Fusion Cloud ERP is an enterprise resource planning suite covering financials, procurement, project accounting, supply chain, and more. This integration supports generic record operations (CRUD + search + watch) across business objects in Fusion ERP, enabling automation and data synchronization. \n\n---\n\n## ‚Äã‚Äã ‚ö†Ô∏è Important Note for Contributors\n\nThis feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions not following this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n## üö® Triggers\n\n| **Trigger** | **Description** | \n|:--|:--|\n| **New Record** | Fires when new records are created in a specified business object (e.g. Invoice, Purchase Order, Customer) in Oracle ERP. | \n\n\n---\n\n## ‚Äã‚Äã üõ†Ô∏è Write Actions\n\n| **Action** | **Description** | **Use Case Example** |\n|:--|:--|:--|\n| **Create Record**     | Create a new record in a specified object (e.g. Invoice, PO, Customer). | Automate creating purchase orders from purchase requests.  |\n| **Update Record**     | Update fields of an existing record (by object + ID).                      | Update invoice status, adjust amounts, modify due dates. |\n| **Delete a Record**    | Delete (or mark for deletion) a record by ID.                             | Remove test or obsolete records.  |\n| **Get a Record**     | Retrieve the details of a specific record (by object type and ID). | Fetch detailed invoice or supplier info when needed.  |\n\n\n\n---\n\n## üîç Search Actions\n\n| Action Name       | Description                                                                 | \n|--------------------|-----------------------------------------------------------------------------|\n| **Search Records**   | Retrieve a list of records matching filter criteria (object + query). |\n\n---\n\n## ‚Äã üìö API Reference\n\n- [Oracle Fusion Cloud ERP API Documentation](https://docs.oracle.com/en/cloud/saas/financials/25d/farfa/index.html)\n\n---\n\n## ‚Äã üß™ Test Account Access\n\n- You can create free trial at https://www.oracle.com/in/erp/financials/.\n\n---\n\n## ‚Äã‚Äã‚Äãüßë‚Äçüíª New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are build with our TypeScript framework and are easy to build. Once they're merged to our repo, they will available as pieces in our automation builder and as MCPs to be used with AI agents and MCP clients.\n\nWe welcome contributions and in fact, we get excited over them. Start your journey here: https://www.activepieces.com/docs/developers/building-pieces/overview\n",
                  "html_url": "https://github.com/activepieces/activepieces/issues/9703"
                },
                "type": "github"
              },
              "hash": "activepieces/activepieces#9703",
              "body": "## ‚Äã üß© Product Overview\n\nOracle Fusion Cloud ERP is an enterprise resource planning suite covering financials, procurement, project accounting, supply chain, and more. This integration supports generic record operations (CRUD + search + watch) across business objects in Fusion ERP, enabling automation and data synchronization. \n\n---\n\n## ‚Äã‚Äã ‚ö†Ô∏è Important Note for Contributors\n\nThis feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions not following this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n## üö® Triggers\n\n| **Trigger** | **Description** | \n|:--|:--|\n| **New Record** | Fires when new records are created in a specified business object (e.g. Invoice, Purchase Order, Customer) in Oracle ERP. | \n\n\n---\n\n## ‚Äã‚Äã üõ†Ô∏è Write Actions\n\n| **Action** | **Description** | **Use Case Example** |\n|:--|:--|:--|\n| **Create Record**     | Create a new record in a specified object (e.g. Invoice, PO, Customer). | Automate creating purchase orders from purchase requests.  |\n| **Update Record**     | Update fields of an existing record (by object + ID).                      | Update invoice status, adjust amounts, modify due dates. |\n| **Delete a Record**    | Delete (or mark for deletion) a record by ID.                             | Remove test or obsolete records.  |\n| **Get a Record**     | Retrieve the details of a specific record (by object type and ID). | Fetch detailed invoice or supplier info when needed.  |\n\n\n\n---\n\n## üîç Search Actions\n\n| Action Name       | Description                                                                 | \n|--------------------|-----------------------------------------------------------------------------|\n| **Search Records**   | Retrieve a list of records matching filter criteria (object + query). |\n\n---\n\n## ‚Äã üìö API Reference\n\n- [Oracle Fusion Cloud ERP API Documentation](https://docs.oracle.com/en/cloud/saas/financials/25d/farfa/index.html)\n\n---\n\n## ‚Äã üß™ Test Account Access\n\n- You can create free trial at https://www.oracle.com/in/erp/financials/.\n\n---\n\n## ‚Äã‚Äã‚Äãüßë‚Äçüíª New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are build with our TypeScript framework and are easy to build. Once they're merged to our repo, they will available as pieces in our automation builder and as MCPs to be used with AI agents and MCP clients.\n\nWe welcome contributions and in fact, we get excited over them. Start your journey here: https://www.activepieces.com/docs/developers/building-pieces/overview\n",
              "url": "https://github.com/activepieces/activepieces/issues/9703",
              "tech": [],
              "repo_name": "activepieces",
              "repo_owner": "activepieces",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "activepieces#8284",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "activepieces",
              "id": "generated-activepieces",
              "name": "Activepieces",
              "description": "",
              "members": [],
              "display_name": "Activepieces",
              "created_at": "2025-12-27T17:50:13.502Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/activepieces?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "activepieces",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.502Z",
            "created_at": "2025-12-27T17:50:13.502Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-activepieces#8284",
              "status": "open",
              "type": "issue",
              "number": 8284,
              "title": "[MCP] Klaviyo",
              "source": {
                "data": {
                  "id": "source-activepieces#8284",
                  "user": {
                    "login": "kishanprmr",
                    "id": 135701940,
                    "node_id": "U_kgDOCBaltA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/135701940?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kishanprmr",
                    "html_url": "https://github.com/kishanprmr",
                    "followers_url": "https://api.github.com/users/kishanprmr/followers",
                    "following_url": "https://api.github.com/users/kishanprmr/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kishanprmr/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kishanprmr/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kishanprmr/subscriptions",
                    "organizations_url": "https://api.github.com/users/kishanprmr/orgs",
                    "repos_url": "https://api.github.com/users/kishanprmr/repos",
                    "events_url": "https://api.github.com/users/kishanprmr/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kishanprmr/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[MCP] Klaviyo",
                  "body": "## üß© Product Overview\n\nKlaviyo is a marketing automation platform for email, SMS, and customer data.  \nThis integration enables AI agents and workflows to create, manage, and interact with profiles, lists, events, campaigns, and segments, automating customer engagement and analytics.\n\n---\n\n## ‚ö†Ô∏è Important Note for Contributors\n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n## üö® Triggers\n\n| **Trigger** | **Use Case** |\n|-------------|---------------|\n| **New Profile** | Triggers when a new profile is created in the account. |\n| **Profile Added to List/Segment** | Fires when a profile is added to a specific list or segment. |\n\n---\n\n## üõ†Ô∏è Write Actions\n\n| **Action Item** | **Use Case** |\n|-----------------|---------------|\n| **Create Profile** | Add a new user profile to Klaviyo, optionally subscribing to email/SMS. |\n| **Update Profile** | Update existing profile data and preferences. |\n| **Subscribe Profile** | Subscribe a profile to email or SMS lists. |\n| **Unsubscribe Profile** | Remove a profile from email or SMS lists. |\n| **Add Profile to List** | Add a profile to a specific list. |\n| **Remove Profile from List** | Remove a profile from a specific list. |\n| **Create List** | Create a new subscriber list. |\n\n---\n\n## üîç Search Actions\n\n| **Action Item** | **Use Case** |\n|-----------------|---------------|\n| **Find Profile by Email/Phone** | Locate a profile using email or phone number. |\n| **Find List by Name** | Look up a list by name to get its ID. |\n| **Find Tag by Name** | Locate a tag to manage tagging workflows. |\n\n---\n\n## üìö API Reference\n\n- [Official Klaviyo API Documentation](https://developers.klaviyo.com/en/reference)\n\n---\n\n## üß™ Test Account Access\n\nYou can test Klaviyo APIs by creating a free account on [Klaviyo](https://www.klaviyo.com/) and generating a private API key from your account settings.\n\n---\n\n## üßë‚Äçüíª New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
                  "html_url": "https://github.com/activepieces/activepieces/issues/8284"
                },
                "type": "github"
              },
              "hash": "activepieces/activepieces#8284",
              "body": "## üß© Product Overview\n\nKlaviyo is a marketing automation platform for email, SMS, and customer data.  \nThis integration enables AI agents and workflows to create, manage, and interact with profiles, lists, events, campaigns, and segments, automating customer engagement and analytics.\n\n---\n\n## ‚ö†Ô∏è Important Note for Contributors\n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n## üö® Triggers\n\n| **Trigger** | **Use Case** |\n|-------------|---------------|\n| **New Profile** | Triggers when a new profile is created in the account. |\n| **Profile Added to List/Segment** | Fires when a profile is added to a specific list or segment. |\n\n---\n\n## üõ†Ô∏è Write Actions\n\n| **Action Item** | **Use Case** |\n|-----------------|---------------|\n| **Create Profile** | Add a new user profile to Klaviyo, optionally subscribing to email/SMS. |\n| **Update Profile** | Update existing profile data and preferences. |\n| **Subscribe Profile** | Subscribe a profile to email or SMS lists. |\n| **Unsubscribe Profile** | Remove a profile from email or SMS lists. |\n| **Add Profile to List** | Add a profile to a specific list. |\n| **Remove Profile from List** | Remove a profile from a specific list. |\n| **Create List** | Create a new subscriber list. |\n\n---\n\n## üîç Search Actions\n\n| **Action Item** | **Use Case** |\n|-----------------|---------------|\n| **Find Profile by Email/Phone** | Locate a profile using email or phone number. |\n| **Find List by Name** | Look up a list by name to get its ID. |\n| **Find Tag by Name** | Locate a tag to manage tagging workflows. |\n\n---\n\n## üìö API Reference\n\n- [Official Klaviyo API Documentation](https://developers.klaviyo.com/en/reference)\n\n---\n\n## üß™ Test Account Access\n\nYou can test Klaviyo APIs by creating a free account on [Klaviyo](https://www.klaviyo.com/) and generating a private API key from your account settings.\n\n---\n\n## üßë‚Äçüíª New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
              "url": "https://github.com/activepieces/activepieces/issues/8284",
              "tech": [],
              "repo_name": "activepieces",
              "repo_owner": "activepieces",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "activepieces#8135",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "activepieces",
              "id": "generated-activepieces",
              "name": "Activepieces",
              "description": "",
              "members": [],
              "display_name": "Activepieces",
              "created_at": "2025-12-27T17:50:13.628Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/activepieces?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "activepieces",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.628Z",
            "created_at": "2025-12-27T17:50:13.628Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-activepieces#8135",
              "status": "open",
              "type": "issue",
              "number": 8135,
              "title": "[MCP] Canva",
              "source": {
                "data": {
                  "id": "source-activepieces#8135",
                  "user": {
                    "login": "kishanprmr",
                    "id": 135701940,
                    "node_id": "U_kgDOCBaltA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/135701940?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kishanprmr",
                    "html_url": "https://github.com/kishanprmr",
                    "followers_url": "https://api.github.com/users/kishanprmr/followers",
                    "following_url": "https://api.github.com/users/kishanprmr/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kishanprmr/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kishanprmr/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kishanprmr/subscriptions",
                    "organizations_url": "https://api.github.com/users/kishanprmr/orgs",
                    "repos_url": "https://api.github.com/users/kishanprmr/repos",
                    "events_url": "https://api.github.com/users/kishanprmr/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kishanprmr/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[MCP] Canva",
                  "body": "## üß© Product Overview  \n\nCanva is an online design platform that enables users to create visual content like social graphics, presentations, and posters. This integration empowers automation builders and AI agents to streamline tasks such as design creation, asset uploads, exports, folder organization, and more.\n\n---\n\n## ‚ö†Ô∏è Important Note for Contributors  \n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n## üõ†Ô∏è Write Actions  \n\n| **Action Item**               | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **Upload Asset** | Auto-upload brand assets when a campaign starts. |\n| **Create Design** | Automatically generate Instagram templates on new blog posts.|\n| **Import Design** | Convert user-submitted PDFs into editable Canva designs. |\n|**Export Design**| Export a brochure as a PDF and save it.|\n|**Move Folder Item**| Organize completed designs into an ‚ÄúArchive‚Äù folder.|\n\n---\n\n## üîç Search Actions  \n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Find Design** | Ensure a design doesn‚Äôt already exist before creation.|\n\n---\n\n## üìñ Read Actions\n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Get a Folder** | Retrieves details about an existing folder.|\n|**Get an Image**| Retrieves details about an existing image.|\n\n---\n\n## üìö API Reference  \n- [Official Canva API Documentation](https://www.canva.dev/docs/connect/api-reference/designs/create-design/)\n\n---\n\n## üß™ Test Account Access  \nYou can sign up for a free account at https://www.canva.com/en_in/.\n\n---\n\n## üßë‚Äçüíª New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
                  "html_url": "https://github.com/activepieces/activepieces/issues/8135"
                },
                "type": "github"
              },
              "hash": "activepieces/activepieces#8135",
              "body": "## üß© Product Overview  \n\nCanva is an online design platform that enables users to create visual content like social graphics, presentations, and posters. This integration empowers automation builders and AI agents to streamline tasks such as design creation, asset uploads, exports, folder organization, and more.\n\n---\n\n## ‚ö†Ô∏è Important Note for Contributors  \n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n## üõ†Ô∏è Write Actions  \n\n| **Action Item**               | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **Upload Asset** | Auto-upload brand assets when a campaign starts. |\n| **Create Design** | Automatically generate Instagram templates on new blog posts.|\n| **Import Design** | Convert user-submitted PDFs into editable Canva designs. |\n|**Export Design**| Export a brochure as a PDF and save it.|\n|**Move Folder Item**| Organize completed designs into an ‚ÄúArchive‚Äù folder.|\n\n---\n\n## üîç Search Actions  \n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Find Design** | Ensure a design doesn‚Äôt already exist before creation.|\n\n---\n\n## üìñ Read Actions\n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Get a Folder** | Retrieves details about an existing folder.|\n|**Get an Image**| Retrieves details about an existing image.|\n\n---\n\n## üìö API Reference  \n- [Official Canva API Documentation](https://www.canva.dev/docs/connect/api-reference/designs/create-design/)\n\n---\n\n## üß™ Test Account Access  \nYou can sign up for a free account at https://www.canva.com/en_in/.\n\n---\n\n## üßë‚Äçüíª New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
              "url": "https://github.com/activepieces/activepieces/issues/8135",
              "tech": [],
              "repo_name": "activepieces",
              "repo_owner": "activepieces",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "activepieces#8135",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "activepieces",
              "id": "generated-activepieces",
              "name": "Activepieces",
              "description": "",
              "members": [],
              "display_name": "Activepieces",
              "created_at": "2025-12-27T17:50:13.635Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/activepieces?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "activepieces",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.635Z",
            "created_at": "2025-12-27T17:50:13.635Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-activepieces#8135",
              "status": "open",
              "type": "issue",
              "number": 8135,
              "title": "[MCP] Canva",
              "source": {
                "data": {
                  "id": "source-activepieces#8135",
                  "user": {
                    "login": "kishanprmr",
                    "id": 135701940,
                    "node_id": "U_kgDOCBaltA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/135701940?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kishanprmr",
                    "html_url": "https://github.com/kishanprmr",
                    "followers_url": "https://api.github.com/users/kishanprmr/followers",
                    "following_url": "https://api.github.com/users/kishanprmr/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kishanprmr/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kishanprmr/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kishanprmr/subscriptions",
                    "organizations_url": "https://api.github.com/users/kishanprmr/orgs",
                    "repos_url": "https://api.github.com/users/kishanprmr/repos",
                    "events_url": "https://api.github.com/users/kishanprmr/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kishanprmr/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[MCP] Canva",
                  "body": "## üß© Product Overview  \n\nCanva is an online design platform that enables users to create visual content like social graphics, presentations, and posters. This integration empowers automation builders and AI agents to streamline tasks such as design creation, asset uploads, exports, folder organization, and more.\n\n---\n\n## ‚ö†Ô∏è Important Note for Contributors  \n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n## üõ†Ô∏è Write Actions  \n\n| **Action Item**               | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **Upload Asset** | Auto-upload brand assets when a campaign starts. |\n| **Create Design** | Automatically generate Instagram templates on new blog posts.|\n| **Import Design** | Convert user-submitted PDFs into editable Canva designs. |\n|**Export Design**| Export a brochure as a PDF and save it.|\n|**Move Folder Item**| Organize completed designs into an ‚ÄúArchive‚Äù folder.|\n\n---\n\n## üîç Search Actions  \n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Find Design** | Ensure a design doesn‚Äôt already exist before creation.|\n\n---\n\n## üìñ Read Actions\n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Get a Folder** | Retrieves details about an existing folder.|\n|**Get an Image**| Retrieves details about an existing image.|\n\n---\n\n## üìö API Reference  \n- [Official Canva API Documentation](https://www.canva.dev/docs/connect/api-reference/designs/create-design/)\n\n---\n\n## üß™ Test Account Access  \nYou can sign up for a free account at https://www.canva.com/en_in/.\n\n---\n\n## üßë‚Äçüíª New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
                  "html_url": "https://github.com/activepieces/activepieces/issues/8135"
                },
                "type": "github"
              },
              "hash": "activepieces/activepieces#8135",
              "body": "## üß© Product Overview  \n\nCanva is an online design platform that enables users to create visual content like social graphics, presentations, and posters. This integration empowers automation builders and AI agents to streamline tasks such as design creation, asset uploads, exports, folder organization, and more.\n\n---\n\n## ‚ö†Ô∏è Important Note for Contributors  \n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n## üõ†Ô∏è Write Actions  \n\n| **Action Item**               | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **Upload Asset** | Auto-upload brand assets when a campaign starts. |\n| **Create Design** | Automatically generate Instagram templates on new blog posts.|\n| **Import Design** | Convert user-submitted PDFs into editable Canva designs. |\n|**Export Design**| Export a brochure as a PDF and save it.|\n|**Move Folder Item**| Organize completed designs into an ‚ÄúArchive‚Äù folder.|\n\n---\n\n## üîç Search Actions  \n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Find Design** | Ensure a design doesn‚Äôt already exist before creation.|\n\n---\n\n## üìñ Read Actions\n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Get a Folder** | Retrieves details about an existing folder.|\n|**Get an Image**| Retrieves details about an existing image.|\n\n---\n\n## üìö API Reference  \n- [Official Canva API Documentation](https://www.canva.dev/docs/connect/api-reference/designs/create-design/)\n\n---\n\n## üß™ Test Account Access  \nYou can sign up for a free account at https://www.canva.com/en_in/.\n\n---\n\n## üßë‚Äçüíª New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
              "url": "https://github.com/activepieces/activepieces/issues/8135",
              "tech": [],
              "repo_name": "activepieces",
              "repo_owner": "activepieces",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "activepieces#8072",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "activepieces",
              "id": "generated-activepieces",
              "name": "Activepieces",
              "description": "",
              "members": [],
              "display_name": "Activepieces",
              "created_at": "2025-12-27T17:50:13.755Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/activepieces?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "activepieces",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.755Z",
            "created_at": "2025-12-27T17:50:13.755Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-activepieces#8072",
              "status": "open",
              "type": "issue",
              "number": 8072,
              "title": "[MCP] Gmail",
              "source": {
                "data": {
                  "id": "source-activepieces#8072",
                  "user": {
                    "login": "kishanprmr",
                    "id": 135701940,
                    "node_id": "U_kgDOCBaltA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/135701940?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kishanprmr",
                    "html_url": "https://github.com/kishanprmr",
                    "followers_url": "https://api.github.com/users/kishanprmr/followers",
                    "following_url": "https://api.github.com/users/kishanprmr/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kishanprmr/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kishanprmr/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kishanprmr/subscriptions",
                    "organizations_url": "https://api.github.com/users/kishanprmr/orgs",
                    "repos_url": "https://api.github.com/users/kishanprmr/repos",
                    "events_url": "https://api.github.com/users/kishanprmr/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kishanprmr/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[MCP] Gmail",
                  "body": "## üß© Product Overview  \n\nGmail is Google‚Äôs email platform for sending, receiving, labeling, archiving, and organizing messages.\nThis integration empowers AI agents and workflows to automate email-based processes, from detection to response, labeling, and thread management.\n\n\n---\n\n## ‚ö†Ô∏è Important Note for Contributors  \n\nThis Gmail piece already exists in Activepieces. Your task is to extend the current piece by adding additional actions and triggers as outlined in the documentation and reference materials.\nPlease avoid duplicating existing functionality. Review the current implementation before making changes, and ensure that all new features follow existing coding patterns and standards.\n\n---\n\n## üö® Triggers  \n\n| **Trigger** | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **New Starred Email** | Fires when an email is starred (within 2 days).|\n| **New Conversation** | Fires when a new conversation (thread) begins.|\n|**New Attachment**|Fires when an email with an attachment arrives (with optional filters).|\n|**New Label**|Triggers when a new label is created.|\n---\n\n## üõ†Ô∏è Write Actions  \n\n| **Action Item**               | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **Reply to Email** | Reply within an existing thread, maintaining context. |\n| **Create Draft Reply** | Generate a reply draft within an existing thread.|\n| **Add Label to Email** | Attach a label to an individual email.|\n|**Remove Label from Email**|Remove a specific label from an email.Remove a specific label from an email.|\n|**Create Label**|Create a new user label in Gmail.|\n|**Archive Email**|Archive (move to ‚ÄúAll Mail‚Äù) rather than deleting.|\n|**Delete Email**|Permanently move an email to Trash.|\n|**Remove Label from Thread**|Strip a label from all emails in a thread.|\n---\n\n## üîç Search Actions  \n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Find Email** | Locate a specific email using search keywords like subject, sender, or content.|\n\n---\n\n\n## üìö API Reference  \n- [Official Gmail API Documentation](https://developers.google.com/workspace/gmail/api/guides)\n\n---\n\n## üß™ Test Account Access  \nYou can test Gmail APIs using a Google account with enabled Gmail API in a [Google Cloud Project Console](https://console.cloud.google.com/).\n\n---\n\n## üßë‚Äçüíª New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
                  "html_url": "https://github.com/activepieces/activepieces/issues/8072"
                },
                "type": "github"
              },
              "hash": "activepieces/activepieces#8072",
              "body": "## üß© Product Overview  \n\nGmail is Google‚Äôs email platform for sending, receiving, labeling, archiving, and organizing messages.\nThis integration empowers AI agents and workflows to automate email-based processes, from detection to response, labeling, and thread management.\n\n\n---\n\n## ‚ö†Ô∏è Important Note for Contributors  \n\nThis Gmail piece already exists in Activepieces. Your task is to extend the current piece by adding additional actions and triggers as outlined in the documentation and reference materials.\nPlease avoid duplicating existing functionality. Review the current implementation before making changes, and ensure that all new features follow existing coding patterns and standards.\n\n---\n\n## üö® Triggers  \n\n| **Trigger** | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **New Starred Email** | Fires when an email is starred (within 2 days).|\n| **New Conversation** | Fires when a new conversation (thread) begins.|\n|**New Attachment**|Fires when an email with an attachment arrives (with optional filters).|\n|**New Label**|Triggers when a new label is created.|\n---\n\n## üõ†Ô∏è Write Actions  \n\n| **Action Item**               | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **Reply to Email** | Reply within an existing thread, maintaining context. |\n| **Create Draft Reply** | Generate a reply draft within an existing thread.|\n| **Add Label to Email** | Attach a label to an individual email.|\n|**Remove Label from Email**|Remove a specific label from an email.Remove a specific label from an email.|\n|**Create Label**|Create a new user label in Gmail.|\n|**Archive Email**|Archive (move to ‚ÄúAll Mail‚Äù) rather than deleting.|\n|**Delete Email**|Permanently move an email to Trash.|\n|**Remove Label from Thread**|Strip a label from all emails in a thread.|\n---\n\n## üîç Search Actions  \n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Find Email** | Locate a specific email using search keywords like subject, sender, or content.|\n\n---\n\n\n## üìö API Reference  \n- [Official Gmail API Documentation](https://developers.google.com/workspace/gmail/api/guides)\n\n---\n\n## üß™ Test Account Access  \nYou can test Gmail APIs using a Google account with enabled Gmail API in a [Google Cloud Project Console](https://console.cloud.google.com/).\n\n---\n\n## üßë‚Äçüíª New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
              "url": "https://github.com/activepieces/activepieces/issues/8072",
              "tech": [],
              "repo_name": "activepieces",
              "repo_owner": "activepieces",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7743",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-27T17:50:13.140Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.140Z",
            "created_at": "2025-12-27T17:50:13.140Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7743",
              "status": "open",
              "type": "issue",
              "number": 7743,
              "title": "[Enhancement]: Don't timeout public database proxies after 10 min",
              "source": {
                "data": {
                  "id": "source-coollabsio#7743",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Don't timeout public database proxies after 10 min",
                  "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the TCP proxy in front of Postgres when you mark \"Expose publicly\" times out after about 10m. Switch this to have no timeout or to have a configurable timeout in the GUI.\n\nUse case: I sometimes have `SELECT *` statements that take a very long time (30m+) to download the results for. The connection timing out prevents that from being successful\n\nBounty: $100 USD once merged and live on Coolify Cloud.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com), a charity that supports teenagers who love coding and electronics! We previously funded database SSL support, backups API, and pgBackRest support for Postgres backups (in progress).",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7743"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7743",
              "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the TCP proxy in front of Postgres when you mark \"Expose publicly\" times out after about 10m. Switch this to have no timeout or to have a configurable timeout in the GUI.\n\nUse case: I sometimes have `SELECT *` statements that take a very long time (30m+) to download the results for. The connection timing out prevents that from being successful\n\nBounty: $100 USD once merged and live on Coolify Cloud.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com), a charity that supports teenagers who love coding and electronics! We previously funded database SSL support, backups API, and pgBackRest support for Postgres backups (in progress).",
              "url": "https://github.com/coollabsio/coolify/issues/7743",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7738",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-27T17:50:13.255Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.255Z",
            "created_at": "2025-12-27T17:50:13.255Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7738",
              "status": "open",
              "type": "issue",
              "number": 7738,
              "title": "[Enhancement]: Environment variables for each server that are auto-added to each application deployed on it",
              "source": {
                "data": {
                  "id": "source-coollabsio#7738",
                  "user": {
                    "login": "pkpio",
                    "id": 816666,
                    "node_id": "MDQ6VXNlcjgxNjY2Ng==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/816666?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/pkpio",
                    "html_url": "https://github.com/pkpio",
                    "followers_url": "https://api.github.com/users/pkpio/followers",
                    "following_url": "https://api.github.com/users/pkpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/pkpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/pkpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/pkpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/pkpio/orgs",
                    "repos_url": "https://api.github.com/users/pkpio/repos",
                    "events_url": "https://api.github.com/users/pkpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/pkpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Environment variables for each server that are auto-added to each application deployed on it",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\nWhen deploying a resource using the \"Multiple Servers\" option, currently there is no way to distinguish between the servers from within the application - because the container running on both servers get identical setup. \n\nThis makes debugging harder as application logs cannot identify which server deployment an issue happened - take for instance a failure due to network errors happening specifically on one server (randomly). \n\nA way to define Environment variables for each server and making them available for each application deployed on that server, will fix this limitation (and also generalised in a way for use cases beyond what I described here).",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7738"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7738",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\nWhen deploying a resource using the \"Multiple Servers\" option, currently there is no way to distinguish between the servers from within the application - because the container running on both servers get identical setup. \n\nThis makes debugging harder as application logs cannot identify which server deployment an issue happened - take for instance a failure due to network errors happening specifically on one server (randomly). \n\nA way to define Environment variables for each server and making them available for each application deployed on that server, will fix this limitation (and also generalised in a way for use cases beyond what I described here).",
              "url": "https://github.com/coollabsio/coolify/issues/7738",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7724",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-27T17:50:13.356Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.356Z",
            "created_at": "2025-12-27T17:50:13.356Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7724",
              "status": "open",
              "type": "issue",
              "number": 7724,
              "title": "[Bug]: Sporadic Permission denied (publickey,password).",
              "source": {
                "data": {
                  "id": "source-coollabsio#7724",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Sporadic Permission denied (publickey,password).",
                  "body": "### Error Message and Logs\n\n<img width=\"380\" height=\"129\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a615ea52-e26d-435d-8121-e01cd7d7f656\" />\n\nStarting maybe ~2 weeks ago we started getting this error constantly. Generating a new private SSH key and setting it up seems to stop it for a bit, then it starts happening again. I'm 99% sure something is causing Coolify to send the wrong SSH key. When I check server logs, it shows that logins are indeed failing. They are not being blocked by fail2ban or anything like that.\n\nI will pay $250 to anyone who can diagnose and fix this issue. It's causing major issues for us. Acceptance criteria: Fix is merged into Coolify Cloud.\n\n### Steps to Reproduce\n\nI'm sorry, I don't have good reproduction steps. It sporadically seems to happen.\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7724"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7724",
              "body": "### Error Message and Logs\n\n<img width=\"380\" height=\"129\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a615ea52-e26d-435d-8121-e01cd7d7f656\" />\n\nStarting maybe ~2 weeks ago we started getting this error constantly. Generating a new private SSH key and setting it up seems to stop it for a bit, then it starts happening again. I'm 99% sure something is causing Coolify to send the wrong SSH key. When I check server logs, it shows that logins are indeed failing. They are not being blocked by fail2ban or anything like that.\n\nI will pay $250 to anyone who can diagnose and fix this issue. It's causing major issues for us. Acceptance criteria: Fix is merged into Coolify Cloud.\n\n### Steps to Reproduce\n\nI'm sorry, I don't have good reproduction steps. It sporadically seems to happen.\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/7724",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7642",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-27T17:50:13.448Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.448Z",
            "created_at": "2025-12-27T17:50:13.448Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7642",
              "status": "open",
              "type": "issue",
              "number": 7642,
              "title": "[Enhancement]: Add surrealDB with and without TIKV",
              "source": {
                "data": {
                  "id": "source-coollabsio#7642",
                  "user": {
                    "login": "Jordan-Hall",
                    "id": 2092344,
                    "node_id": "MDQ6VXNlcjIwOTIzNDQ=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/2092344?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Jordan-Hall",
                    "html_url": "https://github.com/Jordan-Hall",
                    "followers_url": "https://api.github.com/users/Jordan-Hall/followers",
                    "following_url": "https://api.github.com/users/Jordan-Hall/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Jordan-Hall/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Jordan-Hall/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Jordan-Hall/subscriptions",
                    "organizations_url": "https://api.github.com/users/Jordan-Hall/orgs",
                    "repos_url": "https://api.github.com/users/Jordan-Hall/repos",
                    "events_url": "https://api.github.com/users/Jordan-Hall/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Jordan-Hall/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Add surrealDB with and without TIKV",
                  "body": "### Request Type\n\nNew Service\n\n### Description\n\nThey a couple of decussion around surrealdb as a database option but it be nice if it was bulit in with both TIKV and rockdb as an option\n\nhttps://github.com/coollabsio/coolify/discussions/3587\nhttps://github.com/coollabsio/coolify/discussions/4013 ",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7642"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7642",
              "body": "### Request Type\n\nNew Service\n\n### Description\n\nThey a couple of decussion around surrealdb as a database option but it be nice if it was bulit in with both TIKV and rockdb as an option\n\nhttps://github.com/coollabsio/coolify/discussions/3587\nhttps://github.com/coollabsio/coolify/discussions/4013 ",
              "url": "https://github.com/coollabsio/coolify/issues/7642",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7596",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-27T17:50:13.559Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.559Z",
            "created_at": "2025-12-27T17:50:13.559Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7596",
              "status": "open",
              "type": "issue",
              "number": 7596,
              "title": "[Enhancement]: new deployment page",
              "source": {
                "data": {
                  "id": "source-coollabsio#7596",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: new deployment page",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n- Add deployments to sidebar\n- Show past deployments (all of them)\n- Add a filter on the top:\n  - Filter by project\n  - Filter by server\n  - Filter by sources\n  - Filter by status (queued, pending, done)\n- Show live updates / refresh?\n- Hide filters if only 1 server / 1 source\n\n## Design inspiration\n\nVercel example:\n\n<img width=\"1362\" height=\"967\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e46d7470-fff1-46c5-8011-63ba82119db2\" />\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7596"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7596",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n- Add deployments to sidebar\n- Show past deployments (all of them)\n- Add a filter on the top:\n  - Filter by project\n  - Filter by server\n  - Filter by sources\n  - Filter by status (queued, pending, done)\n- Show live updates / refresh?\n- Hide filters if only 1 server / 1 source\n\n## Design inspiration\n\nVercel example:\n\n<img width=\"1362\" height=\"967\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e46d7470-fff1-46c5-8011-63ba82119db2\" />\n",
              "url": "https://github.com/coollabsio/coolify/issues/7596",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7529",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-27T17:50:13.664Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.664Z",
            "created_at": "2025-12-27T17:50:13.664Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7529",
              "status": "open",
              "type": "issue",
              "number": 7529,
              "title": "[Enhancement]: Enable backup restore/import for ServiceDatabase (Docker Compose databases)",
              "source": {
                "data": {
                  "id": "source-coollabsio#7529",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Enable backup restore/import for ServiceDatabase (Docker Compose databases)",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nDatabases created via Docker Compose deployments (`ServiceDatabase`) can create backups but cannot restore/import them through the UI. The import functionality only supports Standalone database types.\n\n### Current Behavior\n\n| Database Type | Backup | Restore/Import |\n|---|---|---|\n| StandalonePostgresql | ‚úÖ | ‚úÖ |\n| StandaloneMysql | ‚úÖ | ‚úÖ |\n| StandaloneMariadb | ‚úÖ | ‚úÖ |\n| StandaloneMongodb | ‚úÖ | ‚úÖ |\n| **ServiceDatabase** (from Docker Compose) | ‚úÖ | ‚ùå |\n\n### Expected Behavior\n\nServiceDatabase should support restore/import functionality, similar to Standalone databases.\n\n### Technical Details\n\n**File:** `app/Livewire/Project/Database/Import.php`\n\nThe `buildRestoreCommand()` method (line 576-614) only handles Standalone database classes:\n\n```php\nswitch ($this->resource->getMorphClass()) {\n    case \\App\\Models\\StandaloneMariadb::class:\n        // ...\n    case \\App\\Models\\StandaloneMysql::class:\n        // ...\n    case \\App\\Models\\StandalonePostgresql::class:\n        // ...\n    case \\App\\Models\\StandaloneMongodb::class:\n        // ...\n    default:\n        $restoreCommand = ''; // ServiceDatabase falls here\n}\n```\n\n### Proposed Solution\n\nAdd support for `ServiceDatabase` in `Import.php`:\n\n1. In `buildRestoreCommand()`, add a case for `ServiceDatabase`:\n```php\ncase \\App\\Models\\ServiceDatabase::class:\n    $dbType = $this->resource->databaseType(); // Returns 'standalone-postgresql', etc.\n    // Build restore command based on $dbType\n    break;\n```\n\n2. The `ServiceDatabase->databaseType()` method already returns the database type (e.g., `standalone-postgresql`, `standalone-mysql`), which can be used to determine the correct restore command.\n\n3. Update `getContainers()` to properly handle ServiceDatabase container naming:\n```php\n// ServiceDatabase container name format: {service-name}-{service-uuid}\n$this->container = $this->resource->name . '-' . $this->resource->service->uuid;\n```\n\n### Related Code\n\n- `app/Livewire/Project/Database/Import.php` - Import/restore component\n- `app/Models/ServiceDatabase.php` - Has `databaseType()` method\n- `app/Jobs/DatabaseBackupJob.php` - Already supports ServiceDatabase for backups\n\n### Use Case\n\nUsers deploying databases via Docker Compose (e.g., `postgres:17-alpine` in a compose file) need the ability to restore backups through the Coolify UI, just like Standalone database deployments.\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7529"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7529",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nDatabases created via Docker Compose deployments (`ServiceDatabase`) can create backups but cannot restore/import them through the UI. The import functionality only supports Standalone database types.\n\n### Current Behavior\n\n| Database Type | Backup | Restore/Import |\n|---|---|---|\n| StandalonePostgresql | ‚úÖ | ‚úÖ |\n| StandaloneMysql | ‚úÖ | ‚úÖ |\n| StandaloneMariadb | ‚úÖ | ‚úÖ |\n| StandaloneMongodb | ‚úÖ | ‚úÖ |\n| **ServiceDatabase** (from Docker Compose) | ‚úÖ | ‚ùå |\n\n### Expected Behavior\n\nServiceDatabase should support restore/import functionality, similar to Standalone databases.\n\n### Technical Details\n\n**File:** `app/Livewire/Project/Database/Import.php`\n\nThe `buildRestoreCommand()` method (line 576-614) only handles Standalone database classes:\n\n```php\nswitch ($this->resource->getMorphClass()) {\n    case \\App\\Models\\StandaloneMariadb::class:\n        // ...\n    case \\App\\Models\\StandaloneMysql::class:\n        // ...\n    case \\App\\Models\\StandalonePostgresql::class:\n        // ...\n    case \\App\\Models\\StandaloneMongodb::class:\n        // ...\n    default:\n        $restoreCommand = ''; // ServiceDatabase falls here\n}\n```\n\n### Proposed Solution\n\nAdd support for `ServiceDatabase` in `Import.php`:\n\n1. In `buildRestoreCommand()`, add a case for `ServiceDatabase`:\n```php\ncase \\App\\Models\\ServiceDatabase::class:\n    $dbType = $this->resource->databaseType(); // Returns 'standalone-postgresql', etc.\n    // Build restore command based on $dbType\n    break;\n```\n\n2. The `ServiceDatabase->databaseType()` method already returns the database type (e.g., `standalone-postgresql`, `standalone-mysql`), which can be used to determine the correct restore command.\n\n3. Update `getContainers()` to properly handle ServiceDatabase container naming:\n```php\n// ServiceDatabase container name format: {service-name}-{service-uuid}\n$this->container = $this->resource->name . '-' . $this->resource->service->uuid;\n```\n\n### Related Code\n\n- `app/Livewire/Project/Database/Import.php` - Import/restore component\n- `app/Models/ServiceDatabase.php` - Has `databaseType()` method\n- `app/Jobs/DatabaseBackupJob.php` - Already supports ServiceDatabase for backups\n\n### Use Case\n\nUsers deploying databases via Docker Compose (e.g., `postgres:17-alpine` in a compose file) need the ability to restore backups through the Coolify UI, just like Standalone database deployments.\n",
              "url": "https://github.com/coollabsio/coolify/issues/7529",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7528",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-27T17:50:13.769Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.769Z",
            "created_at": "2025-12-27T17:50:13.769Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7528",
              "status": "open",
              "type": "issue",
              "number": 7528,
              "title": "[Enhancement]: Enable database detection and backup support for Docker Compose deployments via GitHub App",
              "source": {
                "data": {
                  "id": "source-coollabsio#7528",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Enable database detection and backup support for Docker Compose deployments via GitHub App",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nWhen deploying a Docker Compose file via GitHub App (using the `dockercompose` buildpack), database services are not detected and `ServiceDatabase` records are not created. This means automated backups are not available for databases in these deployments.\n\nHowever, when using \"Empty Docker Compose\" or one-click services (like Supabase), database detection works correctly and backups are available.\n\n### Current Behavior\n\n| Deployment Method | Model | Creates ServiceDatabase | Backups Available |\n|---|---|---|---|\n| Empty Docker Compose | `Service` | ‚úÖ Yes | ‚úÖ Yes |\n| GitHub App (dockercompose buildpack) | `Application` | ‚ùå No | ‚ùå No |\n| One-click Services (e.g., Supabase) | `Service` | ‚úÖ Yes | ‚úÖ Yes |\n\n### Expected Behavior\n\nDatabase services in Docker Compose files deployed via GitHub App should be detected and have backup functionality available, similar to Empty Docker Compose deployments.\n\n### Technical Details\n\nThe issue is in `bootstrap/helpers/shared.php` in the `parseDockerComposeFile()` function:\n\n**Service model path (lines 1263-2025):**\n- Calls `isDatabaseImage()` to detect databases\n- Creates `ServiceDatabase` records for detected databases\n- These databases can have scheduled backups\n\n**Application model path (lines 2026-2767):**\n- Does NOT call `isDatabaseImage()`\n- Does NOT create `ServiceDatabase` records\n- All services are treated as application containers\n- No backup support\n\n### Proposed Solution\n\nAdd database detection logic to the Application model parsing path:\n\n1. In `parseDockerComposeFile()` for the Application model (around line 2066), add:\n   ```php\n   $isDatabase = isDatabaseImage($image, $service);\n   data_set($service, 'is_database', $isDatabase);\n   ```\n\n2. Create `ServiceDatabase` records for detected database services, similar to how it's done in the Service model path.\n\n3. Alternatively, consider refactoring to share the database detection logic between both paths.\n\n### Use Case\n\nUsers deploying full-stack applications via GitHub (e.g., Next.js app + PostgreSQL + pgbouncer in a single compose file) expect database backups to work the same way as standalone database deployments or one-click services.\n\n### Related Code\n\n- `bootstrap/helpers/shared.php` - `parseDockerComposeFile()` function\n- `bootstrap/helpers/docker.php` - `isDatabaseImage()` function\n- `app/Models/ServiceDatabase.php` - Database model with backup support\n- `app/Models/ScheduledDatabaseBackup.php` - Backup scheduling\n\n### Environment\n\n- Coolify version: latest\n- Deployment method: GitHub App with dockercompose buildpack\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7528"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7528",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nWhen deploying a Docker Compose file via GitHub App (using the `dockercompose` buildpack), database services are not detected and `ServiceDatabase` records are not created. This means automated backups are not available for databases in these deployments.\n\nHowever, when using \"Empty Docker Compose\" or one-click services (like Supabase), database detection works correctly and backups are available.\n\n### Current Behavior\n\n| Deployment Method | Model | Creates ServiceDatabase | Backups Available |\n|---|---|---|---|\n| Empty Docker Compose | `Service` | ‚úÖ Yes | ‚úÖ Yes |\n| GitHub App (dockercompose buildpack) | `Application` | ‚ùå No | ‚ùå No |\n| One-click Services (e.g., Supabase) | `Service` | ‚úÖ Yes | ‚úÖ Yes |\n\n### Expected Behavior\n\nDatabase services in Docker Compose files deployed via GitHub App should be detected and have backup functionality available, similar to Empty Docker Compose deployments.\n\n### Technical Details\n\nThe issue is in `bootstrap/helpers/shared.php` in the `parseDockerComposeFile()` function:\n\n**Service model path (lines 1263-2025):**\n- Calls `isDatabaseImage()` to detect databases\n- Creates `ServiceDatabase` records for detected databases\n- These databases can have scheduled backups\n\n**Application model path (lines 2026-2767):**\n- Does NOT call `isDatabaseImage()`\n- Does NOT create `ServiceDatabase` records\n- All services are treated as application containers\n- No backup support\n\n### Proposed Solution\n\nAdd database detection logic to the Application model parsing path:\n\n1. In `parseDockerComposeFile()` for the Application model (around line 2066), add:\n   ```php\n   $isDatabase = isDatabaseImage($image, $service);\n   data_set($service, 'is_database', $isDatabase);\n   ```\n\n2. Create `ServiceDatabase` records for detected database services, similar to how it's done in the Service model path.\n\n3. Alternatively, consider refactoring to share the database detection logic between both paths.\n\n### Use Case\n\nUsers deploying full-stack applications via GitHub (e.g., Next.js app + PostgreSQL + pgbouncer in a single compose file) expect database backups to work the same way as standalone database deployments or one-click services.\n\n### Related Code\n\n- `bootstrap/helpers/shared.php` - `parseDockerComposeFile()` function\n- `bootstrap/helpers/docker.php` - `isDatabaseImage()` function\n- `app/Models/ServiceDatabase.php` - Database model with backup support\n- `app/Models/ScheduledDatabaseBackup.php` - Backup scheduling\n\n### Environment\n\n- Coolify version: latest\n- Deployment method: GitHub App with dockercompose buildpack\n",
              "url": "https://github.com/coollabsio/coolify/issues/7528",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7473",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-27T17:50:13.887Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.887Z",
            "created_at": "2025-12-27T17:50:13.887Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7473",
              "status": "open",
              "type": "issue",
              "number": 7473,
              "title": "[Bug]: Database Backups won't use the custom timeout in ssh command (regression)",
              "source": {
                "data": {
                  "id": "source-coollabsio#7473",
                  "user": {
                    "login": "isokosan",
                    "id": 1430946,
                    "node_id": "MDQ6VXNlcjE0MzA5NDY=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1430946?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/isokosan",
                    "html_url": "https://github.com/isokosan",
                    "followers_url": "https://api.github.com/users/isokosan/followers",
                    "following_url": "https://api.github.com/users/isokosan/following{/other_user}",
                    "gists_url": "https://api.github.com/users/isokosan/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/isokosan/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/isokosan/subscriptions",
                    "organizations_url": "https://api.github.com/users/isokosan/orgs",
                    "repos_url": "https://api.github.com/users/isokosan/repos",
                    "events_url": "https://api.github.com/users/isokosan/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/isokosan/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Database Backups won't use the custom timeout in ssh command (regression)",
                  "body": "### Error Message and Logs\n\nWe had [this issue](https://github.com/coollabsio/coolify/issues/3325) with backups exceeding timeouts and we made a new feature where we can customize the timeout settings in the backups.\n\nThis was working but seems to have regressed as the timeout setting is not being passed to the backup ssh command, instead the default 3600 is being used I'm afraid:\n\nThe process \"timeout 3600 ssh -i /var/www/html/storage/app/ssh/keys/ssh_key@jgcwgggco80sc0occ88skg0s -o StrictHos... truncated ...FoM2ROejJRRmtjT1M0NXNt\" exceeded the timeout of 3600 seconds.\n\n@Cinzya commented that this is about the SSH command now and not the backup itself:\n> I believe this is actually the SSH process timing out and not the backup itself.\n> The SSH process has a hard timeout of 3600. The backup timeout is not really passed to the SSH process to increase that timeout as well. \n> This is either an oversight or there is a specific reason why a SSH process shouldn't linger more then 3600 seconds. \n> But yes, feel free to open a new issue about it. \n\n\n### Steps to Reproduce\n\n1. Configure a database and then backups.\n2. Use the Timeout option in the dashboard to set a custom timeout, eg 10800 (default 3600 seconds)\n3. Click on Backup Now\n4. Check the command that is run by coolify to see the timeout not being passed to the SSH command\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7473"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7473",
              "body": "### Error Message and Logs\n\nWe had [this issue](https://github.com/coollabsio/coolify/issues/3325) with backups exceeding timeouts and we made a new feature where we can customize the timeout settings in the backups.\n\nThis was working but seems to have regressed as the timeout setting is not being passed to the backup ssh command, instead the default 3600 is being used I'm afraid:\n\nThe process \"timeout 3600 ssh -i /var/www/html/storage/app/ssh/keys/ssh_key@jgcwgggco80sc0occ88skg0s -o StrictHos... truncated ...FoM2ROejJRRmtjT1M0NXNt\" exceeded the timeout of 3600 seconds.\n\n@Cinzya commented that this is about the SSH command now and not the backup itself:\n> I believe this is actually the SSH process timing out and not the backup itself.\n> The SSH process has a hard timeout of 3600. The backup timeout is not really passed to the SSH process to increase that timeout as well. \n> This is either an oversight or there is a specific reason why a SSH process shouldn't linger more then 3600 seconds. \n> But yes, feel free to open a new issue about it. \n\n\n### Steps to Reproduce\n\n1. Configure a database and then backups.\n2. Use the Timeout option in the dashboard to set a custom timeout, eg 10800 (default 3600 seconds)\n3. Click on Backup Now\n4. Check the command that is run by coolify to see the timeout not being passed to the SSH command\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/7473",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7458",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-27T17:50:13.991Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:13.991Z",
            "created_at": "2025-12-27T17:50:13.991Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7458",
              "status": "open",
              "type": "issue",
              "number": 7458,
              "title": "[Bug + Multiple Bounties]: Official Selfhosted Supabase MCP Setup hindered by Coolify AND Bounty List",
              "source": {
                "data": {
                  "id": "source-coollabsio#7458",
                  "user": {
                    "login": "rootacc3ss",
                    "id": 192549131,
                    "node_id": "U_kgDOC3oRCw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/192549131?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/rootacc3ss",
                    "html_url": "https://github.com/rootacc3ss",
                    "followers_url": "https://api.github.com/users/rootacc3ss/followers",
                    "following_url": "https://api.github.com/users/rootacc3ss/following{/other_user}",
                    "gists_url": "https://api.github.com/users/rootacc3ss/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/rootacc3ss/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/rootacc3ss/subscriptions",
                    "organizations_url": "https://api.github.com/users/rootacc3ss/orgs",
                    "repos_url": "https://api.github.com/users/rootacc3ss/repos",
                    "events_url": "https://api.github.com/users/rootacc3ss/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/rootacc3ss/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug + Multiple Bounties]: Official Selfhosted Supabase MCP Setup hindered by Coolify AND Bounty List",
                  "body": "### Error Message and Logs\n\n**Bounty! $15.00 on Algora.io; will add ASAP, need to figure out how to use it.**\n\nWhen following these documents from Supabase pertaining to the latest selfhosted Supabase docker setup:\nhttps://supabase.com/docs/guides/self-hosting/enable-mcp\n_you will notice the following..._\n\n1. There is no configuration to turn this on or off with ease, or even commented out docker-compose, nor any notes.\n2. With how we expose Kong via URL by default, the approach in the document could be messy or unsafe\n3. It looks like additional configuration may be required if there are multiple Supabase instances on the same server with individual /mcp exposures as Traefik is handling the routing and everything is using the same ports, etc...\n\n**I am looking for a \"work around\" as the resolution for this bounty.** That is acceptable, but I will require **at minimum a tutorial below** that figures out how to get around this bug/issue and properly documents the following:\n\n- How to configure the MCP and use it on local network\n- How to setup Wireguard to properly allow for usage of this MCP\n- How to configure Cursor/Claude Code/Windsurf to use this MCP\n- **MOST IMPORTANTLY, HOW TO CONNECT TO DIFFERENT SUPABASE INSTANCES ON THE SAME COOLIFY INSTANCE (assuming all of them are running the default Service template)**\n\nCreating a fix within the system we have to spin up and manage a Supabase instance may be difficult due to the template system's restraints, but if you want to work on that complaint of mine and **earn much more than $15**, you can see the bottom of this post. I list off the other bounties I will be offering and putting up cash for upon clearing some wires and hopefully seeing someone (or a few people) dedicate time to it.\n\n### Steps to Reproduce\n\n1. Follow docs linked above\n2. Attempt to edit the docker and piece it all together as tutorial says\n3. ???\n\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nUbuntu 24.04.03\n\n### Additional Information\n\nI am starting this bounty small as I have no clue how this system works and if I will be able to add crypto or not. I want to list these other bounties here firstly to see if there is any immediate response for \n\n**If you claim the small bounty for this, I have a few more I am willing to put in to place -- just let me know if you're interested and make sure to clear whichever one you wish to do with me to I can post the bounty for it:**\n\n- **[$35]** Better Cloudflared/Cloudflare management tools (easy exclusions and inclusions by project, IP, etc... manage domains and subdomains via Cloudflare Zero Trust or DNS settings automatically -- or at least though a portal of some sort)\n- **[$15]** Improved Supabase template (easily configure MCP properly using some sort of fix from this thread, configure mail server for automated mail and OTP with ease, set up external S3 with ease, etc -- I can contribute what I have learned from messing with the template)\n- **[$25]** Working MailCow OR Stalwart+Roundcube \"Service\" template... It's time...\n- **[$XXX]** CoolifyAI -- add API key, get AI assistant w/ knowledge-base similar to the Supabase assistant, ideally with GitHub issue lookup and basic research capability  \n- **[$XXX - $X,XXX]** More proper, fleshed out \"Services\" template system WITH ability to add remote repositories outside of the official Coolify templates; setup scripting w/ select-able options, easily modify docker template or automations/commands with checkboxes, dropdowns and input fields and the works. Ideally, a system in which \"addons\" in these same repositories as the whole \"Services\" themselves can be added on to each individual service; I.e. for Cloudflared, my request above. Or for Supabase, an easy tool to help you visualize the parts missing from Selfhosted that are in Supabase SaaS/Cloud and perhaps an API to interface with it. **This would make Coolify the single self-hosted PaaS with scripting for templates, but also an extension system allowing new functionality.**\n\nIf you are interested in discussing, claiming or collaborating on one of these bounties, see the little repo I made to track this here:\nhttps://github.com/rootacc3ss/coolify-bounties/tree/main",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7458"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7458",
              "body": "### Error Message and Logs\n\n**Bounty! $15.00 on Algora.io; will add ASAP, need to figure out how to use it.**\n\nWhen following these documents from Supabase pertaining to the latest selfhosted Supabase docker setup:\nhttps://supabase.com/docs/guides/self-hosting/enable-mcp\n_you will notice the following..._\n\n1. There is no configuration to turn this on or off with ease, or even commented out docker-compose, nor any notes.\n2. With how we expose Kong via URL by default, the approach in the document could be messy or unsafe\n3. It looks like additional configuration may be required if there are multiple Supabase instances on the same server with individual /mcp exposures as Traefik is handling the routing and everything is using the same ports, etc...\n\n**I am looking for a \"work around\" as the resolution for this bounty.** That is acceptable, but I will require **at minimum a tutorial below** that figures out how to get around this bug/issue and properly documents the following:\n\n- How to configure the MCP and use it on local network\n- How to setup Wireguard to properly allow for usage of this MCP\n- How to configure Cursor/Claude Code/Windsurf to use this MCP\n- **MOST IMPORTANTLY, HOW TO CONNECT TO DIFFERENT SUPABASE INSTANCES ON THE SAME COOLIFY INSTANCE (assuming all of them are running the default Service template)**\n\nCreating a fix within the system we have to spin up and manage a Supabase instance may be difficult due to the template system's restraints, but if you want to work on that complaint of mine and **earn much more than $15**, you can see the bottom of this post. I list off the other bounties I will be offering and putting up cash for upon clearing some wires and hopefully seeing someone (or a few people) dedicate time to it.\n\n### Steps to Reproduce\n\n1. Follow docs linked above\n2. Attempt to edit the docker and piece it all together as tutorial says\n3. ???\n\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nUbuntu 24.04.03\n\n### Additional Information\n\nI am starting this bounty small as I have no clue how this system works and if I will be able to add crypto or not. I want to list these other bounties here firstly to see if there is any immediate response for \n\n**If you claim the small bounty for this, I have a few more I am willing to put in to place -- just let me know if you're interested and make sure to clear whichever one you wish to do with me to I can post the bounty for it:**\n\n- **[$35]** Better Cloudflared/Cloudflare management tools (easy exclusions and inclusions by project, IP, etc... manage domains and subdomains via Cloudflare Zero Trust or DNS settings automatically -- or at least though a portal of some sort)\n- **[$15]** Improved Supabase template (easily configure MCP properly using some sort of fix from this thread, configure mail server for automated mail and OTP with ease, set up external S3 with ease, etc -- I can contribute what I have learned from messing with the template)\n- **[$25]** Working MailCow OR Stalwart+Roundcube \"Service\" template... It's time...\n- **[$XXX]** CoolifyAI -- add API key, get AI assistant w/ knowledge-base similar to the Supabase assistant, ideally with GitHub issue lookup and basic research capability  \n- **[$XXX - $X,XXX]** More proper, fleshed out \"Services\" template system WITH ability to add remote repositories outside of the official Coolify templates; setup scripting w/ select-able options, easily modify docker template or automations/commands with checkboxes, dropdowns and input fields and the works. Ideally, a system in which \"addons\" in these same repositories as the whole \"Services\" themselves can be added on to each individual service; I.e. for Cloudflared, my request above. Or for Supabase, an easy tool to help you visualize the parts missing from Selfhosted that are in Supabase SaaS/Cloud and perhaps an API to interface with it. **This would make Coolify the single self-hosted PaaS with scripting for templates, but also an extension system allowing new functionality.**\n\nIf you are interested in discussing, claiming or collaborating on one of these bounties, see the little repo I made to track this here:\nhttps://github.com/rootacc3ss/coolify-bounties/tree/main",
              "url": "https://github.com/coollabsio/coolify/issues/7458",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7423",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-12-27T17:50:14.119Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:14.119Z",
            "created_at": "2025-12-27T17:50:14.119Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7423",
              "status": "open",
              "type": "issue",
              "number": 7423,
              "title": "[Enhancement]: Use pgBackRest for Postgres backups",
              "source": {
                "data": {
                  "id": "source-coollabsio#7423",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Use pgBackRest for Postgres backups",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\nImplement support for using pgBackRest for Postgres backups, ideally as the new default for Postgres.\n\nThis will enable incremental backups and make the backup experience 100x better for large DBs using Postgres. The current backup system is good, but starts to have failures for larger DBs. The current backup system also causes huge S3 bills for larger DBs (ex. nightly backups of 100gb DBs start to add up).\n\nThis must also support the backups API.\n\n$1,000 USD bounty once this is merged into https://app.coolify.io's/ instance and I've verified it works on Postgres DBs with 100gb of data in them.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com/), a charity that supports teenagers who love computers and electronics! We previously funded database SSL support and the creation of the backups API.",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7423"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7423",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\nImplement support for using pgBackRest for Postgres backups, ideally as the new default for Postgres.\n\nThis will enable incremental backups and make the backup experience 100x better for large DBs using Postgres. The current backup system is good, but starts to have failures for larger DBs. The current backup system also causes huge S3 bills for larger DBs (ex. nightly backups of 100gb DBs start to add up).\n\nThis must also support the backups API.\n\n$1,000 USD bounty once this is merged into https://app.coolify.io's/ instance and I've verified it works on Postgres DBs with 100gb of data in them.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com/), a charity that supports teenagers who love computers and electronics! We previously funded database SSL support and the creation of the backups API.",
              "url": "https://github.com/coollabsio/coolify/issues/7423",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "outerbase#59",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2025-12-27T17:50:21.239Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:21.239Z",
            "created_at": "2025-12-27T17:50:21.239Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#59",
              "status": "open",
              "type": "issue",
              "number": 59,
              "title": "Database dumps do not work on large databases",
              "source": {
                "data": {
                  "id": "source-outerbase#59",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Database dumps do not work on large databases",
                  "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/59"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#59",
              "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
              "url": "https://github.com/outerbase/starbasedb/issues/59",
              "tech": [],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "outerbase#72",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2025-12-27T17:50:21.363Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-27T17:50:21.363Z",
            "created_at": "2025-12-27T17:50:21.363Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#72",
              "status": "open",
              "type": "issue",
              "number": 72,
              "title": "Replicate data from external source to internal source with a Plugin",
              "source": {
                "data": {
                  "id": "source-outerbase#72",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Replicate data from external source to internal source with a Plugin",
                  "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/72"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#72",
              "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
              "url": "https://github.com/outerbase/starbasedb/issues/72",
              "tech": [],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          }
        ],
        "next_cursor": null
      }
    }
  }
}