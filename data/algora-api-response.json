{
  "result": {
    "data": {
      "json": {
        "items": [
          {
            "id": "qdrant#3531",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2025-11-27T11:31:41.795Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:31:41.795Z",
            "created_at": "2025-11-27T11:31:41.795Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3531",
              "status": "open",
              "type": "issue",
              "number": 3531,
              "title": "Better error response for wrong datetime format in REST filter",
              "source": {
                "data": {
                  "id": "source-qdrant#3531",
                  "user": {
                    "login": "timvisee",
                    "id": 856222,
                    "node_id": "MDQ6VXNlcjg1NjIyMg==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/856222?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/timvisee",
                    "html_url": "https://github.com/timvisee",
                    "followers_url": "https://api.github.com/users/timvisee/followers",
                    "following_url": "https://api.github.com/users/timvisee/following{/other_user}",
                    "gists_url": "https://api.github.com/users/timvisee/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/timvisee/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/timvisee/subscriptions",
                    "organizations_url": "https://api.github.com/users/timvisee/orgs",
                    "repos_url": "https://api.github.com/users/timvisee/repos",
                    "events_url": "https://api.github.com/users/timvisee/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/timvisee/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Better error response for wrong datetime format in REST filter",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\nWe recently merged <https://github.com/qdrant/qdrant/pull/3395> which adds a datetime payload index.\r\n\r\nCurrently, the datetime parser is very strict, only allowing [RFC 3339](https://www.rfc-editor.org/rfc/rfc3339) formats in our REST API. A common format such as `YYYY-MM-DD HH:MM:SS` is currently not accepted.\r\n\r\nIf you'd send the following request:\r\n\r\n```json\r\nPOST collections/test_collection/points/scroll\r\n{\r\n  \"limit\": 10,\r\n  \"filter\": {\r\n    \"must\": [\r\n      {\r\n        \"key\": \"updated\",\r\n        \"datetime_range\": {\r\n          \"gt\": \"2014-01-01T00:00:00\"\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nYou'd receive the following error:\r\n\r\n```\r\nFormat error in JSON body: data did not match any variant of untagged enum Condition at line 1 column 96\r\n```\r\n\r\nThis error is very confusing.\r\n\r\n**Describe the solution you'd like**\r\nWe'd strongly prefer a more descriptive error message instead.\r\n\r\nSomething like this would be a lot better:\r\n\r\n```\r\nFormat error in JSON body: '2014-01-01T00:00:00' does not match any accepted datetime format\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n_None_\r\n\r\n**Additional context**\r\nRelated issue: <https://github.com/qdrant/qdrant/issues/3529>",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3531"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3531",
              "body": "**Is your feature request related to a problem? Please describe.**\r\nWe recently merged <https://github.com/qdrant/qdrant/pull/3395> which adds a datetime payload index.\r\n\r\nCurrently, the datetime parser is very strict, only allowing [RFC 3339](https://www.rfc-editor.org/rfc/rfc3339) formats in our REST API. A common format such as `YYYY-MM-DD HH:MM:SS` is currently not accepted.\r\n\r\nIf you'd send the following request:\r\n\r\n```json\r\nPOST collections/test_collection/points/scroll\r\n{\r\n  \"limit\": 10,\r\n  \"filter\": {\r\n    \"must\": [\r\n      {\r\n        \"key\": \"updated\",\r\n        \"datetime_range\": {\r\n          \"gt\": \"2014-01-01T00:00:00\"\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nYou'd receive the following error:\r\n\r\n```\r\nFormat error in JSON body: data did not match any variant of untagged enum Condition at line 1 column 96\r\n```\r\n\r\nThis error is very confusing.\r\n\r\n**Describe the solution you'd like**\r\nWe'd strongly prefer a more descriptive error message instead.\r\n\r\nSomething like this would be a lot better:\r\n\r\n```\r\nFormat error in JSON body: '2014-01-01T00:00:00' does not match any accepted datetime format\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n_None_\r\n\r\n**Additional context**\r\nRelated issue: <https://github.com/qdrant/qdrant/issues/3529>",
              "url": "https://github.com/qdrant/qdrant/issues/3531",
              "tech": [
                "go"
              ],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#3322",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2025-11-27T11:31:46.024Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:31:46.024Z",
            "created_at": "2025-11-27T11:31:46.024Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3322",
              "status": "open",
              "type": "issue",
              "number": 3322,
              "title": "Per-collection metrics for Prometheus",
              "source": {
                "data": {
                  "id": "source-qdrant#3322",
                  "user": {
                    "login": "generall",
                    "id": 1935623,
                    "node_id": "MDQ6VXNlcjE5MzU2MjM=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1935623?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/generall",
                    "html_url": "https://github.com/generall",
                    "followers_url": "https://api.github.com/users/generall/followers",
                    "following_url": "https://api.github.com/users/generall/following{/other_user}",
                    "gists_url": "https://api.github.com/users/generall/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/generall/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/generall/subscriptions",
                    "organizations_url": "https://api.github.com/users/generall/orgs",
                    "repos_url": "https://api.github.com/users/generall/repos",
                    "events_url": "https://api.github.com/users/generall/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/generall/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Per-collection metrics for Prometheus",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, all metrics in `/metrics` are global, meaning that it’s impossible to see differences per collection.\r\n\r\nIn addition to that, all our metrics should have per-collection granularity to allow better aggregation in Prometheus, including:\r\n\r\n- point/vector counts\r\n- REST/gRPC requests\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample:\r\n```\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\"} 0.000046\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection\"} 0.000049\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection-2\"} 0.000046\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreate dedicated endpoint for each collection `/collections/my-collecton/metrics`\r\nbut feedback from DevOps on this idea was negative.\r\n\r\n**Additional context**\r\n\r\nIt might be beneficial to allow users to disable per-collection output. It is especially relevant if there are a lot of collections and metric response could become huge. But this is a nice-to-have requirement.\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently\r\n\r\n",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3322"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3322",
              "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, all metrics in `/metrics` are global, meaning that it’s impossible to see differences per collection.\r\n\r\nIn addition to that, all our metrics should have per-collection granularity to allow better aggregation in Prometheus, including:\r\n\r\n- point/vector counts\r\n- REST/gRPC requests\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample:\r\n```\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\"} 0.000046\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection\"} 0.000049\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection-2\"} 0.000046\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreate dedicated endpoint for each collection `/collections/my-collecton/metrics`\r\nbut feedback from DevOps on this idea was negative.\r\n\r\n**Additional context**\r\n\r\nIt might be beneficial to allow users to disable per-collection output. It is especially relevant if there are a lot of collections and metric response could become huge. But this is a nice-to-have requirement.\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently\r\n\r\n",
              "url": "https://github.com/qdrant/qdrant/issues/3322",
              "tech": [],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#1911",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2025-11-27T11:32:13.845Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:13.845Z",
            "created_at": "2025-11-27T11:32:13.845Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#1911",
              "status": "open",
              "type": "issue",
              "number": 1911,
              "title": "Warn on mismatch between global `prisma` and local `prisma` or `@prisma/client`",
              "source": {
                "data": {
                  "id": "source-prisma#1911",
                  "user": {
                    "login": "janpio",
                    "id": 183673,
                    "node_id": "MDQ6VXNlcjE4MzY3Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/183673?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/janpio",
                    "html_url": "https://github.com/janpio",
                    "followers_url": "https://api.github.com/users/janpio/followers",
                    "following_url": "https://api.github.com/users/janpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/janpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/janpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/janpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/janpio/orgs",
                    "repos_url": "https://api.github.com/users/janpio/repos",
                    "events_url": "https://api.github.com/users/janpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/janpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Warn on mismatch between global `prisma` and local `prisma` or `@prisma/client`",
                  "body": "Using a global `prisma generate` with a different local `prisma` or `@prisma/client` might lead to problems. It might be a good idea to warn users if they are doing that and ask for explicit confirmation.",
                  "html_url": "https://github.com/prisma/prisma/issues/1911"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#1911",
              "body": "Using a global `prisma generate` with a different local `prisma` or `@prisma/client` might lead to problems. It might be a good idea to warn users if they are doing that and ask for explicit confirmation.",
              "url": "https://github.com/prisma/prisma/issues/1911",
              "tech": [
                "go"
              ],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#8548",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2025-11-27T11:32:13.941Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:13.941Z",
            "created_at": "2025-11-27T11:32:13.941Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#8548",
              "status": "open",
              "type": "issue",
              "number": 8548,
              "title": "`prisma format` ends the file with a single CRLF on windows",
              "source": {
                "data": {
                  "id": "source-prisma#8548",
                  "user": {
                    "login": "binary64",
                    "id": 1680627,
                    "node_id": "MDQ6VXNlcjE2ODA2Mjc=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1680627?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/binary64",
                    "html_url": "https://github.com/binary64",
                    "followers_url": "https://api.github.com/users/binary64/followers",
                    "following_url": "https://api.github.com/users/binary64/following{/other_user}",
                    "gists_url": "https://api.github.com/users/binary64/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/binary64/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/binary64/subscriptions",
                    "organizations_url": "https://api.github.com/users/binary64/orgs",
                    "repos_url": "https://api.github.com/users/binary64/repos",
                    "events_url": "https://api.github.com/users/binary64/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/binary64/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "`prisma format` ends the file with a single CRLF on windows",
                  "body": "### Bug description\n\nOn windows, I run `prisma format` and note the unusual file ending. The lines are all LF, but the very last line is CRLF.\r\n\r\nThis causes issue on my Linux CI where it formats it ending in LF's only, causing a diff to occur and the build to fail.\n\n### How to reproduce\n\n1. On windows do prisma format\r\n2. Open in HxD or similar\r\n3. See attached:\r\n \r\n![image](https://user-images.githubusercontent.com/1680627/127931864-fcd66391-9b31-4914-8553-f6c71b3a6fad.png)\r\n\n\n### Expected behavior\n\nLF's only - no CR's to exist at all\n\n### Prisma information\n\n<!-- Do not include your database credentials when sharing your Prisma schema! -->\r\n\n\n### Environment & setup\n\nNode 16\r\nWindows/Linux\n\n### Prisma Version\n\n```\r\n$ C:\\p\\pab\\monorepo\\node_modules\\.bin\\prisma -v\r\nprisma               : 2.26.0\r\n@prisma/client       : 2.28.0\r\nCurrent platform     : windows\r\nQuery Engine         : query-engine 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\query-engine-windows.exe)\r\nMigration Engine     : migration-engine-cli 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\migration-engine-windows.exe)\r\nIntrospection Engine : introspection-core 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\introspection-engine-windows.exe)\r\nFormat Binary        : prisma-fmt 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\prisma-fmt-windows.exe)\r\nDefault Engines Hash : 9b816b3aa13cc270074f172f30d6eda8a8ce867d\r\nStudio               : 0.408.0\r\n```",
                  "html_url": "https://github.com/prisma/prisma/issues/8548"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#8548",
              "body": "### Bug description\n\nOn windows, I run `prisma format` and note the unusual file ending. The lines are all LF, but the very last line is CRLF.\r\n\r\nThis causes issue on my Linux CI where it formats it ending in LF's only, causing a diff to occur and the build to fail.\n\n### How to reproduce\n\n1. On windows do prisma format\r\n2. Open in HxD or similar\r\n3. See attached:\r\n \r\n![image](https://user-images.githubusercontent.com/1680627/127931864-fcd66391-9b31-4914-8553-f6c71b3a6fad.png)\r\n\n\n### Expected behavior\n\nLF's only - no CR's to exist at all\n\n### Prisma information\n\n<!-- Do not include your database credentials when sharing your Prisma schema! -->\r\n\n\n### Environment & setup\n\nNode 16\r\nWindows/Linux\n\n### Prisma Version\n\n```\r\n$ C:\\p\\pab\\monorepo\\node_modules\\.bin\\prisma -v\r\nprisma               : 2.26.0\r\n@prisma/client       : 2.28.0\r\nCurrent platform     : windows\r\nQuery Engine         : query-engine 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\query-engine-windows.exe)\r\nMigration Engine     : migration-engine-cli 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\migration-engine-windows.exe)\r\nIntrospection Engine : introspection-core 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\introspection-engine-windows.exe)\r\nFormat Binary        : prisma-fmt 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\prisma-fmt-windows.exe)\r\nDefault Engines Hash : 9b816b3aa13cc270074f172f30d6eda8a8ce867d\r\nStudio               : 0.408.0\r\n```",
              "url": "https://github.com/prisma/prisma/issues/8548",
              "tech": [],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#7771",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2025-11-27T11:32:14.059Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:14.059Z",
            "created_at": "2025-11-27T11:32:14.059Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#7771",
              "status": "open",
              "type": "issue",
              "number": 7771,
              "title": "Output path of current Prisma in `-v` ",
              "source": {
                "data": {
                  "id": "source-prisma#7771",
                  "user": {
                    "login": "janpio",
                    "id": 183673,
                    "node_id": "MDQ6VXNlcjE4MzY3Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/183673?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/janpio",
                    "html_url": "https://github.com/janpio",
                    "followers_url": "https://api.github.com/users/janpio/followers",
                    "following_url": "https://api.github.com/users/janpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/janpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/janpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/janpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/janpio/orgs",
                    "repos_url": "https://api.github.com/users/janpio/repos",
                    "events_url": "https://api.github.com/users/janpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/janpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Output path of current Prisma in `-v` ",
                  "body": "## Problem\r\n\r\nThis is a situation that can happen:\r\n```\r\n--- yarn prisma -v ---\r\nwarning package.json: No license field\r\nprisma               : 2.26.0-dev.7\r\n@prisma/client       : 2.26.0-dev.7\r\nCurrent platform     : debian-openssl-1.1.x\r\nQuery Engine         : query-engine c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/query-engine-debian-openssl-1.1.x)\r\nMigration Engine     : migration-engine-cli c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/migration-engine-debian-openssl-1.1.x)\r\nIntrospection Engine : introspection-core c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/introspection-engine-debian-openssl-1.1.x)\r\nFormat Binary        : prisma-fmt c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/prisma-fmt-debian-openssl-1.1.x)\r\nDefault Engines Hash : c838e79f39885bc8e1611849b1eb28b5bb5bc922\r\nStudio               : 0.402.0\r\n--- ls node_modules/@prisma/engines/ ---\r\nls: cannot access 'node_modules/@prisma/engines/': No such file or directory\r\n```\r\n\r\nAs you can see `yarn prisma -v` tells us the engines comes from `node_modules/@prisma/engines`, but when you try to list that directory, it is actually not present.\r\n\r\nWhat is happening here is that `yarn prisma` is actually from a few folders _above_ our project. This is kinda visible when you look to not run `yarn -s` but just `yarn`:\r\n```\r\ncodespace ➜ /workspaces/e2e-tests/platforms-serverless/firebase-functions (janpio-patch-5 ✗) $ yarn prisma -v\r\nyarn run v1.22.10\r\nwarning package.json: No license field\r\n$ /workspaces/e2e-tests/node_modules/.bin/prisma -v\r\nprisma               : 2.25.0-dev.36\r\n@prisma/client       : 2.25.0-dev.36\r\n...\r\n```\r\n\r\n## Suggested solution\r\n\r\nOutput the directory of where the executed `prisma` is from, either similar to Yarn the absolute path to the binary in `node_modules`, or the folder where the `package.json` that is responsible for the installation of Prisma comes from.\r\n\r\n## Alternatives\r\n\r\nRely on `yarn` itself to give that information. Will not work with `npx` unfortunately for example.",
                  "html_url": "https://github.com/prisma/prisma/issues/7771"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#7771",
              "body": "## Problem\r\n\r\nThis is a situation that can happen:\r\n```\r\n--- yarn prisma -v ---\r\nwarning package.json: No license field\r\nprisma               : 2.26.0-dev.7\r\n@prisma/client       : 2.26.0-dev.7\r\nCurrent platform     : debian-openssl-1.1.x\r\nQuery Engine         : query-engine c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/query-engine-debian-openssl-1.1.x)\r\nMigration Engine     : migration-engine-cli c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/migration-engine-debian-openssl-1.1.x)\r\nIntrospection Engine : introspection-core c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/introspection-engine-debian-openssl-1.1.x)\r\nFormat Binary        : prisma-fmt c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/prisma-fmt-debian-openssl-1.1.x)\r\nDefault Engines Hash : c838e79f39885bc8e1611849b1eb28b5bb5bc922\r\nStudio               : 0.402.0\r\n--- ls node_modules/@prisma/engines/ ---\r\nls: cannot access 'node_modules/@prisma/engines/': No such file or directory\r\n```\r\n\r\nAs you can see `yarn prisma -v` tells us the engines comes from `node_modules/@prisma/engines`, but when you try to list that directory, it is actually not present.\r\n\r\nWhat is happening here is that `yarn prisma` is actually from a few folders _above_ our project. This is kinda visible when you look to not run `yarn -s` but just `yarn`:\r\n```\r\ncodespace ➜ /workspaces/e2e-tests/platforms-serverless/firebase-functions (janpio-patch-5 ✗) $ yarn prisma -v\r\nyarn run v1.22.10\r\nwarning package.json: No license field\r\n$ /workspaces/e2e-tests/node_modules/.bin/prisma -v\r\nprisma               : 2.25.0-dev.36\r\n@prisma/client       : 2.25.0-dev.36\r\n...\r\n```\r\n\r\n## Suggested solution\r\n\r\nOutput the directory of where the executed `prisma` is from, either similar to Yarn the absolute path to the binary in `node_modules`, or the folder where the `package.json` that is responsible for the installation of Prisma comes from.\r\n\r\n## Alternatives\r\n\r\nRely on `yarn` itself to give that information. Will not work with `npx` unfortunately for example.",
              "url": "https://github.com/prisma/prisma/issues/7771",
              "tech": [],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "PX4#21902",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "PX4",
              "id": "generated-PX4",
              "name": "PX4",
              "description": "",
              "members": [],
              "display_name": "PX4",
              "created_at": "2025-11-27T11:32:15.267Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/PX4?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "PX4",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:15.267Z",
            "created_at": "2025-11-27T11:32:15.267Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-PX4#21902",
              "status": "open",
              "type": "issue",
              "number": 21902,
              "title": "Support EKF2_GPS_POS_* for Multiple GPS",
              "source": {
                "data": {
                  "id": "source-PX4#21902",
                  "user": {
                    "login": "AlexKlimaj",
                    "id": 2019539,
                    "node_id": "MDQ6VXNlcjIwMTk1Mzk=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/2019539?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/AlexKlimaj",
                    "html_url": "https://github.com/AlexKlimaj",
                    "followers_url": "https://api.github.com/users/AlexKlimaj/followers",
                    "following_url": "https://api.github.com/users/AlexKlimaj/following{/other_user}",
                    "gists_url": "https://api.github.com/users/AlexKlimaj/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/AlexKlimaj/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/AlexKlimaj/subscriptions",
                    "organizations_url": "https://api.github.com/users/AlexKlimaj/orgs",
                    "repos_url": "https://api.github.com/users/AlexKlimaj/repos",
                    "events_url": "https://api.github.com/users/AlexKlimaj/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/AlexKlimaj/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Support EKF2_GPS_POS_* for Multiple GPS",
                  "body": "### Describe problem solved by the proposed feature\n\nCurrently the EKF2_GPS_POS_* params only apply to vehicle_gps when it gets used in the EKF.\n\n### Describe your preferred solution\n\nI propose we move these params to an offset in the GPS driver.\n\n### Describe possible alternatives\n\nDo we need these offsets at all?\n\n### Additional context\n\n_No response_",
                  "html_url": "https://github.com/PX4/PX4-Autopilot/issues/21902"
                },
                "type": "github"
              },
              "hash": "PX4/PX4-Autopilot#21902",
              "body": "### Describe problem solved by the proposed feature\n\nCurrently the EKF2_GPS_POS_* params only apply to vehicle_gps when it gets used in the EKF.\n\n### Describe your preferred solution\n\nI propose we move these params to an offset in the GPS driver.\n\n### Describe possible alternatives\n\nDo we need these offsets at all?\n\n### Additional context\n\n_No response_",
              "url": "https://github.com/PX4/PX4-Autopilot/issues/21902",
              "tech": [
                "go"
              ],
              "repo_name": "PX4-Autopilot",
              "repo_owner": "PX4",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "PX4#19970",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "PX4",
              "id": "generated-PX4",
              "name": "PX4",
              "description": "",
              "members": [],
              "display_name": "PX4",
              "created_at": "2025-11-27T11:32:15.351Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/PX4?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "PX4",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:15.351Z",
            "created_at": "2025-11-27T11:32:15.351Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-PX4#19970",
              "status": "open",
              "type": "issue",
              "number": 19970,
              "title": "[Project Tracker] Sensor configuration display UI",
              "source": {
                "data": {
                  "id": "source-PX4#19970",
                  "user": {
                    "login": "junwoo091400",
                    "id": 23277211,
                    "node_id": "MDQ6VXNlcjIzMjc3MjEx",
                    "avatar_url": "https://avatars.githubusercontent.com/u/23277211?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/junwoo091400",
                    "html_url": "https://github.com/junwoo091400",
                    "followers_url": "https://api.github.com/users/junwoo091400/followers",
                    "following_url": "https://api.github.com/users/junwoo091400/following{/other_user}",
                    "gists_url": "https://api.github.com/users/junwoo091400/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/junwoo091400/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/junwoo091400/subscriptions",
                    "organizations_url": "https://api.github.com/users/junwoo091400/orgs",
                    "repos_url": "https://api.github.com/users/junwoo091400/repos",
                    "events_url": "https://api.github.com/users/junwoo091400/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/junwoo091400/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Project Tracker] Sensor configuration display UI",
                  "body": "## Describe problem solved by the proposed feature\r\nCurrently it is hard to figure out which sensors are connected where, with which configuration and which priority (e.g. `CAL_MAG0_PRIO`) in a single view. For example during my [boat project](https://discuss.px4.io/t/rc-speed-boat-with-px4-episode-1-using-px4-to-control-the-boat/28429#things-that-are-still-ambiguous-to-me-22) build, I wasn't sure if I needed to set the priority of magnetometer manually or not.\r\n\r\nThis is also quite related to the calibration pain addressed in the issue #19459. What can we do to improve user experience for setting up the sensors? If so, which part should be addressed and how?\r\n\r\nWhat could be great (in my opinion) could be something like this in QGC (it won't be a literal text output like this, but just for giving some idea):\r\n\r\n```\r\n<mag-type> | <mag-orientation> | <mag-priority> | <mag-protocol?> # First mag sensor\r\n<mag-type> | <mag-orientation> | <mag-priority> | <mag-protocol?> # One for the second mag\r\n<baro-type> |              | <baro-priority> | <baro-protocol>\r\n<gyro-type> | <gyro-orientation> | <gyro-priority> | <gyro-protocol>\r\n```\r\n\r\nBut I am also not sure what others expectation / needs are, so any feedback would be appreciated!\r\n\r\n## Describe your preferred solution\r\n* @davids5 pointed out that transferring device tree information over to QGC could be a solution. Could you elaborate on that?\r\n* @dagar pointed out that having a unified view in general would be good. Could you let me know if a view I suggested above is similar to what you have imagined?\r\n",
                  "html_url": "https://github.com/PX4/PX4-Autopilot/issues/19970"
                },
                "type": "github"
              },
              "hash": "PX4/PX4-Autopilot#19970",
              "body": "## Describe problem solved by the proposed feature\r\nCurrently it is hard to figure out which sensors are connected where, with which configuration and which priority (e.g. `CAL_MAG0_PRIO`) in a single view. For example during my [boat project](https://discuss.px4.io/t/rc-speed-boat-with-px4-episode-1-using-px4-to-control-the-boat/28429#things-that-are-still-ambiguous-to-me-22) build, I wasn't sure if I needed to set the priority of magnetometer manually or not.\r\n\r\nThis is also quite related to the calibration pain addressed in the issue #19459. What can we do to improve user experience for setting up the sensors? If so, which part should be addressed and how?\r\n\r\nWhat could be great (in my opinion) could be something like this in QGC (it won't be a literal text output like this, but just for giving some idea):\r\n\r\n```\r\n<mag-type> | <mag-orientation> | <mag-priority> | <mag-protocol?> # First mag sensor\r\n<mag-type> | <mag-orientation> | <mag-priority> | <mag-protocol?> # One for the second mag\r\n<baro-type> |              | <baro-priority> | <baro-protocol>\r\n<gyro-type> | <gyro-orientation> | <gyro-priority> | <gyro-protocol>\r\n```\r\n\r\nBut I am also not sure what others expectation / needs are, so any feedback would be appreciated!\r\n\r\n## Describe your preferred solution\r\n* @davids5 pointed out that transferring device tree information over to QGC could be a solution. Could you elaborate on that?\r\n* @dagar pointed out that having a unified view in general would be good. Could you let me know if a view I suggested above is similar to what you have imagined?\r\n",
              "url": "https://github.com/PX4/PX4-Autopilot/issues/19970",
              "tech": [
                "go"
              ],
              "repo_name": "PX4-Autopilot",
              "repo_owner": "PX4",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#385",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-27T11:32:16.897Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:16.897Z",
            "created_at": "2025-11-27T11:32:16.897Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#385",
              "status": "open",
              "type": "issue",
              "number": 385,
              "title": "Create workflow: \"Add mediar app to bitdefender exceptions\"",
              "source": {
                "data": {
                  "id": "source-mediar-ai#385",
                  "user": {
                    "login": "m13v",
                    "id": 104702220,
                    "node_id": "U_kgDOBj2hDA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/104702220?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/m13v",
                    "html_url": "https://github.com/m13v",
                    "followers_url": "https://api.github.com/users/m13v/followers",
                    "following_url": "https://api.github.com/users/m13v/following{/other_user}",
                    "gists_url": "https://api.github.com/users/m13v/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/m13v/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/m13v/subscriptions",
                    "organizations_url": "https://api.github.com/users/m13v/orgs",
                    "repos_url": "https://api.github.com/users/m13v/repos",
                    "events_url": "https://api.github.com/users/m13v/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/m13v/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Create workflow: \"Add mediar app to bitdefender exceptions\"",
                  "body": "/bounty 100\n\n1. Download the app https://app.mediar.ai/\n2. Create 'New' workflow\n3. Record+Prompt AI in the chat to create it\n4. Adjust and correct the steps to make it work reliably\n\nWorkflow details:\n1. Some Mediar users use bitdefender, when they install Mediar, bitdefender flags it and deletes it, so we need to add the Mediar to exception before that happens\n2. To add Mediar app to exceptions you need to navigate in the bitdefender to some advanced settings, click on manual exceptions and add mediar program files folder and executables (terminator and mediar) to the exceptions\n\nRequirements:\n- Only apply if you have bitdefender installed\n- CHECK IF ANYONE ALREADY started working on the issue in the comments below\n- comment /attempt to start working on the issue\n- as part of submission you need to create a screen recording to show that the workflow works on your end, end-to-end\n- we'll need to test your workflow back and forth on a VM and other machines to make sure it works across devices",
                  "html_url": "https://github.com/mediar-ai/terminator/issues/385"
                },
                "type": "github"
              },
              "hash": "mediar-ai/terminator#385",
              "body": "/bounty 100\n\n1. Download the app https://app.mediar.ai/\n2. Create 'New' workflow\n3. Record+Prompt AI in the chat to create it\n4. Adjust and correct the steps to make it work reliably\n\nWorkflow details:\n1. Some Mediar users use bitdefender, when they install Mediar, bitdefender flags it and deletes it, so we need to add the Mediar to exception before that happens\n2. To add Mediar app to exceptions you need to navigate in the bitdefender to some advanced settings, click on manual exceptions and add mediar program files folder and executables (terminator and mediar) to the exceptions\n\nRequirements:\n- Only apply if you have bitdefender installed\n- CHECK IF ANYONE ALREADY started working on the issue in the comments below\n- comment /attempt to start working on the issue\n- as part of submission you need to create a screen recording to show that the workflow works on your end, end-to-end\n- we'll need to test your workflow back and forth on a VM and other machines to make sure it works across devices",
              "url": "https://github.com/mediar-ai/terminator/issues/385",
              "tech": [
                "go"
              ],
              "repo_name": "terminator",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#378",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-27T11:32:17.010Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:17.010Z",
            "created_at": "2025-11-27T11:32:17.010Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#378",
              "status": "open",
              "type": "issue",
              "number": 378,
              "title": "Create workflow: \"Supplier invoice reconciliation\"",
              "source": {
                "data": {
                  "id": "source-mediar-ai#378",
                  "user": {
                    "login": "m13v",
                    "id": 104702220,
                    "node_id": "U_kgDOBj2hDA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/104702220?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/m13v",
                    "html_url": "https://github.com/m13v",
                    "followers_url": "https://api.github.com/users/m13v/followers",
                    "following_url": "https://api.github.com/users/m13v/following{/other_user}",
                    "gists_url": "https://api.github.com/users/m13v/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/m13v/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/m13v/subscriptions",
                    "organizations_url": "https://api.github.com/users/m13v/orgs",
                    "repos_url": "https://api.github.com/users/m13v/repos",
                    "events_url": "https://api.github.com/users/m13v/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/m13v/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Create workflow: \"Supplier invoice reconciliation\"",
                  "body": "/bounty 100\n\n1. Download the app https://app.mediar.ai/\n2. Create 'New' workflow\n3. Prompt AI in the chat to create it\n4. Adjust and correct the steps to make it work reliably\n5. Deploy to the dashboard\n6. Ask me questions in the comments please\n\nRequirements:\n- CHECK IF ANYONE ALREADY started working on the issue in the comments below\n- comment /attempt to start working on the issue\n- as part of submission you need to create a screen recording to show that the workflow works on your end, end-to-end\n\nOutput table destination:\nhttps://docs.google.com/spreadsheets/d/1P7tioZ7sC3GdP5aOSrBhYKb_svkFjDbTransEqDMqvA/edit?gid=0#gid=0",
                  "html_url": "https://github.com/mediar-ai/terminator/issues/378"
                },
                "type": "github"
              },
              "hash": "mediar-ai/terminator#378",
              "body": "/bounty 100\n\n1. Download the app https://app.mediar.ai/\n2. Create 'New' workflow\n3. Prompt AI in the chat to create it\n4. Adjust and correct the steps to make it work reliably\n5. Deploy to the dashboard\n6. Ask me questions in the comments please\n\nRequirements:\n- CHECK IF ANYONE ALREADY started working on the issue in the comments below\n- comment /attempt to start working on the issue\n- as part of submission you need to create a screen recording to show that the workflow works on your end, end-to-end\n\nOutput table destination:\nhttps://docs.google.com/spreadsheets/d/1P7tioZ7sC3GdP5aOSrBhYKb_svkFjDbTransEqDMqvA/edit?gid=0#gid=0",
              "url": "https://github.com/mediar-ai/terminator/issues/378",
              "tech": [
                "go"
              ],
              "repo_name": "terminator",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#357",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-27T11:32:17.118Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:17.118Z",
            "created_at": "2025-11-27T11:32:17.118Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#357",
              "status": "open",
              "type": "issue",
              "number": 357,
              "title": "create a TS workflow that delete the oldest version of PyPI before publishing to PyPI",
              "source": {
                "data": {
                  "id": "source-mediar-ai#357",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "create a TS workflow that delete the oldest version of PyPI before publishing to PyPI",
                  "body": "\n/bounty 100 \n\n\nproblem:\n- cannot publish pypi bcs there is limit of versions \n- there is no api / cli to do that so we need to do this w UI \n\ndefinition of done:\n- before publishing to pypi the gh action runs a TS workflow that delete oldest pypi release \n- share video it works (use your own pypi account for the video idk)\n\n\n\n",
                  "html_url": "https://github.com/mediar-ai/terminator/issues/357"
                },
                "type": "github"
              },
              "hash": "mediar-ai/terminator#357",
              "body": "\n/bounty 100 \n\n\nproblem:\n- cannot publish pypi bcs there is limit of versions \n- there is no api / cli to do that so we need to do this w UI \n\ndefinition of done:\n- before publishing to pypi the gh action runs a TS workflow that delete oldest pypi release \n- share video it works (use your own pypi account for the video idk)\n\n\n\n",
              "url": "https://github.com/mediar-ai/terminator/issues/357",
              "tech": [],
              "repo_name": "terminator",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#353",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-27T11:32:17.257Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:17.257Z",
            "created_at": "2025-11-27T11:32:17.257Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#353",
              "status": "open",
              "type": "issue",
              "number": 353,
              "title": "create a typescript workflow that test the browser script bridge",
              "source": {
                "data": {
                  "id": "source-mediar-ai#353",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "create a typescript workflow that test the browser script bridge",
                  "body": "\n/bounty 100\n\nshould be able to reproduce this:\n\n```\nFailed to enable debugger domains: Debugger is not attached to the tab with id: 648628626.\n```\n\nexample ts workflow:\n\nhttps://github.com/mediar-ai/terminator/tree/main/examples/simple_notepad_workflow\n\n\ndefinition of done:\n- uses workflow sdk, terminator sdk, can be ran one liner using terminator cli \n- test different edge cases of the rust bridge using UI (executeBrowserScript function)\n- PR with video showing it runs \n- make it run in our github action \n\n\n\n\n\n\n\n",
                  "html_url": "https://github.com/mediar-ai/terminator/issues/353"
                },
                "type": "github"
              },
              "hash": "mediar-ai/terminator#353",
              "body": "\n/bounty 100\n\nshould be able to reproduce this:\n\n```\nFailed to enable debugger domains: Debugger is not attached to the tab with id: 648628626.\n```\n\nexample ts workflow:\n\nhttps://github.com/mediar-ai/terminator/tree/main/examples/simple_notepad_workflow\n\n\ndefinition of done:\n- uses workflow sdk, terminator sdk, can be ran one liner using terminator cli \n- test different edge cases of the rust bridge using UI (executeBrowserScript function)\n- PR with video showing it runs \n- make it run in our github action \n\n\n\n\n\n\n\n",
              "url": "https://github.com/mediar-ai/terminator/issues/353",
              "tech": [],
              "repo_name": "terminator",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#352",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-27T11:32:17.375Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:17.375Z",
            "created_at": "2025-11-27T11:32:17.375Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#352",
              "status": "open",
              "type": "issue",
              "number": 352,
              "title": "increase success rate of browser extension workflow",
              "source": {
                "data": {
                  "id": "source-mediar-ai#352",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "increase success rate of browser extension workflow",
                  "body": "/bounty 150\n\nproblem:\n\nbrowser extension workflow does not always work:\n- for example if user has multiple monitors or different environment\n- on slow machines workflow fails around step 2-5. probably has to do with hardcoded delays, machine doesn't react in time, can't validate typing input, etc\n- when chrome window opens up a user might have a profile selection window instead of a browser window which will prevent execution\n\ndefinition of done:\n- keep it a single yaml file (not typescript)\n- add more edge case in current implementation of the workflow, send a PR\n- provide a video showing it covers different environments like\n  - slow computer (like cheap VM)\n  - multiple monitors \n  - chrome profiles handling \n  - anything else useful to cover\n\n\n```yaml\n\n\nvariables:\n  extension_dir:\n    default: \"%TEMP%\\\\terminator-bridge\"\n    label: Folder to load (will be created by the download step)\n    type: string\n  release_url:\n    default: https://github.com/mediar-ai/terminator/releases/latest/download/terminator-browser-extension.zip\n    label: GitHub Release asset URL (zip)\n    type: string\n  zip_path:\n    default: \"%TEMP%\\\\terminator-browser-extension.zip\"\n    label: Path to downloaded zip\n    type: string\nselectors:\n  address_bar: role:Edit|name:Address and search bar\n  dev_mode_toggle: role:Button|name:Developer mode\n  extensions_doc: role:Document|name:Extensions\n  folder_field: \"role:Edit|name:Folder:\"\n  load_unpacked: role:Button|name:Load unpacked\n  reload_button: role:Button|name:Reload\n  select_folder_btn: role:Button|name:Select Folder\nsteps:\n  - arguments:\n      app_name: Chrome\n    name: Open Chrome\n    tool_name: open_application\n    id: open_chrome\n  - arguments:\n      engine: javascript\n      run: >\n        const fs = require('fs');\n\n        const path = require('path');\n\n        const os = require('os');\n\n        (async () => {\n          const url = \"${{release_url}}\";\n          if (!url || !url.trim()) throw new Error('release_url is empty');\n          const isWin = process.platform === 'win32';\n          const tmp = isWin ? (process.env.TEMP || os.tmpdir()) : os.tmpdir();\n          const zipPath = isWin ? path.join(tmp, 'terminator-browser-extension.zip') : path.join(tmp, 'terminator-browser-extension.zip');\n          const destDir = isWin ? path.join(tmp, 'terminator-bridge') : path.join(tmp, 'terminator-bridge');\n          const existedBefore = fs.existsSync(destDir);\n          try { fs.rmSync(destDir, { recursive: true, force: true }); } catch (_) {}\n          try { fs.mkdirSync(destDir, { recursive: true }); } catch (e) { throw new Error('Failed to create dest dir: ' + e.message); }\n\n          const res = await fetch(url);\n          if (!res.ok) throw new Error(`Download failed: ${res.status} ${res.statusText}`);\n          const arrayBuf = await res.arrayBuffer();\n          fs.writeFileSync(zipPath, Buffer.from(arrayBuf));\n\n          // Export values via ::set-env for the workflow engine AND return set_env for robust propagation\n          console.log(`::set-env name=zip_path::${zipPath}`);\n          console.log(`::set-env name=extension_dir::${destDir}`);\n          console.log(`::set-env name=is_update_mode::${existedBefore}`);\n          return { set_env: { zip_path: zipPath, extension_dir: destDir, is_update_mode: existedBefore } };\n        })();\n    delay_ms: 200\n    id: step_0\n    tool_name: run_command\n  - arguments:\n      run: |\n        $ErrorActionPreference = 'Stop'\n        # Avoid template substitution issues: compute paths directly\n        $zip = Join-Path $env:TEMP 'terminator-browser-extension.zip'\n        $dest = Join-Path $env:TEMP 'terminator-bridge'\n        if (Test-Path $dest) { Remove-Item -Recurse -Force $dest }\n        New-Item -ItemType Directory -Force -Path $dest | Out-Null\n        Expand-Archive -Path $zip -DestinationPath $dest -Force\n      shell: powershell\n    delay_ms: 400\n    id: step_1\n    tool_name: run_command\n  - arguments:\n      engine: javascript\n      run: >\n        const fs = require('fs');\n\n        const path = require('path');\n\n        const os = require('os');\n\n        (async () => {\n          const isWin = process.platform === 'win32';\n          const root = isWin ? path.join(process.env.TEMP || os.tmpdir(), 'terminator-bridge') : path.join(os.tmpdir(), 'terminator-bridge');\n          const stack = [root];\n          let picked = null;\n          while (stack.length) {\n            const dir = stack.pop();\n            let entries;\n            try { entries = fs.readdirSync(dir, { withFileTypes: true }); } catch (_) { continue; }\n            if (entries.some(e => e.isFile && e.name.toLowerCase() === 'manifest.json' || (!e.isFile && !e.isDirectory && e.name && e.name.toLowerCase() === 'manifest.json'))) {\n              picked = dir; break;\n            }\n            for (const e of entries) {\n              if ((e.isDirectory && e.isDirectory()) || (e.isDirectory === true)) {\n                stack.push(path.join(dir, e.name));\n              }\n            }\n          }\n          if (!picked) {\n            console.log(`::set-env name=extension_dir_text::${root}`);\n            return { set_env: { extension_dir_text: root } };\n          }\n          console.log(`::set-env name=extension_dir_text::${picked}`);\n          return { set_env: { extension_dir_text: picked } };\n        })();\n    continue_on_error: false\n    delay_ms: 100\n    id: step_2\n    tool_name: run_command\n  - arguments:\n      url: chrome://extensions\n    delay_ms: 1000\n    id: step_3\n    tool_name: navigate_browser\n  - arguments:\n      condition: visible\n      selector: ${{ selectors.address_bar }}\n      timeout_ms: 15000\n    continue_on_error: true\n    id: step_4\n    tool_name: wait_for_element\n  - arguments:\n      selector: ${{ selectors.address_bar }}\n    continue_on_error: true\n    id: step_5\n    tool_name: click_element\n  - arguments:\n      clear_before_typing: true\n      selector: ${{ selectors.address_bar }}\n      text_to_type: chrome://extensions\n    continue_on_error: true\n    id: step_6\n    tool_name: type_into_element\n  - arguments:\n      key: \"{Enter}\"\n    continue_on_error: true\n    delay_ms: 800\n    id: step_7\n    tool_name: press_key_global\n  - arguments:\n      engine: javascript\n      run: >\n        // Use terminator.js via global 'desktop'\n\n        const toggleSel = \"role:Button|name:Developer mode\";\n\n        const loadSel = \"role:Button|name:Load unpacked\";\n\n\n        // Wait for Developer mode toggle to appear\n\n        const devToggle = await desktop.locator(toggleSel).first(30000);\n\n        // Presence-based check: if Load unpacked is not visible yet, toggle Dev\n        Mode once\n\n        let loadVisible = false;\n\n        try { await desktop.locator(loadSel).first(1500); loadVisible = true; }\n        catch (_) {}\n\n        if (!loadVisible) {\n          await devToggle.click();\n          await sleep(300);\n        }\n\n        // No explicit click on Load unpacked here; later steps handle it\n    continue_on_error: true\n    delay_ms: 200\n    id: step_8\n    tool_name: run_command\n  - arguments:\n      engine: javascript\n      run: >\n        // Find and remove only Terminator Bridge extension\n\n        const extensionName = \"Terminator Bridge\";\n\n\n        try {\n          // Wait a bit for extensions page to load\n          await sleep(1000);\n\n          // Look for all extension cards on the page\n          const allElements = await desktop.locator(\"role:Group\").all();\n          log(`Found ${allElements.length} groups on extensions page`);\n\n          let terminatorFound = false;\n\n          // Search through elements to find Terminator Bridge\n          for (let element of allElements) {\n            try {\n              const name = await element.name();\n              const text = await element.value();\n\n              // Check if this element contains \"Terminator Bridge\" text\n              if ((name && name.includes(extensionName)) || (text && text.includes(extensionName))) {\n                log(`Found Terminator Bridge extension card`);\n                terminatorFound = true;\n\n                // Look for Remove button within this specific card\n                // Try to find the Remove button that's a child of this card\n                const removeButton = await element.locator(\"role:Button|name:Remove\").first();\n\n                if (removeButton) {\n                  log(`Found Remove button for Terminator Bridge, clicking it`);\n                  await removeButton.click();\n                  await sleep(500);\n\n                  // Confirm removal in the dialog\n                  await desktop.press_key(\"{Enter}\");\n                  log(`Confirmed removal of Terminator Bridge`);\n                  await sleep(1000);\n                  break;\n                } else {\n                  log(`Remove button not found in Terminator Bridge card`);\n                }\n              }\n            } catch (e) {\n              // Skip elements that can't be read\n              continue;\n            }\n          }\n\n          if (!terminatorFound) {\n            log(`Terminator Bridge extension not found - probably not installed`);\n          }\n\n        } catch (error) {\n          log(`Error while trying to remove old extension: ${error.message}`);\n          log(`Continuing with installation anyway...`);\n        }\n    continue_on_error: true\n    delay_ms: 500\n    id: step_9\n    tool_name: run_command\n  - arguments:\n      selector: ${{ selectors.load_unpacked }}\n    continue_on_error: false\n    delay_ms: 300\n    id: step_10\n    tool_name: click_element\n  - arguments:\n      condition: exists\n      selector: ${{ selectors.folder_field }}\n      timeout_ms: 3000\n    continue_on_error: true\n    id: step_11\n    tool_name: wait_for_element\n  - arguments:\n      clear_before_typing: true\n      selector: ${{ selectors.folder_field }}\n      text_to_type: ${{env.extension_dir_text}}\n    continue_on_error: true\n    id: step_12\n    tool_name: type_into_element\n  - arguments:\n      selector: ${{ selectors.select_folder_btn }}\n    continue_on_error: true\n    delay_ms: 1200\n    id: step_13\n    tool_name: click_element\n  - arguments:\n      condition: exists\n      selector: ${{ selectors.reload_button }}\n      timeout_ms: 15000\n    id: step_14\n    tool_name: wait_for_element\n  - arguments:\n      continue1_on_error: true\n      selector: role:Window|name:Google Chrome\n    name: Close Chrome\n    tool_name: close_element\n    id: close_chrome\nstop_on_error: true\n```\n\ni think this is roughly the same\n\nhttps://github.com/mediar-ai/terminator/blob/main/crates/terminator/browser-extension/install_chrome_extension_ui.yml\n",
                  "html_url": "https://github.com/mediar-ai/terminator/issues/352"
                },
                "type": "github"
              },
              "hash": "mediar-ai/terminator#352",
              "body": "/bounty 150\n\nproblem:\n\nbrowser extension workflow does not always work:\n- for example if user has multiple monitors or different environment\n- on slow machines workflow fails around step 2-5. probably has to do with hardcoded delays, machine doesn't react in time, can't validate typing input, etc\n- when chrome window opens up a user might have a profile selection window instead of a browser window which will prevent execution\n\ndefinition of done:\n- keep it a single yaml file (not typescript)\n- add more edge case in current implementation of the workflow, send a PR\n- provide a video showing it covers different environments like\n  - slow computer (like cheap VM)\n  - multiple monitors \n  - chrome profiles handling \n  - anything else useful to cover\n\n\n```yaml\n\n\nvariables:\n  extension_dir:\n    default: \"%TEMP%\\\\terminator-bridge\"\n    label: Folder to load (will be created by the download step)\n    type: string\n  release_url:\n    default: https://github.com/mediar-ai/terminator/releases/latest/download/terminator-browser-extension.zip\n    label: GitHub Release asset URL (zip)\n    type: string\n  zip_path:\n    default: \"%TEMP%\\\\terminator-browser-extension.zip\"\n    label: Path to downloaded zip\n    type: string\nselectors:\n  address_bar: role:Edit|name:Address and search bar\n  dev_mode_toggle: role:Button|name:Developer mode\n  extensions_doc: role:Document|name:Extensions\n  folder_field: \"role:Edit|name:Folder:\"\n  load_unpacked: role:Button|name:Load unpacked\n  reload_button: role:Button|name:Reload\n  select_folder_btn: role:Button|name:Select Folder\nsteps:\n  - arguments:\n      app_name: Chrome\n    name: Open Chrome\n    tool_name: open_application\n    id: open_chrome\n  - arguments:\n      engine: javascript\n      run: >\n        const fs = require('fs');\n\n        const path = require('path');\n\n        const os = require('os');\n\n        (async () => {\n          const url = \"${{release_url}}\";\n          if (!url || !url.trim()) throw new Error('release_url is empty');\n          const isWin = process.platform === 'win32';\n          const tmp = isWin ? (process.env.TEMP || os.tmpdir()) : os.tmpdir();\n          const zipPath = isWin ? path.join(tmp, 'terminator-browser-extension.zip') : path.join(tmp, 'terminator-browser-extension.zip');\n          const destDir = isWin ? path.join(tmp, 'terminator-bridge') : path.join(tmp, 'terminator-bridge');\n          const existedBefore = fs.existsSync(destDir);\n          try { fs.rmSync(destDir, { recursive: true, force: true }); } catch (_) {}\n          try { fs.mkdirSync(destDir, { recursive: true }); } catch (e) { throw new Error('Failed to create dest dir: ' + e.message); }\n\n          const res = await fetch(url);\n          if (!res.ok) throw new Error(`Download failed: ${res.status} ${res.statusText}`);\n          const arrayBuf = await res.arrayBuffer();\n          fs.writeFileSync(zipPath, Buffer.from(arrayBuf));\n\n          // Export values via ::set-env for the workflow engine AND return set_env for robust propagation\n          console.log(`::set-env name=zip_path::${zipPath}`);\n          console.log(`::set-env name=extension_dir::${destDir}`);\n          console.log(`::set-env name=is_update_mode::${existedBefore}`);\n          return { set_env: { zip_path: zipPath, extension_dir: destDir, is_update_mode: existedBefore } };\n        })();\n    delay_ms: 200\n    id: step_0\n    tool_name: run_command\n  - arguments:\n      run: |\n        $ErrorActionPreference = 'Stop'\n        # Avoid template substitution issues: compute paths directly\n        $zip = Join-Path $env:TEMP 'terminator-browser-extension.zip'\n        $dest = Join-Path $env:TEMP 'terminator-bridge'\n        if (Test-Path $dest) { Remove-Item -Recurse -Force $dest }\n        New-Item -ItemType Directory -Force -Path $dest | Out-Null\n        Expand-Archive -Path $zip -DestinationPath $dest -Force\n      shell: powershell\n    delay_ms: 400\n    id: step_1\n    tool_name: run_command\n  - arguments:\n      engine: javascript\n      run: >\n        const fs = require('fs');\n\n        const path = require('path');\n\n        const os = require('os');\n\n        (async () => {\n          const isWin = process.platform === 'win32';\n          const root = isWin ? path.join(process.env.TEMP || os.tmpdir(), 'terminator-bridge') : path.join(os.tmpdir(), 'terminator-bridge');\n          const stack = [root];\n          let picked = null;\n          while (stack.length) {\n            const dir = stack.pop();\n            let entries;\n            try { entries = fs.readdirSync(dir, { withFileTypes: true }); } catch (_) { continue; }\n            if (entries.some(e => e.isFile && e.name.toLowerCase() === 'manifest.json' || (!e.isFile && !e.isDirectory && e.name && e.name.toLowerCase() === 'manifest.json'))) {\n              picked = dir; break;\n            }\n            for (const e of entries) {\n              if ((e.isDirectory && e.isDirectory()) || (e.isDirectory === true)) {\n                stack.push(path.join(dir, e.name));\n              }\n            }\n          }\n          if (!picked) {\n            console.log(`::set-env name=extension_dir_text::${root}`);\n            return { set_env: { extension_dir_text: root } };\n          }\n          console.log(`::set-env name=extension_dir_text::${picked}`);\n          return { set_env: { extension_dir_text: picked } };\n        })();\n    continue_on_error: false\n    delay_ms: 100\n    id: step_2\n    tool_name: run_command\n  - arguments:\n      url: chrome://extensions\n    delay_ms: 1000\n    id: step_3\n    tool_name: navigate_browser\n  - arguments:\n      condition: visible\n      selector: ${{ selectors.address_bar }}\n      timeout_ms: 15000\n    continue_on_error: true\n    id: step_4\n    tool_name: wait_for_element\n  - arguments:\n      selector: ${{ selectors.address_bar }}\n    continue_on_error: true\n    id: step_5\n    tool_name: click_element\n  - arguments:\n      clear_before_typing: true\n      selector: ${{ selectors.address_bar }}\n      text_to_type: chrome://extensions\n    continue_on_error: true\n    id: step_6\n    tool_name: type_into_element\n  - arguments:\n      key: \"{Enter}\"\n    continue_on_error: true\n    delay_ms: 800\n    id: step_7\n    tool_name: press_key_global\n  - arguments:\n      engine: javascript\n      run: >\n        // Use terminator.js via global 'desktop'\n\n        const toggleSel = \"role:Button|name:Developer mode\";\n\n        const loadSel = \"role:Button|name:Load unpacked\";\n\n\n        // Wait for Developer mode toggle to appear\n\n        const devToggle = await desktop.locator(toggleSel).first(30000);\n\n        // Presence-based check: if Load unpacked is not visible yet, toggle Dev\n        Mode once\n\n        let loadVisible = false;\n\n        try { await desktop.locator(loadSel).first(1500); loadVisible = true; }\n        catch (_) {}\n\n        if (!loadVisible) {\n          await devToggle.click();\n          await sleep(300);\n        }\n\n        // No explicit click on Load unpacked here; later steps handle it\n    continue_on_error: true\n    delay_ms: 200\n    id: step_8\n    tool_name: run_command\n  - arguments:\n      engine: javascript\n      run: >\n        // Find and remove only Terminator Bridge extension\n\n        const extensionName = \"Terminator Bridge\";\n\n\n        try {\n          // Wait a bit for extensions page to load\n          await sleep(1000);\n\n          // Look for all extension cards on the page\n          const allElements = await desktop.locator(\"role:Group\").all();\n          log(`Found ${allElements.length} groups on extensions page`);\n\n          let terminatorFound = false;\n\n          // Search through elements to find Terminator Bridge\n          for (let element of allElements) {\n            try {\n              const name = await element.name();\n              const text = await element.value();\n\n              // Check if this element contains \"Terminator Bridge\" text\n              if ((name && name.includes(extensionName)) || (text && text.includes(extensionName))) {\n                log(`Found Terminator Bridge extension card`);\n                terminatorFound = true;\n\n                // Look for Remove button within this specific card\n                // Try to find the Remove button that's a child of this card\n                const removeButton = await element.locator(\"role:Button|name:Remove\").first();\n\n                if (removeButton) {\n                  log(`Found Remove button for Terminator Bridge, clicking it`);\n                  await removeButton.click();\n                  await sleep(500);\n\n                  // Confirm removal in the dialog\n                  await desktop.press_key(\"{Enter}\");\n                  log(`Confirmed removal of Terminator Bridge`);\n                  await sleep(1000);\n                  break;\n                } else {\n                  log(`Remove button not found in Terminator Bridge card`);\n                }\n              }\n            } catch (e) {\n              // Skip elements that can't be read\n              continue;\n            }\n          }\n\n          if (!terminatorFound) {\n            log(`Terminator Bridge extension not found - probably not installed`);\n          }\n\n        } catch (error) {\n          log(`Error while trying to remove old extension: ${error.message}`);\n          log(`Continuing with installation anyway...`);\n        }\n    continue_on_error: true\n    delay_ms: 500\n    id: step_9\n    tool_name: run_command\n  - arguments:\n      selector: ${{ selectors.load_unpacked }}\n    continue_on_error: false\n    delay_ms: 300\n    id: step_10\n    tool_name: click_element\n  - arguments:\n      condition: exists\n      selector: ${{ selectors.folder_field }}\n      timeout_ms: 3000\n    continue_on_error: true\n    id: step_11\n    tool_name: wait_for_element\n  - arguments:\n      clear_before_typing: true\n      selector: ${{ selectors.folder_field }}\n      text_to_type: ${{env.extension_dir_text}}\n    continue_on_error: true\n    id: step_12\n    tool_name: type_into_element\n  - arguments:\n      selector: ${{ selectors.select_folder_btn }}\n    continue_on_error: true\n    delay_ms: 1200\n    id: step_13\n    tool_name: click_element\n  - arguments:\n      condition: exists\n      selector: ${{ selectors.reload_button }}\n      timeout_ms: 15000\n    id: step_14\n    tool_name: wait_for_element\n  - arguments:\n      continue1_on_error: true\n      selector: role:Window|name:Google Chrome\n    name: Close Chrome\n    tool_name: close_element\n    id: close_chrome\nstop_on_error: true\n```\n\ni think this is roughly the same\n\nhttps://github.com/mediar-ai/terminator/blob/main/crates/terminator/browser-extension/install_chrome_extension_ui.yml\n",
              "url": "https://github.com/mediar-ai/terminator/issues/352",
              "tech": [],
              "repo_name": "terminator",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#315",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-27T11:32:17.483Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:17.483Z",
            "created_at": "2025-11-27T11:32:17.483Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#315",
              "status": "open",
              "type": "issue",
              "number": 315,
              "title": "[bounty] test and showcase the new gemini computer use model with terminator MCP",
              "source": {
                "data": {
                  "id": "source-mediar-ai#315",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] test and showcase the new gemini computer use model with terminator MCP",
                  "body": "basic idea: try the new gemini CU model:\n\nhttps://cloud.google.com/vertex-ai/generative-ai/docs/computer-use\n\nand try to build some workflows like reading PDFs or spreadsheets on file system and doing data entry in another software \n\n\ngoal: evaluate if their model adds worthwhile performance gain by using both vision and accessibility to build workflow compared to claude etc\n\n\nrequirements:\n- record yourself building the workflow \n- use the new model somehow (gemini CLI + terminator MCP + gemini model configured for example, or build a custom MCP client in python/js, high preference for JS)\n- use terminator MCP server\n\n\nbonus:\n- professional video level that can be published on social\n\n\nplease share your plan before building things, one-prompt PRs will be banned \n\n/bounty 200\n",
                  "html_url": "https://github.com/mediar-ai/terminator/issues/315"
                },
                "type": "github"
              },
              "hash": "mediar-ai/terminator#315",
              "body": "basic idea: try the new gemini CU model:\n\nhttps://cloud.google.com/vertex-ai/generative-ai/docs/computer-use\n\nand try to build some workflows like reading PDFs or spreadsheets on file system and doing data entry in another software \n\n\ngoal: evaluate if their model adds worthwhile performance gain by using both vision and accessibility to build workflow compared to claude etc\n\n\nrequirements:\n- record yourself building the workflow \n- use the new model somehow (gemini CLI + terminator MCP + gemini model configured for example, or build a custom MCP client in python/js, high preference for JS)\n- use terminator MCP server\n\n\nbonus:\n- professional video level that can be published on social\n\n\nplease share your plan before building things, one-prompt PRs will be banned \n\n/bounty 200\n",
              "url": "https://github.com/mediar-ai/terminator/issues/315",
              "tech": [],
              "repo_name": "terminator",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1626",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-27T11:32:17.577Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:17.577Z",
            "created_at": "2025-11-27T11:32:17.577Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1626",
              "status": "open",
              "type": "issue",
              "number": 1626,
              "title": "[bounty] $400 fix audio device randomly stopping sometimes",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1626",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] $400 fix audio device randomly stopping sometimes",
                  "body": "\ndisplay audio / microphone randomly stops on mac sometimes \n\nhad it running for 48h now and display audio somehow stopped a bit later after 50h\n\n/bounty 400 \n\n@EzraEllette any idea?\n\n\ni suggest finding way to reproduce and then some automated test and a fix ",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1626"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1626",
              "body": "\ndisplay audio / microphone randomly stops on mac sometimes \n\nhad it running for 48h now and display audio somehow stopped a bit later after 50h\n\n/bounty 400 \n\n@EzraEllette any idea?\n\n\ni suggest finding way to reproduce and then some automated test and a fix ",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1626",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1560",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-27T11:32:17.692Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:17.692Z",
            "created_at": "2025-11-27T11:32:17.692Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1560",
              "status": "open",
              "type": "issue",
              "number": 1560,
              "title": "[feature]  Implement Session Tracking for Application and Window Usage",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1560",
                  "user": {
                    "login": "rodgomesc",
                    "id": 4893591,
                    "node_id": "MDQ6VXNlcjQ4OTM1OTE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/4893591?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/rodgomesc",
                    "html_url": "https://github.com/rodgomesc",
                    "followers_url": "https://api.github.com/users/rodgomesc/followers",
                    "following_url": "https://api.github.com/users/rodgomesc/following{/other_user}",
                    "gists_url": "https://api.github.com/users/rodgomesc/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/rodgomesc/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/rodgomesc/subscriptions",
                    "organizations_url": "https://api.github.com/users/rodgomesc/orgs",
                    "repos_url": "https://api.github.com/users/rodgomesc/repos",
                    "events_url": "https://api.github.com/users/rodgomesc/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/rodgomesc/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[feature]  Implement Session Tracking for Application and Window Usage",
                  "body": "\n## Challenge\n\nI'm working on an application that requires accurate session tracking to analyze user behavior patterns,  and provide meaningful insights across different applications and windows. \n\nIn the existing Screenpipe architecture, OCR data is stored with only timestamp information, lacking precise session boundaries (start/end times) for application usage tracking. This limitation prevents us from properly segmenting user activity into coherent sessions.\n\n## 1. Current Workaround\ninternally I implementing a suboptimal solution that:\n1. Queries all OCR database entries chronologically\n2. Manually identifies session boundaries by analyzing timestamp sequences for each application\n3. Determines session end when detecting a different application in subsequent timestamps\n4. Assumes a session is ongoing if no clear delimiter exists in future timestamps\n\nWith that said I would love to hear any feedbacks that could help solve this problem with a minimal overhead on code changes, and make sure I'm not overthinking the solution: cc @louis030195 , i'm planning to start playing with some day next week\n\n## 2. Requirements\n\n1.  **Session Definition:** A \"session\" should be defined as a continuous period of user interaction with a specific application and window.  A break in activity (e.g., switching to a different application or window) should end the current session and potentially start a new one.  A configurable inactivity timeout (e.g., 5 minutes) should also end a session.\n\n2.  **Data Storage:** The database schema must be modified to store session start and end times, associated with specific applications and windows.  It must maintain links to the relevant OCR and audio data chunks.\n\n3.  **API Endpoint:**  A new or modified API endpoint (e.g., `/sessions`) is needed to query for session data.  This endpoint should support filtering by:\n    *   Date range (start and end timestamps).\n    *   Application name.\n    *   Window name.\n    *   Minimum and maximum session duration.\n    *   Associated tags.\n    *   Pagination (limit and offset).\n\n4.  **Real-time Capability:** The system should be able to detect session boundaries in near real-time as data is being ingested. This implies integration with the existing data capture and processing pipeline.\n\n5. **Configurability:** The inactivity timeout for ending a session should be configurable.\n\n## 3. Proposed Solution\n\n### 3.1. Database Schema Changes\n\nWe'll introduce a new table `sessions` and modify the existing tables.\n\n**New Table: `sessions`**\n\n| Column Name      | Data Type  | Constraints                                  | Description                                                                  |\n| :--------------- | :--------- | :------------------------------------------- | :--------------------------------------------------------------------------- |\n| `id`             | INTEGER    | PRIMARY KEY AUTOINCREMENT                    | Unique identifier for the session.                                       |\n| `app_name`       | TEXT       | NOT NULL                                     | Name of the application.                                                 |\n| `window_name`    | TEXT       |                                               | Title of the window.                                                     |\n| `start_time`     | DATETIME   | NOT NULL                                     | Timestamp of the session start.                                            |\n| `end_time`       | DATETIME   | NOT NULL                                     | Timestamp of the session end.                                              |\n| `duration_secs`  | REAL       | NOT NULL                                     | Duration of the session in seconds.                                        |\n\n**Modified Tables:**\n\n*   **`ocr_text`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`audio_transcriptions`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`ui_monitoring`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n\n**Indexes:**\n\n*   Create indexes on `sessions` table columns (`app_name`, `window_name`, `start_time`, `end_time`) for efficient querying.\n*   Create indexes on the `session_id` columns in `ocr_text`, `audio_transcriptions`, and `ui_monitoring`.\n\n### 3.2. API Enhancements\n\nWe'll modify the existing `/search` endpoint to also support session queries.\n\n**Request:**\n\n```\nGET /search?content_type=session&app_name=Cursor&start_time=2024-11-27T00:00:00Z&end_time=2024-11-28T00:00:00Z&min_duration=60&limit=10&offset=0\n```\n\n*   `content_type=session`: Indicates a session-based search.\n*   `app_name`, `window_name`: Filter by application and window (optional).\n*   `start_time`, `end_time`: Date range for the session (optional, defaults to last 24 hours).\n*   `min_duration`, `max_duration`: Filter by session duration in seconds (optional).\n*   `limit`, `offset`: Pagination parameters.\n\n\nafter discussing with @louis030195 on discord he proposed something like this as the output\n\n**Response:**\n\n```json\n{\n  \"data\": [\n    {\n      \"app_name\": \"Cursor\",\n      \"total_usage_time\": 3600,\n      \"windows\": [\n        {\n          \"window_name\": \"page.tsx\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T12:00:00Z\",\n              \"end_time\": \"2024-07-16T12:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [123, 124, 125],\n              \"tags\": [\"coding\", \"frontend\"]\n            },\n            {\n              \"start_time\": \"2024-07-16T14:00:00Z\",\n              \"end_time\": \"2024-07-16T14:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [223, 224, 225],\n              \"tags\": [\"coding\", \"frontend\"]\n            }\n          ],\n          \"total_usage_time\": 3600\n        }\n      ]\n    },\n    {\n      \"app_name\": \"Arc\",\n      \"total_usage_time\": 1200,\n      \"windows\": [\n        {\n          \"window_name\": \"x.com\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T10:30:00Z\",\n              \"end_time\": \"2024-07-16T10:50:00Z\",\n              \"duration\": 1200,\n              \"content_ids\": [126, 127, 128],\n              \"tags\": [\"browsing\", \"social-media\"]\n            }\n          ],\n          \"total_usage_time\": 1200\n        }\n      ]\n    }\n  ],\n  \"pagination\": {\n    \"limit\": 50,\n    \"offset\": 0,\n    \"total\": 2\n  }\n}\n```\n\n### 3.3. Session Boundary Detection Logic\n\n1.  **Real-time Monitoring:**  The existing event listeners for OCR, audio, and UI events will be leveraged.\n\n2.  **Session Tracking:**  Maintain a data structure (likely in memory, possibly augmented with periodic database writes for persistence) to track active sessions.  This structure should map:\n    *   `(app_name, window_name)` -> `(session_id, last_activity_timestamp)`\n\n3.  **New Event Handling:**\n    *   When a new event (OCR, audio, UI) arrives:\n        *   Extract `app_name` and `window_name`.\n        *   Check if an active session exists for this (app, window) combination.\n        *   If a session exists:\n            *   Check if `now() - last_activity_timestamp` exceeds the inactivity timeout.\n            *   If timeout exceeded, end the existing session and create a new one.\n            *   If not timed out, update `last_activity_timestamp` to the event's timestamp.\n        *   If no session exists:\n            *   Create a new session with `start_time` and `end_time` set to the event's timestamp.\n            *   Generate a new `session_id`.\n            *   Insert a new row into the `sessions` table.\n        *   Insert the new data (OCR, audio, UI) into the relevant table, linking it to the active `session_id`.\n\n4.  **Inactivity Timeout:** A configurable timeout (e.g., 5 minutes) will be used to determine session end due to inactivity.\n\n5.  **Periodic Flushing:** To avoid excessive in-memory state, periodically flush closed sessions (those that have exceeded the inactivity timeout) to the database.\n\n6. **Data Migration:** A migration script will be needed to analyze existing data and create initial session records based on timestamp proximity and app/window changes.\n\n### 3.4. Implementation Details\n\n*   **Language/Framework:** Continue using Rust for core logic and database interaction.\n*   **Database:** Continue using SQLite.\n*   **Concurrency:** Use asynchronous operations with `tokio` for handling concurrent events and database interactions.  Leverage `Arc` and `Mutex` for shared state, and channels for communication between tasks.\n*   **Configuration:** Add a new setting for the inactivity timeout.\n*   **Error Handling:** Implement robust error handling with `anyhow` and propagate errors appropriately. Log errors using `tracing`.\n* **Testing:** Thoroughly test session boundary detection with various scenarios, including rapid switching, long inactivity periods, and concurrent events.\n\n## 4. Diagrams\n\n### 4.1. Current Data Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Database\n    User->>Screen: Interacts with screen\n    Screen->>Screenpipe: Captures screen content (OCR)\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Database: Stores OCR data with timestamps\n    Screenpipe->>Database: Stores audio transcriptions with timestamps\n    User->>Screenpipe: Requests data\n    Screenpipe->>Database: Queries data by time range\n    Database->>Screenpipe: Returns data\n    Screenpipe->>User: Returns data\n```\n\n### 4.2. Proposed Database Schema Changes\n\n```mermaid\nclassDiagram\n    class frames {\n        +id : INTEGER [PK]\n        +video_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +name : TEXT\n    }\n    class video_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +device_name : TEXT\n    }\n    class ocr_text {\n        +frame_id : INTEGER [FK]\n        +text : TEXT\n        +text_json : TEXT\n        +app_name : TEXT\n        +window_name : TEXT\n        +ocr_engine : TEXT\n        +focused : BOOLEAN\n        +session_id : INTEGER [FK]\n    }\n    class audio_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +timestamp : TIMESTAMP\n    }\n    class audio_transcriptions {\n        +id : INTEGER [PK]\n        +audio_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +transcription : TEXT\n        +device : TEXT\n        +is_input_device : BOOLEAN\n        +speaker_id : INTEGER\n        +transcription_engine : TEXT\n        +start_time : REAL\n        +end_time : REAL\n        +text_length : INTEGER\n        +session_id : INTEGER [FK]\n    }\n    class ui_monitoring {\n      +id : INTEGER [PK]\n      +text_output : TEXT\n      +timestamp : DATETIME\n      +app : TEXT\n      +window : TEXT\n      +initial_traversal_at : DATETIME\n      +session_id : INTEGER [FK]\n    }\n  class sessions {\n    +id : INTEGER [PK]\n    +app_name : TEXT\n    +window_name : TEXT\n    +start_time : DATETIME\n    +end_time : DATETIME\n    +duration_secs : REAL\n  }\n  frames --|> video_chunks : video_chunk_id\n  ocr_text --|> frames : frame_id\n  audio_transcriptions --|> audio_chunks : audio_chunk_id\n  ocr_text --|> sessions : session_id\n  audio_transcriptions --|> sessions : session_id\n  ui_monitoring --|> sessions : session_id\n```\n\n### 4.3. Modified Data Flow with Session Tracking\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Session Manager\n    participant Database\n\n    User->>Screen: Interacts with App A, Window 1\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to session_id\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: Active session found (session_id)\n    Screenpipe->>Database: Store audio data, link to session_id\n\n    Note over User,Screenpipe: User switches to App B, Window 2\n    User->>Screen: Interacts with App B, Window 2\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App B, Window 2)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: End previous session (App A, Window 1)\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to new session_id\n\n    Note over User,Screenpipe: Inactivity Timeout\n    Screenpipe->>Session Manager: Check for activity\n    Session Manager->>Database: End current session (App B, Window 2)\n```\n\n### 4.4. New API Endpoint (Modified /search)\n\nThe existing `/search` endpoint will be extended to support session-based queries.  No new endpoint is needed.\n\n## 5. Performance Implications\n\n*   **Database:**  The addition of the `sessions` table and foreign keys will add some overhead to write operations.  Proper indexing is crucial to mitigate this.  Read performance for session-based queries should be good with appropriate indexes.\n*   **Memory:**  The in-memory session tracking will require additional memory.  The size of this will depend on the number of concurrent users and the configured timeout.  This should be monitored and potentially optimized (e.g., using a more efficient data structure than a simple `HashMap`).\n*   **CPU:**  The session boundary detection logic will add some CPU overhead.  This should be minimized by efficient checks and the use of asynchronous operations.\n\n## 6. Migration Path\n\n1.  **Add new `sessions` table.**\n2.  **Add `session_id` columns** to `ocr_text`, `audio_transcriptions`, and `ui_monitoring` tables.\n3.  **Backfill `session_id`:**  A migration script will be needed to analyze existing data and create initial session records.  This script will need to:\n    *   Iterate through existing OCR, audio, and UI data in chronological order.\n    *   Apply the session boundary detection logic (described above) to group data into sessions.\n    *   Insert corresponding rows into the `sessions` table.\n    *   Update the `session_id` foreign key in the existing tables.\n\n\n## 7. Alternative Approaches\n\n1.  **Session Table per Content Type:** Instead of a single `sessions` table, we could have separate session tables for each content type (e.g., `ocr_sessions`, `audio_sessions`, `ui_sessions`).  This might simplify queries for a specific content type but could make cross-content type analysis more complex.\n2.  **No Session Table (Denormalized):** We could add `start_time` and `end_time` directly to the existing tables (`ocr_text`, `audio_transcriptions`, `ui_monitoring`). This would avoid the need for joins when querying for sessions, but could lead to data redundancy and potential inconsistencies.\n3.  any other suggestions ????\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1560"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1560",
              "body": "\n## Challenge\n\nI'm working on an application that requires accurate session tracking to analyze user behavior patterns,  and provide meaningful insights across different applications and windows. \n\nIn the existing Screenpipe architecture, OCR data is stored with only timestamp information, lacking precise session boundaries (start/end times) for application usage tracking. This limitation prevents us from properly segmenting user activity into coherent sessions.\n\n## 1. Current Workaround\ninternally I implementing a suboptimal solution that:\n1. Queries all OCR database entries chronologically\n2. Manually identifies session boundaries by analyzing timestamp sequences for each application\n3. Determines session end when detecting a different application in subsequent timestamps\n4. Assumes a session is ongoing if no clear delimiter exists in future timestamps\n\nWith that said I would love to hear any feedbacks that could help solve this problem with a minimal overhead on code changes, and make sure I'm not overthinking the solution: cc @louis030195 , i'm planning to start playing with some day next week\n\n## 2. Requirements\n\n1.  **Session Definition:** A \"session\" should be defined as a continuous period of user interaction with a specific application and window.  A break in activity (e.g., switching to a different application or window) should end the current session and potentially start a new one.  A configurable inactivity timeout (e.g., 5 minutes) should also end a session.\n\n2.  **Data Storage:** The database schema must be modified to store session start and end times, associated with specific applications and windows.  It must maintain links to the relevant OCR and audio data chunks.\n\n3.  **API Endpoint:**  A new or modified API endpoint (e.g., `/sessions`) is needed to query for session data.  This endpoint should support filtering by:\n    *   Date range (start and end timestamps).\n    *   Application name.\n    *   Window name.\n    *   Minimum and maximum session duration.\n    *   Associated tags.\n    *   Pagination (limit and offset).\n\n4.  **Real-time Capability:** The system should be able to detect session boundaries in near real-time as data is being ingested. This implies integration with the existing data capture and processing pipeline.\n\n5. **Configurability:** The inactivity timeout for ending a session should be configurable.\n\n## 3. Proposed Solution\n\n### 3.1. Database Schema Changes\n\nWe'll introduce a new table `sessions` and modify the existing tables.\n\n**New Table: `sessions`**\n\n| Column Name      | Data Type  | Constraints                                  | Description                                                                  |\n| :--------------- | :--------- | :------------------------------------------- | :--------------------------------------------------------------------------- |\n| `id`             | INTEGER    | PRIMARY KEY AUTOINCREMENT                    | Unique identifier for the session.                                       |\n| `app_name`       | TEXT       | NOT NULL                                     | Name of the application.                                                 |\n| `window_name`    | TEXT       |                                               | Title of the window.                                                     |\n| `start_time`     | DATETIME   | NOT NULL                                     | Timestamp of the session start.                                            |\n| `end_time`       | DATETIME   | NOT NULL                                     | Timestamp of the session end.                                              |\n| `duration_secs`  | REAL       | NOT NULL                                     | Duration of the session in seconds.                                        |\n\n**Modified Tables:**\n\n*   **`ocr_text`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`audio_transcriptions`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`ui_monitoring`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n\n**Indexes:**\n\n*   Create indexes on `sessions` table columns (`app_name`, `window_name`, `start_time`, `end_time`) for efficient querying.\n*   Create indexes on the `session_id` columns in `ocr_text`, `audio_transcriptions`, and `ui_monitoring`.\n\n### 3.2. API Enhancements\n\nWe'll modify the existing `/search` endpoint to also support session queries.\n\n**Request:**\n\n```\nGET /search?content_type=session&app_name=Cursor&start_time=2024-11-27T00:00:00Z&end_time=2024-11-28T00:00:00Z&min_duration=60&limit=10&offset=0\n```\n\n*   `content_type=session`: Indicates a session-based search.\n*   `app_name`, `window_name`: Filter by application and window (optional).\n*   `start_time`, `end_time`: Date range for the session (optional, defaults to last 24 hours).\n*   `min_duration`, `max_duration`: Filter by session duration in seconds (optional).\n*   `limit`, `offset`: Pagination parameters.\n\n\nafter discussing with @louis030195 on discord he proposed something like this as the output\n\n**Response:**\n\n```json\n{\n  \"data\": [\n    {\n      \"app_name\": \"Cursor\",\n      \"total_usage_time\": 3600,\n      \"windows\": [\n        {\n          \"window_name\": \"page.tsx\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T12:00:00Z\",\n              \"end_time\": \"2024-07-16T12:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [123, 124, 125],\n              \"tags\": [\"coding\", \"frontend\"]\n            },\n            {\n              \"start_time\": \"2024-07-16T14:00:00Z\",\n              \"end_time\": \"2024-07-16T14:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [223, 224, 225],\n              \"tags\": [\"coding\", \"frontend\"]\n            }\n          ],\n          \"total_usage_time\": 3600\n        }\n      ]\n    },\n    {\n      \"app_name\": \"Arc\",\n      \"total_usage_time\": 1200,\n      \"windows\": [\n        {\n          \"window_name\": \"x.com\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T10:30:00Z\",\n              \"end_time\": \"2024-07-16T10:50:00Z\",\n              \"duration\": 1200,\n              \"content_ids\": [126, 127, 128],\n              \"tags\": [\"browsing\", \"social-media\"]\n            }\n          ],\n          \"total_usage_time\": 1200\n        }\n      ]\n    }\n  ],\n  \"pagination\": {\n    \"limit\": 50,\n    \"offset\": 0,\n    \"total\": 2\n  }\n}\n```\n\n### 3.3. Session Boundary Detection Logic\n\n1.  **Real-time Monitoring:**  The existing event listeners for OCR, audio, and UI events will be leveraged.\n\n2.  **Session Tracking:**  Maintain a data structure (likely in memory, possibly augmented with periodic database writes for persistence) to track active sessions.  This structure should map:\n    *   `(app_name, window_name)` -> `(session_id, last_activity_timestamp)`\n\n3.  **New Event Handling:**\n    *   When a new event (OCR, audio, UI) arrives:\n        *   Extract `app_name` and `window_name`.\n        *   Check if an active session exists for this (app, window) combination.\n        *   If a session exists:\n            *   Check if `now() - last_activity_timestamp` exceeds the inactivity timeout.\n            *   If timeout exceeded, end the existing session and create a new one.\n            *   If not timed out, update `last_activity_timestamp` to the event's timestamp.\n        *   If no session exists:\n            *   Create a new session with `start_time` and `end_time` set to the event's timestamp.\n            *   Generate a new `session_id`.\n            *   Insert a new row into the `sessions` table.\n        *   Insert the new data (OCR, audio, UI) into the relevant table, linking it to the active `session_id`.\n\n4.  **Inactivity Timeout:** A configurable timeout (e.g., 5 minutes) will be used to determine session end due to inactivity.\n\n5.  **Periodic Flushing:** To avoid excessive in-memory state, periodically flush closed sessions (those that have exceeded the inactivity timeout) to the database.\n\n6. **Data Migration:** A migration script will be needed to analyze existing data and create initial session records based on timestamp proximity and app/window changes.\n\n### 3.4. Implementation Details\n\n*   **Language/Framework:** Continue using Rust for core logic and database interaction.\n*   **Database:** Continue using SQLite.\n*   **Concurrency:** Use asynchronous operations with `tokio` for handling concurrent events and database interactions.  Leverage `Arc` and `Mutex` for shared state, and channels for communication between tasks.\n*   **Configuration:** Add a new setting for the inactivity timeout.\n*   **Error Handling:** Implement robust error handling with `anyhow` and propagate errors appropriately. Log errors using `tracing`.\n* **Testing:** Thoroughly test session boundary detection with various scenarios, including rapid switching, long inactivity periods, and concurrent events.\n\n## 4. Diagrams\n\n### 4.1. Current Data Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Database\n    User->>Screen: Interacts with screen\n    Screen->>Screenpipe: Captures screen content (OCR)\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Database: Stores OCR data with timestamps\n    Screenpipe->>Database: Stores audio transcriptions with timestamps\n    User->>Screenpipe: Requests data\n    Screenpipe->>Database: Queries data by time range\n    Database->>Screenpipe: Returns data\n    Screenpipe->>User: Returns data\n```\n\n### 4.2. Proposed Database Schema Changes\n\n```mermaid\nclassDiagram\n    class frames {\n        +id : INTEGER [PK]\n        +video_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +name : TEXT\n    }\n    class video_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +device_name : TEXT\n    }\n    class ocr_text {\n        +frame_id : INTEGER [FK]\n        +text : TEXT\n        +text_json : TEXT\n        +app_name : TEXT\n        +window_name : TEXT\n        +ocr_engine : TEXT\n        +focused : BOOLEAN\n        +session_id : INTEGER [FK]\n    }\n    class audio_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +timestamp : TIMESTAMP\n    }\n    class audio_transcriptions {\n        +id : INTEGER [PK]\n        +audio_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +transcription : TEXT\n        +device : TEXT\n        +is_input_device : BOOLEAN\n        +speaker_id : INTEGER\n        +transcription_engine : TEXT\n        +start_time : REAL\n        +end_time : REAL\n        +text_length : INTEGER\n        +session_id : INTEGER [FK]\n    }\n    class ui_monitoring {\n      +id : INTEGER [PK]\n      +text_output : TEXT\n      +timestamp : DATETIME\n      +app : TEXT\n      +window : TEXT\n      +initial_traversal_at : DATETIME\n      +session_id : INTEGER [FK]\n    }\n  class sessions {\n    +id : INTEGER [PK]\n    +app_name : TEXT\n    +window_name : TEXT\n    +start_time : DATETIME\n    +end_time : DATETIME\n    +duration_secs : REAL\n  }\n  frames --|> video_chunks : video_chunk_id\n  ocr_text --|> frames : frame_id\n  audio_transcriptions --|> audio_chunks : audio_chunk_id\n  ocr_text --|> sessions : session_id\n  audio_transcriptions --|> sessions : session_id\n  ui_monitoring --|> sessions : session_id\n```\n\n### 4.3. Modified Data Flow with Session Tracking\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Session Manager\n    participant Database\n\n    User->>Screen: Interacts with App A, Window 1\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to session_id\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: Active session found (session_id)\n    Screenpipe->>Database: Store audio data, link to session_id\n\n    Note over User,Screenpipe: User switches to App B, Window 2\n    User->>Screen: Interacts with App B, Window 2\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App B, Window 2)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: End previous session (App A, Window 1)\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to new session_id\n\n    Note over User,Screenpipe: Inactivity Timeout\n    Screenpipe->>Session Manager: Check for activity\n    Session Manager->>Database: End current session (App B, Window 2)\n```\n\n### 4.4. New API Endpoint (Modified /search)\n\nThe existing `/search` endpoint will be extended to support session-based queries.  No new endpoint is needed.\n\n## 5. Performance Implications\n\n*   **Database:**  The addition of the `sessions` table and foreign keys will add some overhead to write operations.  Proper indexing is crucial to mitigate this.  Read performance for session-based queries should be good with appropriate indexes.\n*   **Memory:**  The in-memory session tracking will require additional memory.  The size of this will depend on the number of concurrent users and the configured timeout.  This should be monitored and potentially optimized (e.g., using a more efficient data structure than a simple `HashMap`).\n*   **CPU:**  The session boundary detection logic will add some CPU overhead.  This should be minimized by efficient checks and the use of asynchronous operations.\n\n## 6. Migration Path\n\n1.  **Add new `sessions` table.**\n2.  **Add `session_id` columns** to `ocr_text`, `audio_transcriptions`, and `ui_monitoring` tables.\n3.  **Backfill `session_id`:**  A migration script will be needed to analyze existing data and create initial session records.  This script will need to:\n    *   Iterate through existing OCR, audio, and UI data in chronological order.\n    *   Apply the session boundary detection logic (described above) to group data into sessions.\n    *   Insert corresponding rows into the `sessions` table.\n    *   Update the `session_id` foreign key in the existing tables.\n\n\n## 7. Alternative Approaches\n\n1.  **Session Table per Content Type:** Instead of a single `sessions` table, we could have separate session tables for each content type (e.g., `ocr_sessions`, `audio_sessions`, `ui_sessions`).  This might simplify queries for a specific content type but could make cross-content type analysis more complex.\n2.  **No Session Table (Denormalized):** We could add `start_time` and `end_time` directly to the existing tables (`ocr_text`, `audio_transcriptions`, `ui_monitoring`). This would avoid the need for joins when querying for sessions, but could lead to data redundancy and potential inconsistencies.\n3.  any other suggestions ????\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1560",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1441",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-27T11:32:17.805Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:17.805Z",
            "created_at": "2025-11-27T11:32:17.805Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1441",
              "status": "open",
              "type": "issue",
              "number": 1441,
              "title": "[bounty] general purpose scrapper",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1441",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] general purpose scrapper",
                  "body": "\nv0\n\nshould be able to scrap whatsapp\n\nideally you can use the keyboard / mouse api \n\nhttps://docs.screenpi.pe/docs/sdk-reference#input-control-api\n\n\nbasically many ppl would like to scrap data from desktop app and it's hard, like whatsapp, imessage, or even web but without getting banned or because it's local authentication is already done by user usually and stays local, and much less likely detected \n\n\n\n/bounty 200\n\nplease suggest how you would implement a very simple first version that work for whatsapp and UX\n\n\n\n\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1441"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1441",
              "body": "\nv0\n\nshould be able to scrap whatsapp\n\nideally you can use the keyboard / mouse api \n\nhttps://docs.screenpi.pe/docs/sdk-reference#input-control-api\n\n\nbasically many ppl would like to scrap data from desktop app and it's hard, like whatsapp, imessage, or even web but without getting banned or because it's local authentication is already done by user usually and stays local, and much less likely detected \n\n\n\n/bounty 200\n\nplease suggest how you would implement a very simple first version that work for whatsapp and UX\n\n\n\n\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1441",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1298",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-11-27T11:32:17.921Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:17.921Z",
            "created_at": "2025-11-27T11:32:17.921Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1298",
              "status": "open",
              "type": "issue",
              "number": 1298,
              "title": "[docs] document env var somewhere somehow ",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1298",
                  "user": {
                    "login": "dassio",
                    "id": 733502,
                    "node_id": "MDQ6VXNlcjczMzUwMg==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/733502?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/dassio",
                    "html_url": "https://github.com/dassio",
                    "followers_url": "https://api.github.com/users/dassio/followers",
                    "following_url": "https://api.github.com/users/dassio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/dassio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/dassio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/dassio/subscriptions",
                    "organizations_url": "https://api.github.com/users/dassio/orgs",
                    "repos_url": "https://api.github.com/users/dassio/repos",
                    "events_url": "https://api.github.com/users/dassio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/dassio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[docs] document env var somewhere somehow ",
                  "body": "**describe the feature**\nin the desktop app, you can configure hugging face mirror, but for the screenpipe server cli ,there is no such option , when try to use whisper for audio transcription, need to download mode from hugging face \n\n**why is this needed?**\nhugging face is banned in China\n\n\n**additional context**\n```\nyou are using local processing. all your data stays on your computer.\n\nwarning: telemetry is enabled. only error-level data will be sent to highlight.io.\nto disable, use the --disable-telemetry flag.\n\ncheck latest changes here: https://github.com/mediar-ai/screenpipe/releases\n2025-02-07T14:15:37.861529Z  INFO screenpipe: starting pipes\nfailed to start pipe timeline: No pipe.js/pipe.ts found in the pipe/dist directory\n2025-02-07T14:15:37.864597Z  INFO screenpipe_server::server: Server starting on 127.0.0.1:3030\n2025-02-07T14:15:45.839709Z  INFO screenpipe_server::video: Starting FFmpeg process for file: C:\\Users\\dassi\\.screenpipe\\data\\monitor_490607759_2025-02-07_14-15-45.mp4\n2025-02-07T14:15:48.283937Z  INFO screenpipe_server::resource_monitor: Runtime: 10s, Total Memory: 2% (0.25 GB / 16.09 GB), Total CPU: 88%\n2025-02-07T14:15:58.322953Z  INFO screenpipe_server::resource_monitor: Runtime: 20s, Total Memory: 2% (0.26 GB / 16.09 GB), Total CPU: 92%\n2025-02-07T14:16:00.374953Z ERROR screenpipe: continuous recording error: request error: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n\nCaused by:\n    0: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n    1: connection timed out\n```\n\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1298"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1298",
              "body": "**describe the feature**\nin the desktop app, you can configure hugging face mirror, but for the screenpipe server cli ,there is no such option , when try to use whisper for audio transcription, need to download mode from hugging face \n\n**why is this needed?**\nhugging face is banned in China\n\n\n**additional context**\n```\nyou are using local processing. all your data stays on your computer.\n\nwarning: telemetry is enabled. only error-level data will be sent to highlight.io.\nto disable, use the --disable-telemetry flag.\n\ncheck latest changes here: https://github.com/mediar-ai/screenpipe/releases\n2025-02-07T14:15:37.861529Z  INFO screenpipe: starting pipes\nfailed to start pipe timeline: No pipe.js/pipe.ts found in the pipe/dist directory\n2025-02-07T14:15:37.864597Z  INFO screenpipe_server::server: Server starting on 127.0.0.1:3030\n2025-02-07T14:15:45.839709Z  INFO screenpipe_server::video: Starting FFmpeg process for file: C:\\Users\\dassi\\.screenpipe\\data\\monitor_490607759_2025-02-07_14-15-45.mp4\n2025-02-07T14:15:48.283937Z  INFO screenpipe_server::resource_monitor: Runtime: 10s, Total Memory: 2% (0.25 GB / 16.09 GB), Total CPU: 88%\n2025-02-07T14:15:58.322953Z  INFO screenpipe_server::resource_monitor: Runtime: 20s, Total Memory: 2% (0.26 GB / 16.09 GB), Total CPU: 92%\n2025-02-07T14:16:00.374953Z ERROR screenpipe: continuous recording error: request error: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n\nCaused by:\n    0: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n    1: connection timed out\n```\n\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1298",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14077",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-27T11:32:18.347Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:18.347Z",
            "created_at": "2025-11-27T11:32:18.347Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14077",
              "status": "open",
              "type": "issue",
              "number": 14077,
              "title": "CVE-2021-21980 - vSphere Web Client - Path Traversal 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14077",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2021-21980 - vSphere Web Client - Path Traversal 💰",
                  "body": "\n### Description: \n> vSphere Web Client (FLEX/Flash) contains an unauthorized arbitrary file read caused by insecure file access in the web client, letting attackers with network access to port 443 on vCenter Server access sensitive information, exploit requires network access to port 443.\n\n#### Severity: `High`\n\n#### POC: \n- https://github.com/Osyanina/westone-CVE-2022-1388-scanner\n- https://github.com/Osyanina/westone-CVE-2021-21980-scanner\n\n### KEV: True\n\n### Shodan Query: `http.title:\"vmware cloud\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14077"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14077",
              "body": "\n### Description: \n> vSphere Web Client (FLEX/Flash) contains an unauthorized arbitrary file read caused by insecure file access in the web client, letting attackers with network access to port 443 on vCenter Server access sensitive information, exploit requires network access to port 443.\n\n#### Severity: `High`\n\n#### POC: \n- https://github.com/Osyanina/westone-CVE-2022-1388-scanner\n- https://github.com/Osyanina/westone-CVE-2021-21980-scanner\n\n### KEV: True\n\n### Shodan Query: `http.title:\"vmware cloud\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14077",
              "tech": [
                "go"
              ],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14077",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-27T11:32:18.351Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:18.351Z",
            "created_at": "2025-11-27T11:32:18.351Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14077",
              "status": "open",
              "type": "issue",
              "number": 14077,
              "title": "CVE-2021-21980 - vSphere Web Client - Path Traversal 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14077",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2021-21980 - vSphere Web Client - Path Traversal 💰",
                  "body": "\n### Description: \n> vSphere Web Client (FLEX/Flash) contains an unauthorized arbitrary file read caused by insecure file access in the web client, letting attackers with network access to port 443 on vCenter Server access sensitive information, exploit requires network access to port 443.\n\n#### Severity: `High`\n\n#### POC: \n- https://github.com/Osyanina/westone-CVE-2022-1388-scanner\n- https://github.com/Osyanina/westone-CVE-2021-21980-scanner\n\n### KEV: True\n\n### Shodan Query: `http.title:\"vmware cloud\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14077"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14077",
              "body": "\n### Description: \n> vSphere Web Client (FLEX/Flash) contains an unauthorized arbitrary file read caused by insecure file access in the web client, letting attackers with network access to port 443 on vCenter Server access sensitive information, exploit requires network access to port 443.\n\n#### Severity: `High`\n\n#### POC: \n- https://github.com/Osyanina/westone-CVE-2022-1388-scanner\n- https://github.com/Osyanina/westone-CVE-2021-21980-scanner\n\n### KEV: True\n\n### Shodan Query: `http.title:\"vmware cloud\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14077",
              "tech": [
                "go"
              ],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14060",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-27T11:32:18.479Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:18.479Z",
            "created_at": "2025-11-27T11:32:18.479Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14060",
              "status": "open",
              "type": "issue",
              "number": 14060,
              "title": "CVE-2021-4073 - RegistrationMagic - Authentication Bypass 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14060",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2021-4073 - RegistrationMagic - Authentication Bypass 💰",
                  "body": "\n### Description: \n> RegistrationMagic WordPress plugin versions <= 5.0.1.7 contain an authentication bypass caused by missing identity validation in social_login_using_email(), letting unauthenticated users log in as any site user, exploit requires knowing a valid username.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://www.wordfence.com/blog/2021/12/authentication-bypass-vulnerability-patched-in-user-registration-plugin/\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14060"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14060",
              "body": "\n### Description: \n> RegistrationMagic WordPress plugin versions <= 5.0.1.7 contain an authentication bypass caused by missing identity validation in social_login_using_email(), letting unauthenticated users log in as any site user, exploit requires knowing a valid username.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://www.wordfence.com/blog/2021/12/authentication-bypass-vulnerability-patched-in-user-registration-plugin/\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14060",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14026",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-27T11:32:18.589Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:18.589Z",
            "created_at": "2025-11-27T11:32:18.589Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14026",
              "status": "open",
              "type": "issue",
              "number": 14026,
              "title": "CVE-2021-45461 - FreePBX RestApps - Remote Code Execution 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14026",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2021-45461 - FreePBX RestApps - Remote Code Execution 💰",
                  "body": "\n### Description: \n> FreePBX restapps 15.0.19.87, 15.0.19.88, 16.0.18.40, and 16.0.18.41 contain a remote code execution caused by improper input handling, letting remote attackers execute arbitrary code, exploit requires remote network access.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://community.freepbx.org/t/0-day-freepbx-exploit/80092\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14026"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14026",
              "body": "\n### Description: \n> FreePBX restapps 15.0.19.87, 15.0.19.88, 16.0.18.40, and 16.0.18.41 contain a remote code execution caused by improper input handling, letting remote attackers execute arbitrary code, exploit requires remote network access.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://community.freepbx.org/t/0-day-freepbx-exploit/80092\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14026",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13997",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-27T11:32:18.696Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:18.696Z",
            "created_at": "2025-11-27T11:32:18.696Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13997",
              "status": "open",
              "type": "issue",
              "number": 13997,
              "title": "CVE-2022-21445 - Oracle Fusion Middleware - Remote Code Execution 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13997",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2022-21445 - Oracle Fusion Middleware - Remote Code Execution 💰",
                  "body": "\n### Description: \n> Oracle Fusion Middleware ADF Faces versions 12.2.1.3.0 and 12.2.1.4.0 contain a remote code execution caused by an unauthenticated network access vulnerability in ADF Faces, letting attackers compromise the application, exploit requires network access via HTTP.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/hienkiet/CVE-2022-21445-for-12.2.1.3.0-Weblogic\n- https://vulncheck.com/xdb/df8eb20f5b8e\n- https///github.com:hienkiet/CVE-2022-21445-for-12.2.1.3.0-Weblogic.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13997"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13997",
              "body": "\n### Description: \n> Oracle Fusion Middleware ADF Faces versions 12.2.1.3.0 and 12.2.1.4.0 contain a remote code execution caused by an unauthenticated network access vulnerability in ADF Faces, letting attackers compromise the application, exploit requires network access via HTTP.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/hienkiet/CVE-2022-21445-for-12.2.1.3.0-Weblogic\n- https://vulncheck.com/xdb/df8eb20f5b8e\n- https///github.com:hienkiet/CVE-2022-21445-for-12.2.1.3.0-Weblogic.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13997",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13942",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-27T11:32:18.854Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:18.854Z",
            "created_at": "2025-11-27T11:32:18.854Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13942",
              "status": "open",
              "type": "issue",
              "number": 13942,
              "title": "CVE-2022-31199 - Netwrix Auditor - Remote Code Execution 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13942",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2022-31199 - Netwrix Auditor - Remote Code Execution 💰",
                  "body": "\n### Description: \n> Netwrix Auditor User Activity Video Recording component contains remote code execution caused by vulnerabilities in the underlying protocol, letting unauthenticated attackers execute arbitrary code as SYSTEM, exploit requires network access.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://bishopfox.com/blog/netwrix-auditor-advisory\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13942"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13942",
              "body": "\n### Description: \n> Netwrix Auditor User Activity Video Recording component contains remote code execution caused by vulnerabilities in the underlying protocol, letting unauthenticated attackers execute arbitrary code as SYSTEM, exploit requires network access.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://bishopfox.com/blog/netwrix-auditor-advisory\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13942",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13942",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-27T11:32:18.858Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:18.858Z",
            "created_at": "2025-11-27T11:32:18.858Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13942",
              "status": "open",
              "type": "issue",
              "number": 13942,
              "title": "CVE-2022-31199 - Netwrix Auditor - Remote Code Execution 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13942",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2022-31199 - Netwrix Auditor - Remote Code Execution 💰",
                  "body": "\n### Description: \n> Netwrix Auditor User Activity Video Recording component contains remote code execution caused by vulnerabilities in the underlying protocol, letting unauthenticated attackers execute arbitrary code as SYSTEM, exploit requires network access.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://bishopfox.com/blog/netwrix-auditor-advisory\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13942"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13942",
              "body": "\n### Description: \n> Netwrix Auditor User Activity Video Recording component contains remote code execution caused by vulnerabilities in the underlying protocol, letting unauthenticated attackers execute arbitrary code as SYSTEM, exploit requires network access.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://bishopfox.com/blog/netwrix-auditor-advisory\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13942",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13933",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-27T11:32:18.971Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:18.971Z",
            "created_at": "2025-11-27T11:32:18.971Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13933",
              "status": "open",
              "type": "issue",
              "number": 13933,
              "title": "CVE-2023-25158 - GeoTools - SQL Injection 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13933",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2023-25158 - GeoTools - SQL Injection 💰",
                  "body": "\n### Description: \n> GeoTools < 27.4, 28.2 contains a sql_injection caused by unsanitized OGC Filter expressions in JDBCDataStore, letting attackers execute arbitrary SQL commands, exploit requires executing malicious filters.\n\n#### Severity: `Critical`\n\n#### POC: \n- https///github.com:murataydemir/CVE-2023-25157-and-CVE-2023-25158.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13933"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13933",
              "body": "\n### Description: \n> GeoTools < 27.4, 28.2 contains a sql_injection caused by unsanitized OGC Filter expressions in JDBCDataStore, letting attackers execute arbitrary SQL commands, exploit requires executing malicious filters.\n\n#### Severity: `Critical`\n\n#### POC: \n- https///github.com:murataydemir/CVE-2023-25157-and-CVE-2023-25158.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13933",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13923",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-27T11:32:19.080Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:19.080Z",
            "created_at": "2025-11-27T11:32:19.080Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13923",
              "status": "open",
              "type": "issue",
              "number": 13923,
              "title": "CVE-2023-27532 - Veeam Backup & Replication - Credential Disclosure 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13923",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2023-27532 - Veeam Backup & Replication - Credential Disclosure 💰",
                  "body": "\n### Description: \n> Veeam Backup & Replication contains a vulnerability that allows encrypted credentials stored in the configuration database to be obtained, letting attackers access backup infrastructure hosts, exploit requires access to the configuration database.\n\n#### Severity: `High`\n\n#### POC: \n- https://vulncheck.com/xdb/a0eedd90601f\n- https://github.com/puckiestyle/CVE-2023-27532-RCE-Only\n- https///github.com:puckiestyle/CVE-2023-27532-RCE-Only.git\n- https://vulncheck.com/xdb/be7830da6e38\n- https://github.com/sfewer-r7/CVE-2023-27532\n- https///github.com:sfewer-r7/CVE-2023-27532.git\n- https://vulncheck.com/xdb/70b9158e5d47\n- https://github.com/horizon3ai/CVE-2023-27532\n- https///github.com:horizon3ai/CVE-2023-27532.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13923"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13923",
              "body": "\n### Description: \n> Veeam Backup & Replication contains a vulnerability that allows encrypted credentials stored in the configuration database to be obtained, letting attackers access backup infrastructure hosts, exploit requires access to the configuration database.\n\n#### Severity: `High`\n\n#### POC: \n- https://vulncheck.com/xdb/a0eedd90601f\n- https://github.com/puckiestyle/CVE-2023-27532-RCE-Only\n- https///github.com:puckiestyle/CVE-2023-27532-RCE-Only.git\n- https://vulncheck.com/xdb/be7830da6e38\n- https://github.com/sfewer-r7/CVE-2023-27532\n- https///github.com:sfewer-r7/CVE-2023-27532.git\n- https://vulncheck.com/xdb/70b9158e5d47\n- https://github.com/horizon3ai/CVE-2023-27532\n- https///github.com:horizon3ai/CVE-2023-27532.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13923",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13915",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-27T11:32:19.194Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:19.194Z",
            "created_at": "2025-11-27T11:32:19.194Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13915",
              "status": "open",
              "type": "issue",
              "number": 13915,
              "title": "CVE-2023-28725 - General Bytes CAS - Remote Code Execution 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13915",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2023-28725 - General Bytes CAS - Remote Code Execution 💰",
                  "body": "\n### Description: \n> General Bytes Crypto Application Server (CAS) 20230120 contains a remote code execution caused by uploading a Java application to the /batm/app/admin/standalone/deployments directory, letting remote attackers execute arbitrary Java code, exploit requires upload access to the deployment directory.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://generalbytes.atlassian.net/wiki/spaces/ESD/pages/2885222430/Security+Incident+March+17-18th+2023\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13915"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13915",
              "body": "\n### Description: \n> General Bytes Crypto Application Server (CAS) 20230120 contains a remote code execution caused by uploading a Java application to the /batm/app/admin/standalone/deployments directory, letting remote attackers execute arbitrary Java code, exploit requires upload access to the deployment directory.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://generalbytes.atlassian.net/wiki/spaces/ESD/pages/2885222430/Security+Incident+March+17-18th+2023\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13915",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "golemcloud#275",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "golemcloud",
              "id": "generated-golemcloud",
              "name": "Golemcloud",
              "description": "",
              "members": [],
              "display_name": "Golemcloud",
              "created_at": "2025-11-27T11:32:50.426Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/golemcloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:50.426Z",
            "created_at": "2025-11-27T11:32:50.426Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-golemcloud#275",
              "status": "open",
              "type": "issue",
              "number": 275,
              "title": "Incorporate MCP Server into Golem CLI",
              "source": {
                "data": {
                  "id": "source-golemcloud#275",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Incorporate MCP Server into Golem CLI",
                  "body": "With a new command, Golem CLI enters serve mode:\n\n```bash\n%> golem-cli --serve --serve-port 1232\n%> golem-cli running MCP Server at port 1232\n```\n\nIn this mode, Golem CLI creates an MCP Server that exposes different commands as different tools, and exposes relevant resources (the manifest file in the current, ancestor, and children directories) as resources.\n\nWhen this ticket is completed, it should be possible to use an agent such as Claude Code to perform anything that Golem CLI can do. Moreover, all individual tools and resources must be end-to-end tested with an MCP Client that interacts with the MCP Server.\n\n[This library](https://github.com/rust-mcp-stack/rust-mcp-sdk) looks like the one to use for Rust, but perhaps there are better options available.",
                  "html_url": "https://github.com/golemcloud/golem/issues/1926"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem-cli#275",
              "body": "With a new command, Golem CLI enters serve mode:\n\n```bash\n%> golem-cli --serve --serve-port 1232\n%> golem-cli running MCP Server at port 1232\n```\n\nIn this mode, Golem CLI creates an MCP Server that exposes different commands as different tools, and exposes relevant resources (the manifest file in the current, ancestor, and children directories) as resources.\n\nWhen this ticket is completed, it should be possible to use an agent such as Claude Code to perform anything that Golem CLI can do. Moreover, all individual tools and resources must be end-to-end tested with an MCP Client that interacts with the MCP Server.\n\n[This library](https://github.com/rust-mcp-stack/rust-mcp-sdk) looks like the one to use for Rust, but perhaps there are better options available.",
              "url": "https://github.com/golemcloud/golem/issues/1926",
              "tech": [
                "go"
              ],
              "repo_name": "golem-cli",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "golemcloud#23",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "golemcloud",
              "id": "generated-golemcloud",
              "name": "Golemcloud",
              "description": "",
              "members": [],
              "display_name": "Golemcloud",
              "created_at": "2025-11-27T11:32:50.569Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/golemcloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:50.569Z",
            "created_at": "2025-11-27T11:32:50.569Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-golemcloud#23",
              "status": "open",
              "type": "issue",
              "number": 23,
              "title": "Implement Durable Text-to-Speech Provider Components for golem:tts WIT Interface",
              "source": {
                "data": {
                  "id": "source-golemcloud#23",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Implement Durable Text-to-Speech Provider Components for golem:tts WIT Interface",
                  "body": "I have attached to this ticket a WIT file that describes a generic interface for text-to-speech operations. This interface can be implemented by various providers, either by emulating features not present in a given provider, utilizing the provider's native support for a feature, or indicating an error if a particular combination is not natively supported by a provider.\n\nThe intent of this WIT specification is to allow developers of WASM components (on wasmCloud, Spin, or Golem) to leverage text-to-speech capabilities to build voice-powered applications, accessibility services, and audio content generation systems in a portable and provider-agnostic fashion.\n\nThis ticket involves constructing implementations of this WIT interface for the following providers:\n\n- **ElevenLabs**: The leading AI voice synthesis platform with comprehensive voice cloning, real-time streaming, voice conversion, and sound effects generation capabilities.\n- **AWS Polly**: Amazon's enterprise text-to-speech service with extensive language support, custom lexicons, speech marks, and asynchronous synthesis for long-form content.\n- **Google Cloud Text-to-Speech**: Google's neural voice synthesis service with WaveNet and Neural2 voices, device optimization profiles, and streaming synthesis capabilities.\n- **Deepgram Aura**: High-performance real-time TTS with session-based streaming, low-latency neural voices, and conversational AI optimization.\n\nThese implementations must be written in Rust and compilable to WASM Components (WASI 0.23 only, since Golem does not yet support WASI 0.3). The standard Rust toolchain for WASM component development can be employed (see cargo component and the Rust examples of components in this and other Golem repositories).\n\nAdditionally, these implementations should incorporate custom durability semantics using the Golem durability API and the Golem host API. This approach ensures that durability is managed at the level of individual TTS operations (voice synthesis, streaming session creation, voice cloning, batch processing), providing a higher-level and clearer operation log, which aids in debugging and monitoring. See golem:llm and golem:embed for more details and durable implementations in this same repository.\n\nThe final deliverables associated with this ticket are:\n\n- **ElevenLabs implementation**: A WASM Component (WASI 0.23), named `tts-elevenlabs.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **AWS Polly implementation**: A WASM Component (WASI 0.23), named `tts-polly.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Google Cloud TTS implementation**: A WASM Component (WASI 0.23), named `tts-google.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Deepgram Aura implementation**: A WASM Component (WASI 0.23), named `tts-deepgram.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n\n**Note**: If you have a strong recommendation to swap out one or two of these with other popular / common TTS providers (such as Azure Cognitive Services Speech, IBM Watson Text to Speech, or OpenAI TTS), then as long as you get permission beforehand, that's okay with me. However, we definitely need ElevenLabs and AWS Polly.\n\nThese components will require runtime configuration, notably API keys, endpoint URLs, authentication credentials, and provider-specific settings. For configuring this information, the components can use environment variables for now (in the future, they will use wasi-runtime-config, but Golem does not support this yet, whereas Golem has good support for environment variables).\n\nMoreover, the Rust components need to be tested within Golem to ensure compatibility with Golem 1.2.x.\n\nThis WIT has been designed by examining and comparing the APIs of ElevenLabs, AWS Polly, Google Cloud TTS, Azure Speech Services, OpenAI TTS, and Deepgram Aura. However, given there are no implementations, it is possible the provided WIT is not the optimal abstraction across all these providers. Therefore, deviations from the proposed design can be made. However, to be accepted, any deviation must be fully justified and deemed by Golem core contributors to be an improvement from the original specification.\n\n## Implementation Guidelines\n\nEach provider implementation should handle the following key mapping considerations:\n\n- **Voice Management**: Map the unified voice resource to provider-specific voice identifiers, handle voice discovery and metadata appropriately for each provider's voice catalog structure\n- **Audio Format Conversion**: Implement native audio format support where available, or provide format conversion for unsupported output formats using audio processing libraries\n- **Streaming Implementation**: Utilize native streaming APIs where supported (ElevenLabs, Deepgram), or implement chunk-based synthesis for providers without native streaming support\n- **Authentication Handling**: Implement appropriate authentication mechanisms (API keys, OAuth, service accounts) per provider requirements\n- **Feature Availability**: Route advanced features (voice cloning, sound effects, speech marks) through provider-native APIs where supported, or return `unsupported-operation` errors for unavailable features\n- **Error Mapping**: Map provider-specific HTTP errors and API responses to the unified `tts-error` enumeration with appropriate context preservation\n- **Rate Limiting**: Handle provider-specific rate limits and quota management, implementing appropriate retry logic and error reporting\n- **Long-form Content**: Implement efficient handling of long-form synthesis using provider-native async operations (AWS Polly) or intelligent chunking strategies\n\n## Testing Requirements\n\nEach implementation must include comprehensive test suites covering:\n- Basic synthesis operations (text-to-speech with various voices and configurations)\n- Voice discovery and metadata retrieval\n- Streaming synthesis lifecycle (session creation, chunk processing, cleanup)\n- Advanced feature testing (voice cloning, sound effects, custom pronunciations where supported)\n- Audio format validation and quality verification\n- Authentication and authorization scenarios\n- Error handling for unsupported operations and malformed inputs\n- Rate limiting and quota management behavior\n- Connection management and retry logic\n- Long-form content synthesis (>5000 characters)\n- Durability semantics verification across operation boundaries\n- Provider-specific feature utilization (lexicons for Polly, voice settings for ElevenLabs, etc.)\n\n## Configuration Requirements\n\nEach implementation should support the following environment variables:\n\n### Common Configuration\n- `TTS_PROVIDER_ENDPOINT`: Custom endpoint URL (for enterprise/regional deployments)\n- `TTS_PROVIDER_TIMEOUT`: Request timeout in seconds (default: 30)\n- `TTS_PROVIDER_MAX_RETRIES`: Maximum retry attempts (default: 3)\n- `TTS_PROVIDER_LOG_LEVEL`: Logging verbosity (debug, info, warn, error)\n\n### Provider-Specific Configuration\n- **ElevenLabs**: `ELEVENLABS_API_KEY`, `ELEVENLABS_MODEL_VERSION`\n- **AWS Polly**: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `AWS_SESSION_TOKEN`\n- **Google Cloud**: `GOOGLE_APPLICATION_CREDENTIALS`, `GOOGLE_CLOUD_PROJECT`\n- **Deepgram**: `DEEPGRAM_API_KEY`, `DEEPGRAM_API_VERSION`\n\n```wit\npackage golem:tts@1.0.0;\n\n/// Core types and error handling for universal text-to-speech\ninterface types {\n    /// Comprehensive error types covering all TTS operations\n    variant tts-error {\n        /// Input validation errors\n        invalid-text(string),\n        text-too-long(u32),\n        invalid-ssml(string),\n        unsupported-language(string),\n        \n        /// Voice and model errors\n        voice-not-found(string),\n        model-not-found(string),\n        voice-unavailable(string),\n        \n        /// Authentication and authorization\n        unauthorized(string),\n        access-denied(string),\n        \n        /// Resource and quota limits\n        quota-exceeded(quota-info),\n        rate-limited(u32),\n        insufficient-credits,\n        \n        /// Operation errors\n        synthesis-failed(string),\n        unsupported-operation(string),\n        invalid-configuration(string),\n        \n        /// Service errors\n        service-unavailable(string),\n        network-error(string),\n        internal-error(string),\n        \n        /// Storage errors (for async operations)\n        invalid-storage-location(string),\n        storage-access-denied(string),\n    }\n\n    record quota-info {\n        used: u32,\n        limit: u32,\n        reset-time: u64,\n        unit: quota-unit,\n    }\n\n    enum quota-unit {\n        characters,\n        requests,\n        seconds,\n        credits,\n    }\n\n    /// Language identification using BCP 47 codes\n    type language-code = string;\n\n    /// Voice gender classification\n    enum voice-gender {\n        male,\n        female,\n        neutral,\n    }\n\n    /// Voice quality tiers\n    enum voice-quality {\n        standard,\n        premium,\n        neural,\n        studio,\n    }\n\n    /// Text input types\n    enum text-type {\n        plain,\n        ssml,\n    }\n\n    /// Audio output formats\n    enum audio-format {\n        mp3,\n        wav,\n        pcm,\n        ogg-opus,\n        aac,\n        flac,\n        mulaw,\n        alaw,\n    }\n\n    /// Audio quality settings\n    record audio-config {\n        format: audio-format,\n        sample-rate: option<u32>,\n        bit-rate: option<u32>,\n        channels: option<u8>,\n    }\n\n    /// Voice synthesis parameters\n    record voice-settings {\n        /// Speaking rate (0.25 to 4.0, default 1.0)\n        speed: option<f32>,\n        /// Pitch adjustment in semitones (-20.0 to 20.0, default 0.0)\n        pitch: option<f32>,\n        /// Volume gain in dB (-96.0 to 16.0, default 0.0)\n        volume: option<f32>,\n        /// Voice stability (0.0 to 1.0, provider-specific)\n        stability: option<f32>,\n        /// Similarity to original (0.0 to 1.0, provider-specific)\n        similarity: option<f32>,\n        /// Style exaggeration (0.0 to 1.0, provider-specific)\n        style: option<f32>,\n    }\n\n    /// Audio effects and device optimization\n    flags audio-effects {\n        telephone-quality,\n        headphone-optimized,\n        speaker-optimized,\n        car-audio-optimized,\n        noise-reduction,\n        bass-boost,\n        treble-boost,\n    }\n\n    /// Input text with metadata\n    record text-input {\n        content: string,\n        text-type: text-type,\n        language: option<language-code>,\n    }\n\n    /// Complete synthesis result\n    record synthesis-result {\n        audio-data: list<u8>,\n        metadata: synthesis-metadata,\n    }\n\n    /// Metadata about synthesized audio\n    record synthesis-metadata {\n        duration-seconds: f32,\n        character-count: u32,\n        word-count: u32,\n        audio-size-bytes: u32,\n        request-id: string,\n        provider-info: option<string>,\n    }\n\n    /// Streaming audio chunk\n    record audio-chunk {\n        data: list<u8>,\n        sequence-number: u32,\n        is-final: bool,\n        timing-info: option<timing-info>,\n    }\n\n    /// Timing and synchronization information\n    record timing-info {\n        start-time-seconds: f32,\n        end-time-seconds: option<f32>,\n        text-offset: option<u32>,\n        mark-type: option<timing-mark-type>,\n    }\n\n    enum timing-mark-type {\n        word,\n        sentence,\n        paragraph,\n        ssml-mark,\n        viseme,\n    }\n\n\n}\n\n/// Voice discovery and management\ninterface voices {\n    use types.{tts-error, language-code, voice-gender, voice-quality};\n\n    /// Represents a voice that can be used for speech synthesis\n    resource voice {\n        /// Get voice identification\n        get-id: func() -> string;\n        get-name: func() -> string;\n        get-provider-id: func() -> option<string>;\n        \n        /// Get voice characteristics\n        get-language: func() -> language-code;\n        get-additional-languages: func() -> list<language-code>;\n        get-gender: func() -> voice-gender;\n        get-quality: func() -> voice-quality;\n        get-description: func() -> option<string>;\n        \n        /// Voice capabilities\n        supports-ssml: func() -> bool;\n        get-sample-rates: func() -> list<u32>;\n        get-supported-formats: func() -> list<types.audio-format>;\n        \n        /// Voice management (may return unsupported-operation)\n        update-settings: func(settings: types.voice-settings) -> result<_, tts-error>;\n        delete: func() -> result<_, tts-error>;\n        clone: func() -> result<voice, tts-error>;\n        \n        /// Preview voice with sample text\n        preview: func(text: string) -> result<list<u8>, tts-error>;\n    }\n\n    /// Voice search and filtering\n    record voice-filter {\n        language: option<language-code>,\n        gender: option<voice-gender>,\n        quality: option<voice-quality>,\n        supports-ssml: option<bool>,\n        provider: option<string>,\n        search-query: option<string>,\n    }\n\n    /// Detailed voice information\n    record voice-info {\n        id: string,\n        name: string,\n        language: language-code,\n        additional-languages: list<language-code>,\n        gender: voice-gender,\n        quality: voice-quality,\n        description: option<string>,\n        provider: string,\n        sample-rate: u32,\n        is-custom: bool,\n        is-cloned: bool,\n        preview-url: option<string>,\n        use-cases: list<string>,\n    }\n\n    /// Resource-based iterator for voice results\n    resource voice-results {\n        /// Check if more voices are available\n        has-more: func() -> bool;\n        \n        /// Get next batch of voices\n        get-next: func() -> result<list<voice-info>, tts-error>;\n        \n        /// Get total count if available\n        get-total-count: func() -> option<u32>;\n    }\n\n    /// List available voices with filtering and pagination\n    list-voices: func(\n        filter: option<voice-filter>\n    ) -> result<voice-results, tts-error>;\n\n    /// Get specific voice by ID\n    get-voice: func(voice-id: string) -> result<voice, tts-error>;\n\n    /// Search voices by characteristics\n    search-voices: func(\n        query: string,\n        filter: option<voice-filter>\n    ) -> result<list<voice-info>, tts-error>;\n\n    /// Get supported languages\n    list-languages: func() -> result<list<language-info>, tts-error>;\n\n    record language-info {\n        code: language-code,\n        name: string,\n        native-name: string,\n        voice-count: u32,\n    }\n}\n\n/// Core text-to-speech synthesis operations\ninterface synthesis {\n    use types.{\n        text-input, audio-config, voice-settings, audio-effects,\n        synthesis-result, tts-error, timing-info\n    };\n    use voices.{voice};\n\n    /// Synthesis configuration options\n    record synthesis-options {\n        audio-config: option<audio-config>,\n        voice-settings: option<voice-settings>,\n        audio-effects: option<audio-effects>,\n        enable-timing: option<bool>,\n        enable-word-timing: option<bool>,\n        seed: option<u32>,\n        model-version: option<string>,\n        context: option<synthesis-context>,\n    }\n\n    /// Context for better synthesis quality\n    record synthesis-context {\n        previous-text: option<string>,\n        next-text: option<string>,\n        topic: option<string>,\n        emotion: option<string>,\n        speaking-style: option<string>,\n    }\n\n    /// Convert text to speech (removed async)\n    synthesize: func(\n        input: text-input,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-result, tts-error>;\n\n    /// Batch synthesis for multiple inputs (removed async)\n    synthesize-batch: func(\n        inputs: list<text-input>,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<list<synthesis-result>, tts-error>;\n\n    /// Get timing information without audio synthesis\n    get-timing-marks: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<list<timing-info>, tts-error>;\n\n    /// Validate text before synthesis\n    validate-input: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<validation-result, tts-error>;\n\n    record validation-result {\n        is-valid: bool,\n        character-count: u32,\n        estimated-duration: option<f32>,\n        warnings: list<string>,\n        errors: list<string>,\n    }\n}\n\n/// Real-time streaming synthesis\ninterface streaming {\n    use types.{\n        text-input, audio-config, voice-settings, audio-chunk,\n        tts-error, timing-info\n    };\n    use voices.{voice};\n    use synthesis.{synthesis-options};\n\n    /// Streaming synthesis session\n    resource synthesis-stream {\n        /// Send text for synthesis (can be called multiple times)\n        send-text: func(input: text-input) -> result<_, tts-error>;\n        \n        /// Signal end of input and flush remaining audio\n        finish: func() -> result<_, tts-error>;\n        \n        /// Receive next audio chunk (non-blocking)\n        receive-chunk: func() -> result<option<audio-chunk>, tts-error>;\n        \n        /// Check if more chunks are available\n        has-pending-audio: func() -> bool;\n        \n        /// Get current stream status\n        get-status: func() -> stream-status;\n        \n        /// Close stream and clean up resources\n        close: func();\n    }\n\n    enum stream-status {\n        ready,\n        processing,\n        finished,\n        error,\n        closed,\n    }\n\n    /// Create streaming synthesis session\n    create-stream: func(\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-stream, tts-error>;\n\n    /// Real-time voice conversion streaming\n    create-voice-conversion-stream: func(\n        target-voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<voice-conversion-stream, tts-error>;\n\n    resource voice-conversion-stream {\n        /// Send input audio chunks\n        send-audio: func(audio-data: list<u8>) -> result<_, tts-error>;\n        \n        /// Receive converted audio chunks\n        receive-converted: func() -> result<option<audio-chunk>, tts-error>;\n        \n        finish: func() -> result<_, tts-error>;\n        close: func();\n    }\n}\n\n/// Advanced TTS features and voice manipulation\ninterface advanced {\n    use types.{tts-error, audio-config, language-code};\n    use voices.{voice};\n\n    /// Voice cloning and creation (removed async)\n    create-voice-clone: func(\n        name: string,\n        audio-samples: list<audio-sample>,\n        description: option<string>\n    ) -> result<voice, tts-error>;\n\n    record audio-sample {\n        data: list<u8>,\n        transcript: option<string>,\n        quality-rating: option<u8>,\n    }\n\n    /// Design synthetic voice (removed async)\n    design-voice: func(\n        name: string,\n        characteristics: voice-design-params\n    ) -> result<voice, tts-error>;\n\n    record voice-design-params {\n        gender: types.voice-gender,\n        age-category: age-category,\n        accent: string,\n        personality-traits: list<string>,\n        reference-voice: option<string>,\n    }\n\n    enum age-category {\n        child,\n        young-adult,\n        middle-aged,\n        elderly,\n    }\n\n    /// Voice-to-voice conversion (removed async)\n    convert-voice: func(\n        input-audio: list<u8>,\n        target-voice: borrow<voice>,\n        preserve-timing: option<bool>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Generate sound effects from text description (removed async)\n    generate-sound-effect: func(\n        description: string,\n        duration-seconds: option<f32>,\n        style-influence: option<f32>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Custom pronunciation management\n    resource pronunciation-lexicon {\n        get-name: func() -> string;\n        get-language: func() -> language-code;\n        get-entry-count: func() -> u32;\n        \n        /// Add pronunciation rule\n        add-entry: func(word: string, pronunciation: string) -> result<_, tts-error>;\n        \n        /// Remove pronunciation rule\n        remove-entry: func(word: string) -> result<_, tts-error>;\n        \n        /// Export lexicon content\n        export-content: func() -> result<string, tts-error>;\n    }\n\n    /// Create custom pronunciation lexicon\n    create-lexicon: func(\n        name: string,\n        language: language-code,\n        entries: option<list<pronunciation-entry>>\n    ) -> result<pronunciation-lexicon, tts-error>;\n\n    record pronunciation-entry {\n        word: string,\n        pronunciation: string,\n        part-of-speech: option<string>,\n    }\n\n    /// Long-form content synthesis with optimization (removed async)\n    synthesize-long-form: func(\n        content: string,\n        voice: borrow<voice>,\n        output-location: string,\n        chapter-breaks: option<list<u32>>\n    ) -> result<long-form-operation, tts-error>;\n\n    resource long-form-operation {\n        get-status: func() -> operation-status;\n        get-progress: func() -> f32;\n        cancel: func() -> result<_, tts-error>;\n        get-result: func() -> result<long-form-result, tts-error>;\n    }\n\n    enum operation-status {\n        pending,\n        processing,\n        completed,\n        failed,\n        cancelled,\n    }\n\n    record long-form-result {\n        output-location: string,\n        total-duration: f32,\n        chapter-durations: option<list<f32>>,\n        metadata: types.synthesis-metadata,\n    }\n}\n```",
                  "html_url": "https://github.com/golemcloud/golem-ai/issues/23"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem-ai#23",
              "body": "I have attached to this ticket a WIT file that describes a generic interface for text-to-speech operations. This interface can be implemented by various providers, either by emulating features not present in a given provider, utilizing the provider's native support for a feature, or indicating an error if a particular combination is not natively supported by a provider.\n\nThe intent of this WIT specification is to allow developers of WASM components (on wasmCloud, Spin, or Golem) to leverage text-to-speech capabilities to build voice-powered applications, accessibility services, and audio content generation systems in a portable and provider-agnostic fashion.\n\nThis ticket involves constructing implementations of this WIT interface for the following providers:\n\n- **ElevenLabs**: The leading AI voice synthesis platform with comprehensive voice cloning, real-time streaming, voice conversion, and sound effects generation capabilities.\n- **AWS Polly**: Amazon's enterprise text-to-speech service with extensive language support, custom lexicons, speech marks, and asynchronous synthesis for long-form content.\n- **Google Cloud Text-to-Speech**: Google's neural voice synthesis service with WaveNet and Neural2 voices, device optimization profiles, and streaming synthesis capabilities.\n- **Deepgram Aura**: High-performance real-time TTS with session-based streaming, low-latency neural voices, and conversational AI optimization.\n\nThese implementations must be written in Rust and compilable to WASM Components (WASI 0.23 only, since Golem does not yet support WASI 0.3). The standard Rust toolchain for WASM component development can be employed (see cargo component and the Rust examples of components in this and other Golem repositories).\n\nAdditionally, these implementations should incorporate custom durability semantics using the Golem durability API and the Golem host API. This approach ensures that durability is managed at the level of individual TTS operations (voice synthesis, streaming session creation, voice cloning, batch processing), providing a higher-level and clearer operation log, which aids in debugging and monitoring. See golem:llm and golem:embed for more details and durable implementations in this same repository.\n\nThe final deliverables associated with this ticket are:\n\n- **ElevenLabs implementation**: A WASM Component (WASI 0.23), named `tts-elevenlabs.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **AWS Polly implementation**: A WASM Component (WASI 0.23), named `tts-polly.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Google Cloud TTS implementation**: A WASM Component (WASI 0.23), named `tts-google.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Deepgram Aura implementation**: A WASM Component (WASI 0.23), named `tts-deepgram.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n\n**Note**: If you have a strong recommendation to swap out one or two of these with other popular / common TTS providers (such as Azure Cognitive Services Speech, IBM Watson Text to Speech, or OpenAI TTS), then as long as you get permission beforehand, that's okay with me. However, we definitely need ElevenLabs and AWS Polly.\n\nThese components will require runtime configuration, notably API keys, endpoint URLs, authentication credentials, and provider-specific settings. For configuring this information, the components can use environment variables for now (in the future, they will use wasi-runtime-config, but Golem does not support this yet, whereas Golem has good support for environment variables).\n\nMoreover, the Rust components need to be tested within Golem to ensure compatibility with Golem 1.2.x.\n\nThis WIT has been designed by examining and comparing the APIs of ElevenLabs, AWS Polly, Google Cloud TTS, Azure Speech Services, OpenAI TTS, and Deepgram Aura. However, given there are no implementations, it is possible the provided WIT is not the optimal abstraction across all these providers. Therefore, deviations from the proposed design can be made. However, to be accepted, any deviation must be fully justified and deemed by Golem core contributors to be an improvement from the original specification.\n\n## Implementation Guidelines\n\nEach provider implementation should handle the following key mapping considerations:\n\n- **Voice Management**: Map the unified voice resource to provider-specific voice identifiers, handle voice discovery and metadata appropriately for each provider's voice catalog structure\n- **Audio Format Conversion**: Implement native audio format support where available, or provide format conversion for unsupported output formats using audio processing libraries\n- **Streaming Implementation**: Utilize native streaming APIs where supported (ElevenLabs, Deepgram), or implement chunk-based synthesis for providers without native streaming support\n- **Authentication Handling**: Implement appropriate authentication mechanisms (API keys, OAuth, service accounts) per provider requirements\n- **Feature Availability**: Route advanced features (voice cloning, sound effects, speech marks) through provider-native APIs where supported, or return `unsupported-operation` errors for unavailable features\n- **Error Mapping**: Map provider-specific HTTP errors and API responses to the unified `tts-error` enumeration with appropriate context preservation\n- **Rate Limiting**: Handle provider-specific rate limits and quota management, implementing appropriate retry logic and error reporting\n- **Long-form Content**: Implement efficient handling of long-form synthesis using provider-native async operations (AWS Polly) or intelligent chunking strategies\n\n## Testing Requirements\n\nEach implementation must include comprehensive test suites covering:\n- Basic synthesis operations (text-to-speech with various voices and configurations)\n- Voice discovery and metadata retrieval\n- Streaming synthesis lifecycle (session creation, chunk processing, cleanup)\n- Advanced feature testing (voice cloning, sound effects, custom pronunciations where supported)\n- Audio format validation and quality verification\n- Authentication and authorization scenarios\n- Error handling for unsupported operations and malformed inputs\n- Rate limiting and quota management behavior\n- Connection management and retry logic\n- Long-form content synthesis (>5000 characters)\n- Durability semantics verification across operation boundaries\n- Provider-specific feature utilization (lexicons for Polly, voice settings for ElevenLabs, etc.)\n\n## Configuration Requirements\n\nEach implementation should support the following environment variables:\n\n### Common Configuration\n- `TTS_PROVIDER_ENDPOINT`: Custom endpoint URL (for enterprise/regional deployments)\n- `TTS_PROVIDER_TIMEOUT`: Request timeout in seconds (default: 30)\n- `TTS_PROVIDER_MAX_RETRIES`: Maximum retry attempts (default: 3)\n- `TTS_PROVIDER_LOG_LEVEL`: Logging verbosity (debug, info, warn, error)\n\n### Provider-Specific Configuration\n- **ElevenLabs**: `ELEVENLABS_API_KEY`, `ELEVENLABS_MODEL_VERSION`\n- **AWS Polly**: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `AWS_SESSION_TOKEN`\n- **Google Cloud**: `GOOGLE_APPLICATION_CREDENTIALS`, `GOOGLE_CLOUD_PROJECT`\n- **Deepgram**: `DEEPGRAM_API_KEY`, `DEEPGRAM_API_VERSION`\n\n```wit\npackage golem:tts@1.0.0;\n\n/// Core types and error handling for universal text-to-speech\ninterface types {\n    /// Comprehensive error types covering all TTS operations\n    variant tts-error {\n        /// Input validation errors\n        invalid-text(string),\n        text-too-long(u32),\n        invalid-ssml(string),\n        unsupported-language(string),\n        \n        /// Voice and model errors\n        voice-not-found(string),\n        model-not-found(string),\n        voice-unavailable(string),\n        \n        /// Authentication and authorization\n        unauthorized(string),\n        access-denied(string),\n        \n        /// Resource and quota limits\n        quota-exceeded(quota-info),\n        rate-limited(u32),\n        insufficient-credits,\n        \n        /// Operation errors\n        synthesis-failed(string),\n        unsupported-operation(string),\n        invalid-configuration(string),\n        \n        /// Service errors\n        service-unavailable(string),\n        network-error(string),\n        internal-error(string),\n        \n        /// Storage errors (for async operations)\n        invalid-storage-location(string),\n        storage-access-denied(string),\n    }\n\n    record quota-info {\n        used: u32,\n        limit: u32,\n        reset-time: u64,\n        unit: quota-unit,\n    }\n\n    enum quota-unit {\n        characters,\n        requests,\n        seconds,\n        credits,\n    }\n\n    /// Language identification using BCP 47 codes\n    type language-code = string;\n\n    /// Voice gender classification\n    enum voice-gender {\n        male,\n        female,\n        neutral,\n    }\n\n    /// Voice quality tiers\n    enum voice-quality {\n        standard,\n        premium,\n        neural,\n        studio,\n    }\n\n    /// Text input types\n    enum text-type {\n        plain,\n        ssml,\n    }\n\n    /// Audio output formats\n    enum audio-format {\n        mp3,\n        wav,\n        pcm,\n        ogg-opus,\n        aac,\n        flac,\n        mulaw,\n        alaw,\n    }\n\n    /// Audio quality settings\n    record audio-config {\n        format: audio-format,\n        sample-rate: option<u32>,\n        bit-rate: option<u32>,\n        channels: option<u8>,\n    }\n\n    /// Voice synthesis parameters\n    record voice-settings {\n        /// Speaking rate (0.25 to 4.0, default 1.0)\n        speed: option<f32>,\n        /// Pitch adjustment in semitones (-20.0 to 20.0, default 0.0)\n        pitch: option<f32>,\n        /// Volume gain in dB (-96.0 to 16.0, default 0.0)\n        volume: option<f32>,\n        /// Voice stability (0.0 to 1.0, provider-specific)\n        stability: option<f32>,\n        /// Similarity to original (0.0 to 1.0, provider-specific)\n        similarity: option<f32>,\n        /// Style exaggeration (0.0 to 1.0, provider-specific)\n        style: option<f32>,\n    }\n\n    /// Audio effects and device optimization\n    flags audio-effects {\n        telephone-quality,\n        headphone-optimized,\n        speaker-optimized,\n        car-audio-optimized,\n        noise-reduction,\n        bass-boost,\n        treble-boost,\n    }\n\n    /// Input text with metadata\n    record text-input {\n        content: string,\n        text-type: text-type,\n        language: option<language-code>,\n    }\n\n    /// Complete synthesis result\n    record synthesis-result {\n        audio-data: list<u8>,\n        metadata: synthesis-metadata,\n    }\n\n    /// Metadata about synthesized audio\n    record synthesis-metadata {\n        duration-seconds: f32,\n        character-count: u32,\n        word-count: u32,\n        audio-size-bytes: u32,\n        request-id: string,\n        provider-info: option<string>,\n    }\n\n    /// Streaming audio chunk\n    record audio-chunk {\n        data: list<u8>,\n        sequence-number: u32,\n        is-final: bool,\n        timing-info: option<timing-info>,\n    }\n\n    /// Timing and synchronization information\n    record timing-info {\n        start-time-seconds: f32,\n        end-time-seconds: option<f32>,\n        text-offset: option<u32>,\n        mark-type: option<timing-mark-type>,\n    }\n\n    enum timing-mark-type {\n        word,\n        sentence,\n        paragraph,\n        ssml-mark,\n        viseme,\n    }\n\n\n}\n\n/// Voice discovery and management\ninterface voices {\n    use types.{tts-error, language-code, voice-gender, voice-quality};\n\n    /// Represents a voice that can be used for speech synthesis\n    resource voice {\n        /// Get voice identification\n        get-id: func() -> string;\n        get-name: func() -> string;\n        get-provider-id: func() -> option<string>;\n        \n        /// Get voice characteristics\n        get-language: func() -> language-code;\n        get-additional-languages: func() -> list<language-code>;\n        get-gender: func() -> voice-gender;\n        get-quality: func() -> voice-quality;\n        get-description: func() -> option<string>;\n        \n        /// Voice capabilities\n        supports-ssml: func() -> bool;\n        get-sample-rates: func() -> list<u32>;\n        get-supported-formats: func() -> list<types.audio-format>;\n        \n        /// Voice management (may return unsupported-operation)\n        update-settings: func(settings: types.voice-settings) -> result<_, tts-error>;\n        delete: func() -> result<_, tts-error>;\n        clone: func() -> result<voice, tts-error>;\n        \n        /// Preview voice with sample text\n        preview: func(text: string) -> result<list<u8>, tts-error>;\n    }\n\n    /// Voice search and filtering\n    record voice-filter {\n        language: option<language-code>,\n        gender: option<voice-gender>,\n        quality: option<voice-quality>,\n        supports-ssml: option<bool>,\n        provider: option<string>,\n        search-query: option<string>,\n    }\n\n    /// Detailed voice information\n    record voice-info {\n        id: string,\n        name: string,\n        language: language-code,\n        additional-languages: list<language-code>,\n        gender: voice-gender,\n        quality: voice-quality,\n        description: option<string>,\n        provider: string,\n        sample-rate: u32,\n        is-custom: bool,\n        is-cloned: bool,\n        preview-url: option<string>,\n        use-cases: list<string>,\n    }\n\n    /// Resource-based iterator for voice results\n    resource voice-results {\n        /// Check if more voices are available\n        has-more: func() -> bool;\n        \n        /// Get next batch of voices\n        get-next: func() -> result<list<voice-info>, tts-error>;\n        \n        /// Get total count if available\n        get-total-count: func() -> option<u32>;\n    }\n\n    /// List available voices with filtering and pagination\n    list-voices: func(\n        filter: option<voice-filter>\n    ) -> result<voice-results, tts-error>;\n\n    /// Get specific voice by ID\n    get-voice: func(voice-id: string) -> result<voice, tts-error>;\n\n    /// Search voices by characteristics\n    search-voices: func(\n        query: string,\n        filter: option<voice-filter>\n    ) -> result<list<voice-info>, tts-error>;\n\n    /// Get supported languages\n    list-languages: func() -> result<list<language-info>, tts-error>;\n\n    record language-info {\n        code: language-code,\n        name: string,\n        native-name: string,\n        voice-count: u32,\n    }\n}\n\n/// Core text-to-speech synthesis operations\ninterface synthesis {\n    use types.{\n        text-input, audio-config, voice-settings, audio-effects,\n        synthesis-result, tts-error, timing-info\n    };\n    use voices.{voice};\n\n    /// Synthesis configuration options\n    record synthesis-options {\n        audio-config: option<audio-config>,\n        voice-settings: option<voice-settings>,\n        audio-effects: option<audio-effects>,\n        enable-timing: option<bool>,\n        enable-word-timing: option<bool>,\n        seed: option<u32>,\n        model-version: option<string>,\n        context: option<synthesis-context>,\n    }\n\n    /// Context for better synthesis quality\n    record synthesis-context {\n        previous-text: option<string>,\n        next-text: option<string>,\n        topic: option<string>,\n        emotion: option<string>,\n        speaking-style: option<string>,\n    }\n\n    /// Convert text to speech (removed async)\n    synthesize: func(\n        input: text-input,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-result, tts-error>;\n\n    /// Batch synthesis for multiple inputs (removed async)\n    synthesize-batch: func(\n        inputs: list<text-input>,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<list<synthesis-result>, tts-error>;\n\n    /// Get timing information without audio synthesis\n    get-timing-marks: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<list<timing-info>, tts-error>;\n\n    /// Validate text before synthesis\n    validate-input: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<validation-result, tts-error>;\n\n    record validation-result {\n        is-valid: bool,\n        character-count: u32,\n        estimated-duration: option<f32>,\n        warnings: list<string>,\n        errors: list<string>,\n    }\n}\n\n/// Real-time streaming synthesis\ninterface streaming {\n    use types.{\n        text-input, audio-config, voice-settings, audio-chunk,\n        tts-error, timing-info\n    };\n    use voices.{voice};\n    use synthesis.{synthesis-options};\n\n    /// Streaming synthesis session\n    resource synthesis-stream {\n        /// Send text for synthesis (can be called multiple times)\n        send-text: func(input: text-input) -> result<_, tts-error>;\n        \n        /// Signal end of input and flush remaining audio\n        finish: func() -> result<_, tts-error>;\n        \n        /// Receive next audio chunk (non-blocking)\n        receive-chunk: func() -> result<option<audio-chunk>, tts-error>;\n        \n        /// Check if more chunks are available\n        has-pending-audio: func() -> bool;\n        \n        /// Get current stream status\n        get-status: func() -> stream-status;\n        \n        /// Close stream and clean up resources\n        close: func();\n    }\n\n    enum stream-status {\n        ready,\n        processing,\n        finished,\n        error,\n        closed,\n    }\n\n    /// Create streaming synthesis session\n    create-stream: func(\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-stream, tts-error>;\n\n    /// Real-time voice conversion streaming\n    create-voice-conversion-stream: func(\n        target-voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<voice-conversion-stream, tts-error>;\n\n    resource voice-conversion-stream {\n        /// Send input audio chunks\n        send-audio: func(audio-data: list<u8>) -> result<_, tts-error>;\n        \n        /// Receive converted audio chunks\n        receive-converted: func() -> result<option<audio-chunk>, tts-error>;\n        \n        finish: func() -> result<_, tts-error>;\n        close: func();\n    }\n}\n\n/// Advanced TTS features and voice manipulation\ninterface advanced {\n    use types.{tts-error, audio-config, language-code};\n    use voices.{voice};\n\n    /// Voice cloning and creation (removed async)\n    create-voice-clone: func(\n        name: string,\n        audio-samples: list<audio-sample>,\n        description: option<string>\n    ) -> result<voice, tts-error>;\n\n    record audio-sample {\n        data: list<u8>,\n        transcript: option<string>,\n        quality-rating: option<u8>,\n    }\n\n    /// Design synthetic voice (removed async)\n    design-voice: func(\n        name: string,\n        characteristics: voice-design-params\n    ) -> result<voice, tts-error>;\n\n    record voice-design-params {\n        gender: types.voice-gender,\n        age-category: age-category,\n        accent: string,\n        personality-traits: list<string>,\n        reference-voice: option<string>,\n    }\n\n    enum age-category {\n        child,\n        young-adult,\n        middle-aged,\n        elderly,\n    }\n\n    /// Voice-to-voice conversion (removed async)\n    convert-voice: func(\n        input-audio: list<u8>,\n        target-voice: borrow<voice>,\n        preserve-timing: option<bool>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Generate sound effects from text description (removed async)\n    generate-sound-effect: func(\n        description: string,\n        duration-seconds: option<f32>,\n        style-influence: option<f32>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Custom pronunciation management\n    resource pronunciation-lexicon {\n        get-name: func() -> string;\n        get-language: func() -> language-code;\n        get-entry-count: func() -> u32;\n        \n        /// Add pronunciation rule\n        add-entry: func(word: string, pronunciation: string) -> result<_, tts-error>;\n        \n        /// Remove pronunciation rule\n        remove-entry: func(word: string) -> result<_, tts-error>;\n        \n        /// Export lexicon content\n        export-content: func() -> result<string, tts-error>;\n    }\n\n    /// Create custom pronunciation lexicon\n    create-lexicon: func(\n        name: string,\n        language: language-code,\n        entries: option<list<pronunciation-entry>>\n    ) -> result<pronunciation-lexicon, tts-error>;\n\n    record pronunciation-entry {\n        word: string,\n        pronunciation: string,\n        part-of-speech: option<string>,\n    }\n\n    /// Long-form content synthesis with optimization (removed async)\n    synthesize-long-form: func(\n        content: string,\n        voice: borrow<voice>,\n        output-location: string,\n        chapter-breaks: option<list<u32>>\n    ) -> result<long-form-operation, tts-error>;\n\n    resource long-form-operation {\n        get-status: func() -> operation-status;\n        get-progress: func() -> f32;\n        cancel: func() -> result<_, tts-error>;\n        get-result: func() -> result<long-form-result, tts-error>;\n    }\n\n    enum operation-status {\n        pending,\n        processing,\n        completed,\n        failed,\n        cancelled,\n    }\n\n    record long-form-result {\n        output-location: string,\n        total-duration: f32,\n        chapter-durations: option<list<f32>>,\n        metadata: types.synthesis-metadata,\n    }\n}\n```",
              "url": "https://github.com/golemcloud/golem-ai/issues/23",
              "tech": [
                "go"
              ],
              "repo_name": "golem-ai",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "golemcloud#21",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "golemcloud",
              "id": "generated-golemcloud",
              "name": "Golemcloud",
              "description": "",
              "members": [],
              "display_name": "Golemcloud",
              "created_at": "2025-11-27T11:32:50.668Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/golemcloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-27T11:32:50.668Z",
            "created_at": "2025-11-27T11:32:50.668Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-golemcloud#21",
              "status": "open",
              "type": "issue",
              "number": 21,
              "title": "Implement Durable Vector Database Provider Components for golem:vector WIT Interface",
              "source": {
                "data": {
                  "id": "source-golemcloud#21",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Implement Durable Vector Database Provider Components for golem:vector WIT Interface",
                  "body": "I have attached to this ticket a WIT file that describes a generic interface for vector database operations. This interface can be implemented by various providers, either by emulating features not present in a given provider, utilizing the provider's native support for a feature, or indicating an error if a particular combination is not natively supported by a provider.\n\nThe intent of this WIT specification is to allow developers of WASM components (on wasmCloud, Spin, or Golem) to leverage vector database capabilities to build agents and services in a portable and provider-agnostic fashion.\n\nThis ticket involves constructing implementations of this WIT interface for the following providers:\n\n- **Qdrant**: Offers advanced vector similarity search with support for sparse vectors, recommendations, and discovery operations.​\n- **Pinecone**: Provides managed vector database services with hybrid vector support and namespace organization.​\n- **Milvus**: Supplies enterprise-grade vector database with comprehensive data types and clustering capabilities.​\n- **pgvector**: Extends PostgreSQL with vector operations, binary vectors, and mathematical functions.​\n\nThese implementations must be written in Rust and compilable to WASM Components (WASI 0.23 only, since Golem does not yet support WASI 0.3). The standard Rust toolchain for WASM component development can be employed (see cargo component and the Rust examples of components in this and other Golem repositories).\n\nAdditionally, these implementations should incorporate custom durability semantics using the Golem durability API and the Golem host API. This approach ensures that durability is managed at the level of individual vector operations (upsert, search, delete), providing a higher-level and clearer operation log, which aids in debugging and monitoring. See `golem:llm` and `golem:embed` for more details and durable implementations in this same repository.\n\nThe final deliverables associated with this ticket are:\n\n- **Qdrant implementation**: A WASM Component (WASI 0.2), named `vector-qdrant.wasm`, with a full test suite and custom durability implementation at the level of vector operations.​\n- **Pinecone implementation**: A WASM Component (WASI 0.2), named `vector-pinecone.wasm`, with a full test suite and custom durability implementation at the level of vector operations.​\n- **Milvus implementation**: A WASM Component (WASI 0.2), named `vector-milvus.wasm`, with a full test suite and custom durability implementation at the level of vector operations.​\n- **pgvector implementation**: A WASM Component (WASI 0.2), named `vector-pgvector.wasm`, with a full test suite and custom durability implementation at the level of vector operations.​\n\nNote: If you have a strong recommendation to swap out one or two of these with other popular / common vector databases, then as long as you get permission beforehand, that's okay with me. However, we definitely need Pinecone, pgvector, and Qdrant. \n\nThese components will require runtime configuration, notably API keys, connection strings, and database credentials. For configuring this information, the components can use environment variables for now (in the future, they will use wasi-runtime-config, but Golem does not support this yet, whereas Golem has good support for environment variables).\n\nMoreover, the Rust components need to be tested within Golem to ensure compatibility with Golem 1.2.x.\n\nThis WIT has been designed by examining and comparing the APIs of Qdrant, Pinecone, Chroma, Weaviate, Milvus, and pgvector. However, given there are no implementations, it is possible the provided WIT is not the optimal abstraction across all these providers. Therefore, deviations from the proposed design can be made. However, to be accepted, any deviation must be fully justified and deemed by Golem core contributors to be an improvement from the original specification.\n\n```wit\npackage golem:vector@1.0.0;\n\n/// Core types and fundamental data structures for vector operations\ninterface types {\n    /// Unique identifier for vectors and collections\n    type id = string;\n    \n    /// Standard dense vector representation\n    type dense-vector = list<f32>;\n    \n    /// Sparse vector with explicit indices\n    record sparse-vector {\n        /// Zero-based indices of non-zero elements\n        indices: list<u32>,\n        /// Values corresponding to the indices\n        values: list<f32>,\n        /// Total dimensionality of the vector space\n        total-dimensions: u32,\n    }\n    \n    /// Binary vector representation\n    record binary-vector {\n        /// Packed binary data\n        data: list<u8>,\n        /// Number of bits/dimensions\n        dimensions: u32,\n    }\n    \n    /// Half-precision vector (16-bit floats)\n    record half-vector {\n        /// Half-precision values (represented as f32 for compatibility)\n        data: list<f32>,\n        /// Number of dimensions\n        dimensions: u32,\n    }\n    \n    /// Vector data supporting multiple representations\n    variant vector-data {\n        /// Standard 32-bit floating point vector\n        dense(dense-vector),\n        /// Sparse vector representation\n        sparse(sparse-vector),\n        /// Binary/bit vector\n        binary(binary-vector),\n        /// Half-precision vector\n        half(half-vector),\n        /// Named vectors for multi-vector collections\n        named(list<tuple<string, dense-vector>>),\n        /// Hybrid dense + sparse combination\n        hybrid(tuple<dense-vector, sparse-vector>),\n    }\n    \n    /// Supported distance metrics\n    enum distance-metric {\n        /// Cosine similarity (1 - cosine distance)\n        cosine,\n        /// Euclidean (L2) distance\n        euclidean,\n        /// Dot product / inner product\n        dot-product,\n        /// Manhattan (L1) distance\n        manhattan,\n        /// Hamming distance (for binary vectors)\n        hamming,\n        /// Jaccard distance (for binary/sparse vectors)\n        jaccard,\n    }\n    \n    /// Metadata value types\n    variant metadata-value {\n        string-val(string),\n        number-val(f64),\n        integer-val(s64),\n        boolean-val(bool),\n        array-val(list<metadata-value>),\n        object-val(list<tuple<string, metadata-value>>),\n        null-val,\n        /// Geographic coordinates\n        geo-val(geo-coordinates),\n        /// ISO 8601 datetime string\n        datetime-val(string),\n        /// Binary data\n        blob-val(list<u8>),\n    }\n    \n    /// Geographic coordinates\n    record geo-coordinates {\n        latitude: f64,\n        longitude: f64,\n    }\n    \n    /// Key-value metadata\n    type metadata = list<tuple<string, metadata-value>>;\n    \n    /// Filter operators for metadata queries\n    enum filter-operator {\n        /// Equal to\n        eq,\n        /// Not equal to\n        ne,\n        /// Greater than\n        gt,\n        /// Greater than or equal\n        gte,\n        /// Less than\n        lt,\n        /// Less than or equal\n        lte,\n        /// Value is in list\n        %in,\n        /// Value is not in list\n        nin,\n        /// Text contains substring (case insensitive)\n        contains,\n        /// Text doesn't contain substring\n        not-contains,\n        /// Regular expression match\n        regex,\n        /// Geographic distance within radius\n        geo-within,\n        /// Geographic bounding box\n        geo-bbox,\n    }\n    \n    /// Basic filter condition\n    record filter-condition {\n        /// Field path (supports nested fields with dot notation)\n        field: string,\n        /// Filter operator\n        operator: filter-operator,\n        /// Value to compare against\n        value: metadata-value,\n    }\n    \n    /// Complex filter expressions with boolean logic\n    variant filter-expression {\n        /// Simple condition\n        condition(filter-condition),\n        /// Logical AND of multiple expressions\n        and(list<filter-expression>),\n        /// Logical OR of multiple expressions\n        or(list<filter-expression>),\n        /// Logical NOT of expression\n        not(filter-expression),\n    }\n    \n    /// Vector record for storage operations\n    record vector-record {\n        /// Unique identifier\n        id: id,\n        /// Vector data\n        vector: vector-data,\n        /// Associated metadata\n        metadata: option<metadata>,\n    }\n    \n    /// Search result with similarity score\n    record search-result {\n        /// Vector identifier\n        id: id,\n        /// Similarity score (higher = more similar)\n        score: f32,\n        /// Distance from query vector (lower = more similar)\n        distance: f32,\n        /// Vector data (if requested)\n        vector: option<vector-data>,\n        /// Associated metadata (if requested)\n        metadata: option<metadata>,\n    }\n    \n    /// Standard error types\n    variant vector-error {\n        /// Resource not found\n        not-found(string),\n        /// Resource already exists\n        already-exists(string),\n        /// Invalid parameters or configuration\n        invalid-params(string),\n        /// Feature not supported by this provider\n        unsupported-feature(string),\n        /// Vector dimension mismatch\n        dimension-mismatch(string),\n        /// Invalid vector format or data\n        invalid-vector(string),\n        /// Authentication/authorization failure\n        unauthorized(string),\n        /// Rate limit exceeded\n        rate-limited(string),\n        /// Internal provider error\n        provider-error(string),\n        /// Network/connection issues\n        connection-error(string),\n    }\n    \n\n}\n\n/// Collection/index management and configuration\ninterface collections {\n    use types.{id, distance-metric, vector-error};\n    \n    /// Index configuration parameters\n    record index-config {\n        index-type: option<string>,\n        parameters: list<tuple<string, string>>,\n    }\n    \n    /// Collection information and statistics\n    record collection-info {\n        name: string,\n        description: option<string>,\n        dimension: u32,\n        metric: distance-metric,\n        vector-count: u64,\n        size-bytes: option<u64>,\n        index-ready: bool,\n        created-at: option<u64>,\n        updated-at: option<u64>,\n        provider-stats: option<types.metadata>,\n    }\n    \n    /// Create or update collection (upsert)\n    upsert-collection: func(\n        name: string,\n        description: option<string>,\n        dimension: u32,\n        metric: distance-metric,\n        index-config: option<index-config>,\n        metadata: option<types.metadata>\n    ) -> result<collection-info, vector-error>;\n    \n    /// List all collections\n    list-collections: func() -> result<list<collection-info>, vector-error>;\n    \n    /// Get collection information\n    get-collection: func(name: string) -> result<collection-info, vector-error>;\n    \n    /// Update collection metadata only\n    update-collection: func(\n        name: string,\n        description: option<string>,\n        metadata: option<types.metadata>\n    ) -> result<collection-info, vector-error>;\n    \n    /// Delete collection and all vectors\n    delete-collection: func(name: string) -> result<_, vector-error>;\n    \n    /// Check if collection exists\n    collection-exists: func(name: string) -> result<bool, vector-error>;\n}\n\n/// Core vector operations (CRUD)\ninterface vectors {\n    use types.{id, vector-record, vector-data, metadata, filter-expression, vector-error};\n    \n    /// Batch operation result\n    record batch-result {\n        success-count: u32,\n        failure-count: u32,\n        errors: list<tuple<u32, vector-error>>,\n    }\n    \n    /// List response with pagination\n    record list-response {\n        vectors: list<vector-record>,\n        next-cursor: option<string>,\n        total-count: option<u64>,\n    }\n    \n    /// Upsert vectors into collection\n    upsert-vectors: func(\n        collection: string,\n        vectors: list<vector-record>,\n        namespace: option<string>\n    ) -> result<batch-result, vector-error>;\n    \n    /// Upsert single vector (convenience)\n    upsert-vector: func(\n        collection: string,\n        id: id,\n        vector: vector-data,\n        metadata: option<metadata>,\n        namespace: option<string>\n    ) -> result<_, vector-error>;\n    \n    /// Get vectors by IDs\n    get-vectors: func(\n        collection: string,\n        ids: list<id>,\n        namespace: option<string>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>\n    ) -> result<list<vector-record>, vector-error>;\n    \n    /// Get single vector by ID (convenience)\n    get-vector: func(\n        collection: string,\n        id: id,\n        namespace: option<string>\n    ) -> result<option<vector-record>, vector-error>;\n    \n    /// Update vector in place\n    update-vector: func(\n        collection: string,\n        id: id,\n        vector: option<vector-data>,\n        metadata: option<metadata>,\n        namespace: option<string>,\n        merge-metadata: option<bool>\n    ) -> result<_, vector-error>;\n    \n    /// Delete vectors by IDs\n    delete-vectors: func(\n        collection: string,\n        ids: list<id>,\n        namespace: option<string>\n    ) -> result<u32, vector-error>;\n    \n    /// Delete vectors by filter\n    delete-by-filter: func(\n        collection: string,\n        filter: filter-expression,\n        namespace: option<string>\n    ) -> result<u32, vector-error>;\n    \n    /// Delete all vectors in namespace\n    delete-namespace: func(\n        collection: string,\n        namespace: string\n    ) -> result<u32, vector-error>;\n    \n    /// List vectors with filtering and pagination\n    list-vectors: func(\n        collection: string,\n        namespace: option<string>,\n        filter: option<filter-expression>,\n        limit: option<u32>,\n        cursor: option<string>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>\n    ) -> result<list-response, vector-error>;\n    \n    /// Count vectors matching filter\n    count-vectors: func(\n        collection: string,\n        filter: option<filter-expression>,\n        namespace: option<string>\n    ) -> result<u64, vector-error>;\n}\n\n/// Core similarity search operations\ninterface search {\n    use types.{id, vector-data, search-result, filter-expression, vector-error};\n    \n    /// Search query variants\n    variant search-query {\n        vector(vector-data),\n        by-id(id),\n        multi-vector(list<tuple<string, vector-data>>),\n    }\n    \n    /// Similarity search\n    search-vectors: func(\n        collection: string,\n        query: search-query,\n        limit: u32,\n        filter: option<filter-expression>,\n        namespace: option<string>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>,\n        min-score: option<f32>,\n        max-distance: option<f32>,\n        search-params: option<list<tuple<string, string>>>\n    ) -> result<list<search-result>, vector-error>;\n    \n    /// Simple vector similarity search (convenience)\n    find-similar: func(\n        collection: string,\n        vector: vector-data,\n        limit: u32,\n        namespace: option<string>\n    ) -> result<list<search-result>, vector-error>;\n    \n    /// Batch similarity search\n    batch-search: func(\n        collection: string,\n        queries: list<search-query>,\n        limit: u32,\n        filter: option<filter-expression>,\n        namespace: option<string>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>,\n        search-params: option<list<tuple<string, string>>>\n    ) -> result<list<list<search-result>>, vector-error>;\n}\n}\n\n/// Extended search capabilities (provider-dependent)\ninterface search-extended {\n    use types.{id, vector-data, search-result, filter-expression, vector-error, metadata-value};\n    \n    /// Recommendation example types\n    variant recommendation-example {\n        vector-id(id),\n        vector-data(vector-data),\n    }\n    \n    enum recommendation-strategy {\n        average-vector,\n        best-score,\n        centroid,\n    }\n    \n    /// Context pair for discovery\n    record context-pair {\n        positive: recommendation-example,\n        negative: recommendation-example,\n    }\n    \n    /// Grouped search result\n    record grouped-search-result {\n        group-value: metadata-value,\n        results: list<search-result>,\n        group-count: u32,\n    }\n    \n    /// Recommendation-based search\n    recommend-vectors: func(\n        collection: string,\n        positive: list<recommendation-example>,\n        negative: option<list<recommendation-example>>,\n        limit: u32,\n        filter: option<filter-expression>,\n        namespace: option<string>,\n        strategy: option<recommendation-strategy>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>\n    ) -> result<list<search-result>, vector-error>;\n    \n    /// Discovery/context-based search\n    discover-vectors: func(\n        collection: string,\n        context-pairs: list<context-pair>,\n        limit: u32,\n        filter: option<filter-expression>,\n        namespace: option<string>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>\n    ) -> result<list<search-result>, vector-error>;\n    \n    /// Grouped search for diverse results\n    search-groups: func(\n        collection: string,\n        query: search.search-query,\n        group-by: string,\n        group-size: u32,\n        max-groups: u32,\n        filter: option<filter-expression>,\n        namespace: option<string>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>\n    ) -> result<list<grouped-search-result>, vector-error>;\n    \n    /// Range search within distance bounds\n    search-range: func(\n        collection: string,\n        vector: vector-data,\n        min-distance: option<f32>,\n        max-distance: f32,\n        filter: option<filter-expression>,\n        namespace: option<string>,\n        limit: option<u32>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>\n    ) -> result<list<search-result>, vector-error>;\n    \n    /// Text/document search (auto-embedding)\n    search-text: func(\n        collection: string,\n        query-text: string,\n        limit: u32,\n        filter: option<filter-expression>,\n        namespace: option<string>\n    ) -> result<list<search-result>, vector-error>;\n}\n\n/// Analytics and statistics\ninterface analytics {\n    use types.{vector-error, metadata-value, filter-expression};\n    \n    /// Collection statistics\n    record collection-stats {\n        vector-count: u64,\n        dimension: u32,\n        size-bytes: u64,\n        index-size-bytes: option<u64>,\n        namespace-stats: list<tuple<string, namespace-stats>>,\n        distance-distribution: option<distance-stats>,\n    }\n    \n    record namespace-stats {\n        vector-count: u64,\n        size-bytes: u64,\n    }\n    \n    record distance-stats {\n        min-distance: f32,\n        max-distance: f32,\n        avg-distance: f32,\n        percentiles: list<tuple<f32, f32>>,\n    }\n    \n    /// Field statistics for metadata\n    record field-stats {\n        field-name: string,\n        value-count: u64,\n        unique-values: u64,\n        null-count: u64,\n        data-type: string,\n        sample-values: list<metadata-value>,\n    }\n    \n    /// Get collection statistics\n    get-collection-stats: func(\n        collection: string,\n        namespace: option<string>\n    ) -> result<collection-stats, vector-error>;\n    \n    /// Get field statistics\n    get-field-stats: func(\n        collection: string,\n        field: string,\n        namespace: option<string>\n    ) -> result<field-stats, vector-error>;\n    \n    /// Get value distribution for a field\n    get-field-distribution: func(\n        collection: string,\n        field: string,\n        limit: option<u32>,\n        namespace: option<string>\n    ) -> result<list<tuple<metadata-value, u64>>, vector-error>;\n}\n\n/// Namespace/partition management\ninterface namespaces {\n    use types.{vector-error, metadata};\n    \n    /// Namespace information\n    record namespace-info {\n        name: string,\n        collection: string,\n        vector-count: u64,\n        size-bytes: u64,\n        created-at: option<u64>,\n        metadata: option<metadata>,\n    }\n    \n    /// Create or update namespace (upsert)\n    upsert-namespace: func(\n        collection: string,\n        namespace: string,\n        metadata: option<metadata>\n    ) -> result<namespace-info, vector-error>;\n    \n    /// List namespaces in collection\n    list-namespaces: func(collection: string) -> result<list<namespace-info>, vector-error>;\n    \n    /// Get namespace information\n    get-namespace: func(\n        collection: string,\n        namespace: string\n    ) -> result<namespace-info, vector-error>;\n    \n    /// Delete namespace and all vectors within it\n    delete-namespace: func(\n        collection: string,\n        namespace: string\n    ) -> result<_, vector-error>;\n    \n    /// Check if namespace exists\n    namespace-exists: func(\n        collection: string,\n        namespace: string\n    ) -> result<bool, vector-error>;\n}\n\n/// Connection and configuration management\ninterface connection {\n    use types.{vector-error, metadata};\n    \n    variant credentials {\n        api-key(string),\n        username-password(tuple<string, string>),\n        token(string),\n        certificate(list<u8>),\n        oauth(oauth-config),\n    }\n    \n    record oauth-config {\n        client-id: string,\n        client-secret: option<string>,\n        token-url: string,\n        scope: option<string>,\n    }\n    \n    /// Connection status\n    record connection-status {\n        connected: bool,\n        provider: option<string>,\n        endpoint: option<string>,\n        last-activity: option<u64>,\n        connection-id: option<string>,\n    }\n    \n    /// Establish connection to vector database\n    connect: func(\n        endpoint: string,\n        credentials: option<credentials>,\n        timeout-ms: option<u32>,\n        options: option<metadata>\n    ) -> result<_, vector-error>;\n    \n    /// Close connection\n    disconnect: func() -> result<_, vector-error>;\n    \n    /// Get current connection status\n    get-connection-status: func() -> result<connection-status, vector-error>;\n    \n    /// Test connection without modifying state\n    test-connection: func(\n        endpoint: string,\n        credentials: option<credentials>,\n        timeout-ms: option<u32>,\n        options: option<metadata>\n    ) -> result<bool, vector-error>;\n}",
                  "html_url": "https://github.com/golemcloud/golem-ai/issues/21"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem-ai#21",
              "body": "I have attached to this ticket a WIT file that describes a generic interface for vector database operations. This interface can be implemented by various providers, either by emulating features not present in a given provider, utilizing the provider's native support for a feature, or indicating an error if a particular combination is not natively supported by a provider.\n\nThe intent of this WIT specification is to allow developers of WASM components (on wasmCloud, Spin, or Golem) to leverage vector database capabilities to build agents and services in a portable and provider-agnostic fashion.\n\nThis ticket involves constructing implementations of this WIT interface for the following providers:\n\n- **Qdrant**: Offers advanced vector similarity search with support for sparse vectors, recommendations, and discovery operations.​\n- **Pinecone**: Provides managed vector database services with hybrid vector support and namespace organization.​\n- **Milvus**: Supplies enterprise-grade vector database with comprehensive data types and clustering capabilities.​\n- **pgvector**: Extends PostgreSQL with vector operations, binary vectors, and mathematical functions.​\n\nThese implementations must be written in Rust and compilable to WASM Components (WASI 0.23 only, since Golem does not yet support WASI 0.3). The standard Rust toolchain for WASM component development can be employed (see cargo component and the Rust examples of components in this and other Golem repositories).\n\nAdditionally, these implementations should incorporate custom durability semantics using the Golem durability API and the Golem host API. This approach ensures that durability is managed at the level of individual vector operations (upsert, search, delete), providing a higher-level and clearer operation log, which aids in debugging and monitoring. See `golem:llm` and `golem:embed` for more details and durable implementations in this same repository.\n\nThe final deliverables associated with this ticket are:\n\n- **Qdrant implementation**: A WASM Component (WASI 0.2), named `vector-qdrant.wasm`, with a full test suite and custom durability implementation at the level of vector operations.​\n- **Pinecone implementation**: A WASM Component (WASI 0.2), named `vector-pinecone.wasm`, with a full test suite and custom durability implementation at the level of vector operations.​\n- **Milvus implementation**: A WASM Component (WASI 0.2), named `vector-milvus.wasm`, with a full test suite and custom durability implementation at the level of vector operations.​\n- **pgvector implementation**: A WASM Component (WASI 0.2), named `vector-pgvector.wasm`, with a full test suite and custom durability implementation at the level of vector operations.​\n\nNote: If you have a strong recommendation to swap out one or two of these with other popular / common vector databases, then as long as you get permission beforehand, that's okay with me. However, we definitely need Pinecone, pgvector, and Qdrant. \n\nThese components will require runtime configuration, notably API keys, connection strings, and database credentials. For configuring this information, the components can use environment variables for now (in the future, they will use wasi-runtime-config, but Golem does not support this yet, whereas Golem has good support for environment variables).\n\nMoreover, the Rust components need to be tested within Golem to ensure compatibility with Golem 1.2.x.\n\nThis WIT has been designed by examining and comparing the APIs of Qdrant, Pinecone, Chroma, Weaviate, Milvus, and pgvector. However, given there are no implementations, it is possible the provided WIT is not the optimal abstraction across all these providers. Therefore, deviations from the proposed design can be made. However, to be accepted, any deviation must be fully justified and deemed by Golem core contributors to be an improvement from the original specification.\n\n```wit\npackage golem:vector@1.0.0;\n\n/// Core types and fundamental data structures for vector operations\ninterface types {\n    /// Unique identifier for vectors and collections\n    type id = string;\n    \n    /// Standard dense vector representation\n    type dense-vector = list<f32>;\n    \n    /// Sparse vector with explicit indices\n    record sparse-vector {\n        /// Zero-based indices of non-zero elements\n        indices: list<u32>,\n        /// Values corresponding to the indices\n        values: list<f32>,\n        /// Total dimensionality of the vector space\n        total-dimensions: u32,\n    }\n    \n    /// Binary vector representation\n    record binary-vector {\n        /// Packed binary data\n        data: list<u8>,\n        /// Number of bits/dimensions\n        dimensions: u32,\n    }\n    \n    /// Half-precision vector (16-bit floats)\n    record half-vector {\n        /// Half-precision values (represented as f32 for compatibility)\n        data: list<f32>,\n        /// Number of dimensions\n        dimensions: u32,\n    }\n    \n    /// Vector data supporting multiple representations\n    variant vector-data {\n        /// Standard 32-bit floating point vector\n        dense(dense-vector),\n        /// Sparse vector representation\n        sparse(sparse-vector),\n        /// Binary/bit vector\n        binary(binary-vector),\n        /// Half-precision vector\n        half(half-vector),\n        /// Named vectors for multi-vector collections\n        named(list<tuple<string, dense-vector>>),\n        /// Hybrid dense + sparse combination\n        hybrid(tuple<dense-vector, sparse-vector>),\n    }\n    \n    /// Supported distance metrics\n    enum distance-metric {\n        /// Cosine similarity (1 - cosine distance)\n        cosine,\n        /// Euclidean (L2) distance\n        euclidean,\n        /// Dot product / inner product\n        dot-product,\n        /// Manhattan (L1) distance\n        manhattan,\n        /// Hamming distance (for binary vectors)\n        hamming,\n        /// Jaccard distance (for binary/sparse vectors)\n        jaccard,\n    }\n    \n    /// Metadata value types\n    variant metadata-value {\n        string-val(string),\n        number-val(f64),\n        integer-val(s64),\n        boolean-val(bool),\n        array-val(list<metadata-value>),\n        object-val(list<tuple<string, metadata-value>>),\n        null-val,\n        /// Geographic coordinates\n        geo-val(geo-coordinates),\n        /// ISO 8601 datetime string\n        datetime-val(string),\n        /// Binary data\n        blob-val(list<u8>),\n    }\n    \n    /// Geographic coordinates\n    record geo-coordinates {\n        latitude: f64,\n        longitude: f64,\n    }\n    \n    /// Key-value metadata\n    type metadata = list<tuple<string, metadata-value>>;\n    \n    /// Filter operators for metadata queries\n    enum filter-operator {\n        /// Equal to\n        eq,\n        /// Not equal to\n        ne,\n        /// Greater than\n        gt,\n        /// Greater than or equal\n        gte,\n        /// Less than\n        lt,\n        /// Less than or equal\n        lte,\n        /// Value is in list\n        %in,\n        /// Value is not in list\n        nin,\n        /// Text contains substring (case insensitive)\n        contains,\n        /// Text doesn't contain substring\n        not-contains,\n        /// Regular expression match\n        regex,\n        /// Geographic distance within radius\n        geo-within,\n        /// Geographic bounding box\n        geo-bbox,\n    }\n    \n    /// Basic filter condition\n    record filter-condition {\n        /// Field path (supports nested fields with dot notation)\n        field: string,\n        /// Filter operator\n        operator: filter-operator,\n        /// Value to compare against\n        value: metadata-value,\n    }\n    \n    /// Complex filter expressions with boolean logic\n    variant filter-expression {\n        /// Simple condition\n        condition(filter-condition),\n        /// Logical AND of multiple expressions\n        and(list<filter-expression>),\n        /// Logical OR of multiple expressions\n        or(list<filter-expression>),\n        /// Logical NOT of expression\n        not(filter-expression),\n    }\n    \n    /// Vector record for storage operations\n    record vector-record {\n        /// Unique identifier\n        id: id,\n        /// Vector data\n        vector: vector-data,\n        /// Associated metadata\n        metadata: option<metadata>,\n    }\n    \n    /// Search result with similarity score\n    record search-result {\n        /// Vector identifier\n        id: id,\n        /// Similarity score (higher = more similar)\n        score: f32,\n        /// Distance from query vector (lower = more similar)\n        distance: f32,\n        /// Vector data (if requested)\n        vector: option<vector-data>,\n        /// Associated metadata (if requested)\n        metadata: option<metadata>,\n    }\n    \n    /// Standard error types\n    variant vector-error {\n        /// Resource not found\n        not-found(string),\n        /// Resource already exists\n        already-exists(string),\n        /// Invalid parameters or configuration\n        invalid-params(string),\n        /// Feature not supported by this provider\n        unsupported-feature(string),\n        /// Vector dimension mismatch\n        dimension-mismatch(string),\n        /// Invalid vector format or data\n        invalid-vector(string),\n        /// Authentication/authorization failure\n        unauthorized(string),\n        /// Rate limit exceeded\n        rate-limited(string),\n        /// Internal provider error\n        provider-error(string),\n        /// Network/connection issues\n        connection-error(string),\n    }\n    \n\n}\n\n/// Collection/index management and configuration\ninterface collections {\n    use types.{id, distance-metric, vector-error};\n    \n    /// Index configuration parameters\n    record index-config {\n        index-type: option<string>,\n        parameters: list<tuple<string, string>>,\n    }\n    \n    /// Collection information and statistics\n    record collection-info {\n        name: string,\n        description: option<string>,\n        dimension: u32,\n        metric: distance-metric,\n        vector-count: u64,\n        size-bytes: option<u64>,\n        index-ready: bool,\n        created-at: option<u64>,\n        updated-at: option<u64>,\n        provider-stats: option<types.metadata>,\n    }\n    \n    /// Create or update collection (upsert)\n    upsert-collection: func(\n        name: string,\n        description: option<string>,\n        dimension: u32,\n        metric: distance-metric,\n        index-config: option<index-config>,\n        metadata: option<types.metadata>\n    ) -> result<collection-info, vector-error>;\n    \n    /// List all collections\n    list-collections: func() -> result<list<collection-info>, vector-error>;\n    \n    /// Get collection information\n    get-collection: func(name: string) -> result<collection-info, vector-error>;\n    \n    /// Update collection metadata only\n    update-collection: func(\n        name: string,\n        description: option<string>,\n        metadata: option<types.metadata>\n    ) -> result<collection-info, vector-error>;\n    \n    /// Delete collection and all vectors\n    delete-collection: func(name: string) -> result<_, vector-error>;\n    \n    /// Check if collection exists\n    collection-exists: func(name: string) -> result<bool, vector-error>;\n}\n\n/// Core vector operations (CRUD)\ninterface vectors {\n    use types.{id, vector-record, vector-data, metadata, filter-expression, vector-error};\n    \n    /// Batch operation result\n    record batch-result {\n        success-count: u32,\n        failure-count: u32,\n        errors: list<tuple<u32, vector-error>>,\n    }\n    \n    /// List response with pagination\n    record list-response {\n        vectors: list<vector-record>,\n        next-cursor: option<string>,\n        total-count: option<u64>,\n    }\n    \n    /// Upsert vectors into collection\n    upsert-vectors: func(\n        collection: string,\n        vectors: list<vector-record>,\n        namespace: option<string>\n    ) -> result<batch-result, vector-error>;\n    \n    /// Upsert single vector (convenience)\n    upsert-vector: func(\n        collection: string,\n        id: id,\n        vector: vector-data,\n        metadata: option<metadata>,\n        namespace: option<string>\n    ) -> result<_, vector-error>;\n    \n    /// Get vectors by IDs\n    get-vectors: func(\n        collection: string,\n        ids: list<id>,\n        namespace: option<string>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>\n    ) -> result<list<vector-record>, vector-error>;\n    \n    /// Get single vector by ID (convenience)\n    get-vector: func(\n        collection: string,\n        id: id,\n        namespace: option<string>\n    ) -> result<option<vector-record>, vector-error>;\n    \n    /// Update vector in place\n    update-vector: func(\n        collection: string,\n        id: id,\n        vector: option<vector-data>,\n        metadata: option<metadata>,\n        namespace: option<string>,\n        merge-metadata: option<bool>\n    ) -> result<_, vector-error>;\n    \n    /// Delete vectors by IDs\n    delete-vectors: func(\n        collection: string,\n        ids: list<id>,\n        namespace: option<string>\n    ) -> result<u32, vector-error>;\n    \n    /// Delete vectors by filter\n    delete-by-filter: func(\n        collection: string,\n        filter: filter-expression,\n        namespace: option<string>\n    ) -> result<u32, vector-error>;\n    \n    /// Delete all vectors in namespace\n    delete-namespace: func(\n        collection: string,\n        namespace: string\n    ) -> result<u32, vector-error>;\n    \n    /// List vectors with filtering and pagination\n    list-vectors: func(\n        collection: string,\n        namespace: option<string>,\n        filter: option<filter-expression>,\n        limit: option<u32>,\n        cursor: option<string>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>\n    ) -> result<list-response, vector-error>;\n    \n    /// Count vectors matching filter\n    count-vectors: func(\n        collection: string,\n        filter: option<filter-expression>,\n        namespace: option<string>\n    ) -> result<u64, vector-error>;\n}\n\n/// Core similarity search operations\ninterface search {\n    use types.{id, vector-data, search-result, filter-expression, vector-error};\n    \n    /// Search query variants\n    variant search-query {\n        vector(vector-data),\n        by-id(id),\n        multi-vector(list<tuple<string, vector-data>>),\n    }\n    \n    /// Similarity search\n    search-vectors: func(\n        collection: string,\n        query: search-query,\n        limit: u32,\n        filter: option<filter-expression>,\n        namespace: option<string>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>,\n        min-score: option<f32>,\n        max-distance: option<f32>,\n        search-params: option<list<tuple<string, string>>>\n    ) -> result<list<search-result>, vector-error>;\n    \n    /// Simple vector similarity search (convenience)\n    find-similar: func(\n        collection: string,\n        vector: vector-data,\n        limit: u32,\n        namespace: option<string>\n    ) -> result<list<search-result>, vector-error>;\n    \n    /// Batch similarity search\n    batch-search: func(\n        collection: string,\n        queries: list<search-query>,\n        limit: u32,\n        filter: option<filter-expression>,\n        namespace: option<string>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>,\n        search-params: option<list<tuple<string, string>>>\n    ) -> result<list<list<search-result>>, vector-error>;\n}\n}\n\n/// Extended search capabilities (provider-dependent)\ninterface search-extended {\n    use types.{id, vector-data, search-result, filter-expression, vector-error, metadata-value};\n    \n    /// Recommendation example types\n    variant recommendation-example {\n        vector-id(id),\n        vector-data(vector-data),\n    }\n    \n    enum recommendation-strategy {\n        average-vector,\n        best-score,\n        centroid,\n    }\n    \n    /// Context pair for discovery\n    record context-pair {\n        positive: recommendation-example,\n        negative: recommendation-example,\n    }\n    \n    /// Grouped search result\n    record grouped-search-result {\n        group-value: metadata-value,\n        results: list<search-result>,\n        group-count: u32,\n    }\n    \n    /// Recommendation-based search\n    recommend-vectors: func(\n        collection: string,\n        positive: list<recommendation-example>,\n        negative: option<list<recommendation-example>>,\n        limit: u32,\n        filter: option<filter-expression>,\n        namespace: option<string>,\n        strategy: option<recommendation-strategy>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>\n    ) -> result<list<search-result>, vector-error>;\n    \n    /// Discovery/context-based search\n    discover-vectors: func(\n        collection: string,\n        context-pairs: list<context-pair>,\n        limit: u32,\n        filter: option<filter-expression>,\n        namespace: option<string>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>\n    ) -> result<list<search-result>, vector-error>;\n    \n    /// Grouped search for diverse results\n    search-groups: func(\n        collection: string,\n        query: search.search-query,\n        group-by: string,\n        group-size: u32,\n        max-groups: u32,\n        filter: option<filter-expression>,\n        namespace: option<string>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>\n    ) -> result<list<grouped-search-result>, vector-error>;\n    \n    /// Range search within distance bounds\n    search-range: func(\n        collection: string,\n        vector: vector-data,\n        min-distance: option<f32>,\n        max-distance: f32,\n        filter: option<filter-expression>,\n        namespace: option<string>,\n        limit: option<u32>,\n        include-vectors: option<bool>,\n        include-metadata: option<bool>\n    ) -> result<list<search-result>, vector-error>;\n    \n    /// Text/document search (auto-embedding)\n    search-text: func(\n        collection: string,\n        query-text: string,\n        limit: u32,\n        filter: option<filter-expression>,\n        namespace: option<string>\n    ) -> result<list<search-result>, vector-error>;\n}\n\n/// Analytics and statistics\ninterface analytics {\n    use types.{vector-error, metadata-value, filter-expression};\n    \n    /// Collection statistics\n    record collection-stats {\n        vector-count: u64,\n        dimension: u32,\n        size-bytes: u64,\n        index-size-bytes: option<u64>,\n        namespace-stats: list<tuple<string, namespace-stats>>,\n        distance-distribution: option<distance-stats>,\n    }\n    \n    record namespace-stats {\n        vector-count: u64,\n        size-bytes: u64,\n    }\n    \n    record distance-stats {\n        min-distance: f32,\n        max-distance: f32,\n        avg-distance: f32,\n        percentiles: list<tuple<f32, f32>>,\n    }\n    \n    /// Field statistics for metadata\n    record field-stats {\n        field-name: string,\n        value-count: u64,\n        unique-values: u64,\n        null-count: u64,\n        data-type: string,\n        sample-values: list<metadata-value>,\n    }\n    \n    /// Get collection statistics\n    get-collection-stats: func(\n        collection: string,\n        namespace: option<string>\n    ) -> result<collection-stats, vector-error>;\n    \n    /// Get field statistics\n    get-field-stats: func(\n        collection: string,\n        field: string,\n        namespace: option<string>\n    ) -> result<field-stats, vector-error>;\n    \n    /// Get value distribution for a field\n    get-field-distribution: func(\n        collection: string,\n        field: string,\n        limit: option<u32>,\n        namespace: option<string>\n    ) -> result<list<tuple<metadata-value, u64>>, vector-error>;\n}\n\n/// Namespace/partition management\ninterface namespaces {\n    use types.{vector-error, metadata};\n    \n    /// Namespace information\n    record namespace-info {\n        name: string,\n        collection: string,\n        vector-count: u64,\n        size-bytes: u64,\n        created-at: option<u64>,\n        metadata: option<metadata>,\n    }\n    \n    /// Create or update namespace (upsert)\n    upsert-namespace: func(\n        collection: string,\n        namespace: string,\n        metadata: option<metadata>\n    ) -> result<namespace-info, vector-error>;\n    \n    /// List namespaces in collection\n    list-namespaces: func(collection: string) -> result<list<namespace-info>, vector-error>;\n    \n    /// Get namespace information\n    get-namespace: func(\n        collection: string,\n        namespace: string\n    ) -> result<namespace-info, vector-error>;\n    \n    /// Delete namespace and all vectors within it\n    delete-namespace: func(\n        collection: string,\n        namespace: string\n    ) -> result<_, vector-error>;\n    \n    /// Check if namespace exists\n    namespace-exists: func(\n        collection: string,\n        namespace: string\n    ) -> result<bool, vector-error>;\n}\n\n/// Connection and configuration management\ninterface connection {\n    use types.{vector-error, metadata};\n    \n    variant credentials {\n        api-key(string),\n        username-password(tuple<string, string>),\n        token(string),\n        certificate(list<u8>),\n        oauth(oauth-config),\n    }\n    \n    record oauth-config {\n        client-id: string,\n        client-secret: option<string>,\n        token-url: string,\n        scope: option<string>,\n    }\n    \n    /// Connection status\n    record connection-status {\n        connected: bool,\n        provider: option<string>,\n        endpoint: option<string>,\n        last-activity: option<u64>,\n        connection-id: option<string>,\n    }\n    \n    /// Establish connection to vector database\n    connect: func(\n        endpoint: string,\n        credentials: option<credentials>,\n        timeout-ms: option<u32>,\n        options: option<metadata>\n    ) -> result<_, vector-error>;\n    \n    /// Close connection\n    disconnect: func() -> result<_, vector-error>;\n    \n    /// Get current connection status\n    get-connection-status: func() -> result<connection-status, vector-error>;\n    \n    /// Test connection without modifying state\n    test-connection: func(\n        endpoint: string,\n        credentials: option<credentials>,\n        timeout-ms: option<u32>,\n        options: option<metadata>\n    ) -> result<bool, vector-error>;\n}",
              "url": "https://github.com/golemcloud/golem-ai/issues/21",
              "tech": [
                "go"
              ],
              "repo_name": "golem-ai",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          }
        ],
        "next_cursor": null
      }
    }
  }
}