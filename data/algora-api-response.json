{
  "result": {
    "data": {
      "json": {
        "items": [
          {
            "id": "outerbase#59",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2025-12-17T18:24:22.290Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:22.290Z",
            "created_at": "2025-12-17T18:24:22.290Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#59",
              "status": "open",
              "type": "issue",
              "number": 59,
              "title": "Database dumps do not work on large databases",
              "source": {
                "data": {
                  "id": "source-outerbase#59",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Database dumps do not work on large databases",
                  "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/59"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#59",
              "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
              "url": "https://github.com/outerbase/starbasedb/issues/59",
              "tech": [
                "go"
              ],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "outerbase#72",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2025-12-17T18:24:22.968Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:22.968Z",
            "created_at": "2025-12-17T18:24:22.968Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#72",
              "status": "open",
              "type": "issue",
              "number": 72,
              "title": "Replicate data from external source to internal source with a Plugin",
              "source": {
                "data": {
                  "id": "source-outerbase#72",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Replicate data from external source to internal source with a Plugin",
                  "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/72"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#72",
              "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
              "url": "https://github.com/outerbase/starbasedb/issues/72",
              "tech": [],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "golemcloud#2497",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "golemcloud",
              "id": "generated-golemcloud",
              "name": "Golemcloud",
              "description": "",
              "members": [],
              "display_name": "Golemcloud",
              "created_at": "2025-12-17T18:24:22.290Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/golemcloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:22.290Z",
            "created_at": "2025-12-17T18:24:22.290Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-golemcloud#2497",
              "status": "open",
              "type": "issue",
              "number": 2497,
              "title": "add pgvector types to golem rdbms postgres",
              "source": {
                "data": {
                  "id": "source-golemcloud#2497",
                  "user": {
                    "login": "justcoon",
                    "id": 5932736,
                    "node_id": "MDQ6VXNlcjU5MzI3MzY=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/5932736?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/justcoon",
                    "html_url": "https://github.com/justcoon",
                    "followers_url": "https://api.github.com/users/justcoon/followers",
                    "following_url": "https://api.github.com/users/justcoon/following{/other_user}",
                    "gists_url": "https://api.github.com/users/justcoon/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/justcoon/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/justcoon/subscriptions",
                    "organizations_url": "https://api.github.com/users/justcoon/orgs",
                    "repos_url": "https://api.github.com/users/justcoon/repos",
                    "events_url": "https://api.github.com/users/justcoon/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/justcoon/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "add pgvector types to golem rdbms postgres",
                  "body": "add [pgvector types](https://github.com/pgvector/pgvector?tab=readme-ov-file#reference) to https://github.com/golemcloud/golem/blob/main/wit/deps/golem-rdbms/postgres.wit\n\n* [vector](https://github.com/pgvector/pgvector?tab=readme-ov-file#vector-type)\n* [halfvec](https://github.com/pgvector/pgvector?tab=readme-ov-file#halfvec-type)\n* [sparsevec](https://github.com/pgvector/pgvector?tab=readme-ov-file#sparsevec-type)\n* [bit](https://github.com/pgvector/pgvector?tab=readme-ov-file#bit-type) - this is already supported\n\nwit changes:\n```wit\n  record sparse-vec {\n    dim: s32,\n    indices: list<s32>,\n    values: list<f32>\n  }\n\n  variant db-column-type {\n    // ...\n    vector,\n    halfvec,\n    sparsevec\n  } \n\n  variant db-value {\n    // ...\n    vector(list<f32>),\n    halfvec(list<f32>), \n    sparsevec(sparse-vec)\n  }\n```\nNOTE: as [wit](https://component-model.bytecodealliance.org/design/wit.html#primitive-types) do not have support for `f16`, `f32` is used in `db-value::halfvec`  wit type\n",
                  "html_url": "https://github.com/golemcloud/golem/issues/2497"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem#2497",
              "body": "add [pgvector types](https://github.com/pgvector/pgvector?tab=readme-ov-file#reference) to https://github.com/golemcloud/golem/blob/main/wit/deps/golem-rdbms/postgres.wit\n\n* [vector](https://github.com/pgvector/pgvector?tab=readme-ov-file#vector-type)\n* [halfvec](https://github.com/pgvector/pgvector?tab=readme-ov-file#halfvec-type)\n* [sparsevec](https://github.com/pgvector/pgvector?tab=readme-ov-file#sparsevec-type)\n* [bit](https://github.com/pgvector/pgvector?tab=readme-ov-file#bit-type) - this is already supported\n\nwit changes:\n```wit\n  record sparse-vec {\n    dim: s32,\n    indices: list<s32>,\n    values: list<f32>\n  }\n\n  variant db-column-type {\n    // ...\n    vector,\n    halfvec,\n    sparsevec\n  } \n\n  variant db-value {\n    // ...\n    vector(list<f32>),\n    halfvec(list<f32>), \n    sparsevec(sparse-vec)\n  }\n```\nNOTE: as [wit](https://component-model.bytecodealliance.org/design/wit.html#primitive-types) do not have support for `f16`, `f32` is used in `db-value::halfvec`  wit type\n",
              "url": "https://github.com/golemcloud/golem/issues/2497",
              "tech": [
                "go"
              ],
              "repo_name": "golem",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "golemcloud#275",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "golemcloud",
              "id": "generated-golemcloud",
              "name": "Golemcloud",
              "description": "",
              "members": [],
              "display_name": "Golemcloud",
              "created_at": "2025-12-17T18:24:23.959Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/golemcloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:23.959Z",
            "created_at": "2025-12-17T18:24:23.959Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-golemcloud#275",
              "status": "open",
              "type": "issue",
              "number": 275,
              "title": "Incorporate MCP Server into Golem CLI",
              "source": {
                "data": {
                  "id": "source-golemcloud#275",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Incorporate MCP Server into Golem CLI",
                  "body": "With a new command, Golem CLI enters serve mode:\n\n```bash\n%> golem-cli --serve --serve-port 1232\n%> golem-cli running MCP Server at port 1232\n```\n\nIn this mode, Golem CLI creates an MCP Server that exposes different commands as different tools, and exposes relevant resources (the manifest file in the current, ancestor, and children directories) as resources.\n\nWhen this ticket is completed, it should be possible to use an agent such as Claude Code to perform anything that Golem CLI can do. Moreover, all individual tools and resources must be end-to-end tested with an MCP Client that interacts with the MCP Server.\n\n[This library](https://github.com/rust-mcp-stack/rust-mcp-sdk) looks like the one to use for Rust, but perhaps there are better options available.",
                  "html_url": "https://github.com/golemcloud/golem/issues/1926"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem-cli#275",
              "body": "With a new command, Golem CLI enters serve mode:\n\n```bash\n%> golem-cli --serve --serve-port 1232\n%> golem-cli running MCP Server at port 1232\n```\n\nIn this mode, Golem CLI creates an MCP Server that exposes different commands as different tools, and exposes relevant resources (the manifest file in the current, ancestor, and children directories) as resources.\n\nWhen this ticket is completed, it should be possible to use an agent such as Claude Code to perform anything that Golem CLI can do. Moreover, all individual tools and resources must be end-to-end tested with an MCP Client that interacts with the MCP Server.\n\n[This library](https://github.com/rust-mcp-stack/rust-mcp-sdk) looks like the one to use for Rust, but perhaps there are better options available.",
              "url": "https://github.com/golemcloud/golem/issues/1926",
              "tech": [
                "go"
              ],
              "repo_name": "golem-cli",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "golemcloud#23",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "golemcloud",
              "id": "generated-golemcloud",
              "name": "Golemcloud",
              "description": "",
              "members": [],
              "display_name": "Golemcloud",
              "created_at": "2025-12-17T18:24:24.773Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/golemcloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:24.773Z",
            "created_at": "2025-12-17T18:24:24.773Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-golemcloud#23",
              "status": "open",
              "type": "issue",
              "number": 23,
              "title": "Implement Durable Text-to-Speech Provider Components for golem:tts WIT Interface",
              "source": {
                "data": {
                  "id": "source-golemcloud#23",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Implement Durable Text-to-Speech Provider Components for golem:tts WIT Interface",
                  "body": "I have attached to this ticket a WIT file that describes a generic interface for text-to-speech operations. This interface can be implemented by various providers, either by emulating features not present in a given provider, utilizing the provider's native support for a feature, or indicating an error if a particular combination is not natively supported by a provider.\n\nThe intent of this WIT specification is to allow developers of WASM components (on wasmCloud, Spin, or Golem) to leverage text-to-speech capabilities to build voice-powered applications, accessibility services, and audio content generation systems in a portable and provider-agnostic fashion.\n\nThis ticket involves constructing implementations of this WIT interface for the following providers:\n\n- **ElevenLabs**: The leading AI voice synthesis platform with comprehensive voice cloning, real-time streaming, voice conversion, and sound effects generation capabilities.\n- **AWS Polly**: Amazon's enterprise text-to-speech service with extensive language support, custom lexicons, speech marks, and asynchronous synthesis for long-form content.\n- **Google Cloud Text-to-Speech**: Google's neural voice synthesis service with WaveNet and Neural2 voices, device optimization profiles, and streaming synthesis capabilities.\n- **Deepgram Aura**: High-performance real-time TTS with session-based streaming, low-latency neural voices, and conversational AI optimization.\n\nThese implementations must be written in Rust and compilable to WASM Components (WASI 0.23 only, since Golem does not yet support WASI 0.3). The standard Rust toolchain for WASM component development can be employed (see cargo component and the Rust examples of components in this and other Golem repositories).\n\nAdditionally, these implementations should incorporate custom durability semantics using the Golem durability API and the Golem host API. This approach ensures that durability is managed at the level of individual TTS operations (voice synthesis, streaming session creation, voice cloning, batch processing), providing a higher-level and clearer operation log, which aids in debugging and monitoring. See golem:llm and golem:embed for more details and durable implementations in this same repository.\n\nThe final deliverables associated with this ticket are:\n\n- **ElevenLabs implementation**: A WASM Component (WASI 0.23), named `tts-elevenlabs.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **AWS Polly implementation**: A WASM Component (WASI 0.23), named `tts-polly.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Google Cloud TTS implementation**: A WASM Component (WASI 0.23), named `tts-google.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Deepgram Aura implementation**: A WASM Component (WASI 0.23), named `tts-deepgram.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n\n**Note**: If you have a strong recommendation to swap out one or two of these with other popular / common TTS providers (such as Azure Cognitive Services Speech, IBM Watson Text to Speech, or OpenAI TTS), then as long as you get permission beforehand, that's okay with me. However, we definitely need ElevenLabs and AWS Polly.\n\nThese components will require runtime configuration, notably API keys, endpoint URLs, authentication credentials, and provider-specific settings. For configuring this information, the components can use environment variables for now (in the future, they will use wasi-runtime-config, but Golem does not support this yet, whereas Golem has good support for environment variables).\n\nMoreover, the Rust components need to be tested within Golem to ensure compatibility with Golem 1.2.x.\n\nThis WIT has been designed by examining and comparing the APIs of ElevenLabs, AWS Polly, Google Cloud TTS, Azure Speech Services, OpenAI TTS, and Deepgram Aura. However, given there are no implementations, it is possible the provided WIT is not the optimal abstraction across all these providers. Therefore, deviations from the proposed design can be made. However, to be accepted, any deviation must be fully justified and deemed by Golem core contributors to be an improvement from the original specification.\n\n## Implementation Guidelines\n\nEach provider implementation should handle the following key mapping considerations:\n\n- **Voice Management**: Map the unified voice resource to provider-specific voice identifiers, handle voice discovery and metadata appropriately for each provider's voice catalog structure\n- **Audio Format Conversion**: Implement native audio format support where available, or provide format conversion for unsupported output formats using audio processing libraries\n- **Streaming Implementation**: Utilize native streaming APIs where supported (ElevenLabs, Deepgram), or implement chunk-based synthesis for providers without native streaming support\n- **Authentication Handling**: Implement appropriate authentication mechanisms (API keys, OAuth, service accounts) per provider requirements\n- **Feature Availability**: Route advanced features (voice cloning, sound effects, speech marks) through provider-native APIs where supported, or return `unsupported-operation` errors for unavailable features\n- **Error Mapping**: Map provider-specific HTTP errors and API responses to the unified `tts-error` enumeration with appropriate context preservation\n- **Rate Limiting**: Handle provider-specific rate limits and quota management, implementing appropriate retry logic and error reporting\n- **Long-form Content**: Implement efficient handling of long-form synthesis using provider-native async operations (AWS Polly) or intelligent chunking strategies\n\n## Testing Requirements\n\nEach implementation must include comprehensive test suites covering:\n- Basic synthesis operations (text-to-speech with various voices and configurations)\n- Voice discovery and metadata retrieval\n- Streaming synthesis lifecycle (session creation, chunk processing, cleanup)\n- Advanced feature testing (voice cloning, sound effects, custom pronunciations where supported)\n- Audio format validation and quality verification\n- Authentication and authorization scenarios\n- Error handling for unsupported operations and malformed inputs\n- Rate limiting and quota management behavior\n- Connection management and retry logic\n- Long-form content synthesis (>5000 characters)\n- Durability semantics verification across operation boundaries\n- Provider-specific feature utilization (lexicons for Polly, voice settings for ElevenLabs, etc.)\n\n## Configuration Requirements\n\nEach implementation should support the following environment variables:\n\n### Common Configuration\n- `TTS_PROVIDER_ENDPOINT`: Custom endpoint URL (for enterprise/regional deployments)\n- `TTS_PROVIDER_TIMEOUT`: Request timeout in seconds (default: 30)\n- `TTS_PROVIDER_MAX_RETRIES`: Maximum retry attempts (default: 3)\n- `TTS_PROVIDER_LOG_LEVEL`: Logging verbosity (debug, info, warn, error)\n\n### Provider-Specific Configuration\n- **ElevenLabs**: `ELEVENLABS_API_KEY`, `ELEVENLABS_MODEL_VERSION`\n- **AWS Polly**: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `AWS_SESSION_TOKEN`\n- **Google Cloud**: `GOOGLE_APPLICATION_CREDENTIALS`, `GOOGLE_CLOUD_PROJECT`\n- **Deepgram**: `DEEPGRAM_API_KEY`, `DEEPGRAM_API_VERSION`\n\n```wit\npackage golem:tts@1.0.0;\n\n/// Core types and error handling for universal text-to-speech\ninterface types {\n    /// Comprehensive error types covering all TTS operations\n    variant tts-error {\n        /// Input validation errors\n        invalid-text(string),\n        text-too-long(u32),\n        invalid-ssml(string),\n        unsupported-language(string),\n        \n        /// Voice and model errors\n        voice-not-found(string),\n        model-not-found(string),\n        voice-unavailable(string),\n        \n        /// Authentication and authorization\n        unauthorized(string),\n        access-denied(string),\n        \n        /// Resource and quota limits\n        quota-exceeded(quota-info),\n        rate-limited(u32),\n        insufficient-credits,\n        \n        /// Operation errors\n        synthesis-failed(string),\n        unsupported-operation(string),\n        invalid-configuration(string),\n        \n        /// Service errors\n        service-unavailable(string),\n        network-error(string),\n        internal-error(string),\n        \n        /// Storage errors (for async operations)\n        invalid-storage-location(string),\n        storage-access-denied(string),\n    }\n\n    record quota-info {\n        used: u32,\n        limit: u32,\n        reset-time: u64,\n        unit: quota-unit,\n    }\n\n    enum quota-unit {\n        characters,\n        requests,\n        seconds,\n        credits,\n    }\n\n    /// Language identification using BCP 47 codes\n    type language-code = string;\n\n    /// Voice gender classification\n    enum voice-gender {\n        male,\n        female,\n        neutral,\n    }\n\n    /// Voice quality tiers\n    enum voice-quality {\n        standard,\n        premium,\n        neural,\n        studio,\n    }\n\n    /// Text input types\n    enum text-type {\n        plain,\n        ssml,\n    }\n\n    /// Audio output formats\n    enum audio-format {\n        mp3,\n        wav,\n        pcm,\n        ogg-opus,\n        aac,\n        flac,\n        mulaw,\n        alaw,\n    }\n\n    /// Audio quality settings\n    record audio-config {\n        format: audio-format,\n        sample-rate: option<u32>,\n        bit-rate: option<u32>,\n        channels: option<u8>,\n    }\n\n    /// Voice synthesis parameters\n    record voice-settings {\n        /// Speaking rate (0.25 to 4.0, default 1.0)\n        speed: option<f32>,\n        /// Pitch adjustment in semitones (-20.0 to 20.0, default 0.0)\n        pitch: option<f32>,\n        /// Volume gain in dB (-96.0 to 16.0, default 0.0)\n        volume: option<f32>,\n        /// Voice stability (0.0 to 1.0, provider-specific)\n        stability: option<f32>,\n        /// Similarity to original (0.0 to 1.0, provider-specific)\n        similarity: option<f32>,\n        /// Style exaggeration (0.0 to 1.0, provider-specific)\n        style: option<f32>,\n    }\n\n    /// Audio effects and device optimization\n    flags audio-effects {\n        telephone-quality,\n        headphone-optimized,\n        speaker-optimized,\n        car-audio-optimized,\n        noise-reduction,\n        bass-boost,\n        treble-boost,\n    }\n\n    /// Input text with metadata\n    record text-input {\n        content: string,\n        text-type: text-type,\n        language: option<language-code>,\n    }\n\n    /// Complete synthesis result\n    record synthesis-result {\n        audio-data: list<u8>,\n        metadata: synthesis-metadata,\n    }\n\n    /// Metadata about synthesized audio\n    record synthesis-metadata {\n        duration-seconds: f32,\n        character-count: u32,\n        word-count: u32,\n        audio-size-bytes: u32,\n        request-id: string,\n        provider-info: option<string>,\n    }\n\n    /// Streaming audio chunk\n    record audio-chunk {\n        data: list<u8>,\n        sequence-number: u32,\n        is-final: bool,\n        timing-info: option<timing-info>,\n    }\n\n    /// Timing and synchronization information\n    record timing-info {\n        start-time-seconds: f32,\n        end-time-seconds: option<f32>,\n        text-offset: option<u32>,\n        mark-type: option<timing-mark-type>,\n    }\n\n    enum timing-mark-type {\n        word,\n        sentence,\n        paragraph,\n        ssml-mark,\n        viseme,\n    }\n\n\n}\n\n/// Voice discovery and management\ninterface voices {\n    use types.{tts-error, language-code, voice-gender, voice-quality};\n\n    /// Represents a voice that can be used for speech synthesis\n    resource voice {\n        /// Get voice identification\n        get-id: func() -> string;\n        get-name: func() -> string;\n        get-provider-id: func() -> option<string>;\n        \n        /// Get voice characteristics\n        get-language: func() -> language-code;\n        get-additional-languages: func() -> list<language-code>;\n        get-gender: func() -> voice-gender;\n        get-quality: func() -> voice-quality;\n        get-description: func() -> option<string>;\n        \n        /// Voice capabilities\n        supports-ssml: func() -> bool;\n        get-sample-rates: func() -> list<u32>;\n        get-supported-formats: func() -> list<types.audio-format>;\n        \n        /// Voice management (may return unsupported-operation)\n        update-settings: func(settings: types.voice-settings) -> result<_, tts-error>;\n        delete: func() -> result<_, tts-error>;\n        clone: func() -> result<voice, tts-error>;\n        \n        /// Preview voice with sample text\n        preview: func(text: string) -> result<list<u8>, tts-error>;\n    }\n\n    /// Voice search and filtering\n    record voice-filter {\n        language: option<language-code>,\n        gender: option<voice-gender>,\n        quality: option<voice-quality>,\n        supports-ssml: option<bool>,\n        provider: option<string>,\n        search-query: option<string>,\n    }\n\n    /// Detailed voice information\n    record voice-info {\n        id: string,\n        name: string,\n        language: language-code,\n        additional-languages: list<language-code>,\n        gender: voice-gender,\n        quality: voice-quality,\n        description: option<string>,\n        provider: string,\n        sample-rate: u32,\n        is-custom: bool,\n        is-cloned: bool,\n        preview-url: option<string>,\n        use-cases: list<string>,\n    }\n\n    /// Resource-based iterator for voice results\n    resource voice-results {\n        /// Check if more voices are available\n        has-more: func() -> bool;\n        \n        /// Get next batch of voices\n        get-next: func() -> result<list<voice-info>, tts-error>;\n        \n        /// Get total count if available\n        get-total-count: func() -> option<u32>;\n    }\n\n    /// List available voices with filtering and pagination\n    list-voices: func(\n        filter: option<voice-filter>\n    ) -> result<voice-results, tts-error>;\n\n    /// Get specific voice by ID\n    get-voice: func(voice-id: string) -> result<voice, tts-error>;\n\n    /// Search voices by characteristics\n    search-voices: func(\n        query: string,\n        filter: option<voice-filter>\n    ) -> result<list<voice-info>, tts-error>;\n\n    /// Get supported languages\n    list-languages: func() -> result<list<language-info>, tts-error>;\n\n    record language-info {\n        code: language-code,\n        name: string,\n        native-name: string,\n        voice-count: u32,\n    }\n}\n\n/// Core text-to-speech synthesis operations\ninterface synthesis {\n    use types.{\n        text-input, audio-config, voice-settings, audio-effects,\n        synthesis-result, tts-error, timing-info\n    };\n    use voices.{voice};\n\n    /// Synthesis configuration options\n    record synthesis-options {\n        audio-config: option<audio-config>,\n        voice-settings: option<voice-settings>,\n        audio-effects: option<audio-effects>,\n        enable-timing: option<bool>,\n        enable-word-timing: option<bool>,\n        seed: option<u32>,\n        model-version: option<string>,\n        context: option<synthesis-context>,\n    }\n\n    /// Context for better synthesis quality\n    record synthesis-context {\n        previous-text: option<string>,\n        next-text: option<string>,\n        topic: option<string>,\n        emotion: option<string>,\n        speaking-style: option<string>,\n    }\n\n    /// Convert text to speech (removed async)\n    synthesize: func(\n        input: text-input,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-result, tts-error>;\n\n    /// Batch synthesis for multiple inputs (removed async)\n    synthesize-batch: func(\n        inputs: list<text-input>,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<list<synthesis-result>, tts-error>;\n\n    /// Get timing information without audio synthesis\n    get-timing-marks: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<list<timing-info>, tts-error>;\n\n    /// Validate text before synthesis\n    validate-input: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<validation-result, tts-error>;\n\n    record validation-result {\n        is-valid: bool,\n        character-count: u32,\n        estimated-duration: option<f32>,\n        warnings: list<string>,\n        errors: list<string>,\n    }\n}\n\n/// Real-time streaming synthesis\ninterface streaming {\n    use types.{\n        text-input, audio-config, voice-settings, audio-chunk,\n        tts-error, timing-info\n    };\n    use voices.{voice};\n    use synthesis.{synthesis-options};\n\n    /// Streaming synthesis session\n    resource synthesis-stream {\n        /// Send text for synthesis (can be called multiple times)\n        send-text: func(input: text-input) -> result<_, tts-error>;\n        \n        /// Signal end of input and flush remaining audio\n        finish: func() -> result<_, tts-error>;\n        \n        /// Receive next audio chunk (non-blocking)\n        receive-chunk: func() -> result<option<audio-chunk>, tts-error>;\n        \n        /// Check if more chunks are available\n        has-pending-audio: func() -> bool;\n        \n        /// Get current stream status\n        get-status: func() -> stream-status;\n        \n        /// Close stream and clean up resources\n        close: func();\n    }\n\n    enum stream-status {\n        ready,\n        processing,\n        finished,\n        error,\n        closed,\n    }\n\n    /// Create streaming synthesis session\n    create-stream: func(\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-stream, tts-error>;\n\n    /// Real-time voice conversion streaming\n    create-voice-conversion-stream: func(\n        target-voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<voice-conversion-stream, tts-error>;\n\n    resource voice-conversion-stream {\n        /// Send input audio chunks\n        send-audio: func(audio-data: list<u8>) -> result<_, tts-error>;\n        \n        /// Receive converted audio chunks\n        receive-converted: func() -> result<option<audio-chunk>, tts-error>;\n        \n        finish: func() -> result<_, tts-error>;\n        close: func();\n    }\n}\n\n/// Advanced TTS features and voice manipulation\ninterface advanced {\n    use types.{tts-error, audio-config, language-code};\n    use voices.{voice};\n\n    /// Voice cloning and creation (removed async)\n    create-voice-clone: func(\n        name: string,\n        audio-samples: list<audio-sample>,\n        description: option<string>\n    ) -> result<voice, tts-error>;\n\n    record audio-sample {\n        data: list<u8>,\n        transcript: option<string>,\n        quality-rating: option<u8>,\n    }\n\n    /// Design synthetic voice (removed async)\n    design-voice: func(\n        name: string,\n        characteristics: voice-design-params\n    ) -> result<voice, tts-error>;\n\n    record voice-design-params {\n        gender: types.voice-gender,\n        age-category: age-category,\n        accent: string,\n        personality-traits: list<string>,\n        reference-voice: option<string>,\n    }\n\n    enum age-category {\n        child,\n        young-adult,\n        middle-aged,\n        elderly,\n    }\n\n    /// Voice-to-voice conversion (removed async)\n    convert-voice: func(\n        input-audio: list<u8>,\n        target-voice: borrow<voice>,\n        preserve-timing: option<bool>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Generate sound effects from text description (removed async)\n    generate-sound-effect: func(\n        description: string,\n        duration-seconds: option<f32>,\n        style-influence: option<f32>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Custom pronunciation management\n    resource pronunciation-lexicon {\n        get-name: func() -> string;\n        get-language: func() -> language-code;\n        get-entry-count: func() -> u32;\n        \n        /// Add pronunciation rule\n        add-entry: func(word: string, pronunciation: string) -> result<_, tts-error>;\n        \n        /// Remove pronunciation rule\n        remove-entry: func(word: string) -> result<_, tts-error>;\n        \n        /// Export lexicon content\n        export-content: func() -> result<string, tts-error>;\n    }\n\n    /// Create custom pronunciation lexicon\n    create-lexicon: func(\n        name: string,\n        language: language-code,\n        entries: option<list<pronunciation-entry>>\n    ) -> result<pronunciation-lexicon, tts-error>;\n\n    record pronunciation-entry {\n        word: string,\n        pronunciation: string,\n        part-of-speech: option<string>,\n    }\n\n    /// Long-form content synthesis with optimization (removed async)\n    synthesize-long-form: func(\n        content: string,\n        voice: borrow<voice>,\n        output-location: string,\n        chapter-breaks: option<list<u32>>\n    ) -> result<long-form-operation, tts-error>;\n\n    resource long-form-operation {\n        get-status: func() -> operation-status;\n        get-progress: func() -> f32;\n        cancel: func() -> result<_, tts-error>;\n        get-result: func() -> result<long-form-result, tts-error>;\n    }\n\n    enum operation-status {\n        pending,\n        processing,\n        completed,\n        failed,\n        cancelled,\n    }\n\n    record long-form-result {\n        output-location: string,\n        total-duration: f32,\n        chapter-durations: option<list<f32>>,\n        metadata: types.synthesis-metadata,\n    }\n}\n```",
                  "html_url": "https://github.com/golemcloud/golem-ai/issues/23"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem-ai#23",
              "body": "I have attached to this ticket a WIT file that describes a generic interface for text-to-speech operations. This interface can be implemented by various providers, either by emulating features not present in a given provider, utilizing the provider's native support for a feature, or indicating an error if a particular combination is not natively supported by a provider.\n\nThe intent of this WIT specification is to allow developers of WASM components (on wasmCloud, Spin, or Golem) to leverage text-to-speech capabilities to build voice-powered applications, accessibility services, and audio content generation systems in a portable and provider-agnostic fashion.\n\nThis ticket involves constructing implementations of this WIT interface for the following providers:\n\n- **ElevenLabs**: The leading AI voice synthesis platform with comprehensive voice cloning, real-time streaming, voice conversion, and sound effects generation capabilities.\n- **AWS Polly**: Amazon's enterprise text-to-speech service with extensive language support, custom lexicons, speech marks, and asynchronous synthesis for long-form content.\n- **Google Cloud Text-to-Speech**: Google's neural voice synthesis service with WaveNet and Neural2 voices, device optimization profiles, and streaming synthesis capabilities.\n- **Deepgram Aura**: High-performance real-time TTS with session-based streaming, low-latency neural voices, and conversational AI optimization.\n\nThese implementations must be written in Rust and compilable to WASM Components (WASI 0.23 only, since Golem does not yet support WASI 0.3). The standard Rust toolchain for WASM component development can be employed (see cargo component and the Rust examples of components in this and other Golem repositories).\n\nAdditionally, these implementations should incorporate custom durability semantics using the Golem durability API and the Golem host API. This approach ensures that durability is managed at the level of individual TTS operations (voice synthesis, streaming session creation, voice cloning, batch processing), providing a higher-level and clearer operation log, which aids in debugging and monitoring. See golem:llm and golem:embed for more details and durable implementations in this same repository.\n\nThe final deliverables associated with this ticket are:\n\n- **ElevenLabs implementation**: A WASM Component (WASI 0.23), named `tts-elevenlabs.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **AWS Polly implementation**: A WASM Component (WASI 0.23), named `tts-polly.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Google Cloud TTS implementation**: A WASM Component (WASI 0.23), named `tts-google.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Deepgram Aura implementation**: A WASM Component (WASI 0.23), named `tts-deepgram.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n\n**Note**: If you have a strong recommendation to swap out one or two of these with other popular / common TTS providers (such as Azure Cognitive Services Speech, IBM Watson Text to Speech, or OpenAI TTS), then as long as you get permission beforehand, that's okay with me. However, we definitely need ElevenLabs and AWS Polly.\n\nThese components will require runtime configuration, notably API keys, endpoint URLs, authentication credentials, and provider-specific settings. For configuring this information, the components can use environment variables for now (in the future, they will use wasi-runtime-config, but Golem does not support this yet, whereas Golem has good support for environment variables).\n\nMoreover, the Rust components need to be tested within Golem to ensure compatibility with Golem 1.2.x.\n\nThis WIT has been designed by examining and comparing the APIs of ElevenLabs, AWS Polly, Google Cloud TTS, Azure Speech Services, OpenAI TTS, and Deepgram Aura. However, given there are no implementations, it is possible the provided WIT is not the optimal abstraction across all these providers. Therefore, deviations from the proposed design can be made. However, to be accepted, any deviation must be fully justified and deemed by Golem core contributors to be an improvement from the original specification.\n\n## Implementation Guidelines\n\nEach provider implementation should handle the following key mapping considerations:\n\n- **Voice Management**: Map the unified voice resource to provider-specific voice identifiers, handle voice discovery and metadata appropriately for each provider's voice catalog structure\n- **Audio Format Conversion**: Implement native audio format support where available, or provide format conversion for unsupported output formats using audio processing libraries\n- **Streaming Implementation**: Utilize native streaming APIs where supported (ElevenLabs, Deepgram), or implement chunk-based synthesis for providers without native streaming support\n- **Authentication Handling**: Implement appropriate authentication mechanisms (API keys, OAuth, service accounts) per provider requirements\n- **Feature Availability**: Route advanced features (voice cloning, sound effects, speech marks) through provider-native APIs where supported, or return `unsupported-operation` errors for unavailable features\n- **Error Mapping**: Map provider-specific HTTP errors and API responses to the unified `tts-error` enumeration with appropriate context preservation\n- **Rate Limiting**: Handle provider-specific rate limits and quota management, implementing appropriate retry logic and error reporting\n- **Long-form Content**: Implement efficient handling of long-form synthesis using provider-native async operations (AWS Polly) or intelligent chunking strategies\n\n## Testing Requirements\n\nEach implementation must include comprehensive test suites covering:\n- Basic synthesis operations (text-to-speech with various voices and configurations)\n- Voice discovery and metadata retrieval\n- Streaming synthesis lifecycle (session creation, chunk processing, cleanup)\n- Advanced feature testing (voice cloning, sound effects, custom pronunciations where supported)\n- Audio format validation and quality verification\n- Authentication and authorization scenarios\n- Error handling for unsupported operations and malformed inputs\n- Rate limiting and quota management behavior\n- Connection management and retry logic\n- Long-form content synthesis (>5000 characters)\n- Durability semantics verification across operation boundaries\n- Provider-specific feature utilization (lexicons for Polly, voice settings for ElevenLabs, etc.)\n\n## Configuration Requirements\n\nEach implementation should support the following environment variables:\n\n### Common Configuration\n- `TTS_PROVIDER_ENDPOINT`: Custom endpoint URL (for enterprise/regional deployments)\n- `TTS_PROVIDER_TIMEOUT`: Request timeout in seconds (default: 30)\n- `TTS_PROVIDER_MAX_RETRIES`: Maximum retry attempts (default: 3)\n- `TTS_PROVIDER_LOG_LEVEL`: Logging verbosity (debug, info, warn, error)\n\n### Provider-Specific Configuration\n- **ElevenLabs**: `ELEVENLABS_API_KEY`, `ELEVENLABS_MODEL_VERSION`\n- **AWS Polly**: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `AWS_SESSION_TOKEN`\n- **Google Cloud**: `GOOGLE_APPLICATION_CREDENTIALS`, `GOOGLE_CLOUD_PROJECT`\n- **Deepgram**: `DEEPGRAM_API_KEY`, `DEEPGRAM_API_VERSION`\n\n```wit\npackage golem:tts@1.0.0;\n\n/// Core types and error handling for universal text-to-speech\ninterface types {\n    /// Comprehensive error types covering all TTS operations\n    variant tts-error {\n        /// Input validation errors\n        invalid-text(string),\n        text-too-long(u32),\n        invalid-ssml(string),\n        unsupported-language(string),\n        \n        /// Voice and model errors\n        voice-not-found(string),\n        model-not-found(string),\n        voice-unavailable(string),\n        \n        /// Authentication and authorization\n        unauthorized(string),\n        access-denied(string),\n        \n        /// Resource and quota limits\n        quota-exceeded(quota-info),\n        rate-limited(u32),\n        insufficient-credits,\n        \n        /// Operation errors\n        synthesis-failed(string),\n        unsupported-operation(string),\n        invalid-configuration(string),\n        \n        /// Service errors\n        service-unavailable(string),\n        network-error(string),\n        internal-error(string),\n        \n        /// Storage errors (for async operations)\n        invalid-storage-location(string),\n        storage-access-denied(string),\n    }\n\n    record quota-info {\n        used: u32,\n        limit: u32,\n        reset-time: u64,\n        unit: quota-unit,\n    }\n\n    enum quota-unit {\n        characters,\n        requests,\n        seconds,\n        credits,\n    }\n\n    /// Language identification using BCP 47 codes\n    type language-code = string;\n\n    /// Voice gender classification\n    enum voice-gender {\n        male,\n        female,\n        neutral,\n    }\n\n    /// Voice quality tiers\n    enum voice-quality {\n        standard,\n        premium,\n        neural,\n        studio,\n    }\n\n    /// Text input types\n    enum text-type {\n        plain,\n        ssml,\n    }\n\n    /// Audio output formats\n    enum audio-format {\n        mp3,\n        wav,\n        pcm,\n        ogg-opus,\n        aac,\n        flac,\n        mulaw,\n        alaw,\n    }\n\n    /// Audio quality settings\n    record audio-config {\n        format: audio-format,\n        sample-rate: option<u32>,\n        bit-rate: option<u32>,\n        channels: option<u8>,\n    }\n\n    /// Voice synthesis parameters\n    record voice-settings {\n        /// Speaking rate (0.25 to 4.0, default 1.0)\n        speed: option<f32>,\n        /// Pitch adjustment in semitones (-20.0 to 20.0, default 0.0)\n        pitch: option<f32>,\n        /// Volume gain in dB (-96.0 to 16.0, default 0.0)\n        volume: option<f32>,\n        /// Voice stability (0.0 to 1.0, provider-specific)\n        stability: option<f32>,\n        /// Similarity to original (0.0 to 1.0, provider-specific)\n        similarity: option<f32>,\n        /// Style exaggeration (0.0 to 1.0, provider-specific)\n        style: option<f32>,\n    }\n\n    /// Audio effects and device optimization\n    flags audio-effects {\n        telephone-quality,\n        headphone-optimized,\n        speaker-optimized,\n        car-audio-optimized,\n        noise-reduction,\n        bass-boost,\n        treble-boost,\n    }\n\n    /// Input text with metadata\n    record text-input {\n        content: string,\n        text-type: text-type,\n        language: option<language-code>,\n    }\n\n    /// Complete synthesis result\n    record synthesis-result {\n        audio-data: list<u8>,\n        metadata: synthesis-metadata,\n    }\n\n    /// Metadata about synthesized audio\n    record synthesis-metadata {\n        duration-seconds: f32,\n        character-count: u32,\n        word-count: u32,\n        audio-size-bytes: u32,\n        request-id: string,\n        provider-info: option<string>,\n    }\n\n    /// Streaming audio chunk\n    record audio-chunk {\n        data: list<u8>,\n        sequence-number: u32,\n        is-final: bool,\n        timing-info: option<timing-info>,\n    }\n\n    /// Timing and synchronization information\n    record timing-info {\n        start-time-seconds: f32,\n        end-time-seconds: option<f32>,\n        text-offset: option<u32>,\n        mark-type: option<timing-mark-type>,\n    }\n\n    enum timing-mark-type {\n        word,\n        sentence,\n        paragraph,\n        ssml-mark,\n        viseme,\n    }\n\n\n}\n\n/// Voice discovery and management\ninterface voices {\n    use types.{tts-error, language-code, voice-gender, voice-quality};\n\n    /// Represents a voice that can be used for speech synthesis\n    resource voice {\n        /// Get voice identification\n        get-id: func() -> string;\n        get-name: func() -> string;\n        get-provider-id: func() -> option<string>;\n        \n        /// Get voice characteristics\n        get-language: func() -> language-code;\n        get-additional-languages: func() -> list<language-code>;\n        get-gender: func() -> voice-gender;\n        get-quality: func() -> voice-quality;\n        get-description: func() -> option<string>;\n        \n        /// Voice capabilities\n        supports-ssml: func() -> bool;\n        get-sample-rates: func() -> list<u32>;\n        get-supported-formats: func() -> list<types.audio-format>;\n        \n        /// Voice management (may return unsupported-operation)\n        update-settings: func(settings: types.voice-settings) -> result<_, tts-error>;\n        delete: func() -> result<_, tts-error>;\n        clone: func() -> result<voice, tts-error>;\n        \n        /// Preview voice with sample text\n        preview: func(text: string) -> result<list<u8>, tts-error>;\n    }\n\n    /// Voice search and filtering\n    record voice-filter {\n        language: option<language-code>,\n        gender: option<voice-gender>,\n        quality: option<voice-quality>,\n        supports-ssml: option<bool>,\n        provider: option<string>,\n        search-query: option<string>,\n    }\n\n    /// Detailed voice information\n    record voice-info {\n        id: string,\n        name: string,\n        language: language-code,\n        additional-languages: list<language-code>,\n        gender: voice-gender,\n        quality: voice-quality,\n        description: option<string>,\n        provider: string,\n        sample-rate: u32,\n        is-custom: bool,\n        is-cloned: bool,\n        preview-url: option<string>,\n        use-cases: list<string>,\n    }\n\n    /// Resource-based iterator for voice results\n    resource voice-results {\n        /// Check if more voices are available\n        has-more: func() -> bool;\n        \n        /// Get next batch of voices\n        get-next: func() -> result<list<voice-info>, tts-error>;\n        \n        /// Get total count if available\n        get-total-count: func() -> option<u32>;\n    }\n\n    /// List available voices with filtering and pagination\n    list-voices: func(\n        filter: option<voice-filter>\n    ) -> result<voice-results, tts-error>;\n\n    /// Get specific voice by ID\n    get-voice: func(voice-id: string) -> result<voice, tts-error>;\n\n    /// Search voices by characteristics\n    search-voices: func(\n        query: string,\n        filter: option<voice-filter>\n    ) -> result<list<voice-info>, tts-error>;\n\n    /// Get supported languages\n    list-languages: func() -> result<list<language-info>, tts-error>;\n\n    record language-info {\n        code: language-code,\n        name: string,\n        native-name: string,\n        voice-count: u32,\n    }\n}\n\n/// Core text-to-speech synthesis operations\ninterface synthesis {\n    use types.{\n        text-input, audio-config, voice-settings, audio-effects,\n        synthesis-result, tts-error, timing-info\n    };\n    use voices.{voice};\n\n    /// Synthesis configuration options\n    record synthesis-options {\n        audio-config: option<audio-config>,\n        voice-settings: option<voice-settings>,\n        audio-effects: option<audio-effects>,\n        enable-timing: option<bool>,\n        enable-word-timing: option<bool>,\n        seed: option<u32>,\n        model-version: option<string>,\n        context: option<synthesis-context>,\n    }\n\n    /// Context for better synthesis quality\n    record synthesis-context {\n        previous-text: option<string>,\n        next-text: option<string>,\n        topic: option<string>,\n        emotion: option<string>,\n        speaking-style: option<string>,\n    }\n\n    /// Convert text to speech (removed async)\n    synthesize: func(\n        input: text-input,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-result, tts-error>;\n\n    /// Batch synthesis for multiple inputs (removed async)\n    synthesize-batch: func(\n        inputs: list<text-input>,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<list<synthesis-result>, tts-error>;\n\n    /// Get timing information without audio synthesis\n    get-timing-marks: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<list<timing-info>, tts-error>;\n\n    /// Validate text before synthesis\n    validate-input: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<validation-result, tts-error>;\n\n    record validation-result {\n        is-valid: bool,\n        character-count: u32,\n        estimated-duration: option<f32>,\n        warnings: list<string>,\n        errors: list<string>,\n    }\n}\n\n/// Real-time streaming synthesis\ninterface streaming {\n    use types.{\n        text-input, audio-config, voice-settings, audio-chunk,\n        tts-error, timing-info\n    };\n    use voices.{voice};\n    use synthesis.{synthesis-options};\n\n    /// Streaming synthesis session\n    resource synthesis-stream {\n        /// Send text for synthesis (can be called multiple times)\n        send-text: func(input: text-input) -> result<_, tts-error>;\n        \n        /// Signal end of input and flush remaining audio\n        finish: func() -> result<_, tts-error>;\n        \n        /// Receive next audio chunk (non-blocking)\n        receive-chunk: func() -> result<option<audio-chunk>, tts-error>;\n        \n        /// Check if more chunks are available\n        has-pending-audio: func() -> bool;\n        \n        /// Get current stream status\n        get-status: func() -> stream-status;\n        \n        /// Close stream and clean up resources\n        close: func();\n    }\n\n    enum stream-status {\n        ready,\n        processing,\n        finished,\n        error,\n        closed,\n    }\n\n    /// Create streaming synthesis session\n    create-stream: func(\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-stream, tts-error>;\n\n    /// Real-time voice conversion streaming\n    create-voice-conversion-stream: func(\n        target-voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<voice-conversion-stream, tts-error>;\n\n    resource voice-conversion-stream {\n        /// Send input audio chunks\n        send-audio: func(audio-data: list<u8>) -> result<_, tts-error>;\n        \n        /// Receive converted audio chunks\n        receive-converted: func() -> result<option<audio-chunk>, tts-error>;\n        \n        finish: func() -> result<_, tts-error>;\n        close: func();\n    }\n}\n\n/// Advanced TTS features and voice manipulation\ninterface advanced {\n    use types.{tts-error, audio-config, language-code};\n    use voices.{voice};\n\n    /// Voice cloning and creation (removed async)\n    create-voice-clone: func(\n        name: string,\n        audio-samples: list<audio-sample>,\n        description: option<string>\n    ) -> result<voice, tts-error>;\n\n    record audio-sample {\n        data: list<u8>,\n        transcript: option<string>,\n        quality-rating: option<u8>,\n    }\n\n    /// Design synthetic voice (removed async)\n    design-voice: func(\n        name: string,\n        characteristics: voice-design-params\n    ) -> result<voice, tts-error>;\n\n    record voice-design-params {\n        gender: types.voice-gender,\n        age-category: age-category,\n        accent: string,\n        personality-traits: list<string>,\n        reference-voice: option<string>,\n    }\n\n    enum age-category {\n        child,\n        young-adult,\n        middle-aged,\n        elderly,\n    }\n\n    /// Voice-to-voice conversion (removed async)\n    convert-voice: func(\n        input-audio: list<u8>,\n        target-voice: borrow<voice>,\n        preserve-timing: option<bool>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Generate sound effects from text description (removed async)\n    generate-sound-effect: func(\n        description: string,\n        duration-seconds: option<f32>,\n        style-influence: option<f32>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Custom pronunciation management\n    resource pronunciation-lexicon {\n        get-name: func() -> string;\n        get-language: func() -> language-code;\n        get-entry-count: func() -> u32;\n        \n        /// Add pronunciation rule\n        add-entry: func(word: string, pronunciation: string) -> result<_, tts-error>;\n        \n        /// Remove pronunciation rule\n        remove-entry: func(word: string) -> result<_, tts-error>;\n        \n        /// Export lexicon content\n        export-content: func() -> result<string, tts-error>;\n    }\n\n    /// Create custom pronunciation lexicon\n    create-lexicon: func(\n        name: string,\n        language: language-code,\n        entries: option<list<pronunciation-entry>>\n    ) -> result<pronunciation-lexicon, tts-error>;\n\n    record pronunciation-entry {\n        word: string,\n        pronunciation: string,\n        part-of-speech: option<string>,\n    }\n\n    /// Long-form content synthesis with optimization (removed async)\n    synthesize-long-form: func(\n        content: string,\n        voice: borrow<voice>,\n        output-location: string,\n        chapter-breaks: option<list<u32>>\n    ) -> result<long-form-operation, tts-error>;\n\n    resource long-form-operation {\n        get-status: func() -> operation-status;\n        get-progress: func() -> f32;\n        cancel: func() -> result<_, tts-error>;\n        get-result: func() -> result<long-form-result, tts-error>;\n    }\n\n    enum operation-status {\n        pending,\n        processing,\n        completed,\n        failed,\n        cancelled,\n    }\n\n    record long-form-result {\n        output-location: string,\n        total-duration: f32,\n        chapter-durations: option<list<f32>>,\n        metadata: types.synthesis-metadata,\n    }\n}\n```",
              "url": "https://github.com/golemcloud/golem-ai/issues/23",
              "tech": [
                "go"
              ],
              "repo_name": "golem-ai",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#516",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-17T18:24:14.792Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:14.792Z",
            "created_at": "2025-12-17T18:24:14.792Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#516",
              "status": "open",
              "type": "issue",
              "number": 516,
              "title": "Finalize Patch & Diffing",
              "source": {
                "data": {
                  "id": "source-ZIO#516",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Finalize Patch & Diffing",
                  "body": "# Algebraic Patch/Diff System for ZIO Schema 2\n\n## Overview\n\nImplement a pure, algebraic patch/diff system for ZIO Schema 2 that represents structural changes as first-class, serializable data. The system provides a typed API (`Patch[A]`) built on an untyped core (`DynamicPatch`) that operates on `DynamicValue`.\n\nBelow is a rough outline or sketch of the design of patching & diffing, subject to revision by the implementor based on technical feasibility considerations.\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed patch (user-facing API)\ncase class Patch[A](dynamicPatch: DynamicPatch, schema: Schema[A]) {\n  /** Apply patch with specified mode */\n  def apply(value: A, mode: PatchMode = PatchMode.Strict): Either[SchemaError, A]\n  \n  /** Compose patches sequentially (monoid operation) */\n  def ++(that: Patch[A]): Patch[A]\n}\n\n// Untyped patch (operates on DynamicValue)\ncase class DynamicPatch(ops: Vector[DynamicPatchOp]) {\n  /** Apply to dynamic value */\n  def apply(value: DynamicValue, mode: PatchMode): Either[SchemaError, DynamicValue]\n  \n  /** Compose patches */\n  def ++(that: DynamicPatch): DynamicPatch\n}\n```\n\n### Operations\n\n```scala\ncase class DynamicPatchOp(optic: DynamicOptic, operation: Operation)\n\nsealed trait Operation\nobject Operation {\n  case class Set(value: DynamicValue) extends Operation\n  case class PrimitiveDelta(op: PrimitiveOp) extends Operation\n  case class SequenceEdit(ops: Vector[SeqOp]) extends Operation\n  case class MapEdit(ops: Vector[MapOp]) extends Operation\n}\n```\n\n## Typed API\n\nAll typed operations live in `Patch` companion object:\n\n```scala\nobject Patch {\n  /** Empty patch (monoid identity) */\n  def empty[A](implicit schema: Schema[A]): Patch[A]\n  \n  /** Set a field/element to a value (clobber semantics) */\n  def set[S, A](optic: Optic[S, A], value: A)(implicit schema: Schema[S]): Patch[S]\n  \n  /** Increment numeric field */\n  def increment[S](optic: Optic[S, Int], delta: Int)(implicit schema: Schema[S]): Patch[S]\n  def incrementLong[S](optic: Optic[S, Long], delta: Long)(implicit schema: Schema[S]): Patch[S]\n  def incrementDouble[S](optic: Optic[S, Double], delta: Double)(implicit schema: Schema[S]): Patch[S]\n  \n  /** Edit string field */\n  def editString[S](optic: Optic[S, String], edits: Vector[StringOp])(implicit schema: Schema[S]): Patch[S]\n  \n  /** Sequence operations */\n  def append[S, A](optic: Optic[S, Vector[A]], elements: Vector[A])(implicit schema: Schema[S]): Patch[S]\n  def insertAt[S, A](optic: Optic[S, Vector[A]], index: Int, elements: Vector[A])(implicit schema: Schema[S]): Patch[S]\n  def deleteAt[S, A](optic: Optic[S, Vector[A]], index: Int, count: Int)(implicit schema: Schema[S]): Patch[S]\n  \n  /** Map operations */\n  def addKey[S, K, V](optic: Optic[S, Map[K, V]], key: K, value: V)(implicit schema: Schema[S]): Patch[S]\n  def removeKey[S, K, V](optic: Optic[S, Map[K, V]], key: K)(implicit schema: Schema[S]): Patch[S]\n  def modifyKey[S, K, V](optic: Optic[S, Map[K, V]], key: K, valuePatch: Patch[V])(implicit schema: Schema[S]): Patch[S]\n}\n```\n\n## Primitive Operations\n\n```scala\nsealed trait PrimitiveOp\nobject PrimitiveOp {\n  // Numeric deltas\n  case class IntDelta(delta: Int) extends PrimitiveOp\n  case class LongDelta(delta: Long) extends PrimitiveOp\n  case class DoubleDelta(delta: Double) extends PrimitiveOp\n  case class FloatDelta(delta: Float) extends PrimitiveOp\n  case class ShortDelta(delta: Short) extends PrimitiveOp\n  case class ByteDelta(delta: Byte) extends PrimitiveOp\n  case class BigIntDelta(delta: BigInt) extends PrimitiveOp\n  case class BigDecimalDelta(delta: BigDecimal) extends PrimitiveOp\n  \n  // String edits (LCS-based)\n  case class StringEdit(ops: Vector[StringOp]) extends PrimitiveOp\n  \n  // Temporal deltas\n  case class InstantDelta(duration: java.time.Duration) extends PrimitiveOp\n  case class DurationDelta(duration: java.time.Duration) extends PrimitiveOp\n  case class LocalDateDelta(period: java.time.Period) extends PrimitiveOp\n  case class LocalDateTimeDelta(period: java.time.Period, duration: java.time.Duration) extends PrimitiveOp\n  case class PeriodDelta(period: java.time.Period) extends PrimitiveOp\n  // ... other temporal types\n}\n\nsealed trait StringOp\nobject StringOp {\n  case class Insert(index: Int, text: String) extends StringOp\n  case class Delete(index: Int, length: Int) extends StringOp\n}\n```\n\n## Collection Operations\n\n```scala\nsealed trait SeqOp\nobject SeqOp {\n  /** Insert at index (fails if index occupied in Strict mode) */\n  case class Insert(index: Int, values: Vector[DynamicValue]) extends SeqOp\n  \n  /** Append to end (always succeeds) */\n  case class Append(values: Vector[DynamicValue]) extends SeqOp\n  \n  /** Delete count elements starting at index */\n  case class Delete(index: Int, count: Int) extends SeqOp\n  \n  /** Modify element at index with nested operation */\n  case class Modify(index: Int, op: Operation) extends SeqOp\n}\n\nsealed trait MapOp\nobject MapOp {\n  /** Add key-value (fails if key exists in Strict mode) */\n  case class Add(key: DynamicValue, value: DynamicValue) extends MapOp\n  \n  /** Remove key (fails if key missing in Strict mode) */\n  case class Remove(key: DynamicValue) extends MapOp\n  \n  /** Modify value at key with nested operation */\n  case class Modify(key: DynamicValue, op: Operation) extends MapOp\n}\n```\n\n## Patch Application Modes\n\n```scala\nsealed trait PatchMode\nobject PatchMode {\n  /** Fail on precondition violations (e.g. modifying non-existent key) */\n  case object Strict extends PatchMode\n  \n  /** Skip operations that fail preconditions */\n  case object Lenient extends PatchMode\n  \n  /** Replace/overwrite on conflicts */\n  case object Clobber extends PatchMode\n}\n```\n\n## Schema Integration\n\n```scala\ntrait Schema[A] {\n  /** \n   * Compute smart patch from oldValue to newValue.\n   * Uses heuristics to choose between delta/edit vs set operations.\n   */\n  def diff(oldValue: A, newValue: A): Patch[A]\n  \n  /** Convenience method - apply patch with Strict mode */\n  def patch(value: A, patch: Patch[A]): Either[SchemaError, A] =\n    patch.apply(value, PatchMode.Strict)\n}\n```\n\n## Diffing Strategy\n\nThe `Schema#diff` implementation uses smart heuristics:\n\n1. **New elements/keys**: Use `Operation.Set` \n   - Sequence insertions at new indices\n   - Map additions for new keys\n   - Sum type switches to different cases\n\n2. **String modifications**: Use `StringEdit` if edit sequence is shorter than new string, otherwise use `Set`\n\n3. **Numeric modifications**: Use delta operations (`IntDelta`, etc.)\n\n4. **Structural modifications**: Recursively diff nested structures, using field-level patches for records\n\n5. **Temporal modifications**: Use temporal delta operations for date/time types\n\n## Laws\n\n### Roundtrip Law\nFor all values, the following must hold:\n```scala\n (schema: Schema[A], old: A, new: A).\n  schema.diff(old, new).apply(old) == Right(new)\n```\n\n### Monoid Laws\n```scala\n// Identity (empty patch)\n (p: Patch[A]). \n  p ++ Patch.empty == p\n  Patch.empty ++ p == p\n\n// Associativity\n (p1: Patch[A], p2: Patch[A], p3: Patch[A]).\n  (p1 ++ p2) ++ p3 == p1 ++ (p2 ++ p3)\n```\n\n### Serializability\nAll patch types are pure data (DynamicValue, DynamicOptic, primitives) and must be serializable:\n```scala\n (p: Patch[A]). \n  jsonCodec.decode(jsonCodec.encode(p)) == Right(p)\n```\n\n## Implementation Notes\n\n- `Operation.Set` uses `DynamicValue` to represent whole values for materialization cases\n- `Patch[A]` converts typed values to `DynamicValue` via `Schema[A]` before applying `DynamicPatch` constructor\n- String edits use LCS (Longest Common Subsequence) algorithm\n- Sequence edits also use LCS for computing minimal insert/delete sequences\n\n## Success Criteria\n\n- [ ] `DynamicPatch` defined with all operation types, capable of transforming one DynamicValue to another in the most minimal possible way\n- [ ] `Patch[A]` wraps `DynamicPatch` with an additional `Schema[A]`\n- [ ] Typed API in `Patch` companion object for all common operations\n- [ ] `Schema#diff` implements smart diffing strategy\n- [ ] `PatchMode` controls patch application behavior\n- [ ] All fallible operations return `Either[SchemaError, A]` so error information is preserved\n- [ ] Roundtrip law holds for all schema types\n- [ ] Monoid laws hold for patch composition\n- [ ] All patch types serialize/deserialize correctly (except `Patch` itself, which cannot be serialized unless `Schema` is serialized, which in the general case requires a `TypeRegistry`)\n- [ ] String diffs use LCS algorithm\n- [ ] Sequence diffs use LCS algorithm\n- [ ] Comprehensive tests for all operation types, and for serialization of non-`Patch` types such as DynamicPatch and everything it contains\n\n## Example Usage\n\n```scala\n@schema \n@optics\ncase class Person(name: String, age: Int, address: Address)\n\n@schema \n@optics\ncase class Address(street: String, city: String, country: String)\n\nval old = Person(\"Alice\", 30, Address(\"123 Main St\", \"NYC\", \"USA\"))\nval new1 = Person(\"Alice\", 31, Address(\"456 Elm St\", \"NYC\", \"USA\"))\n\n// Automatic diffing\nval patch1: Patch[Person] = Person.schema.diff(old, new1)\npatch1(old) // Right(new1)\n\n// Manual patch construction\nval patch2: Patch[Person] = Patch.increment(Person.age, 1) ++ \n             Patch.set(Person.address(Address.street), \"456 Elm St\")\npatch2(old) // Right(new1)\n\n// Patch composition\nval patch3 = patch1 ++ patch2\npatch3(old) // Applies both patches sequentially\n\n// Different application modes\npatch2(old, PatchMode.Strict)   // Fails if preconditions violated\npatch2(old, PatchMode.Lenient)  // Skips failed operations\npatch2(old, PatchMode.Clobber)  // Replaces on conflicts\n\n// Serialization (via @schema on DynamicPatch)\nval json = jsonCodec.encode(patch1.dynamicPatch)\nval recovered = jsonCodec.decode[DynamicPatch](json)\n```",
                  "html_url": "https://github.com/zio/zio-blocks/issues/516"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#516",
              "body": "# Algebraic Patch/Diff System for ZIO Schema 2\n\n## Overview\n\nImplement a pure, algebraic patch/diff system for ZIO Schema 2 that represents structural changes as first-class, serializable data. The system provides a typed API (`Patch[A]`) built on an untyped core (`DynamicPatch`) that operates on `DynamicValue`.\n\nBelow is a rough outline or sketch of the design of patching & diffing, subject to revision by the implementor based on technical feasibility considerations.\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed patch (user-facing API)\ncase class Patch[A](dynamicPatch: DynamicPatch, schema: Schema[A]) {\n  /** Apply patch with specified mode */\n  def apply(value: A, mode: PatchMode = PatchMode.Strict): Either[SchemaError, A]\n  \n  /** Compose patches sequentially (monoid operation) */\n  def ++(that: Patch[A]): Patch[A]\n}\n\n// Untyped patch (operates on DynamicValue)\ncase class DynamicPatch(ops: Vector[DynamicPatchOp]) {\n  /** Apply to dynamic value */\n  def apply(value: DynamicValue, mode: PatchMode): Either[SchemaError, DynamicValue]\n  \n  /** Compose patches */\n  def ++(that: DynamicPatch): DynamicPatch\n}\n```\n\n### Operations\n\n```scala\ncase class DynamicPatchOp(optic: DynamicOptic, operation: Operation)\n\nsealed trait Operation\nobject Operation {\n  case class Set(value: DynamicValue) extends Operation\n  case class PrimitiveDelta(op: PrimitiveOp) extends Operation\n  case class SequenceEdit(ops: Vector[SeqOp]) extends Operation\n  case class MapEdit(ops: Vector[MapOp]) extends Operation\n}\n```\n\n## Typed API\n\nAll typed operations live in `Patch` companion object:\n\n```scala\nobject Patch {\n  /** Empty patch (monoid identity) */\n  def empty[A](implicit schema: Schema[A]): Patch[A]\n  \n  /** Set a field/element to a value (clobber semantics) */\n  def set[S, A](optic: Optic[S, A], value: A)(implicit schema: Schema[S]): Patch[S]\n  \n  /** Increment numeric field */\n  def increment[S](optic: Optic[S, Int], delta: Int)(implicit schema: Schema[S]): Patch[S]\n  def incrementLong[S](optic: Optic[S, Long], delta: Long)(implicit schema: Schema[S]): Patch[S]\n  def incrementDouble[S](optic: Optic[S, Double], delta: Double)(implicit schema: Schema[S]): Patch[S]\n  \n  /** Edit string field */\n  def editString[S](optic: Optic[S, String], edits: Vector[StringOp])(implicit schema: Schema[S]): Patch[S]\n  \n  /** Sequence operations */\n  def append[S, A](optic: Optic[S, Vector[A]], elements: Vector[A])(implicit schema: Schema[S]): Patch[S]\n  def insertAt[S, A](optic: Optic[S, Vector[A]], index: Int, elements: Vector[A])(implicit schema: Schema[S]): Patch[S]\n  def deleteAt[S, A](optic: Optic[S, Vector[A]], index: Int, count: Int)(implicit schema: Schema[S]): Patch[S]\n  \n  /** Map operations */\n  def addKey[S, K, V](optic: Optic[S, Map[K, V]], key: K, value: V)(implicit schema: Schema[S]): Patch[S]\n  def removeKey[S, K, V](optic: Optic[S, Map[K, V]], key: K)(implicit schema: Schema[S]): Patch[S]\n  def modifyKey[S, K, V](optic: Optic[S, Map[K, V]], key: K, valuePatch: Patch[V])(implicit schema: Schema[S]): Patch[S]\n}\n```\n\n## Primitive Operations\n\n```scala\nsealed trait PrimitiveOp\nobject PrimitiveOp {\n  // Numeric deltas\n  case class IntDelta(delta: Int) extends PrimitiveOp\n  case class LongDelta(delta: Long) extends PrimitiveOp\n  case class DoubleDelta(delta: Double) extends PrimitiveOp\n  case class FloatDelta(delta: Float) extends PrimitiveOp\n  case class ShortDelta(delta: Short) extends PrimitiveOp\n  case class ByteDelta(delta: Byte) extends PrimitiveOp\n  case class BigIntDelta(delta: BigInt) extends PrimitiveOp\n  case class BigDecimalDelta(delta: BigDecimal) extends PrimitiveOp\n  \n  // String edits (LCS-based)\n  case class StringEdit(ops: Vector[StringOp]) extends PrimitiveOp\n  \n  // Temporal deltas\n  case class InstantDelta(duration: java.time.Duration) extends PrimitiveOp\n  case class DurationDelta(duration: java.time.Duration) extends PrimitiveOp\n  case class LocalDateDelta(period: java.time.Period) extends PrimitiveOp\n  case class LocalDateTimeDelta(period: java.time.Period, duration: java.time.Duration) extends PrimitiveOp\n  case class PeriodDelta(period: java.time.Period) extends PrimitiveOp\n  // ... other temporal types\n}\n\nsealed trait StringOp\nobject StringOp {\n  case class Insert(index: Int, text: String) extends StringOp\n  case class Delete(index: Int, length: Int) extends StringOp\n}\n```\n\n## Collection Operations\n\n```scala\nsealed trait SeqOp\nobject SeqOp {\n  /** Insert at index (fails if index occupied in Strict mode) */\n  case class Insert(index: Int, values: Vector[DynamicValue]) extends SeqOp\n  \n  /** Append to end (always succeeds) */\n  case class Append(values: Vector[DynamicValue]) extends SeqOp\n  \n  /** Delete count elements starting at index */\n  case class Delete(index: Int, count: Int) extends SeqOp\n  \n  /** Modify element at index with nested operation */\n  case class Modify(index: Int, op: Operation) extends SeqOp\n}\n\nsealed trait MapOp\nobject MapOp {\n  /** Add key-value (fails if key exists in Strict mode) */\n  case class Add(key: DynamicValue, value: DynamicValue) extends MapOp\n  \n  /** Remove key (fails if key missing in Strict mode) */\n  case class Remove(key: DynamicValue) extends MapOp\n  \n  /** Modify value at key with nested operation */\n  case class Modify(key: DynamicValue, op: Operation) extends MapOp\n}\n```\n\n## Patch Application Modes\n\n```scala\nsealed trait PatchMode\nobject PatchMode {\n  /** Fail on precondition violations (e.g. modifying non-existent key) */\n  case object Strict extends PatchMode\n  \n  /** Skip operations that fail preconditions */\n  case object Lenient extends PatchMode\n  \n  /** Replace/overwrite on conflicts */\n  case object Clobber extends PatchMode\n}\n```\n\n## Schema Integration\n\n```scala\ntrait Schema[A] {\n  /** \n   * Compute smart patch from oldValue to newValue.\n   * Uses heuristics to choose between delta/edit vs set operations.\n   */\n  def diff(oldValue: A, newValue: A): Patch[A]\n  \n  /** Convenience method - apply patch with Strict mode */\n  def patch(value: A, patch: Patch[A]): Either[SchemaError, A] =\n    patch.apply(value, PatchMode.Strict)\n}\n```\n\n## Diffing Strategy\n\nThe `Schema#diff` implementation uses smart heuristics:\n\n1. **New elements/keys**: Use `Operation.Set` \n   - Sequence insertions at new indices\n   - Map additions for new keys\n   - Sum type switches to different cases\n\n2. **String modifications**: Use `StringEdit` if edit sequence is shorter than new string, otherwise use `Set`\n\n3. **Numeric modifications**: Use delta operations (`IntDelta`, etc.)\n\n4. **Structural modifications**: Recursively diff nested structures, using field-level patches for records\n\n5. **Temporal modifications**: Use temporal delta operations for date/time types\n\n## Laws\n\n### Roundtrip Law\nFor all values, the following must hold:\n```scala\n (schema: Schema[A], old: A, new: A).\n  schema.diff(old, new).apply(old) == Right(new)\n```\n\n### Monoid Laws\n```scala\n// Identity (empty patch)\n (p: Patch[A]). \n  p ++ Patch.empty == p\n  Patch.empty ++ p == p\n\n// Associativity\n (p1: Patch[A], p2: Patch[A], p3: Patch[A]).\n  (p1 ++ p2) ++ p3 == p1 ++ (p2 ++ p3)\n```\n\n### Serializability\nAll patch types are pure data (DynamicValue, DynamicOptic, primitives) and must be serializable:\n```scala\n (p: Patch[A]). \n  jsonCodec.decode(jsonCodec.encode(p)) == Right(p)\n```\n\n## Implementation Notes\n\n- `Operation.Set` uses `DynamicValue` to represent whole values for materialization cases\n- `Patch[A]` converts typed values to `DynamicValue` via `Schema[A]` before applying `DynamicPatch` constructor\n- String edits use LCS (Longest Common Subsequence) algorithm\n- Sequence edits also use LCS for computing minimal insert/delete sequences\n\n## Success Criteria\n\n- [ ] `DynamicPatch` defined with all operation types, capable of transforming one DynamicValue to another in the most minimal possible way\n- [ ] `Patch[A]` wraps `DynamicPatch` with an additional `Schema[A]`\n- [ ] Typed API in `Patch` companion object for all common operations\n- [ ] `Schema#diff` implements smart diffing strategy\n- [ ] `PatchMode` controls patch application behavior\n- [ ] All fallible operations return `Either[SchemaError, A]` so error information is preserved\n- [ ] Roundtrip law holds for all schema types\n- [ ] Monoid laws hold for patch composition\n- [ ] All patch types serialize/deserialize correctly (except `Patch` itself, which cannot be serialized unless `Schema` is serialized, which in the general case requires a `TypeRegistry`)\n- [ ] String diffs use LCS algorithm\n- [ ] Sequence diffs use LCS algorithm\n- [ ] Comprehensive tests for all operation types, and for serialization of non-`Patch` types such as DynamicPatch and everything it contains\n\n## Example Usage\n\n```scala\n@schema \n@optics\ncase class Person(name: String, age: Int, address: Address)\n\n@schema \n@optics\ncase class Address(street: String, city: String, country: String)\n\nval old = Person(\"Alice\", 30, Address(\"123 Main St\", \"NYC\", \"USA\"))\nval new1 = Person(\"Alice\", 31, Address(\"456 Elm St\", \"NYC\", \"USA\"))\n\n// Automatic diffing\nval patch1: Patch[Person] = Person.schema.diff(old, new1)\npatch1(old) // Right(new1)\n\n// Manual patch construction\nval patch2: Patch[Person] = Patch.increment(Person.age, 1) ++ \n             Patch.set(Person.address(Address.street), \"456 Elm St\")\npatch2(old) // Right(new1)\n\n// Patch composition\nval patch3 = patch1 ++ patch2\npatch3(old) // Applies both patches sequentially\n\n// Different application modes\npatch2(old, PatchMode.Strict)   // Fails if preconditions violated\npatch2(old, PatchMode.Lenient)  // Skips failed operations\npatch2(old, PatchMode.Clobber)  // Replaces on conflicts\n\n// Serialization (via @schema on DynamicPatch)\nval json = jsonCodec.encode(patch1.dynamicPatch)\nval recovered = jsonCodec.decode[DynamicPatch](json)\n```",
              "url": "https://github.com/zio/zio-blocks/issues/516",
              "tech": [
                "go"
              ],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#471",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-17T18:24:16.086Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:16.086Z",
            "created_at": "2025-12-17T18:24:16.086Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#471",
              "status": "open",
              "type": "issue",
              "number": 471,
              "title": "Replace TypeName by TypeId & Macro Derivation",
              "source": {
                "data": {
                  "id": "source-ZIO#471",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Replace TypeName by TypeId & Macro Derivation",
                  "body": "```scala\n// ============================================================================\n// Owner: Where a type is defined\n// ============================================================================\n\nfinal case class Owner(segments: List[Owner.Segment]) {\n  def asString: String = segments.map(_.name).mkString(\".\")\n}\n\nobject Owner {\n  sealed trait Segment { def name: String }\n\n  final case class Package(name: String) extends Segment\n  final case class Term(name: String)    extends Segment\n  final case class Type(name: String)    extends Segment\n\n  val Root: Owner = Owner(Nil)\n}\n\n// ============================================================================\n// TypeParam: Type parameter specification\n// ============================================================================\n\nfinal case class TypeParam(\n  name: String,\n  index: Int\n  // Can extend with: variance, bounds, kind\n)\n\n// ============================================================================\n// TypeId: Identity of a type or type constructor (phantom-typed by A)\n// ============================================================================\n\nsealed trait TypeId[A <: AnyKind] {\n  def name: String\n  def owner: Owner\n  def typeParams: List[TypeParam]\n\n  final def arity: Int = typeParams.size\n\n  final def fullName: String =\n    if (owner.segments.isEmpty) name\n    else owner.asString + \".\" + name\n}\n\nobject TypeId {\n  private final case class NominalImpl(\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam]\n  ) extends TypeId[Nothing]\n\n  private final case class AliasImpl(\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    aliased: TypeRepr\n  ) extends TypeId[Nothing]\n\n  private final case class OpaqueImpl(\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    representation: TypeRepr\n  ) extends TypeId[Nothing]\n\n  /** Macro-derived TypeId for any type or type constructor */\n  def derive[A <: AnyKind]: TypeId[A] =\n    macro TypeIdMacros.deriveMacro[A]\n\n  /** Manual construction: nominal type */\n  def nominal[A <: AnyKind](\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam]\n  ): TypeId[A] =\n    NominalImpl(name, owner, typeParams).asInstanceOf[TypeId[A]]\n\n  /** Manual construction: type alias */\n  def alias[A <: AnyKind](\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    aliased: TypeRepr\n  ): TypeId[A] =\n    AliasImpl(name, owner, typeParams, aliased).asInstanceOf[TypeId[A]]\n\n  /** Manual construction: opaque type */\n  def opaque[A <: AnyKind](\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    representation: TypeRepr\n  ): TypeId[A] =\n    OpaqueImpl(name, owner, typeParams, representation).asInstanceOf[TypeId[A]]\n\n  /** Pattern matching support */\n  object Nominal {\n    def unapply(id: TypeId[_]): Option[(String, Owner, List[TypeParam])] = id match {\n      case impl: NominalImpl => Some((impl.name, impl.owner, impl.typeParams))\n      case _                 => None\n    }\n  }\n\n  object Alias {\n    def unapply(id: TypeId[_]): Option[(String, Owner, List[TypeParam], TypeRepr)] = id match {\n      case impl: AliasImpl => Some((impl.name, impl.owner, impl.typeParams, impl.aliased))\n      case _               => None\n    }\n  }\n\n  object Opaque {\n    def unapply(id: TypeId[_]): Option[(String, Owner, List[TypeParam], TypeRepr)] = id match {\n      case impl: OpaqueImpl => Some((impl.name, impl.owner, impl.typeParams, impl.representation))\n      case _                => None\n    }\n  }\n}\n\n// ============================================================================\n// TypeRepr: Type expressions\n// ============================================================================\n\nsealed trait TypeRepr\n\nobject TypeRepr {\n  /** Reference to a named type constructor (unapplied).\n    * - If id.arity == 0, this is already a proper type\n    * - If id.arity > 0, this is a type constructor\n    */\n  final case class Ref(id: TypeId[_ <: AnyKind]) extends TypeRepr\n\n  /** Reference to a type parameter (can itself be a constructor) */\n  final case class ParamRef(param: TypeParam) extends TypeRepr\n\n  /** Application of a type constructor to arguments.\n    * Examples:\n    *   List[Int]    Applied(Ref(listId), List(Ref(intId)))\n    *   F[A]         Applied(ParamRef(F), List(ParamRef(A)))\n    */\n  final case class Applied(\n    tycon: TypeRepr,\n    args: List[TypeRepr]\n  ) extends TypeRepr\n\n  /** Structural/refinement type: { def foo: Int; type T; ... } */\n  final case class Structural(\n    parents: List[TypeRepr],\n    members: List[Member]\n  ) extends TypeRepr\n\n  /** Intersection type: A & B */\n  final case class Intersection(left: TypeRepr, right: TypeRepr) extends TypeRepr\n\n  /** Union type: A | B */\n  final case class Union(left: TypeRepr, right: TypeRepr) extends TypeRepr\n\n  /** Tuple type: (A, B, C) */\n  final case class Tuple(elems: List[TypeRepr]) extends TypeRepr\n\n  /** Function type: (A, B) => C */\n  final case class Function(params: List[TypeRepr], result: TypeRepr) extends TypeRepr\n\n  /** Singleton type: x.type */\n  final case class Singleton(path: TermPath) extends TypeRepr\n\n  /** Constant/literal type: 42, \"foo\", true */\n  final case class Constant(value: Any) extends TypeRepr\n\n  /** Top type */\n  case object AnyType extends TypeRepr\n\n  /** Bottom type */\n  case object NothingType extends TypeRepr\n}\n\n// ============================================================================\n// Member: Structural type members\n// ============================================================================\n\nsealed trait Member\n\nobject Member {\n  final case class Val(\n    name: String,\n    tpe: TypeRepr,\n    isVar: Boolean = false\n  ) extends Member\n\n  final case class Def(\n    name: String,\n    paramLists: List[List[Param]],\n    result: TypeRepr\n  ) extends Member\n\n  final case class TypeMember(\n    name: String,\n    typeParams: List[TypeParam],\n    lowerBound: Option[TypeRepr],\n    upperBound: Option[TypeRepr]\n  ) extends Member\n}\n\nfinal case class Param(name: String, tpe: TypeRepr)\n\n// ============================================================================\n// TermPath: For singleton types\n// ============================================================================\n\nfinal case class TermPath(segments: List[TermPath.Segment])\n\nobject TermPath {\n  sealed trait Segment { def name: String }\n\n  final case class Package(name: String) extends Segment\n  final case class Term(name: String)    extends Segment\n}\n\n// ============================================================================\n// Examples\n// ============================================================================\n\nobject Examples {\n  import TypeId.{nominal, alias, opaque}\n  import TypeRepr._\n  import Member._\n\n  private val pkgScala          = Owner(List(Owner.Package(\"scala\")))\n  private val pkgScalaCollection =\n    Owner(List(Owner.Package(\"scala\"), Owner.Package(\"collection\"), Owner.Package(\"immutable\")))\n  private val pkgJavaLang       = Owner(List(Owner.Package(\"java\"), Owner.Package(\"lang\")))\n  private val pkgMyApp          = Owner(List(Owner.Package(\"myapp\")))\n\n  // ===== Basic nominal types =====\n\n  val intId: TypeId[Int]       = nominal[Int](\"Int\", pkgScala, Nil)\n  val stringId: TypeId[String] = nominal[String](\"String\", pkgJavaLang, Nil)\n  val booleanId: TypeId[Boolean] = nominal[Boolean](\"Boolean\", pkgScala, Nil)\n\n  val intType: TypeRepr     = Ref(intId)\n  val stringType: TypeRepr  = Ref(stringId)\n  val booleanType: TypeRepr = Ref(booleanId)\n\n  // ===== Type constructors =====\n\n  val A = TypeParam(\"A\", 0)\n  val B = TypeParam(\"B\", 1)\n  val K = TypeParam(\"K\", 0)\n  val V = TypeParam(\"V\", 1)\n\n  val listId: TypeId[List]   = nominal[List](\"List\", pkgScalaCollection, List(A))\n  val optionId: TypeId[Option] = nominal[Option](\"Option\", pkgScala, List(A))\n  val mapId: TypeId[Map]     = nominal[Map](\"Map\", pkgScalaCollection, List(K, V))\n  val eitherId: TypeId[Either] = nominal[Either](\"Either\", pkgScala, List(A, B))\n\n  // Type constructors (unapplied)\n  val listConstructor: TypeRepr   = Ref(listId)\n  val optionConstructor: TypeRepr = Ref(optionId)\n\n  // Applied types\n  val listIntType: TypeRepr       = Applied(Ref(listId), List(intType))\n  val optionStringType: TypeRepr  = Applied(Ref(optionId), List(stringType))\n  val mapStringIntType: TypeRepr  = Applied(Ref(mapId), List(stringType, intType))\n\n  // ===== Type aliases =====\n\n  // type Age = Int\n  val ageId: TypeId[Int] = alias[Int](\n    name       = \"Age\",\n    owner      = pkgMyApp,\n    typeParams = Nil,\n    aliased    = intType\n  )\n  val ageType: TypeRepr = Ref(ageId)\n\n  // type MyList[A] = List[A]\n  val myListId: TypeId[List] = alias[List](\n    name       = \"MyList\",\n    owner      = pkgMyApp,\n    typeParams = List(A),\n    aliased    = Applied(Ref(listId), List(ParamRef(A)))\n  )\n\n  // type StringMap[V] = Map[String, V]\n  val stringMapId: TypeId[Map[String, *]] = alias[Map[String, *]](\n    name       = \"StringMap\",\n    owner      = pkgMyApp,\n    typeParams = List(V),\n    aliased    = Applied(Ref(mapId), List(stringType, ParamRef(V)))\n  )\n\n  // type Id[A] = A\n  val idId: TypeId[AnyKind] = alias[AnyKind](\n    name       = \"Id\",\n    owner      = pkgMyApp,\n    typeParams = List(A),\n    aliased    = ParamRef(A)\n  )\n\n  // ===== Opaque types =====\n\n  // opaque type Email = String\n  val emailId: TypeId[String] = opaque[String](\n    name           = \"Email\",\n    owner          = pkgMyApp,\n    typeParams     = Nil,\n    representation = stringType\n  )\n  val emailType: TypeRepr = Ref(emailId)\n\n  // opaque type SafeList[A] = List[A]\n  val safeListId: TypeId[List] = opaque[List](\n    name           = \"SafeList\",\n    owner          = pkgMyApp,\n    typeParams     = List(A),\n    representation = Applied(Ref(listId), List(ParamRef(A)))\n  )\n\n  // ===== Structural types =====\n\n  // { def size: Int; val isEmpty: Boolean }\n  val sizedType: TypeRepr = Structural(\n    parents = Nil,\n    members = List(\n      Def(\"size\", Nil, intType),\n      Val(\"isEmpty\", booleanType, isVar = false)\n    )\n  )\n\n  // type Record[A] = { def value: A }\n  val recordId: TypeId[AnyKind] = alias[AnyKind](\n    name       = \"Record\",\n    owner      = pkgMyApp,\n    typeParams = List(A),\n    aliased    = Structural(\n      parents = Nil,\n      members = List(\n        Def(\"value\", Nil, ParamRef(A))\n      )\n    )\n  )\n\n  // { type T; def get: T }\n  val T = TypeParam(\"T\", 0)\n  val genericGetterType: TypeRepr = Structural(\n    parents = Nil,\n    members = List(\n      TypeMember(\"T\", Nil, None, None),\n      // Note: ParamRef(T) here is a shorthand for \"the type member T\";\n      // if you want precise scoping you can extend the model, but for\n      // most uses you'll just inspect the name.\n      Def(\"get\", Nil, ParamRef(T))\n    )\n  )\n\n  // ===== Higher-kinded example =====\n\n  // type F[G[_], A] = G[A]\n  val G = TypeParam(\"G\", 0)\n  val fId: TypeId[AnyKind] = alias[AnyKind](\n    name       = \"F\",\n    owner      = pkgMyApp,\n    typeParams = List(G, A),\n    aliased    = Applied(\n      tycon = ParamRef(G),  // G is itself a type constructor\n      args  = List(ParamRef(A))\n    )\n  )\n\n  // ===== Singleton and constant types =====\n\n  // 42 (literal type)\n  val fortyTwoType: TypeRepr = Constant(42)\n\n  // \"hello\" (literal type)\n  val helloType: TypeRepr = Constant(\"hello\")\n\n  // myObject.type\n  val myObjectSingleton: TypeRepr = Singleton(\n    TermPath(List(TermPath.Package(\"myapp\"), TermPath.Term(\"myObject\")))\n  )\n\n  // ===== Complex types =====\n\n  // Option[List[String]]\n  val optionListStringType: TypeRepr =\n    Applied(Ref(optionId), List(Applied(Ref(listId), List(stringType))))\n\n  // Map[Email, List[Age]]\n  val emailToAgesType: TypeRepr =\n    Applied(\n      Ref(mapId),\n      List(\n        Ref(emailId),\n        Applied(Ref(listId), List(Ref(ageId)))\n      )\n    )\n\n  // (Int, String) => Boolean\n  val intStringToBoolType: TypeRepr =\n    Function(List(intType, stringType), booleanType)\n\n  // String & { def length: Int }\n  val stringWithLengthType: TypeRepr =\n    Intersection(\n      stringType,\n      Structural(Nil, List(Def(\"length\", Nil, intType)))\n    )\n\n  // ===== Utility: substitute type parameters =====\n\n  def substitute(\n    repr: TypeRepr,\n    substitutions: Map[TypeParam, TypeRepr]\n  ): TypeRepr =\n    repr match {\n      case ParamRef(param) =>\n        substitutions.getOrElse(param, repr)\n\n      case Ref(_) =>\n        repr\n\n      case Applied(tycon, args) =>\n        Applied(\n          substitute(tycon, substitutions),\n          args.map(substitute(_, substitutions))\n        )\n\n      case Structural(parents, members) =>\n        Structural(\n          parents.map(substitute(_, substitutions)),\n          members.map(substituteMember(_, substitutions))\n        )\n\n      case Intersection(l, r) =>\n        Intersection(\n          substitute(l, substitutions),\n          substitute(r, substitutions)\n        )\n\n      case Union(l, r) =>\n        Union(\n          substitute(l, substitutions),\n          substitute(r, substitutions)\n        )\n\n      case Tuple(elems) =>\n        Tuple(elems.map(substitute(_, substitutions)))\n\n      case Function(params, result) =>\n        Function(\n          params.map(substitute(_, substitutions)),\n          substitute(result, substitutions)\n        )\n\n      case Singleton(_) | Constant(_) | AnyType | NothingType =>\n        repr\n    }\n\n  private def substituteMember(\n    m: Member,\n    substitutions: Map[TypeParam, TypeRepr]\n  ): Member =\n    m match {\n      case Val(name, tpe, isVar) =>\n        Val(name, substitute(tpe, substitutions), isVar)\n\n      case Def(name, paramLists, result) =>\n        Def(\n          name,\n          paramLists.map(_.map { p => Param(p.name, substitute(p.tpe, substitutions)) }),\n          substitute(result, substitutions)\n        )\n\n      case TypeMember(name, typeParams, lower, upper) =>\n        TypeMember(\n          name,\n          typeParams,\n          lower.map(substitute(_, substitutions)),\n          upper.map(substitute(_, substitutions))\n        )\n    }\n\n  // Get underlying type for alias/opaque with substitution\n  def underlyingType(\n    id: TypeId[_],\n    args: List[TypeRepr]\n  ): Option[TypeRepr] = id match {\n    case TypeId.Alias(_, _, typeParams, aliased) =>\n      val subs = typeParams.zip(args).toMap\n      Some(substitute(aliased, subs))\n\n    case TypeId.Opaque(_, _, typeParams, representation) =>\n      val subs = typeParams.zip(args).toMap\n      Some(substitute(representation, subs))\n\n    case _ =>\n      None\n  }\n\n  // Examples:\n  // underlyingType(ageId, Nil)                  => Some(Int)\n  // underlyingType(myListId, List(intType))     => Some(List[Int])\n  // underlyingType(stringMapId, List(intType))  => Some(Map[String, Int])\n  // underlyingType(emailId, Nil)                => Some(String)\n\n  // ===== Type safety via phantom types =====\n\n  def processList(id: TypeId[List]): String =\n    s\"Processing list type constructor: ${id.fullName}\"\n\n  def processScalar[A](id: TypeId[A]): String =\n    s\"Processing scalar type: ${id.fullName}\"\n\n  // These compile:\n  val _x: String = processList(listId)\n  val _y: String = processList(myListId)     // MyList is an alias for List\n  val _z: String = processList(safeListId)   // SafeList is opaque over List\n\n  val _s1: String = processScalar(intId)\n  val _s2: String = processScalar(ageId)     // Age is an alias for Int\n  val _s3: String = processScalar(emailId)   // Email is opaque over String\n\n  // These would NOT compile:\n  // processList(intId)     // Type mismatch\n  // processScalar(listId)  // Type mismatch\n}\n```",
                  "html_url": "https://github.com/zio/zio-blocks/issues/471"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#471",
              "body": "```scala\n// ============================================================================\n// Owner: Where a type is defined\n// ============================================================================\n\nfinal case class Owner(segments: List[Owner.Segment]) {\n  def asString: String = segments.map(_.name).mkString(\".\")\n}\n\nobject Owner {\n  sealed trait Segment { def name: String }\n\n  final case class Package(name: String) extends Segment\n  final case class Term(name: String)    extends Segment\n  final case class Type(name: String)    extends Segment\n\n  val Root: Owner = Owner(Nil)\n}\n\n// ============================================================================\n// TypeParam: Type parameter specification\n// ============================================================================\n\nfinal case class TypeParam(\n  name: String,\n  index: Int\n  // Can extend with: variance, bounds, kind\n)\n\n// ============================================================================\n// TypeId: Identity of a type or type constructor (phantom-typed by A)\n// ============================================================================\n\nsealed trait TypeId[A <: AnyKind] {\n  def name: String\n  def owner: Owner\n  def typeParams: List[TypeParam]\n\n  final def arity: Int = typeParams.size\n\n  final def fullName: String =\n    if (owner.segments.isEmpty) name\n    else owner.asString + \".\" + name\n}\n\nobject TypeId {\n  private final case class NominalImpl(\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam]\n  ) extends TypeId[Nothing]\n\n  private final case class AliasImpl(\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    aliased: TypeRepr\n  ) extends TypeId[Nothing]\n\n  private final case class OpaqueImpl(\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    representation: TypeRepr\n  ) extends TypeId[Nothing]\n\n  /** Macro-derived TypeId for any type or type constructor */\n  def derive[A <: AnyKind]: TypeId[A] =\n    macro TypeIdMacros.deriveMacro[A]\n\n  /** Manual construction: nominal type */\n  def nominal[A <: AnyKind](\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam]\n  ): TypeId[A] =\n    NominalImpl(name, owner, typeParams).asInstanceOf[TypeId[A]]\n\n  /** Manual construction: type alias */\n  def alias[A <: AnyKind](\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    aliased: TypeRepr\n  ): TypeId[A] =\n    AliasImpl(name, owner, typeParams, aliased).asInstanceOf[TypeId[A]]\n\n  /** Manual construction: opaque type */\n  def opaque[A <: AnyKind](\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    representation: TypeRepr\n  ): TypeId[A] =\n    OpaqueImpl(name, owner, typeParams, representation).asInstanceOf[TypeId[A]]\n\n  /** Pattern matching support */\n  object Nominal {\n    def unapply(id: TypeId[_]): Option[(String, Owner, List[TypeParam])] = id match {\n      case impl: NominalImpl => Some((impl.name, impl.owner, impl.typeParams))\n      case _                 => None\n    }\n  }\n\n  object Alias {\n    def unapply(id: TypeId[_]): Option[(String, Owner, List[TypeParam], TypeRepr)] = id match {\n      case impl: AliasImpl => Some((impl.name, impl.owner, impl.typeParams, impl.aliased))\n      case _               => None\n    }\n  }\n\n  object Opaque {\n    def unapply(id: TypeId[_]): Option[(String, Owner, List[TypeParam], TypeRepr)] = id match {\n      case impl: OpaqueImpl => Some((impl.name, impl.owner, impl.typeParams, impl.representation))\n      case _                => None\n    }\n  }\n}\n\n// ============================================================================\n// TypeRepr: Type expressions\n// ============================================================================\n\nsealed trait TypeRepr\n\nobject TypeRepr {\n  /** Reference to a named type constructor (unapplied).\n    * - If id.arity == 0, this is already a proper type\n    * - If id.arity > 0, this is a type constructor\n    */\n  final case class Ref(id: TypeId[_ <: AnyKind]) extends TypeRepr\n\n  /** Reference to a type parameter (can itself be a constructor) */\n  final case class ParamRef(param: TypeParam) extends TypeRepr\n\n  /** Application of a type constructor to arguments.\n    * Examples:\n    *   List[Int]    Applied(Ref(listId), List(Ref(intId)))\n    *   F[A]         Applied(ParamRef(F), List(ParamRef(A)))\n    */\n  final case class Applied(\n    tycon: TypeRepr,\n    args: List[TypeRepr]\n  ) extends TypeRepr\n\n  /** Structural/refinement type: { def foo: Int; type T; ... } */\n  final case class Structural(\n    parents: List[TypeRepr],\n    members: List[Member]\n  ) extends TypeRepr\n\n  /** Intersection type: A & B */\n  final case class Intersection(left: TypeRepr, right: TypeRepr) extends TypeRepr\n\n  /** Union type: A | B */\n  final case class Union(left: TypeRepr, right: TypeRepr) extends TypeRepr\n\n  /** Tuple type: (A, B, C) */\n  final case class Tuple(elems: List[TypeRepr]) extends TypeRepr\n\n  /** Function type: (A, B) => C */\n  final case class Function(params: List[TypeRepr], result: TypeRepr) extends TypeRepr\n\n  /** Singleton type: x.type */\n  final case class Singleton(path: TermPath) extends TypeRepr\n\n  /** Constant/literal type: 42, \"foo\", true */\n  final case class Constant(value: Any) extends TypeRepr\n\n  /** Top type */\n  case object AnyType extends TypeRepr\n\n  /** Bottom type */\n  case object NothingType extends TypeRepr\n}\n\n// ============================================================================\n// Member: Structural type members\n// ============================================================================\n\nsealed trait Member\n\nobject Member {\n  final case class Val(\n    name: String,\n    tpe: TypeRepr,\n    isVar: Boolean = false\n  ) extends Member\n\n  final case class Def(\n    name: String,\n    paramLists: List[List[Param]],\n    result: TypeRepr\n  ) extends Member\n\n  final case class TypeMember(\n    name: String,\n    typeParams: List[TypeParam],\n    lowerBound: Option[TypeRepr],\n    upperBound: Option[TypeRepr]\n  ) extends Member\n}\n\nfinal case class Param(name: String, tpe: TypeRepr)\n\n// ============================================================================\n// TermPath: For singleton types\n// ============================================================================\n\nfinal case class TermPath(segments: List[TermPath.Segment])\n\nobject TermPath {\n  sealed trait Segment { def name: String }\n\n  final case class Package(name: String) extends Segment\n  final case class Term(name: String)    extends Segment\n}\n\n// ============================================================================\n// Examples\n// ============================================================================\n\nobject Examples {\n  import TypeId.{nominal, alias, opaque}\n  import TypeRepr._\n  import Member._\n\n  private val pkgScala          = Owner(List(Owner.Package(\"scala\")))\n  private val pkgScalaCollection =\n    Owner(List(Owner.Package(\"scala\"), Owner.Package(\"collection\"), Owner.Package(\"immutable\")))\n  private val pkgJavaLang       = Owner(List(Owner.Package(\"java\"), Owner.Package(\"lang\")))\n  private val pkgMyApp          = Owner(List(Owner.Package(\"myapp\")))\n\n  // ===== Basic nominal types =====\n\n  val intId: TypeId[Int]       = nominal[Int](\"Int\", pkgScala, Nil)\n  val stringId: TypeId[String] = nominal[String](\"String\", pkgJavaLang, Nil)\n  val booleanId: TypeId[Boolean] = nominal[Boolean](\"Boolean\", pkgScala, Nil)\n\n  val intType: TypeRepr     = Ref(intId)\n  val stringType: TypeRepr  = Ref(stringId)\n  val booleanType: TypeRepr = Ref(booleanId)\n\n  // ===== Type constructors =====\n\n  val A = TypeParam(\"A\", 0)\n  val B = TypeParam(\"B\", 1)\n  val K = TypeParam(\"K\", 0)\n  val V = TypeParam(\"V\", 1)\n\n  val listId: TypeId[List]   = nominal[List](\"List\", pkgScalaCollection, List(A))\n  val optionId: TypeId[Option] = nominal[Option](\"Option\", pkgScala, List(A))\n  val mapId: TypeId[Map]     = nominal[Map](\"Map\", pkgScalaCollection, List(K, V))\n  val eitherId: TypeId[Either] = nominal[Either](\"Either\", pkgScala, List(A, B))\n\n  // Type constructors (unapplied)\n  val listConstructor: TypeRepr   = Ref(listId)\n  val optionConstructor: TypeRepr = Ref(optionId)\n\n  // Applied types\n  val listIntType: TypeRepr       = Applied(Ref(listId), List(intType))\n  val optionStringType: TypeRepr  = Applied(Ref(optionId), List(stringType))\n  val mapStringIntType: TypeRepr  = Applied(Ref(mapId), List(stringType, intType))\n\n  // ===== Type aliases =====\n\n  // type Age = Int\n  val ageId: TypeId[Int] = alias[Int](\n    name       = \"Age\",\n    owner      = pkgMyApp,\n    typeParams = Nil,\n    aliased    = intType\n  )\n  val ageType: TypeRepr = Ref(ageId)\n\n  // type MyList[A] = List[A]\n  val myListId: TypeId[List] = alias[List](\n    name       = \"MyList\",\n    owner      = pkgMyApp,\n    typeParams = List(A),\n    aliased    = Applied(Ref(listId), List(ParamRef(A)))\n  )\n\n  // type StringMap[V] = Map[String, V]\n  val stringMapId: TypeId[Map[String, *]] = alias[Map[String, *]](\n    name       = \"StringMap\",\n    owner      = pkgMyApp,\n    typeParams = List(V),\n    aliased    = Applied(Ref(mapId), List(stringType, ParamRef(V)))\n  )\n\n  // type Id[A] = A\n  val idId: TypeId[AnyKind] = alias[AnyKind](\n    name       = \"Id\",\n    owner      = pkgMyApp,\n    typeParams = List(A),\n    aliased    = ParamRef(A)\n  )\n\n  // ===== Opaque types =====\n\n  // opaque type Email = String\n  val emailId: TypeId[String] = opaque[String](\n    name           = \"Email\",\n    owner          = pkgMyApp,\n    typeParams     = Nil,\n    representation = stringType\n  )\n  val emailType: TypeRepr = Ref(emailId)\n\n  // opaque type SafeList[A] = List[A]\n  val safeListId: TypeId[List] = opaque[List](\n    name           = \"SafeList\",\n    owner          = pkgMyApp,\n    typeParams     = List(A),\n    representation = Applied(Ref(listId), List(ParamRef(A)))\n  )\n\n  // ===== Structural types =====\n\n  // { def size: Int; val isEmpty: Boolean }\n  val sizedType: TypeRepr = Structural(\n    parents = Nil,\n    members = List(\n      Def(\"size\", Nil, intType),\n      Val(\"isEmpty\", booleanType, isVar = false)\n    )\n  )\n\n  // type Record[A] = { def value: A }\n  val recordId: TypeId[AnyKind] = alias[AnyKind](\n    name       = \"Record\",\n    owner      = pkgMyApp,\n    typeParams = List(A),\n    aliased    = Structural(\n      parents = Nil,\n      members = List(\n        Def(\"value\", Nil, ParamRef(A))\n      )\n    )\n  )\n\n  // { type T; def get: T }\n  val T = TypeParam(\"T\", 0)\n  val genericGetterType: TypeRepr = Structural(\n    parents = Nil,\n    members = List(\n      TypeMember(\"T\", Nil, None, None),\n      // Note: ParamRef(T) here is a shorthand for \"the type member T\";\n      // if you want precise scoping you can extend the model, but for\n      // most uses you'll just inspect the name.\n      Def(\"get\", Nil, ParamRef(T))\n    )\n  )\n\n  // ===== Higher-kinded example =====\n\n  // type F[G[_], A] = G[A]\n  val G = TypeParam(\"G\", 0)\n  val fId: TypeId[AnyKind] = alias[AnyKind](\n    name       = \"F\",\n    owner      = pkgMyApp,\n    typeParams = List(G, A),\n    aliased    = Applied(\n      tycon = ParamRef(G),  // G is itself a type constructor\n      args  = List(ParamRef(A))\n    )\n  )\n\n  // ===== Singleton and constant types =====\n\n  // 42 (literal type)\n  val fortyTwoType: TypeRepr = Constant(42)\n\n  // \"hello\" (literal type)\n  val helloType: TypeRepr = Constant(\"hello\")\n\n  // myObject.type\n  val myObjectSingleton: TypeRepr = Singleton(\n    TermPath(List(TermPath.Package(\"myapp\"), TermPath.Term(\"myObject\")))\n  )\n\n  // ===== Complex types =====\n\n  // Option[List[String]]\n  val optionListStringType: TypeRepr =\n    Applied(Ref(optionId), List(Applied(Ref(listId), List(stringType))))\n\n  // Map[Email, List[Age]]\n  val emailToAgesType: TypeRepr =\n    Applied(\n      Ref(mapId),\n      List(\n        Ref(emailId),\n        Applied(Ref(listId), List(Ref(ageId)))\n      )\n    )\n\n  // (Int, String) => Boolean\n  val intStringToBoolType: TypeRepr =\n    Function(List(intType, stringType), booleanType)\n\n  // String & { def length: Int }\n  val stringWithLengthType: TypeRepr =\n    Intersection(\n      stringType,\n      Structural(Nil, List(Def(\"length\", Nil, intType)))\n    )\n\n  // ===== Utility: substitute type parameters =====\n\n  def substitute(\n    repr: TypeRepr,\n    substitutions: Map[TypeParam, TypeRepr]\n  ): TypeRepr =\n    repr match {\n      case ParamRef(param) =>\n        substitutions.getOrElse(param, repr)\n\n      case Ref(_) =>\n        repr\n\n      case Applied(tycon, args) =>\n        Applied(\n          substitute(tycon, substitutions),\n          args.map(substitute(_, substitutions))\n        )\n\n      case Structural(parents, members) =>\n        Structural(\n          parents.map(substitute(_, substitutions)),\n          members.map(substituteMember(_, substitutions))\n        )\n\n      case Intersection(l, r) =>\n        Intersection(\n          substitute(l, substitutions),\n          substitute(r, substitutions)\n        )\n\n      case Union(l, r) =>\n        Union(\n          substitute(l, substitutions),\n          substitute(r, substitutions)\n        )\n\n      case Tuple(elems) =>\n        Tuple(elems.map(substitute(_, substitutions)))\n\n      case Function(params, result) =>\n        Function(\n          params.map(substitute(_, substitutions)),\n          substitute(result, substitutions)\n        )\n\n      case Singleton(_) | Constant(_) | AnyType | NothingType =>\n        repr\n    }\n\n  private def substituteMember(\n    m: Member,\n    substitutions: Map[TypeParam, TypeRepr]\n  ): Member =\n    m match {\n      case Val(name, tpe, isVar) =>\n        Val(name, substitute(tpe, substitutions), isVar)\n\n      case Def(name, paramLists, result) =>\n        Def(\n          name,\n          paramLists.map(_.map { p => Param(p.name, substitute(p.tpe, substitutions)) }),\n          substitute(result, substitutions)\n        )\n\n      case TypeMember(name, typeParams, lower, upper) =>\n        TypeMember(\n          name,\n          typeParams,\n          lower.map(substitute(_, substitutions)),\n          upper.map(substitute(_, substitutions))\n        )\n    }\n\n  // Get underlying type for alias/opaque with substitution\n  def underlyingType(\n    id: TypeId[_],\n    args: List[TypeRepr]\n  ): Option[TypeRepr] = id match {\n    case TypeId.Alias(_, _, typeParams, aliased) =>\n      val subs = typeParams.zip(args).toMap\n      Some(substitute(aliased, subs))\n\n    case TypeId.Opaque(_, _, typeParams, representation) =>\n      val subs = typeParams.zip(args).toMap\n      Some(substitute(representation, subs))\n\n    case _ =>\n      None\n  }\n\n  // Examples:\n  // underlyingType(ageId, Nil)                  => Some(Int)\n  // underlyingType(myListId, List(intType))     => Some(List[Int])\n  // underlyingType(stringMapId, List(intType))  => Some(Map[String, Int])\n  // underlyingType(emailId, Nil)                => Some(String)\n\n  // ===== Type safety via phantom types =====\n\n  def processList(id: TypeId[List]): String =\n    s\"Processing list type constructor: ${id.fullName}\"\n\n  def processScalar[A](id: TypeId[A]): String =\n    s\"Processing scalar type: ${id.fullName}\"\n\n  // These compile:\n  val _x: String = processList(listId)\n  val _y: String = processList(myListId)     // MyList is an alias for List\n  val _z: String = processList(safeListId)   // SafeList is opaque over List\n\n  val _s1: String = processScalar(intId)\n  val _s2: String = processScalar(ageId)     // Age is an alias for Int\n  val _s3: String = processScalar(emailId)   // Email is opaque over String\n\n  // These would NOT compile:\n  // processList(intId)     // Type mismatch\n  // processScalar(listId)  // Type mismatch\n}\n```",
              "url": "https://github.com/zio/zio-blocks/issues/471",
              "tech": [
                "go"
              ],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#514",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-17T18:24:18.603Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:18.603Z",
            "created_at": "2025-12-17T18:24:18.603Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#514",
              "status": "open",
              "type": "issue",
              "number": 514,
              "title": "Add annotation macros for Scala 2.13 and Scala 3.5+",
              "source": {
                "data": {
                  "id": "source-ZIO#514",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add annotation macros for Scala 2.13 and Scala 3.5+",
                  "body": "# Overview\n\nThis ticket involves adding two annotation macros for Scala 2.13 and Scala 3.5+. These annotation macros will add new definitions in the companion object of the trait / class / enum to which they are applied.\n\nThe annotation macros are as follows:\n\n - `@optic`: Adds optics for all terms of the record / enum inside the companion object. Comes in an optional variant, called `@optics_`, which prefixes all optics with an underscore character (`_`) to avoid name collisions. The names of these optics are the same as the term names, except for sum term names, the first letter is lower-cased to avoid colliding with the object of the same name in the same scope.\n - `@schema`: Adds an `implicit` / `given` schema for the record / enum inside the companion object, with the name `<xyz>Schema`, e.g. `personSchema`.\n\n**Note 1**: In the ideal case, applying `@optics` to a sealed trait or enum would result in optics being added to the companion objects of the subtypes of the sealed trait / enum.\n\n## Optics\n### Case Class\n#### User-Code\n\n```scala\n@optics\nfinal case class Person(name: String, age: Int)\n```\n#### Macro Expansion\n```scala\n@optics\nfinal case class Person(name: String, age: Int)\nobject Person {\n  val name: Lens[Person, String] = ???\n  val age: Lens[Person, Int] = ???\n}\n```\n\n### Sealed Trait\n#### User-Code\n\n```scala\n@optics\nsealed trait Result[+A]\nobject Result {\n  @optics final case class Success[A](value: A) extends Result[A]\n  @optics final case class Failure(error: String) extends Result[Nothing]\n  case object Pending extends Result[Nothing]\n}\n```\n\n#### Macro Expansion\n\n```scala\n@optics\nsealed trait Result[+A]\nobject Result {\n  @optics final case class Success[A](value: A) extends Result[A]\n  object Success {\n    val value: Lens[Success[A], A] = ???\n  }\n  \n  @optics final case class Failure(error: String) extends Result[Nothing]\n  object Failure {\n    val error: Lens[Failure, String] = ???\n  }\n  \n  case object Pending extends Result[Nothing]\n  \n  val success: Prism[Result[A], Success[A]] = ???\n  val failure: Prism[Result[Nothing], Failure] = ???\n  val pending: Prism[Result[Nothing], Pending.type] = ???\n}\n```\n\n### Enum\n#### User-Code\n\n```scala\n@optics\nenum Status {\n  case Active(since: Long)\n  case Inactive\n  case Suspended(reason: String, until: Long)\n}\n```\n#### Macro Expansion\n```scala\n@optics\nenum Status {\n  case Active(since: Long)\n  case Inactive\n  case Suspended(reason: String, until: Long)\n}\nobject Status {\n  object Active {\n    val since: Lens[Active, Long] = ???\n  }\n  object Suspended {\n    val reason: Lens[Suspended, String] = ???\n    val until: Lens[Suspended, Long] = ???\n  }\n  \n  val active: Prism[Status, Active] = ???\n  val inactive: Prism[Status, Inactive.type] = ???\n  val suspended: Prism[Status, Suspended] = ???\n}\n```\n## Optics\n### Case Class\n#### User-Code\n```scala\n@optics\nfinal case class Person(name: String, age: Int)\n```\n#### Macro Expansion\n```scala\n@optics\nfinal case class Person(name: String, age: Int)\nobject Person {\n  val name: Lens[Person, String] = ???\n  val age: Lens[Person, Int] = ???\n}\n```\n\n### Sealed Trait\n#### User-Code\n```scala\n@optics\nsealed trait Result[+A]\nobject Result {\n  @optics final case class Success[A](value: A) extends Result[A]\n  @optics final case class Failure(error: String) extends Result[Nothing]\n  case object Pending extends Result[Nothing]\n}\n```\n#### Macro Expansion\n```scala\n@optics\nsealed trait Result[+A]\nobject Result {\n  @optics final case class Success[A](value: A) extends Result[A]\n  object Success {\n    val value: Lens[Success[A], A] = ???\n  }\n  \n  @optics final case class Failure(error: String) extends Result[Nothing]\n  object Failure {\n    val error: Lens[Failure, String] = ???\n  }\n  \n  case object Pending extends Result[Nothing]\n  \n  val success: Prism[Result[A], Success[A]] = ???\n  val failure: Prism[Result[Nothing], Failure] = ???\n  val pending: Prism[Result[Nothing], Pending.type] = ???\n}\n```\n\n### Enum\n#### User-Code\n```scala\n@optics\nenum Status {\n  case Active(since: Long)\n  case Inactive\n  case Suspended(reason: String, until: Long)\n}\n```\n#### Macro Expansion\n```scala\n@optics\nenum Status {\n  case Active(since: Long)\n  case Inactive\n  case Suspended(reason: String, until: Long)\n}\nobject Status {\n  object Active {\n    val since: Lens[Active, Long] = ???\n  }\n  object Suspended {\n    val reason: Lens[Suspended, String] = ???\n    val until: Lens[Suspended, Long] = ???\n  }\n  \n  val active: Prism[Status, Active] = ???\n  val inactive: Prism[Status, Inactive.type] = ???\n  val suspended: Prism[Status, Suspended] = ???\n}\n```\n\n## Schema\n### Case Class\n#### User-Code (Scala 2.13)\n```scala\n@schema\nfinal case class Person(name: String, age: Int)\n```\n#### Macro Expansion (Scala 2.13)\n```scala\n@schema\nfinal case class Person(name: String, age: Int)\nobject Person {\n  implicit val personSchema: Schema[Person] = Schema.derived[Person]\n}\n```\n\n#### User-Code (Scala 3.5)\n```scala\n@schema\nfinal case class Person(name: String, age: Int)\n```\n#### Macro Expansion (Scala 3.5)\n```scala\n@schema\nfinal case class Person(name: String, age: Int)\nobject Person {\n  given personSchema: Schema[Person] = Schema.derived[Person]\n}\n```\n\n### Sealed Trait\n#### User-Code (Scala 2.13)\n```scala\n@schema\nsealed trait Result[+A]\nobject Result {\n  @schema final case class Success[A](value: A) extends Result[A]\n  @schema final case class Failure(error: String) extends Result[Nothing]\n  case object Pending extends Result[Nothing]\n}\n```\n#### Macro Expansion (Scala 2.13)\n```scala\n@schema\nsealed trait Result[+A]\nobject Result {\n  @schema final case class Success[A](value: A) extends Result[A]\n  object Success {\n    implicit def successSchema[A: Schema]: Schema[Success[A]] = Schema.derived[Success[A]]\n  }\n  \n  @schema final case class Failure(error: String) extends Result[Nothing]\n  object Failure {\n    implicit val failureSchema: Schema[Failure] = Schema.derived[Failure]\n  }\n  \n  case object Pending extends Result[Nothing]\n  \n  implicit def resultSchema[A: Schema]: Schema[Result[A]] = Schema.derived[Result[A]]\n}\n```\n\n#### User-Code (Scala 3.5)\n```scala\n@schema\nsealed trait Result[+A]\nobject Result {\n  @schema final case class Success[A](value: A) extends Result[A]\n  @schema final case class Failure(error: String) extends Result[Nothing]\n  case object Pending extends Result[Nothing]\n}\n```\n#### Macro Expansion (Scala 3.5)\n```scala\n@schema\nsealed trait Result[+A]\nobject Result {\n  @schema final case class Success[A](value: A) extends Result[A]\n  object Success {\n    given successSchema[A: Schema]: Schema[Success[A]] = Schema.derived[Success[A]]\n  }\n  \n  @schema final case class Failure(error: String) extends Result[Nothing]\n  object Failure {\n    given failureSchema: Schema[Failure] = Schema.derived[Failure]\n  }\n  \n  case object Pending extends Result[Nothing]\n  \n  given resultSchema[A: Schema]: Schema[Result[A]] = Schema.derived[Result[A]]\n}\n```\n\n### Enum\n#### User-Code (Scala 3.5)\n```scala\n@schema\nenum Status {\n  case Active(since: Long)\n  case Inactive\n  case Suspended(reason: String, until: Long)\n}\n```\n#### Macro Expansion (Scala 3.5)\n```scala\n@schema\nenum Status {\n  case Active(since: Long)\n  case Inactive\n  case Suspended(reason: String, until: Long)\n}\nobject Status {\n  given statusSchema: Schema[Status] = Schema.derived[Status]\n}\n```",
                  "html_url": "https://github.com/zio/zio-blocks/issues/514"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#514",
              "body": "# Overview\n\nThis ticket involves adding two annotation macros for Scala 2.13 and Scala 3.5+. These annotation macros will add new definitions in the companion object of the trait / class / enum to which they are applied.\n\nThe annotation macros are as follows:\n\n - `@optic`: Adds optics for all terms of the record / enum inside the companion object. Comes in an optional variant, called `@optics_`, which prefixes all optics with an underscore character (`_`) to avoid name collisions. The names of these optics are the same as the term names, except for sum term names, the first letter is lower-cased to avoid colliding with the object of the same name in the same scope.\n - `@schema`: Adds an `implicit` / `given` schema for the record / enum inside the companion object, with the name `<xyz>Schema`, e.g. `personSchema`.\n\n**Note 1**: In the ideal case, applying `@optics` to a sealed trait or enum would result in optics being added to the companion objects of the subtypes of the sealed trait / enum.\n\n## Optics\n### Case Class\n#### User-Code\n\n```scala\n@optics\nfinal case class Person(name: String, age: Int)\n```\n#### Macro Expansion\n```scala\n@optics\nfinal case class Person(name: String, age: Int)\nobject Person {\n  val name: Lens[Person, String] = ???\n  val age: Lens[Person, Int] = ???\n}\n```\n\n### Sealed Trait\n#### User-Code\n\n```scala\n@optics\nsealed trait Result[+A]\nobject Result {\n  @optics final case class Success[A](value: A) extends Result[A]\n  @optics final case class Failure(error: String) extends Result[Nothing]\n  case object Pending extends Result[Nothing]\n}\n```\n\n#### Macro Expansion\n\n```scala\n@optics\nsealed trait Result[+A]\nobject Result {\n  @optics final case class Success[A](value: A) extends Result[A]\n  object Success {\n    val value: Lens[Success[A], A] = ???\n  }\n  \n  @optics final case class Failure(error: String) extends Result[Nothing]\n  object Failure {\n    val error: Lens[Failure, String] = ???\n  }\n  \n  case object Pending extends Result[Nothing]\n  \n  val success: Prism[Result[A], Success[A]] = ???\n  val failure: Prism[Result[Nothing], Failure] = ???\n  val pending: Prism[Result[Nothing], Pending.type] = ???\n}\n```\n\n### Enum\n#### User-Code\n\n```scala\n@optics\nenum Status {\n  case Active(since: Long)\n  case Inactive\n  case Suspended(reason: String, until: Long)\n}\n```\n#### Macro Expansion\n```scala\n@optics\nenum Status {\n  case Active(since: Long)\n  case Inactive\n  case Suspended(reason: String, until: Long)\n}\nobject Status {\n  object Active {\n    val since: Lens[Active, Long] = ???\n  }\n  object Suspended {\n    val reason: Lens[Suspended, String] = ???\n    val until: Lens[Suspended, Long] = ???\n  }\n  \n  val active: Prism[Status, Active] = ???\n  val inactive: Prism[Status, Inactive.type] = ???\n  val suspended: Prism[Status, Suspended] = ???\n}\n```\n## Optics\n### Case Class\n#### User-Code\n```scala\n@optics\nfinal case class Person(name: String, age: Int)\n```\n#### Macro Expansion\n```scala\n@optics\nfinal case class Person(name: String, age: Int)\nobject Person {\n  val name: Lens[Person, String] = ???\n  val age: Lens[Person, Int] = ???\n}\n```\n\n### Sealed Trait\n#### User-Code\n```scala\n@optics\nsealed trait Result[+A]\nobject Result {\n  @optics final case class Success[A](value: A) extends Result[A]\n  @optics final case class Failure(error: String) extends Result[Nothing]\n  case object Pending extends Result[Nothing]\n}\n```\n#### Macro Expansion\n```scala\n@optics\nsealed trait Result[+A]\nobject Result {\n  @optics final case class Success[A](value: A) extends Result[A]\n  object Success {\n    val value: Lens[Success[A], A] = ???\n  }\n  \n  @optics final case class Failure(error: String) extends Result[Nothing]\n  object Failure {\n    val error: Lens[Failure, String] = ???\n  }\n  \n  case object Pending extends Result[Nothing]\n  \n  val success: Prism[Result[A], Success[A]] = ???\n  val failure: Prism[Result[Nothing], Failure] = ???\n  val pending: Prism[Result[Nothing], Pending.type] = ???\n}\n```\n\n### Enum\n#### User-Code\n```scala\n@optics\nenum Status {\n  case Active(since: Long)\n  case Inactive\n  case Suspended(reason: String, until: Long)\n}\n```\n#### Macro Expansion\n```scala\n@optics\nenum Status {\n  case Active(since: Long)\n  case Inactive\n  case Suspended(reason: String, until: Long)\n}\nobject Status {\n  object Active {\n    val since: Lens[Active, Long] = ???\n  }\n  object Suspended {\n    val reason: Lens[Suspended, String] = ???\n    val until: Lens[Suspended, Long] = ???\n  }\n  \n  val active: Prism[Status, Active] = ???\n  val inactive: Prism[Status, Inactive.type] = ???\n  val suspended: Prism[Status, Suspended] = ???\n}\n```\n\n## Schema\n### Case Class\n#### User-Code (Scala 2.13)\n```scala\n@schema\nfinal case class Person(name: String, age: Int)\n```\n#### Macro Expansion (Scala 2.13)\n```scala\n@schema\nfinal case class Person(name: String, age: Int)\nobject Person {\n  implicit val personSchema: Schema[Person] = Schema.derived[Person]\n}\n```\n\n#### User-Code (Scala 3.5)\n```scala\n@schema\nfinal case class Person(name: String, age: Int)\n```\n#### Macro Expansion (Scala 3.5)\n```scala\n@schema\nfinal case class Person(name: String, age: Int)\nobject Person {\n  given personSchema: Schema[Person] = Schema.derived[Person]\n}\n```\n\n### Sealed Trait\n#### User-Code (Scala 2.13)\n```scala\n@schema\nsealed trait Result[+A]\nobject Result {\n  @schema final case class Success[A](value: A) extends Result[A]\n  @schema final case class Failure(error: String) extends Result[Nothing]\n  case object Pending extends Result[Nothing]\n}\n```\n#### Macro Expansion (Scala 2.13)\n```scala\n@schema\nsealed trait Result[+A]\nobject Result {\n  @schema final case class Success[A](value: A) extends Result[A]\n  object Success {\n    implicit def successSchema[A: Schema]: Schema[Success[A]] = Schema.derived[Success[A]]\n  }\n  \n  @schema final case class Failure(error: String) extends Result[Nothing]\n  object Failure {\n    implicit val failureSchema: Schema[Failure] = Schema.derived[Failure]\n  }\n  \n  case object Pending extends Result[Nothing]\n  \n  implicit def resultSchema[A: Schema]: Schema[Result[A]] = Schema.derived[Result[A]]\n}\n```\n\n#### User-Code (Scala 3.5)\n```scala\n@schema\nsealed trait Result[+A]\nobject Result {\n  @schema final case class Success[A](value: A) extends Result[A]\n  @schema final case class Failure(error: String) extends Result[Nothing]\n  case object Pending extends Result[Nothing]\n}\n```\n#### Macro Expansion (Scala 3.5)\n```scala\n@schema\nsealed trait Result[+A]\nobject Result {\n  @schema final case class Success[A](value: A) extends Result[A]\n  object Success {\n    given successSchema[A: Schema]: Schema[Success[A]] = Schema.derived[Success[A]]\n  }\n  \n  @schema final case class Failure(error: String) extends Result[Nothing]\n  object Failure {\n    given failureSchema: Schema[Failure] = Schema.derived[Failure]\n  }\n  \n  case object Pending extends Result[Nothing]\n  \n  given resultSchema[A: Schema]: Schema[Result[A]] = Schema.derived[Result[A]]\n}\n```\n\n### Enum\n#### User-Code (Scala 3.5)\n```scala\n@schema\nenum Status {\n  case Active(since: Long)\n  case Inactive\n  case Suspended(reason: String, until: Long)\n}\n```\n#### Macro Expansion (Scala 3.5)\n```scala\n@schema\nenum Status {\n  case Active(since: Long)\n  case Inactive\n  case Suspended(reason: String, until: Long)\n}\nobject Status {\n  given statusSchema: Schema[Status] = Schema.derived[Status]\n}\n```",
              "url": "https://github.com/zio/zio-blocks/issues/514",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#3697",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-17T18:24:20.442Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:20.442Z",
            "created_at": "2025-12-17T18:24:20.442Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#3697",
              "status": "open",
              "type": "issue",
              "number": 3697,
              "title": "Datastar requests from Endpoint",
              "source": {
                "data": {
                  "id": "source-ZIO#3697",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Datastar requests from Endpoint",
                  "body": "Build Datastar expressions for request against an Endpoint from its definition\n",
                  "html_url": "https://github.com/zio/zio-http/issues/3697"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3697",
              "body": "Build Datastar expressions for request against an Endpoint from its definition\n",
              "url": "https://github.com/zio/zio-http/issues/3697",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#709",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-17T18:24:21.131Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:21.131Z",
            "created_at": "2025-12-17T18:24:21.131Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#709",
              "status": "open",
              "type": "issue",
              "number": 709,
              "title": "Support Http Range header on request for Files",
              "source": {
                "data": {
                  "id": "source-ZIO#709",
                  "user": {
                    "login": "ashprakasan",
                    "id": 8946971,
                    "node_id": "MDQ6VXNlcjg5NDY5NzE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/8946971?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ashprakasan",
                    "html_url": "https://github.com/ashprakasan",
                    "followers_url": "https://api.github.com/users/ashprakasan/followers",
                    "following_url": "https://api.github.com/users/ashprakasan/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ashprakasan/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ashprakasan/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ashprakasan/subscriptions",
                    "organizations_url": "https://api.github.com/users/ashprakasan/orgs",
                    "repos_url": "https://api.github.com/users/ashprakasan/repos",
                    "events_url": "https://api.github.com/users/ashprakasan/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ashprakasan/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Support Http Range header on request for Files",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe Range HTTP request header indicates the part of a document that the server should return. Several parts can be requested with one Range header at once, and the server may send back these ranges in a multipart document.\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample requesting 3 ranges from files -\r\n`Range: bytes=200-1000, 2000-6576, 19000-`\r\n\r\nSend only those parts of the document in Response.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCurrently, the range is hardcoded as follows - \r\n` ctx.write(new DefaultFileRegion(raf.getChannel, 0, fileLength))`\r\nManipulate the positions as per request headers instead.\r\n\r\n**Additional context**\r\n\r\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Range\r\n",
                  "html_url": "https://github.com/zio/zio-http/issues/709"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#709",
              "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe Range HTTP request header indicates the part of a document that the server should return. Several parts can be requested with one Range header at once, and the server may send back these ranges in a multipart document.\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample requesting 3 ranges from files -\r\n`Range: bytes=200-1000, 2000-6576, 19000-`\r\n\r\nSend only those parts of the document in Response.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCurrently, the range is hardcoded as follows - \r\n` ctx.write(new DefaultFileRegion(raf.getChannel, 0, fileLength))`\r\nManipulate the positions as per request headers instead.\r\n\r\n**Additional context**\r\n\r\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Range\r\n",
              "url": "https://github.com/zio/zio-http/issues/709",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#3472",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-17T18:24:22.290Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:22.290Z",
            "created_at": "2025-12-17T18:24:22.290Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#3472",
              "status": "open",
              "type": "issue",
              "number": 3472,
              "title": "Split into multiple modules",
              "source": {
                "data": {
                  "id": "source-ZIO#3472",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Split into multiple modules",
                  "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
                  "html_url": "https://github.com/zio/zio-http/issues/3472"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3472",
              "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
              "url": "https://github.com/zio/zio-http/issues/3472",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9810",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-17T18:24:22.968Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:22.968Z",
            "created_at": "2025-12-17T18:24:22.968Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9810",
              "status": "open",
              "type": "issue",
              "number": 9810,
              "title": "ZStreams buffer(1) is buffering 2.",
              "source": {
                "data": {
                  "id": "source-ZIO#9810",
                  "user": {
                    "login": "douglasthomsen",
                    "id": 88000378,
                    "node_id": "MDQ6VXNlcjg4MDAwMzc4",
                    "avatar_url": "https://avatars.githubusercontent.com/u/88000378?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/douglasthomsen",
                    "html_url": "https://github.com/douglasthomsen",
                    "followers_url": "https://api.github.com/users/douglasthomsen/followers",
                    "following_url": "https://api.github.com/users/douglasthomsen/following{/other_user}",
                    "gists_url": "https://api.github.com/users/douglasthomsen/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/douglasthomsen/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/douglasthomsen/subscriptions",
                    "organizations_url": "https://api.github.com/users/douglasthomsen/orgs",
                    "repos_url": "https://api.github.com/users/douglasthomsen/repos",
                    "events_url": "https://api.github.com/users/douglasthomsen/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/douglasthomsen/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZStreams buffer(1) is buffering 2.",
                  "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
                  "html_url": "https://github.com/zio/zio/issues/9810"
                },
                "type": "github"
              },
              "hash": "zio/zio#9810",
              "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
              "url": "https://github.com/zio/zio/issues/9810",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9844",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-17T18:24:23.959Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:23.959Z",
            "created_at": "2025-12-17T18:24:23.959Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9844",
              "status": "open",
              "type": "issue",
              "number": 9844,
              "title": "improved `Queue` shutdown functionality",
              "source": {
                "data": {
                  "id": "source-ZIO#9844",
                  "user": {
                    "login": "mberndt123",
                    "id": 11650737,
                    "node_id": "MDQ6VXNlcjExNjUwNzM3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/11650737?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/mberndt123",
                    "html_url": "https://github.com/mberndt123",
                    "followers_url": "https://api.github.com/users/mberndt123/followers",
                    "following_url": "https://api.github.com/users/mberndt123/following{/other_user}",
                    "gists_url": "https://api.github.com/users/mberndt123/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/mberndt123/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/mberndt123/subscriptions",
                    "organizations_url": "https://api.github.com/users/mberndt123/orgs",
                    "repos_url": "https://api.github.com/users/mberndt123/repos",
                    "events_url": "https://api.github.com/users/mberndt123/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/mberndt123/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "improved `Queue` shutdown functionality",
                  "body": "Hey, I've recently proposed something on Discord, and since feedback has been rather positive, I'm making a ticket to track the idea.\n\nI've been working with Queues recently, and I've been having some issues around `shutdown` that I would like to address.\n\nSpecifically, I find it a common pattern that I send some kind of request object through a queue because I want another fiber to perform some action on my behalf. Along with the request, I send a `Promise` to have that fiber communicate the outcome of that action to me. By and large this works fine. The issue arises when the fiber that I'm sending requests to fails. In that case, I would like it to communicate the cause of the failure back to the other fibers. This is easy enough for the requests that I've already pulled out of the queue: I simply fail those promises.\nBut I also need to deal with other cases: fibers currently blocked in an `offer` call, future attempts to `offer` to the queue, and I also need to deal with requests that have been submitted to the queue but not yet retrieved.\n\nSo my idea is as follows:\n - add an `E` type parameter to `Queue`\n - add a `shutdownCause` method that takes a type parameter of type `Cause[E]`\n - `shutdownCause` would also return the items currently buffered in the queue in order to dispose of them\n - after `shutdownCause` has been called, any attempt to interact with the queue will fail with the cause\n - methods like `take, offer` etc. should indicate errors of type `E`\n - streams created with `ZStream.fromQueue` would also fail with this cause\n - `shutdownCause` should be atomic: when multiple fibers call it at the same time, one of them wins and the others fail with the cause supplied by the winner\n\nAfaik, adding a new method is a binary compatible change, as is adding a new type parameter. Hence I think this is a source incompatible but binary compatible change. @ghostdogpr therefore suggested it could be added in a ZIO 2.2 release.\n",
                  "html_url": "https://github.com/zio/zio/issues/9844"
                },
                "type": "github"
              },
              "hash": "zio/zio#9844",
              "body": "Hey, I've recently proposed something on Discord, and since feedback has been rather positive, I'm making a ticket to track the idea.\n\nI've been working with Queues recently, and I've been having some issues around `shutdown` that I would like to address.\n\nSpecifically, I find it a common pattern that I send some kind of request object through a queue because I want another fiber to perform some action on my behalf. Along with the request, I send a `Promise` to have that fiber communicate the outcome of that action to me. By and large this works fine. The issue arises when the fiber that I'm sending requests to fails. In that case, I would like it to communicate the cause of the failure back to the other fibers. This is easy enough for the requests that I've already pulled out of the queue: I simply fail those promises.\nBut I also need to deal with other cases: fibers currently blocked in an `offer` call, future attempts to `offer` to the queue, and I also need to deal with requests that have been submitted to the queue but not yet retrieved.\n\nSo my idea is as follows:\n - add an `E` type parameter to `Queue`\n - add a `shutdownCause` method that takes a type parameter of type `Cause[E]`\n - `shutdownCause` would also return the items currently buffered in the queue in order to dispose of them\n - after `shutdownCause` has been called, any attempt to interact with the queue will fail with the cause\n - methods like `take, offer` etc. should indicate errors of type `E`\n - streams created with `ZStream.fromQueue` would also fail with this cause\n - `shutdownCause` should be atomic: when multiple fibers call it at the same time, one of them wins and the others fail with the cause supplied by the winner\n\nAfaik, adding a new method is a binary compatible change, as is adding a new type parameter. Hence I think this is a source incompatible but binary compatible change. @ghostdogpr therefore suggested it could be added in a ZIO 2.2 release.\n",
              "url": "https://github.com/zio/zio/issues/9844",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9878",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-17T18:24:24.773Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:24.773Z",
            "created_at": "2025-12-17T18:24:24.773Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9878",
              "status": "open",
              "type": "issue",
              "number": 9878,
              "title": "ZScheduler parks+unparks workers too frequently",
              "source": {
                "data": {
                  "id": "source-ZIO#9878",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZScheduler parks+unparks workers too frequently",
                  "body": "Unparking workers is slow and invoked in the hotpath too often. I think we may need to trade some fairness for aggression to avoid excessive cycling.\n\n`maybeUnparkWorker` (obviously `LockSupport.unpark(worker)`) is very expensive: https://github.com/zio/zio/blob/series/2.x/core/jvm-native/src/main/scala/zio/internal/ZScheduler.scala#L443-L454",
                  "html_url": "https://github.com/zio/zio/issues/9878"
                },
                "type": "github"
              },
              "hash": "zio/zio#9878",
              "body": "Unparking workers is slow and invoked in the hotpath too often. I think we may need to trade some fairness for aggression to avoid excessive cycling.\n\n`maybeUnparkWorker` (obviously `LockSupport.unpark(worker)`) is very expensive: https://github.com/zio/zio/blob/series/2.x/core/jvm-native/src/main/scala/zio/internal/ZScheduler.scala#L443-L454",
              "url": "https://github.com/zio/zio/issues/9878",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9877",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-12-17T18:24:26.203Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:26.203Z",
            "created_at": "2025-12-17T18:24:26.203Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9877",
              "status": "open",
              "type": "issue",
              "number": 9877,
              "title": "Can Fiber(Runtime) and Promise be merged?",
              "source": {
                "data": {
                  "id": "source-ZIO#9877",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Can Fiber(Runtime) and Promise be merged?",
                  "body": "A Promise awaiting completion is essentially a Fiber parked awaiting an async callback. When a Fiber is forking work (which will eventually complete a promise), then awaiting a Promise, we end up with unnecessary allocations + indirection.\n\nit would be useful to have `Promise.become` or similar to link fibers/promises.",
                  "html_url": "https://github.com/zio/zio/issues/9877"
                },
                "type": "github"
              },
              "hash": "zio/zio#9877",
              "body": "A Promise awaiting completion is essentially a Fiber parked awaiting an async callback. When a Fiber is forking work (which will eventually complete a promise), then awaiting a Promise, we end up with unnecessary allocations + indirection.\n\nit would be useful to have `Promise.become` or similar to link fibers/promises.",
              "url": "https://github.com/zio/zio/issues/9877",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "activepieces#9703",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "activepieces",
              "id": "generated-activepieces",
              "name": "Activepieces",
              "description": "",
              "members": [],
              "display_name": "Activepieces",
              "created_at": "2025-12-17T18:24:39.910Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/activepieces?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "activepieces",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:39.910Z",
            "created_at": "2025-12-17T18:24:39.910Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-activepieces#9703",
              "status": "open",
              "type": "issue",
              "number": 9703,
              "title": "[MCP] Oracle Fusion Cloud ERP",
              "source": {
                "data": {
                  "id": "source-activepieces#9703",
                  "user": {
                    "login": "kishanprmr",
                    "id": 135701940,
                    "node_id": "U_kgDOCBaltA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/135701940?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kishanprmr",
                    "html_url": "https://github.com/kishanprmr",
                    "followers_url": "https://api.github.com/users/kishanprmr/followers",
                    "following_url": "https://api.github.com/users/kishanprmr/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kishanprmr/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kishanprmr/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kishanprmr/subscriptions",
                    "organizations_url": "https://api.github.com/users/kishanprmr/orgs",
                    "repos_url": "https://api.github.com/users/kishanprmr/repos",
                    "events_url": "https://api.github.com/users/kishanprmr/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kishanprmr/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[MCP] Oracle Fusion Cloud ERP",
                  "body": "##   Product Overview\n\nOracle Fusion Cloud ERP is an enterprise resource planning suite covering financials, procurement, project accounting, supply chain, and more. This integration supports generic record operations (CRUD + search + watch) across business objects in Fusion ERP, enabling automation and data synchronization. \n\n---\n\n##   Important Note for Contributors\n\nThis feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions not following this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n##  Triggers\n\n| **Trigger** | **Description** | \n|:--|:--|\n| **New Record** | Fires when new records are created in a specified business object (e.g. Invoice, Purchase Order, Customer) in Oracle ERP. | \n\n\n---\n\n##   Write Actions\n\n| **Action** | **Description** | **Use Case Example** |\n|:--|:--|:--|\n| **Create Record**     | Create a new record in a specified object (e.g. Invoice, PO, Customer). | Automate creating purchase orders from purchase requests.  |\n| **Update Record**     | Update fields of an existing record (by object + ID).                      | Update invoice status, adjust amounts, modify due dates. |\n| **Delete a Record**    | Delete (or mark for deletion) a record by ID.                             | Remove test or obsolete records.  |\n| **Get a Record**     | Retrieve the details of a specific record (by object type and ID). | Fetch detailed invoice or supplier info when needed.  |\n\n\n\n---\n\n##  Search Actions\n\n| Action Name       | Description                                                                 | \n|--------------------|-----------------------------------------------------------------------------|\n| **Search Records**   | Retrieve a list of records matching filter criteria (object + query). |\n\n---\n\n##   API Reference\n\n- [Oracle Fusion Cloud ERP API Documentation](https://docs.oracle.com/en/cloud/saas/financials/25d/farfa/index.html)\n\n---\n\n##   Test Account Access\n\n- You can create free trial at https://www.oracle.com/in/erp/financials/.\n\n---\n\n##  New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are build with our TypeScript framework and are easy to build. Once they're merged to our repo, they will available as pieces in our automation builder and as MCPs to be used with AI agents and MCP clients.\n\nWe welcome contributions and in fact, we get excited over them. Start your journey here: https://www.activepieces.com/docs/developers/building-pieces/overview\n",
                  "html_url": "https://github.com/activepieces/activepieces/issues/9703"
                },
                "type": "github"
              },
              "hash": "activepieces/activepieces#9703",
              "body": "##   Product Overview\n\nOracle Fusion Cloud ERP is an enterprise resource planning suite covering financials, procurement, project accounting, supply chain, and more. This integration supports generic record operations (CRUD + search + watch) across business objects in Fusion ERP, enabling automation and data synchronization. \n\n---\n\n##   Important Note for Contributors\n\nThis feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions not following this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n##  Triggers\n\n| **Trigger** | **Description** | \n|:--|:--|\n| **New Record** | Fires when new records are created in a specified business object (e.g. Invoice, Purchase Order, Customer) in Oracle ERP. | \n\n\n---\n\n##   Write Actions\n\n| **Action** | **Description** | **Use Case Example** |\n|:--|:--|:--|\n| **Create Record**     | Create a new record in a specified object (e.g. Invoice, PO, Customer). | Automate creating purchase orders from purchase requests.  |\n| **Update Record**     | Update fields of an existing record (by object + ID).                      | Update invoice status, adjust amounts, modify due dates. |\n| **Delete a Record**    | Delete (or mark for deletion) a record by ID.                             | Remove test or obsolete records.  |\n| **Get a Record**     | Retrieve the details of a specific record (by object type and ID). | Fetch detailed invoice or supplier info when needed.  |\n\n\n\n---\n\n##  Search Actions\n\n| Action Name       | Description                                                                 | \n|--------------------|-----------------------------------------------------------------------------|\n| **Search Records**   | Retrieve a list of records matching filter criteria (object + query). |\n\n---\n\n##   API Reference\n\n- [Oracle Fusion Cloud ERP API Documentation](https://docs.oracle.com/en/cloud/saas/financials/25d/farfa/index.html)\n\n---\n\n##   Test Account Access\n\n- You can create free trial at https://www.oracle.com/in/erp/financials/.\n\n---\n\n##  New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are build with our TypeScript framework and are easy to build. Once they're merged to our repo, they will available as pieces in our automation builder and as MCPs to be used with AI agents and MCP clients.\n\nWe welcome contributions and in fact, we get excited over them. Start your journey here: https://www.activepieces.com/docs/developers/building-pieces/overview\n",
              "url": "https://github.com/activepieces/activepieces/issues/9703",
              "tech": [
                "go"
              ],
              "repo_name": "activepieces",
              "repo_owner": "activepieces",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "activepieces#8284",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "activepieces",
              "id": "generated-activepieces",
              "name": "Activepieces",
              "description": "",
              "members": [],
              "display_name": "Activepieces",
              "created_at": "2025-12-17T18:24:40.020Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/activepieces?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "activepieces",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:40.020Z",
            "created_at": "2025-12-17T18:24:40.020Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-activepieces#8284",
              "status": "open",
              "type": "issue",
              "number": 8284,
              "title": "[MCP] Klaviyo",
              "source": {
                "data": {
                  "id": "source-activepieces#8284",
                  "user": {
                    "login": "kishanprmr",
                    "id": 135701940,
                    "node_id": "U_kgDOCBaltA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/135701940?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kishanprmr",
                    "html_url": "https://github.com/kishanprmr",
                    "followers_url": "https://api.github.com/users/kishanprmr/followers",
                    "following_url": "https://api.github.com/users/kishanprmr/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kishanprmr/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kishanprmr/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kishanprmr/subscriptions",
                    "organizations_url": "https://api.github.com/users/kishanprmr/orgs",
                    "repos_url": "https://api.github.com/users/kishanprmr/repos",
                    "events_url": "https://api.github.com/users/kishanprmr/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kishanprmr/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[MCP] Klaviyo",
                  "body": "##  Product Overview\n\nKlaviyo is a marketing automation platform for email, SMS, and customer data.  \nThis integration enables AI agents and workflows to create, manage, and interact with profiles, lists, events, campaigns, and segments, automating customer engagement and analytics.\n\n---\n\n##  Important Note for Contributors\n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n##  Triggers\n\n| **Trigger** | **Use Case** |\n|-------------|---------------|\n| **New Profile** | Triggers when a new profile is created in the account. |\n| **Profile Added to List/Segment** | Fires when a profile is added to a specific list or segment. |\n\n---\n\n##  Write Actions\n\n| **Action Item** | **Use Case** |\n|-----------------|---------------|\n| **Create Profile** | Add a new user profile to Klaviyo, optionally subscribing to email/SMS. |\n| **Update Profile** | Update existing profile data and preferences. |\n| **Subscribe Profile** | Subscribe a profile to email or SMS lists. |\n| **Unsubscribe Profile** | Remove a profile from email or SMS lists. |\n| **Add Profile to List** | Add a profile to a specific list. |\n| **Remove Profile from List** | Remove a profile from a specific list. |\n| **Create List** | Create a new subscriber list. |\n\n---\n\n##  Search Actions\n\n| **Action Item** | **Use Case** |\n|-----------------|---------------|\n| **Find Profile by Email/Phone** | Locate a profile using email or phone number. |\n| **Find List by Name** | Look up a list by name to get its ID. |\n| **Find Tag by Name** | Locate a tag to manage tagging workflows. |\n\n---\n\n##  API Reference\n\n- [Official Klaviyo API Documentation](https://developers.klaviyo.com/en/reference)\n\n---\n\n##  Test Account Access\n\nYou can test Klaviyo APIs by creating a free account on [Klaviyo](https://www.klaviyo.com/) and generating a private API key from your account settings.\n\n---\n\n##  New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
                  "html_url": "https://github.com/activepieces/activepieces/issues/8284"
                },
                "type": "github"
              },
              "hash": "activepieces/activepieces#8284",
              "body": "##  Product Overview\n\nKlaviyo is a marketing automation platform for email, SMS, and customer data.  \nThis integration enables AI agents and workflows to create, manage, and interact with profiles, lists, events, campaigns, and segments, automating customer engagement and analytics.\n\n---\n\n##  Important Note for Contributors\n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n##  Triggers\n\n| **Trigger** | **Use Case** |\n|-------------|---------------|\n| **New Profile** | Triggers when a new profile is created in the account. |\n| **Profile Added to List/Segment** | Fires when a profile is added to a specific list or segment. |\n\n---\n\n##  Write Actions\n\n| **Action Item** | **Use Case** |\n|-----------------|---------------|\n| **Create Profile** | Add a new user profile to Klaviyo, optionally subscribing to email/SMS. |\n| **Update Profile** | Update existing profile data and preferences. |\n| **Subscribe Profile** | Subscribe a profile to email or SMS lists. |\n| **Unsubscribe Profile** | Remove a profile from email or SMS lists. |\n| **Add Profile to List** | Add a profile to a specific list. |\n| **Remove Profile from List** | Remove a profile from a specific list. |\n| **Create List** | Create a new subscriber list. |\n\n---\n\n##  Search Actions\n\n| **Action Item** | **Use Case** |\n|-----------------|---------------|\n| **Find Profile by Email/Phone** | Locate a profile using email or phone number. |\n| **Find List by Name** | Look up a list by name to get its ID. |\n| **Find Tag by Name** | Locate a tag to manage tagging workflows. |\n\n---\n\n##  API Reference\n\n- [Official Klaviyo API Documentation](https://developers.klaviyo.com/en/reference)\n\n---\n\n##  Test Account Access\n\nYou can test Klaviyo APIs by creating a free account on [Klaviyo](https://www.klaviyo.com/) and generating a private API key from your account settings.\n\n---\n\n##  New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
              "url": "https://github.com/activepieces/activepieces/issues/8284",
              "tech": [],
              "repo_name": "activepieces",
              "repo_owner": "activepieces",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "activepieces#8135",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "activepieces",
              "id": "generated-activepieces",
              "name": "Activepieces",
              "description": "",
              "members": [],
              "display_name": "Activepieces",
              "created_at": "2025-12-17T18:24:40.161Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/activepieces?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "activepieces",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:40.161Z",
            "created_at": "2025-12-17T18:24:40.161Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-activepieces#8135",
              "status": "open",
              "type": "issue",
              "number": 8135,
              "title": "[MCP] Canva",
              "source": {
                "data": {
                  "id": "source-activepieces#8135",
                  "user": {
                    "login": "kishanprmr",
                    "id": 135701940,
                    "node_id": "U_kgDOCBaltA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/135701940?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kishanprmr",
                    "html_url": "https://github.com/kishanprmr",
                    "followers_url": "https://api.github.com/users/kishanprmr/followers",
                    "following_url": "https://api.github.com/users/kishanprmr/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kishanprmr/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kishanprmr/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kishanprmr/subscriptions",
                    "organizations_url": "https://api.github.com/users/kishanprmr/orgs",
                    "repos_url": "https://api.github.com/users/kishanprmr/repos",
                    "events_url": "https://api.github.com/users/kishanprmr/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kishanprmr/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[MCP] Canva",
                  "body": "##  Product Overview  \n\nCanva is an online design platform that enables users to create visual content like social graphics, presentations, and posters. This integration empowers automation builders and AI agents to streamline tasks such as design creation, asset uploads, exports, folder organization, and more.\n\n---\n\n##  Important Note for Contributors  \n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n##  Write Actions  \n\n| **Action Item**               | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **Upload Asset** | Auto-upload brand assets when a campaign starts. |\n| **Create Design** | Automatically generate Instagram templates on new blog posts.|\n| **Import Design** | Convert user-submitted PDFs into editable Canva designs. |\n|**Export Design**| Export a brochure as a PDF and save it.|\n|**Move Folder Item**| Organize completed designs into an Archive folder.|\n\n---\n\n##  Search Actions  \n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Find Design** | Ensure a design doesnt already exist before creation.|\n\n---\n\n##  Read Actions\n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Get a Folder** | Retrieves details about an existing folder.|\n|**Get an Image**| Retrieves details about an existing image.|\n\n---\n\n##  API Reference  \n- [Official Canva API Documentation](https://www.canva.dev/docs/connect/api-reference/designs/create-design/)\n\n---\n\n##  Test Account Access  \nYou can sign up for a free account at https://www.canva.com/en_in/.\n\n---\n\n##  New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
                  "html_url": "https://github.com/activepieces/activepieces/issues/8135"
                },
                "type": "github"
              },
              "hash": "activepieces/activepieces#8135",
              "body": "##  Product Overview  \n\nCanva is an online design platform that enables users to create visual content like social graphics, presentations, and posters. This integration empowers automation builders and AI agents to streamline tasks such as design creation, asset uploads, exports, folder organization, and more.\n\n---\n\n##  Important Note for Contributors  \n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n##  Write Actions  \n\n| **Action Item**               | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **Upload Asset** | Auto-upload brand assets when a campaign starts. |\n| **Create Design** | Automatically generate Instagram templates on new blog posts.|\n| **Import Design** | Convert user-submitted PDFs into editable Canva designs. |\n|**Export Design**| Export a brochure as a PDF and save it.|\n|**Move Folder Item**| Organize completed designs into an Archive folder.|\n\n---\n\n##  Search Actions  \n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Find Design** | Ensure a design doesnt already exist before creation.|\n\n---\n\n##  Read Actions\n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Get a Folder** | Retrieves details about an existing folder.|\n|**Get an Image**| Retrieves details about an existing image.|\n\n---\n\n##  API Reference  \n- [Official Canva API Documentation](https://www.canva.dev/docs/connect/api-reference/designs/create-design/)\n\n---\n\n##  Test Account Access  \nYou can sign up for a free account at https://www.canva.com/en_in/.\n\n---\n\n##  New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
              "url": "https://github.com/activepieces/activepieces/issues/8135",
              "tech": [],
              "repo_name": "activepieces",
              "repo_owner": "activepieces",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "activepieces#8135",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "activepieces",
              "id": "generated-activepieces",
              "name": "Activepieces",
              "description": "",
              "members": [],
              "display_name": "Activepieces",
              "created_at": "2025-12-17T18:24:40.164Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/activepieces?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "activepieces",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:40.164Z",
            "created_at": "2025-12-17T18:24:40.164Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-activepieces#8135",
              "status": "open",
              "type": "issue",
              "number": 8135,
              "title": "[MCP] Canva",
              "source": {
                "data": {
                  "id": "source-activepieces#8135",
                  "user": {
                    "login": "kishanprmr",
                    "id": 135701940,
                    "node_id": "U_kgDOCBaltA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/135701940?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kishanprmr",
                    "html_url": "https://github.com/kishanprmr",
                    "followers_url": "https://api.github.com/users/kishanprmr/followers",
                    "following_url": "https://api.github.com/users/kishanprmr/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kishanprmr/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kishanprmr/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kishanprmr/subscriptions",
                    "organizations_url": "https://api.github.com/users/kishanprmr/orgs",
                    "repos_url": "https://api.github.com/users/kishanprmr/repos",
                    "events_url": "https://api.github.com/users/kishanprmr/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kishanprmr/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[MCP] Canva",
                  "body": "##  Product Overview  \n\nCanva is an online design platform that enables users to create visual content like social graphics, presentations, and posters. This integration empowers automation builders and AI agents to streamline tasks such as design creation, asset uploads, exports, folder organization, and more.\n\n---\n\n##  Important Note for Contributors  \n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n##  Write Actions  \n\n| **Action Item**               | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **Upload Asset** | Auto-upload brand assets when a campaign starts. |\n| **Create Design** | Automatically generate Instagram templates on new blog posts.|\n| **Import Design** | Convert user-submitted PDFs into editable Canva designs. |\n|**Export Design**| Export a brochure as a PDF and save it.|\n|**Move Folder Item**| Organize completed designs into an Archive folder.|\n\n---\n\n##  Search Actions  \n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Find Design** | Ensure a design doesnt already exist before creation.|\n\n---\n\n##  Read Actions\n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Get a Folder** | Retrieves details about an existing folder.|\n|**Get an Image**| Retrieves details about an existing image.|\n\n---\n\n##  API Reference  \n- [Official Canva API Documentation](https://www.canva.dev/docs/connect/api-reference/designs/create-design/)\n\n---\n\n##  Test Account Access  \nYou can sign up for a free account at https://www.canva.com/en_in/.\n\n---\n\n##  New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
                  "html_url": "https://github.com/activepieces/activepieces/issues/8135"
                },
                "type": "github"
              },
              "hash": "activepieces/activepieces#8135",
              "body": "##  Product Overview  \n\nCanva is an online design platform that enables users to create visual content like social graphics, presentations, and posters. This integration empowers automation builders and AI agents to streamline tasks such as design creation, asset uploads, exports, folder organization, and more.\n\n---\n\n##  Important Note for Contributors  \n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n##  Write Actions  \n\n| **Action Item**               | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **Upload Asset** | Auto-upload brand assets when a campaign starts. |\n| **Create Design** | Automatically generate Instagram templates on new blog posts.|\n| **Import Design** | Convert user-submitted PDFs into editable Canva designs. |\n|**Export Design**| Export a brochure as a PDF and save it.|\n|**Move Folder Item**| Organize completed designs into an Archive folder.|\n\n---\n\n##  Search Actions  \n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Find Design** | Ensure a design doesnt already exist before creation.|\n\n---\n\n##  Read Actions\n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Get a Folder** | Retrieves details about an existing folder.|\n|**Get an Image**| Retrieves details about an existing image.|\n\n---\n\n##  API Reference  \n- [Official Canva API Documentation](https://www.canva.dev/docs/connect/api-reference/designs/create-design/)\n\n---\n\n##  Test Account Access  \nYou can sign up for a free account at https://www.canva.com/en_in/.\n\n---\n\n##  New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
              "url": "https://github.com/activepieces/activepieces/issues/8135",
              "tech": [],
              "repo_name": "activepieces",
              "repo_owner": "activepieces",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "activepieces#8072",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "activepieces",
              "id": "generated-activepieces",
              "name": "Activepieces",
              "description": "",
              "members": [],
              "display_name": "Activepieces",
              "created_at": "2025-12-17T18:24:40.402Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/activepieces?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "activepieces",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:40.402Z",
            "created_at": "2025-12-17T18:24:40.402Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-activepieces#8072",
              "status": "open",
              "type": "issue",
              "number": 8072,
              "title": "[MCP] Gmail",
              "source": {
                "data": {
                  "id": "source-activepieces#8072",
                  "user": {
                    "login": "kishanprmr",
                    "id": 135701940,
                    "node_id": "U_kgDOCBaltA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/135701940?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kishanprmr",
                    "html_url": "https://github.com/kishanprmr",
                    "followers_url": "https://api.github.com/users/kishanprmr/followers",
                    "following_url": "https://api.github.com/users/kishanprmr/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kishanprmr/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kishanprmr/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kishanprmr/subscriptions",
                    "organizations_url": "https://api.github.com/users/kishanprmr/orgs",
                    "repos_url": "https://api.github.com/users/kishanprmr/repos",
                    "events_url": "https://api.github.com/users/kishanprmr/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kishanprmr/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[MCP] Gmail",
                  "body": "##  Product Overview  \n\nGmail is Googles email platform for sending, receiving, labeling, archiving, and organizing messages.\nThis integration empowers AI agents and workflows to automate email-based processes, from detection to response, labeling, and thread management.\n\n\n---\n\n##  Important Note for Contributors  \n\nThis Gmail piece already exists in Activepieces. Your task is to extend the current piece by adding additional actions and triggers as outlined in the documentation and reference materials.\nPlease avoid duplicating existing functionality. Review the current implementation before making changes, and ensure that all new features follow existing coding patterns and standards.\n\n---\n\n##  Triggers  \n\n| **Trigger** | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **New Starred Email** | Fires when an email is starred (within 2 days).|\n| **New Conversation** | Fires when a new conversation (thread) begins.|\n|**New Attachment**|Fires when an email with an attachment arrives (with optional filters).|\n|**New Label**|Triggers when a new label is created.|\n---\n\n##  Write Actions  \n\n| **Action Item**               | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **Reply to Email** | Reply within an existing thread, maintaining context. |\n| **Create Draft Reply** | Generate a reply draft within an existing thread.|\n| **Add Label to Email** | Attach a label to an individual email.|\n|**Remove Label from Email**|Remove a specific label from an email.Remove a specific label from an email.|\n|**Create Label**|Create a new user label in Gmail.|\n|**Archive Email**|Archive (move to All Mail) rather than deleting.|\n|**Delete Email**|Permanently move an email to Trash.|\n|**Remove Label from Thread**|Strip a label from all emails in a thread.|\n---\n\n##  Search Actions  \n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Find Email** | Locate a specific email using search keywords like subject, sender, or content.|\n\n---\n\n\n##  API Reference  \n- [Official Gmail API Documentation](https://developers.google.com/workspace/gmail/api/guides)\n\n---\n\n##  Test Account Access  \nYou can test Gmail APIs using a Google account with enabled Gmail API in a [Google Cloud Project Console](https://console.cloud.google.com/).\n\n---\n\n##  New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
                  "html_url": "https://github.com/activepieces/activepieces/issues/8072"
                },
                "type": "github"
              },
              "hash": "activepieces/activepieces#8072",
              "body": "##  Product Overview  \n\nGmail is Googles email platform for sending, receiving, labeling, archiving, and organizing messages.\nThis integration empowers AI agents and workflows to automate email-based processes, from detection to response, labeling, and thread management.\n\n\n---\n\n##  Important Note for Contributors  \n\nThis Gmail piece already exists in Activepieces. Your task is to extend the current piece by adding additional actions and triggers as outlined in the documentation and reference materials.\nPlease avoid duplicating existing functionality. Review the current implementation before making changes, and ensure that all new features follow existing coding patterns and standards.\n\n---\n\n##  Triggers  \n\n| **Trigger** | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **New Starred Email** | Fires when an email is starred (within 2 days).|\n| **New Conversation** | Fires when a new conversation (thread) begins.|\n|**New Attachment**|Fires when an email with an attachment arrives (with optional filters).|\n|**New Label**|Triggers when a new label is created.|\n---\n\n##  Write Actions  \n\n| **Action Item**               | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **Reply to Email** | Reply within an existing thread, maintaining context. |\n| **Create Draft Reply** | Generate a reply draft within an existing thread.|\n| **Add Label to Email** | Attach a label to an individual email.|\n|**Remove Label from Email**|Remove a specific label from an email.Remove a specific label from an email.|\n|**Create Label**|Create a new user label in Gmail.|\n|**Archive Email**|Archive (move to All Mail) rather than deleting.|\n|**Delete Email**|Permanently move an email to Trash.|\n|**Remove Label from Thread**|Strip a label from all emails in a thread.|\n---\n\n##  Search Actions  \n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Find Email** | Locate a specific email using search keywords like subject, sender, or content.|\n\n---\n\n\n##  API Reference  \n- [Official Gmail API Documentation](https://developers.google.com/workspace/gmail/api/guides)\n\n---\n\n##  Test Account Access  \nYou can test Gmail APIs using a Google account with enabled Gmail API in a [Google Cloud Project Console](https://console.cloud.google.com/).\n\n---\n\n##  New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
              "url": "https://github.com/activepieces/activepieces/issues/8072",
              "tech": [],
              "repo_name": "activepieces",
              "repo_owner": "activepieces",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#378",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-12-17T18:24:40.169Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:40.169Z",
            "created_at": "2025-12-17T18:24:40.169Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#378",
              "status": "open",
              "type": "issue",
              "number": 378,
              "title": "Create workflow: \"Supplier invoice reconciliation\"",
              "source": {
                "data": {
                  "id": "source-mediar-ai#378",
                  "user": {
                    "login": "m13v",
                    "id": 104702220,
                    "node_id": "U_kgDOBj2hDA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/104702220?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/m13v",
                    "html_url": "https://github.com/m13v",
                    "followers_url": "https://api.github.com/users/m13v/followers",
                    "following_url": "https://api.github.com/users/m13v/following{/other_user}",
                    "gists_url": "https://api.github.com/users/m13v/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/m13v/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/m13v/subscriptions",
                    "organizations_url": "https://api.github.com/users/m13v/orgs",
                    "repos_url": "https://api.github.com/users/m13v/repos",
                    "events_url": "https://api.github.com/users/m13v/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/m13v/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Create workflow: \"Supplier invoice reconciliation\"",
                  "body": "/bounty 100\n\n1. Download the app https://app.mediar.ai/\n2. Create 'New' workflow\n3. Prompt AI in the chat to create it\n4. Adjust and correct the steps to make it work reliably\n5. Deploy to the dashboard\n6. Ask me questions in the comments please\n\nRequirements:\n- CHECK IF ANYONE ALREADY started working on the issue in the comments below\n- comment /attempt to start working on the issue\n- as part of submission you need to create a screen recording to show that the workflow works on your end, end-to-end\n\nOutput table destination:\nhttps://docs.google.com/spreadsheets/d/1P7tioZ7sC3GdP5aOSrBhYKb_svkFjDbTransEqDMqvA/edit?gid=0#gid=0",
                  "html_url": "https://github.com/mediar-ai/terminator/issues/378"
                },
                "type": "github"
              },
              "hash": "mediar-ai/terminator#378",
              "body": "/bounty 100\n\n1. Download the app https://app.mediar.ai/\n2. Create 'New' workflow\n3. Prompt AI in the chat to create it\n4. Adjust and correct the steps to make it work reliably\n5. Deploy to the dashboard\n6. Ask me questions in the comments please\n\nRequirements:\n- CHECK IF ANYONE ALREADY started working on the issue in the comments below\n- comment /attempt to start working on the issue\n- as part of submission you need to create a screen recording to show that the workflow works on your end, end-to-end\n\nOutput table destination:\nhttps://docs.google.com/spreadsheets/d/1P7tioZ7sC3GdP5aOSrBhYKb_svkFjDbTransEqDMqvA/edit?gid=0#gid=0",
              "url": "https://github.com/mediar-ai/terminator/issues/378",
              "tech": [
                "go"
              ],
              "repo_name": "terminator",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#357",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-12-17T18:24:40.302Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:40.302Z",
            "created_at": "2025-12-17T18:24:40.302Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#357",
              "status": "open",
              "type": "issue",
              "number": 357,
              "title": "create a TS workflow that delete the oldest version of PyPI before publishing to PyPI",
              "source": {
                "data": {
                  "id": "source-mediar-ai#357",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "create a TS workflow that delete the oldest version of PyPI before publishing to PyPI",
                  "body": "\n/bounty 100 \n\n\nproblem:\n- cannot publish pypi bcs there is limit of versions \n- there is no api / cli to do that so we need to do this w UI \n\ndefinition of done:\n- before publishing to pypi the gh action runs a TS workflow that delete oldest pypi release \n- share video it works (use your own pypi account for the video idk)\n\n\n\n",
                  "html_url": "https://github.com/mediar-ai/terminator/issues/357"
                },
                "type": "github"
              },
              "hash": "mediar-ai/terminator#357",
              "body": "\n/bounty 100 \n\n\nproblem:\n- cannot publish pypi bcs there is limit of versions \n- there is no api / cli to do that so we need to do this w UI \n\ndefinition of done:\n- before publishing to pypi the gh action runs a TS workflow that delete oldest pypi release \n- share video it works (use your own pypi account for the video idk)\n\n\n\n",
              "url": "https://github.com/mediar-ai/terminator/issues/357",
              "tech": [
                "go"
              ],
              "repo_name": "terminator",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#353",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-12-17T18:24:40.492Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:40.492Z",
            "created_at": "2025-12-17T18:24:40.492Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#353",
              "status": "open",
              "type": "issue",
              "number": 353,
              "title": "create a typescript workflow that test the browser script bridge",
              "source": {
                "data": {
                  "id": "source-mediar-ai#353",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "create a typescript workflow that test the browser script bridge",
                  "body": "\n/bounty 100\n\nshould be able to reproduce this:\n\n```\nFailed to enable debugger domains: Debugger is not attached to the tab with id: 648628626.\n```\n\nexample ts workflow:\n\nhttps://github.com/mediar-ai/terminator/tree/main/examples/simple_notepad_workflow\n\n\ndefinition of done:\n- uses workflow sdk, terminator sdk, can be ran one liner using terminator cli \n- test different edge cases of the rust bridge using UI (executeBrowserScript function)\n- PR with video showing it runs \n- make it run in our github action \n\n\n\n\n\n\n\n",
                  "html_url": "https://github.com/mediar-ai/terminator/issues/353"
                },
                "type": "github"
              },
              "hash": "mediar-ai/terminator#353",
              "body": "\n/bounty 100\n\nshould be able to reproduce this:\n\n```\nFailed to enable debugger domains: Debugger is not attached to the tab with id: 648628626.\n```\n\nexample ts workflow:\n\nhttps://github.com/mediar-ai/terminator/tree/main/examples/simple_notepad_workflow\n\n\ndefinition of done:\n- uses workflow sdk, terminator sdk, can be ran one liner using terminator cli \n- test different edge cases of the rust bridge using UI (executeBrowserScript function)\n- PR with video showing it runs \n- make it run in our github action \n\n\n\n\n\n\n\n",
              "url": "https://github.com/mediar-ai/terminator/issues/353",
              "tech": [],
              "repo_name": "terminator",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#352",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-12-17T18:24:40.596Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:40.596Z",
            "created_at": "2025-12-17T18:24:40.596Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#352",
              "status": "open",
              "type": "issue",
              "number": 352,
              "title": "increase success rate of browser extension workflow",
              "source": {
                "data": {
                  "id": "source-mediar-ai#352",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "increase success rate of browser extension workflow",
                  "body": "/bounty 150\n\nproblem:\n\nbrowser extension workflow does not always work:\n- for example if user has multiple monitors or different environment\n- on slow machines workflow fails around step 2-5. probably has to do with hardcoded delays, machine doesn't react in time, can't validate typing input, etc\n- when chrome window opens up a user might have a profile selection window instead of a browser window which will prevent execution\n\ndefinition of done:\n- keep it a single yaml file (not typescript)\n- add more edge case in current implementation of the workflow, send a PR\n- provide a video showing it covers different environments like\n  - slow computer (like cheap VM)\n  - multiple monitors \n  - chrome profiles handling \n  - anything else useful to cover\n\n\n```yaml\n\n\nvariables:\n  extension_dir:\n    default: \"%TEMP%\\\\terminator-bridge\"\n    label: Folder to load (will be created by the download step)\n    type: string\n  release_url:\n    default: https://github.com/mediar-ai/terminator/releases/latest/download/terminator-browser-extension.zip\n    label: GitHub Release asset URL (zip)\n    type: string\n  zip_path:\n    default: \"%TEMP%\\\\terminator-browser-extension.zip\"\n    label: Path to downloaded zip\n    type: string\nselectors:\n  address_bar: role:Edit|name:Address and search bar\n  dev_mode_toggle: role:Button|name:Developer mode\n  extensions_doc: role:Document|name:Extensions\n  folder_field: \"role:Edit|name:Folder:\"\n  load_unpacked: role:Button|name:Load unpacked\n  reload_button: role:Button|name:Reload\n  select_folder_btn: role:Button|name:Select Folder\nsteps:\n  - arguments:\n      app_name: Chrome\n    name: Open Chrome\n    tool_name: open_application\n    id: open_chrome\n  - arguments:\n      engine: javascript\n      run: >\n        const fs = require('fs');\n\n        const path = require('path');\n\n        const os = require('os');\n\n        (async () => {\n          const url = \"${{release_url}}\";\n          if (!url || !url.trim()) throw new Error('release_url is empty');\n          const isWin = process.platform === 'win32';\n          const tmp = isWin ? (process.env.TEMP || os.tmpdir()) : os.tmpdir();\n          const zipPath = isWin ? path.join(tmp, 'terminator-browser-extension.zip') : path.join(tmp, 'terminator-browser-extension.zip');\n          const destDir = isWin ? path.join(tmp, 'terminator-bridge') : path.join(tmp, 'terminator-bridge');\n          const existedBefore = fs.existsSync(destDir);\n          try { fs.rmSync(destDir, { recursive: true, force: true }); } catch (_) {}\n          try { fs.mkdirSync(destDir, { recursive: true }); } catch (e) { throw new Error('Failed to create dest dir: ' + e.message); }\n\n          const res = await fetch(url);\n          if (!res.ok) throw new Error(`Download failed: ${res.status} ${res.statusText}`);\n          const arrayBuf = await res.arrayBuffer();\n          fs.writeFileSync(zipPath, Buffer.from(arrayBuf));\n\n          // Export values via ::set-env for the workflow engine AND return set_env for robust propagation\n          console.log(`::set-env name=zip_path::${zipPath}`);\n          console.log(`::set-env name=extension_dir::${destDir}`);\n          console.log(`::set-env name=is_update_mode::${existedBefore}`);\n          return { set_env: { zip_path: zipPath, extension_dir: destDir, is_update_mode: existedBefore } };\n        })();\n    delay_ms: 200\n    id: step_0\n    tool_name: run_command\n  - arguments:\n      run: |\n        $ErrorActionPreference = 'Stop'\n        # Avoid template substitution issues: compute paths directly\n        $zip = Join-Path $env:TEMP 'terminator-browser-extension.zip'\n        $dest = Join-Path $env:TEMP 'terminator-bridge'\n        if (Test-Path $dest) { Remove-Item -Recurse -Force $dest }\n        New-Item -ItemType Directory -Force -Path $dest | Out-Null\n        Expand-Archive -Path $zip -DestinationPath $dest -Force\n      shell: powershell\n    delay_ms: 400\n    id: step_1\n    tool_name: run_command\n  - arguments:\n      engine: javascript\n      run: >\n        const fs = require('fs');\n\n        const path = require('path');\n\n        const os = require('os');\n\n        (async () => {\n          const isWin = process.platform === 'win32';\n          const root = isWin ? path.join(process.env.TEMP || os.tmpdir(), 'terminator-bridge') : path.join(os.tmpdir(), 'terminator-bridge');\n          const stack = [root];\n          let picked = null;\n          while (stack.length) {\n            const dir = stack.pop();\n            let entries;\n            try { entries = fs.readdirSync(dir, { withFileTypes: true }); } catch (_) { continue; }\n            if (entries.some(e => e.isFile && e.name.toLowerCase() === 'manifest.json' || (!e.isFile && !e.isDirectory && e.name && e.name.toLowerCase() === 'manifest.json'))) {\n              picked = dir; break;\n            }\n            for (const e of entries) {\n              if ((e.isDirectory && e.isDirectory()) || (e.isDirectory === true)) {\n                stack.push(path.join(dir, e.name));\n              }\n            }\n          }\n          if (!picked) {\n            console.log(`::set-env name=extension_dir_text::${root}`);\n            return { set_env: { extension_dir_text: root } };\n          }\n          console.log(`::set-env name=extension_dir_text::${picked}`);\n          return { set_env: { extension_dir_text: picked } };\n        })();\n    continue_on_error: false\n    delay_ms: 100\n    id: step_2\n    tool_name: run_command\n  - arguments:\n      url: chrome://extensions\n    delay_ms: 1000\n    id: step_3\n    tool_name: navigate_browser\n  - arguments:\n      condition: visible\n      selector: ${{ selectors.address_bar }}\n      timeout_ms: 15000\n    continue_on_error: true\n    id: step_4\n    tool_name: wait_for_element\n  - arguments:\n      selector: ${{ selectors.address_bar }}\n    continue_on_error: true\n    id: step_5\n    tool_name: click_element\n  - arguments:\n      clear_before_typing: true\n      selector: ${{ selectors.address_bar }}\n      text_to_type: chrome://extensions\n    continue_on_error: true\n    id: step_6\n    tool_name: type_into_element\n  - arguments:\n      key: \"{Enter}\"\n    continue_on_error: true\n    delay_ms: 800\n    id: step_7\n    tool_name: press_key_global\n  - arguments:\n      engine: javascript\n      run: >\n        // Use terminator.js via global 'desktop'\n\n        const toggleSel = \"role:Button|name:Developer mode\";\n\n        const loadSel = \"role:Button|name:Load unpacked\";\n\n\n        // Wait for Developer mode toggle to appear\n\n        const devToggle = await desktop.locator(toggleSel).first(30000);\n\n        // Presence-based check: if Load unpacked is not visible yet, toggle Dev\n        Mode once\n\n        let loadVisible = false;\n\n        try { await desktop.locator(loadSel).first(1500); loadVisible = true; }\n        catch (_) {}\n\n        if (!loadVisible) {\n          await devToggle.click();\n          await sleep(300);\n        }\n\n        // No explicit click on Load unpacked here; later steps handle it\n    continue_on_error: true\n    delay_ms: 200\n    id: step_8\n    tool_name: run_command\n  - arguments:\n      engine: javascript\n      run: >\n        // Find and remove only Terminator Bridge extension\n\n        const extensionName = \"Terminator Bridge\";\n\n\n        try {\n          // Wait a bit for extensions page to load\n          await sleep(1000);\n\n          // Look for all extension cards on the page\n          const allElements = await desktop.locator(\"role:Group\").all();\n          log(`Found ${allElements.length} groups on extensions page`);\n\n          let terminatorFound = false;\n\n          // Search through elements to find Terminator Bridge\n          for (let element of allElements) {\n            try {\n              const name = await element.name();\n              const text = await element.value();\n\n              // Check if this element contains \"Terminator Bridge\" text\n              if ((name && name.includes(extensionName)) || (text && text.includes(extensionName))) {\n                log(`Found Terminator Bridge extension card`);\n                terminatorFound = true;\n\n                // Look for Remove button within this specific card\n                // Try to find the Remove button that's a child of this card\n                const removeButton = await element.locator(\"role:Button|name:Remove\").first();\n\n                if (removeButton) {\n                  log(`Found Remove button for Terminator Bridge, clicking it`);\n                  await removeButton.click();\n                  await sleep(500);\n\n                  // Confirm removal in the dialog\n                  await desktop.press_key(\"{Enter}\");\n                  log(`Confirmed removal of Terminator Bridge`);\n                  await sleep(1000);\n                  break;\n                } else {\n                  log(`Remove button not found in Terminator Bridge card`);\n                }\n              }\n            } catch (e) {\n              // Skip elements that can't be read\n              continue;\n            }\n          }\n\n          if (!terminatorFound) {\n            log(`Terminator Bridge extension not found - probably not installed`);\n          }\n\n        } catch (error) {\n          log(`Error while trying to remove old extension: ${error.message}`);\n          log(`Continuing with installation anyway...`);\n        }\n    continue_on_error: true\n    delay_ms: 500\n    id: step_9\n    tool_name: run_command\n  - arguments:\n      selector: ${{ selectors.load_unpacked }}\n    continue_on_error: false\n    delay_ms: 300\n    id: step_10\n    tool_name: click_element\n  - arguments:\n      condition: exists\n      selector: ${{ selectors.folder_field }}\n      timeout_ms: 3000\n    continue_on_error: true\n    id: step_11\n    tool_name: wait_for_element\n  - arguments:\n      clear_before_typing: true\n      selector: ${{ selectors.folder_field }}\n      text_to_type: ${{env.extension_dir_text}}\n    continue_on_error: true\n    id: step_12\n    tool_name: type_into_element\n  - arguments:\n      selector: ${{ selectors.select_folder_btn }}\n    continue_on_error: true\n    delay_ms: 1200\n    id: step_13\n    tool_name: click_element\n  - arguments:\n      condition: exists\n      selector: ${{ selectors.reload_button }}\n      timeout_ms: 15000\n    id: step_14\n    tool_name: wait_for_element\n  - arguments:\n      continue1_on_error: true\n      selector: role:Window|name:Google Chrome\n    name: Close Chrome\n    tool_name: close_element\n    id: close_chrome\nstop_on_error: true\n```\n\ni think this is roughly the same\n\nhttps://github.com/mediar-ai/terminator/blob/main/crates/terminator/browser-extension/install_chrome_extension_ui.yml\n",
                  "html_url": "https://github.com/mediar-ai/terminator/issues/352"
                },
                "type": "github"
              },
              "hash": "mediar-ai/terminator#352",
              "body": "/bounty 150\n\nproblem:\n\nbrowser extension workflow does not always work:\n- for example if user has multiple monitors or different environment\n- on slow machines workflow fails around step 2-5. probably has to do with hardcoded delays, machine doesn't react in time, can't validate typing input, etc\n- when chrome window opens up a user might have a profile selection window instead of a browser window which will prevent execution\n\ndefinition of done:\n- keep it a single yaml file (not typescript)\n- add more edge case in current implementation of the workflow, send a PR\n- provide a video showing it covers different environments like\n  - slow computer (like cheap VM)\n  - multiple monitors \n  - chrome profiles handling \n  - anything else useful to cover\n\n\n```yaml\n\n\nvariables:\n  extension_dir:\n    default: \"%TEMP%\\\\terminator-bridge\"\n    label: Folder to load (will be created by the download step)\n    type: string\n  release_url:\n    default: https://github.com/mediar-ai/terminator/releases/latest/download/terminator-browser-extension.zip\n    label: GitHub Release asset URL (zip)\n    type: string\n  zip_path:\n    default: \"%TEMP%\\\\terminator-browser-extension.zip\"\n    label: Path to downloaded zip\n    type: string\nselectors:\n  address_bar: role:Edit|name:Address and search bar\n  dev_mode_toggle: role:Button|name:Developer mode\n  extensions_doc: role:Document|name:Extensions\n  folder_field: \"role:Edit|name:Folder:\"\n  load_unpacked: role:Button|name:Load unpacked\n  reload_button: role:Button|name:Reload\n  select_folder_btn: role:Button|name:Select Folder\nsteps:\n  - arguments:\n      app_name: Chrome\n    name: Open Chrome\n    tool_name: open_application\n    id: open_chrome\n  - arguments:\n      engine: javascript\n      run: >\n        const fs = require('fs');\n\n        const path = require('path');\n\n        const os = require('os');\n\n        (async () => {\n          const url = \"${{release_url}}\";\n          if (!url || !url.trim()) throw new Error('release_url is empty');\n          const isWin = process.platform === 'win32';\n          const tmp = isWin ? (process.env.TEMP || os.tmpdir()) : os.tmpdir();\n          const zipPath = isWin ? path.join(tmp, 'terminator-browser-extension.zip') : path.join(tmp, 'terminator-browser-extension.zip');\n          const destDir = isWin ? path.join(tmp, 'terminator-bridge') : path.join(tmp, 'terminator-bridge');\n          const existedBefore = fs.existsSync(destDir);\n          try { fs.rmSync(destDir, { recursive: true, force: true }); } catch (_) {}\n          try { fs.mkdirSync(destDir, { recursive: true }); } catch (e) { throw new Error('Failed to create dest dir: ' + e.message); }\n\n          const res = await fetch(url);\n          if (!res.ok) throw new Error(`Download failed: ${res.status} ${res.statusText}`);\n          const arrayBuf = await res.arrayBuffer();\n          fs.writeFileSync(zipPath, Buffer.from(arrayBuf));\n\n          // Export values via ::set-env for the workflow engine AND return set_env for robust propagation\n          console.log(`::set-env name=zip_path::${zipPath}`);\n          console.log(`::set-env name=extension_dir::${destDir}`);\n          console.log(`::set-env name=is_update_mode::${existedBefore}`);\n          return { set_env: { zip_path: zipPath, extension_dir: destDir, is_update_mode: existedBefore } };\n        })();\n    delay_ms: 200\n    id: step_0\n    tool_name: run_command\n  - arguments:\n      run: |\n        $ErrorActionPreference = 'Stop'\n        # Avoid template substitution issues: compute paths directly\n        $zip = Join-Path $env:TEMP 'terminator-browser-extension.zip'\n        $dest = Join-Path $env:TEMP 'terminator-bridge'\n        if (Test-Path $dest) { Remove-Item -Recurse -Force $dest }\n        New-Item -ItemType Directory -Force -Path $dest | Out-Null\n        Expand-Archive -Path $zip -DestinationPath $dest -Force\n      shell: powershell\n    delay_ms: 400\n    id: step_1\n    tool_name: run_command\n  - arguments:\n      engine: javascript\n      run: >\n        const fs = require('fs');\n\n        const path = require('path');\n\n        const os = require('os');\n\n        (async () => {\n          const isWin = process.platform === 'win32';\n          const root = isWin ? path.join(process.env.TEMP || os.tmpdir(), 'terminator-bridge') : path.join(os.tmpdir(), 'terminator-bridge');\n          const stack = [root];\n          let picked = null;\n          while (stack.length) {\n            const dir = stack.pop();\n            let entries;\n            try { entries = fs.readdirSync(dir, { withFileTypes: true }); } catch (_) { continue; }\n            if (entries.some(e => e.isFile && e.name.toLowerCase() === 'manifest.json' || (!e.isFile && !e.isDirectory && e.name && e.name.toLowerCase() === 'manifest.json'))) {\n              picked = dir; break;\n            }\n            for (const e of entries) {\n              if ((e.isDirectory && e.isDirectory()) || (e.isDirectory === true)) {\n                stack.push(path.join(dir, e.name));\n              }\n            }\n          }\n          if (!picked) {\n            console.log(`::set-env name=extension_dir_text::${root}`);\n            return { set_env: { extension_dir_text: root } };\n          }\n          console.log(`::set-env name=extension_dir_text::${picked}`);\n          return { set_env: { extension_dir_text: picked } };\n        })();\n    continue_on_error: false\n    delay_ms: 100\n    id: step_2\n    tool_name: run_command\n  - arguments:\n      url: chrome://extensions\n    delay_ms: 1000\n    id: step_3\n    tool_name: navigate_browser\n  - arguments:\n      condition: visible\n      selector: ${{ selectors.address_bar }}\n      timeout_ms: 15000\n    continue_on_error: true\n    id: step_4\n    tool_name: wait_for_element\n  - arguments:\n      selector: ${{ selectors.address_bar }}\n    continue_on_error: true\n    id: step_5\n    tool_name: click_element\n  - arguments:\n      clear_before_typing: true\n      selector: ${{ selectors.address_bar }}\n      text_to_type: chrome://extensions\n    continue_on_error: true\n    id: step_6\n    tool_name: type_into_element\n  - arguments:\n      key: \"{Enter}\"\n    continue_on_error: true\n    delay_ms: 800\n    id: step_7\n    tool_name: press_key_global\n  - arguments:\n      engine: javascript\n      run: >\n        // Use terminator.js via global 'desktop'\n\n        const toggleSel = \"role:Button|name:Developer mode\";\n\n        const loadSel = \"role:Button|name:Load unpacked\";\n\n\n        // Wait for Developer mode toggle to appear\n\n        const devToggle = await desktop.locator(toggleSel).first(30000);\n\n        // Presence-based check: if Load unpacked is not visible yet, toggle Dev\n        Mode once\n\n        let loadVisible = false;\n\n        try { await desktop.locator(loadSel).first(1500); loadVisible = true; }\n        catch (_) {}\n\n        if (!loadVisible) {\n          await devToggle.click();\n          await sleep(300);\n        }\n\n        // No explicit click on Load unpacked here; later steps handle it\n    continue_on_error: true\n    delay_ms: 200\n    id: step_8\n    tool_name: run_command\n  - arguments:\n      engine: javascript\n      run: >\n        // Find and remove only Terminator Bridge extension\n\n        const extensionName = \"Terminator Bridge\";\n\n\n        try {\n          // Wait a bit for extensions page to load\n          await sleep(1000);\n\n          // Look for all extension cards on the page\n          const allElements = await desktop.locator(\"role:Group\").all();\n          log(`Found ${allElements.length} groups on extensions page`);\n\n          let terminatorFound = false;\n\n          // Search through elements to find Terminator Bridge\n          for (let element of allElements) {\n            try {\n              const name = await element.name();\n              const text = await element.value();\n\n              // Check if this element contains \"Terminator Bridge\" text\n              if ((name && name.includes(extensionName)) || (text && text.includes(extensionName))) {\n                log(`Found Terminator Bridge extension card`);\n                terminatorFound = true;\n\n                // Look for Remove button within this specific card\n                // Try to find the Remove button that's a child of this card\n                const removeButton = await element.locator(\"role:Button|name:Remove\").first();\n\n                if (removeButton) {\n                  log(`Found Remove button for Terminator Bridge, clicking it`);\n                  await removeButton.click();\n                  await sleep(500);\n\n                  // Confirm removal in the dialog\n                  await desktop.press_key(\"{Enter}\");\n                  log(`Confirmed removal of Terminator Bridge`);\n                  await sleep(1000);\n                  break;\n                } else {\n                  log(`Remove button not found in Terminator Bridge card`);\n                }\n              }\n            } catch (e) {\n              // Skip elements that can't be read\n              continue;\n            }\n          }\n\n          if (!terminatorFound) {\n            log(`Terminator Bridge extension not found - probably not installed`);\n          }\n\n        } catch (error) {\n          log(`Error while trying to remove old extension: ${error.message}`);\n          log(`Continuing with installation anyway...`);\n        }\n    continue_on_error: true\n    delay_ms: 500\n    id: step_9\n    tool_name: run_command\n  - arguments:\n      selector: ${{ selectors.load_unpacked }}\n    continue_on_error: false\n    delay_ms: 300\n    id: step_10\n    tool_name: click_element\n  - arguments:\n      condition: exists\n      selector: ${{ selectors.folder_field }}\n      timeout_ms: 3000\n    continue_on_error: true\n    id: step_11\n    tool_name: wait_for_element\n  - arguments:\n      clear_before_typing: true\n      selector: ${{ selectors.folder_field }}\n      text_to_type: ${{env.extension_dir_text}}\n    continue_on_error: true\n    id: step_12\n    tool_name: type_into_element\n  - arguments:\n      selector: ${{ selectors.select_folder_btn }}\n    continue_on_error: true\n    delay_ms: 1200\n    id: step_13\n    tool_name: click_element\n  - arguments:\n      condition: exists\n      selector: ${{ selectors.reload_button }}\n      timeout_ms: 15000\n    id: step_14\n    tool_name: wait_for_element\n  - arguments:\n      continue1_on_error: true\n      selector: role:Window|name:Google Chrome\n    name: Close Chrome\n    tool_name: close_element\n    id: close_chrome\nstop_on_error: true\n```\n\ni think this is roughly the same\n\nhttps://github.com/mediar-ai/terminator/blob/main/crates/terminator/browser-extension/install_chrome_extension_ui.yml\n",
              "url": "https://github.com/mediar-ai/terminator/issues/352",
              "tech": [],
              "repo_name": "terminator",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#315",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-12-17T18:24:40.758Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:40.758Z",
            "created_at": "2025-12-17T18:24:40.758Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#315",
              "status": "open",
              "type": "issue",
              "number": 315,
              "title": "[bounty] test and showcase the new gemini computer use model with terminator MCP",
              "source": {
                "data": {
                  "id": "source-mediar-ai#315",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] test and showcase the new gemini computer use model with terminator MCP",
                  "body": "basic idea: try the new gemini CU model:\n\nhttps://cloud.google.com/vertex-ai/generative-ai/docs/computer-use\n\nand try to build some workflows like reading PDFs or spreadsheets on file system and doing data entry in another software \n\n\ngoal: evaluate if their model adds worthwhile performance gain by using both vision and accessibility to build workflow compared to claude etc\n\n\nrequirements:\n- record yourself building the workflow \n- use the new model somehow (gemini CLI + terminator MCP + gemini model configured for example, or build a custom MCP client in python/js, high preference for JS)\n- use terminator MCP server\n\n\nbonus:\n- professional video level that can be published on social\n\n\nplease share your plan before building things, one-prompt PRs will be banned \n\n/bounty 200\n",
                  "html_url": "https://github.com/mediar-ai/terminator/issues/315"
                },
                "type": "github"
              },
              "hash": "mediar-ai/terminator#315",
              "body": "basic idea: try the new gemini CU model:\n\nhttps://cloud.google.com/vertex-ai/generative-ai/docs/computer-use\n\nand try to build some workflows like reading PDFs or spreadsheets on file system and doing data entry in another software \n\n\ngoal: evaluate if their model adds worthwhile performance gain by using both vision and accessibility to build workflow compared to claude etc\n\n\nrequirements:\n- record yourself building the workflow \n- use the new model somehow (gemini CLI + terminator MCP + gemini model configured for example, or build a custom MCP client in python/js, high preference for JS)\n- use terminator MCP server\n\n\nbonus:\n- professional video level that can be published on social\n\n\nplease share your plan before building things, one-prompt PRs will be banned \n\n/bounty 200\n",
              "url": "https://github.com/mediar-ai/terminator/issues/315",
              "tech": [],
              "repo_name": "terminator",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1626",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-12-17T18:24:40.892Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:40.892Z",
            "created_at": "2025-12-17T18:24:40.892Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1626",
              "status": "open",
              "type": "issue",
              "number": 1626,
              "title": "[bounty] $400 fix audio device randomly stopping sometimes",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1626",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] $400 fix audio device randomly stopping sometimes",
                  "body": "\ndisplay audio / microphone randomly stops on mac sometimes \n\nhad it running for 48h now and display audio somehow stopped a bit later after 50h\n\n/bounty 400 \n\n@EzraEllette any idea?\n\n\ni suggest finding way to reproduce and then some automated test and a fix ",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1626"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1626",
              "body": "\ndisplay audio / microphone randomly stops on mac sometimes \n\nhad it running for 48h now and display audio somehow stopped a bit later after 50h\n\n/bounty 400 \n\n@EzraEllette any idea?\n\n\ni suggest finding way to reproduce and then some automated test and a fix ",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1626",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1560",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-12-17T18:24:41.006Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:41.006Z",
            "created_at": "2025-12-17T18:24:41.006Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1560",
              "status": "open",
              "type": "issue",
              "number": 1560,
              "title": "[feature]  Implement Session Tracking for Application and Window Usage",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1560",
                  "user": {
                    "login": "rodgomesc",
                    "id": 4893591,
                    "node_id": "MDQ6VXNlcjQ4OTM1OTE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/4893591?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/rodgomesc",
                    "html_url": "https://github.com/rodgomesc",
                    "followers_url": "https://api.github.com/users/rodgomesc/followers",
                    "following_url": "https://api.github.com/users/rodgomesc/following{/other_user}",
                    "gists_url": "https://api.github.com/users/rodgomesc/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/rodgomesc/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/rodgomesc/subscriptions",
                    "organizations_url": "https://api.github.com/users/rodgomesc/orgs",
                    "repos_url": "https://api.github.com/users/rodgomesc/repos",
                    "events_url": "https://api.github.com/users/rodgomesc/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/rodgomesc/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[feature]  Implement Session Tracking for Application and Window Usage",
                  "body": "\n## Challenge\n\nI'm working on an application that requires accurate session tracking to analyze user behavior patterns,  and provide meaningful insights across different applications and windows. \n\nIn the existing Screenpipe architecture, OCR data is stored with only timestamp information, lacking precise session boundaries (start/end times) for application usage tracking. This limitation prevents us from properly segmenting user activity into coherent sessions.\n\n## 1. Current Workaround\ninternally I implementing a suboptimal solution that:\n1. Queries all OCR database entries chronologically\n2. Manually identifies session boundaries by analyzing timestamp sequences for each application\n3. Determines session end when detecting a different application in subsequent timestamps\n4. Assumes a session is ongoing if no clear delimiter exists in future timestamps\n\nWith that said I would love to hear any feedbacks that could help solve this problem with a minimal overhead on code changes, and make sure I'm not overthinking the solution: cc @louis030195 , i'm planning to start playing with some day next week\n\n## 2. Requirements\n\n1.  **Session Definition:** A \"session\" should be defined as a continuous period of user interaction with a specific application and window.  A break in activity (e.g., switching to a different application or window) should end the current session and potentially start a new one.  A configurable inactivity timeout (e.g., 5 minutes) should also end a session.\n\n2.  **Data Storage:** The database schema must be modified to store session start and end times, associated with specific applications and windows.  It must maintain links to the relevant OCR and audio data chunks.\n\n3.  **API Endpoint:**  A new or modified API endpoint (e.g., `/sessions`) is needed to query for session data.  This endpoint should support filtering by:\n    *   Date range (start and end timestamps).\n    *   Application name.\n    *   Window name.\n    *   Minimum and maximum session duration.\n    *   Associated tags.\n    *   Pagination (limit and offset).\n\n4.  **Real-time Capability:** The system should be able to detect session boundaries in near real-time as data is being ingested. This implies integration with the existing data capture and processing pipeline.\n\n5. **Configurability:** The inactivity timeout for ending a session should be configurable.\n\n## 3. Proposed Solution\n\n### 3.1. Database Schema Changes\n\nWe'll introduce a new table `sessions` and modify the existing tables.\n\n**New Table: `sessions`**\n\n| Column Name      | Data Type  | Constraints                                  | Description                                                                  |\n| :--------------- | :--------- | :------------------------------------------- | :--------------------------------------------------------------------------- |\n| `id`             | INTEGER    | PRIMARY KEY AUTOINCREMENT                    | Unique identifier for the session.                                       |\n| `app_name`       | TEXT       | NOT NULL                                     | Name of the application.                                                 |\n| `window_name`    | TEXT       |                                               | Title of the window.                                                     |\n| `start_time`     | DATETIME   | NOT NULL                                     | Timestamp of the session start.                                            |\n| `end_time`       | DATETIME   | NOT NULL                                     | Timestamp of the session end.                                              |\n| `duration_secs`  | REAL       | NOT NULL                                     | Duration of the session in seconds.                                        |\n\n**Modified Tables:**\n\n*   **`ocr_text`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`audio_transcriptions`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`ui_monitoring`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n\n**Indexes:**\n\n*   Create indexes on `sessions` table columns (`app_name`, `window_name`, `start_time`, `end_time`) for efficient querying.\n*   Create indexes on the `session_id` columns in `ocr_text`, `audio_transcriptions`, and `ui_monitoring`.\n\n### 3.2. API Enhancements\n\nWe'll modify the existing `/search` endpoint to also support session queries.\n\n**Request:**\n\n```\nGET /search?content_type=session&app_name=Cursor&start_time=2024-11-27T00:00:00Z&end_time=2024-11-28T00:00:00Z&min_duration=60&limit=10&offset=0\n```\n\n*   `content_type=session`: Indicates a session-based search.\n*   `app_name`, `window_name`: Filter by application and window (optional).\n*   `start_time`, `end_time`: Date range for the session (optional, defaults to last 24 hours).\n*   `min_duration`, `max_duration`: Filter by session duration in seconds (optional).\n*   `limit`, `offset`: Pagination parameters.\n\n\nafter discussing with @louis030195 on discord he proposed something like this as the output\n\n**Response:**\n\n```json\n{\n  \"data\": [\n    {\n      \"app_name\": \"Cursor\",\n      \"total_usage_time\": 3600,\n      \"windows\": [\n        {\n          \"window_name\": \"page.tsx\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T12:00:00Z\",\n              \"end_time\": \"2024-07-16T12:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [123, 124, 125],\n              \"tags\": [\"coding\", \"frontend\"]\n            },\n            {\n              \"start_time\": \"2024-07-16T14:00:00Z\",\n              \"end_time\": \"2024-07-16T14:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [223, 224, 225],\n              \"tags\": [\"coding\", \"frontend\"]\n            }\n          ],\n          \"total_usage_time\": 3600\n        }\n      ]\n    },\n    {\n      \"app_name\": \"Arc\",\n      \"total_usage_time\": 1200,\n      \"windows\": [\n        {\n          \"window_name\": \"x.com\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T10:30:00Z\",\n              \"end_time\": \"2024-07-16T10:50:00Z\",\n              \"duration\": 1200,\n              \"content_ids\": [126, 127, 128],\n              \"tags\": [\"browsing\", \"social-media\"]\n            }\n          ],\n          \"total_usage_time\": 1200\n        }\n      ]\n    }\n  ],\n  \"pagination\": {\n    \"limit\": 50,\n    \"offset\": 0,\n    \"total\": 2\n  }\n}\n```\n\n### 3.3. Session Boundary Detection Logic\n\n1.  **Real-time Monitoring:**  The existing event listeners for OCR, audio, and UI events will be leveraged.\n\n2.  **Session Tracking:**  Maintain a data structure (likely in memory, possibly augmented with periodic database writes for persistence) to track active sessions.  This structure should map:\n    *   `(app_name, window_name)` -> `(session_id, last_activity_timestamp)`\n\n3.  **New Event Handling:**\n    *   When a new event (OCR, audio, UI) arrives:\n        *   Extract `app_name` and `window_name`.\n        *   Check if an active session exists for this (app, window) combination.\n        *   If a session exists:\n            *   Check if `now() - last_activity_timestamp` exceeds the inactivity timeout.\n            *   If timeout exceeded, end the existing session and create a new one.\n            *   If not timed out, update `last_activity_timestamp` to the event's timestamp.\n        *   If no session exists:\n            *   Create a new session with `start_time` and `end_time` set to the event's timestamp.\n            *   Generate a new `session_id`.\n            *   Insert a new row into the `sessions` table.\n        *   Insert the new data (OCR, audio, UI) into the relevant table, linking it to the active `session_id`.\n\n4.  **Inactivity Timeout:** A configurable timeout (e.g., 5 minutes) will be used to determine session end due to inactivity.\n\n5.  **Periodic Flushing:** To avoid excessive in-memory state, periodically flush closed sessions (those that have exceeded the inactivity timeout) to the database.\n\n6. **Data Migration:** A migration script will be needed to analyze existing data and create initial session records based on timestamp proximity and app/window changes.\n\n### 3.4. Implementation Details\n\n*   **Language/Framework:** Continue using Rust for core logic and database interaction.\n*   **Database:** Continue using SQLite.\n*   **Concurrency:** Use asynchronous operations with `tokio` for handling concurrent events and database interactions.  Leverage `Arc` and `Mutex` for shared state, and channels for communication between tasks.\n*   **Configuration:** Add a new setting for the inactivity timeout.\n*   **Error Handling:** Implement robust error handling with `anyhow` and propagate errors appropriately. Log errors using `tracing`.\n* **Testing:** Thoroughly test session boundary detection with various scenarios, including rapid switching, long inactivity periods, and concurrent events.\n\n## 4. Diagrams\n\n### 4.1. Current Data Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Database\n    User->>Screen: Interacts with screen\n    Screen->>Screenpipe: Captures screen content (OCR)\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Database: Stores OCR data with timestamps\n    Screenpipe->>Database: Stores audio transcriptions with timestamps\n    User->>Screenpipe: Requests data\n    Screenpipe->>Database: Queries data by time range\n    Database->>Screenpipe: Returns data\n    Screenpipe->>User: Returns data\n```\n\n### 4.2. Proposed Database Schema Changes\n\n```mermaid\nclassDiagram\n    class frames {\n        +id : INTEGER [PK]\n        +video_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +name : TEXT\n    }\n    class video_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +device_name : TEXT\n    }\n    class ocr_text {\n        +frame_id : INTEGER [FK]\n        +text : TEXT\n        +text_json : TEXT\n        +app_name : TEXT\n        +window_name : TEXT\n        +ocr_engine : TEXT\n        +focused : BOOLEAN\n        +session_id : INTEGER [FK]\n    }\n    class audio_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +timestamp : TIMESTAMP\n    }\n    class audio_transcriptions {\n        +id : INTEGER [PK]\n        +audio_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +transcription : TEXT\n        +device : TEXT\n        +is_input_device : BOOLEAN\n        +speaker_id : INTEGER\n        +transcription_engine : TEXT\n        +start_time : REAL\n        +end_time : REAL\n        +text_length : INTEGER\n        +session_id : INTEGER [FK]\n    }\n    class ui_monitoring {\n      +id : INTEGER [PK]\n      +text_output : TEXT\n      +timestamp : DATETIME\n      +app : TEXT\n      +window : TEXT\n      +initial_traversal_at : DATETIME\n      +session_id : INTEGER [FK]\n    }\n  class sessions {\n    +id : INTEGER [PK]\n    +app_name : TEXT\n    +window_name : TEXT\n    +start_time : DATETIME\n    +end_time : DATETIME\n    +duration_secs : REAL\n  }\n  frames --|> video_chunks : video_chunk_id\n  ocr_text --|> frames : frame_id\n  audio_transcriptions --|> audio_chunks : audio_chunk_id\n  ocr_text --|> sessions : session_id\n  audio_transcriptions --|> sessions : session_id\n  ui_monitoring --|> sessions : session_id\n```\n\n### 4.3. Modified Data Flow with Session Tracking\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Session Manager\n    participant Database\n\n    User->>Screen: Interacts with App A, Window 1\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to session_id\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: Active session found (session_id)\n    Screenpipe->>Database: Store audio data, link to session_id\n\n    Note over User,Screenpipe: User switches to App B, Window 2\n    User->>Screen: Interacts with App B, Window 2\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App B, Window 2)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: End previous session (App A, Window 1)\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to new session_id\n\n    Note over User,Screenpipe: Inactivity Timeout\n    Screenpipe->>Session Manager: Check for activity\n    Session Manager->>Database: End current session (App B, Window 2)\n```\n\n### 4.4. New API Endpoint (Modified /search)\n\nThe existing `/search` endpoint will be extended to support session-based queries.  No new endpoint is needed.\n\n## 5. Performance Implications\n\n*   **Database:**  The addition of the `sessions` table and foreign keys will add some overhead to write operations.  Proper indexing is crucial to mitigate this.  Read performance for session-based queries should be good with appropriate indexes.\n*   **Memory:**  The in-memory session tracking will require additional memory.  The size of this will depend on the number of concurrent users and the configured timeout.  This should be monitored and potentially optimized (e.g., using a more efficient data structure than a simple `HashMap`).\n*   **CPU:**  The session boundary detection logic will add some CPU overhead.  This should be minimized by efficient checks and the use of asynchronous operations.\n\n## 6. Migration Path\n\n1.  **Add new `sessions` table.**\n2.  **Add `session_id` columns** to `ocr_text`, `audio_transcriptions`, and `ui_monitoring` tables.\n3.  **Backfill `session_id`:**  A migration script will be needed to analyze existing data and create initial session records.  This script will need to:\n    *   Iterate through existing OCR, audio, and UI data in chronological order.\n    *   Apply the session boundary detection logic (described above) to group data into sessions.\n    *   Insert corresponding rows into the `sessions` table.\n    *   Update the `session_id` foreign key in the existing tables.\n\n\n## 7. Alternative Approaches\n\n1.  **Session Table per Content Type:** Instead of a single `sessions` table, we could have separate session tables for each content type (e.g., `ocr_sessions`, `audio_sessions`, `ui_sessions`).  This might simplify queries for a specific content type but could make cross-content type analysis more complex.\n2.  **No Session Table (Denormalized):** We could add `start_time` and `end_time` directly to the existing tables (`ocr_text`, `audio_transcriptions`, `ui_monitoring`). This would avoid the need for joins when querying for sessions, but could lead to data redundancy and potential inconsistencies.\n3.  any other suggestions ????\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1560"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1560",
              "body": "\n## Challenge\n\nI'm working on an application that requires accurate session tracking to analyze user behavior patterns,  and provide meaningful insights across different applications and windows. \n\nIn the existing Screenpipe architecture, OCR data is stored with only timestamp information, lacking precise session boundaries (start/end times) for application usage tracking. This limitation prevents us from properly segmenting user activity into coherent sessions.\n\n## 1. Current Workaround\ninternally I implementing a suboptimal solution that:\n1. Queries all OCR database entries chronologically\n2. Manually identifies session boundaries by analyzing timestamp sequences for each application\n3. Determines session end when detecting a different application in subsequent timestamps\n4. Assumes a session is ongoing if no clear delimiter exists in future timestamps\n\nWith that said I would love to hear any feedbacks that could help solve this problem with a minimal overhead on code changes, and make sure I'm not overthinking the solution: cc @louis030195 , i'm planning to start playing with some day next week\n\n## 2. Requirements\n\n1.  **Session Definition:** A \"session\" should be defined as a continuous period of user interaction with a specific application and window.  A break in activity (e.g., switching to a different application or window) should end the current session and potentially start a new one.  A configurable inactivity timeout (e.g., 5 minutes) should also end a session.\n\n2.  **Data Storage:** The database schema must be modified to store session start and end times, associated with specific applications and windows.  It must maintain links to the relevant OCR and audio data chunks.\n\n3.  **API Endpoint:**  A new or modified API endpoint (e.g., `/sessions`) is needed to query for session data.  This endpoint should support filtering by:\n    *   Date range (start and end timestamps).\n    *   Application name.\n    *   Window name.\n    *   Minimum and maximum session duration.\n    *   Associated tags.\n    *   Pagination (limit and offset).\n\n4.  **Real-time Capability:** The system should be able to detect session boundaries in near real-time as data is being ingested. This implies integration with the existing data capture and processing pipeline.\n\n5. **Configurability:** The inactivity timeout for ending a session should be configurable.\n\n## 3. Proposed Solution\n\n### 3.1. Database Schema Changes\n\nWe'll introduce a new table `sessions` and modify the existing tables.\n\n**New Table: `sessions`**\n\n| Column Name      | Data Type  | Constraints                                  | Description                                                                  |\n| :--------------- | :--------- | :------------------------------------------- | :--------------------------------------------------------------------------- |\n| `id`             | INTEGER    | PRIMARY KEY AUTOINCREMENT                    | Unique identifier for the session.                                       |\n| `app_name`       | TEXT       | NOT NULL                                     | Name of the application.                                                 |\n| `window_name`    | TEXT       |                                               | Title of the window.                                                     |\n| `start_time`     | DATETIME   | NOT NULL                                     | Timestamp of the session start.                                            |\n| `end_time`       | DATETIME   | NOT NULL                                     | Timestamp of the session end.                                              |\n| `duration_secs`  | REAL       | NOT NULL                                     | Duration of the session in seconds.                                        |\n\n**Modified Tables:**\n\n*   **`ocr_text`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`audio_transcriptions`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`ui_monitoring`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n\n**Indexes:**\n\n*   Create indexes on `sessions` table columns (`app_name`, `window_name`, `start_time`, `end_time`) for efficient querying.\n*   Create indexes on the `session_id` columns in `ocr_text`, `audio_transcriptions`, and `ui_monitoring`.\n\n### 3.2. API Enhancements\n\nWe'll modify the existing `/search` endpoint to also support session queries.\n\n**Request:**\n\n```\nGET /search?content_type=session&app_name=Cursor&start_time=2024-11-27T00:00:00Z&end_time=2024-11-28T00:00:00Z&min_duration=60&limit=10&offset=0\n```\n\n*   `content_type=session`: Indicates a session-based search.\n*   `app_name`, `window_name`: Filter by application and window (optional).\n*   `start_time`, `end_time`: Date range for the session (optional, defaults to last 24 hours).\n*   `min_duration`, `max_duration`: Filter by session duration in seconds (optional).\n*   `limit`, `offset`: Pagination parameters.\n\n\nafter discussing with @louis030195 on discord he proposed something like this as the output\n\n**Response:**\n\n```json\n{\n  \"data\": [\n    {\n      \"app_name\": \"Cursor\",\n      \"total_usage_time\": 3600,\n      \"windows\": [\n        {\n          \"window_name\": \"page.tsx\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T12:00:00Z\",\n              \"end_time\": \"2024-07-16T12:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [123, 124, 125],\n              \"tags\": [\"coding\", \"frontend\"]\n            },\n            {\n              \"start_time\": \"2024-07-16T14:00:00Z\",\n              \"end_time\": \"2024-07-16T14:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [223, 224, 225],\n              \"tags\": [\"coding\", \"frontend\"]\n            }\n          ],\n          \"total_usage_time\": 3600\n        }\n      ]\n    },\n    {\n      \"app_name\": \"Arc\",\n      \"total_usage_time\": 1200,\n      \"windows\": [\n        {\n          \"window_name\": \"x.com\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T10:30:00Z\",\n              \"end_time\": \"2024-07-16T10:50:00Z\",\n              \"duration\": 1200,\n              \"content_ids\": [126, 127, 128],\n              \"tags\": [\"browsing\", \"social-media\"]\n            }\n          ],\n          \"total_usage_time\": 1200\n        }\n      ]\n    }\n  ],\n  \"pagination\": {\n    \"limit\": 50,\n    \"offset\": 0,\n    \"total\": 2\n  }\n}\n```\n\n### 3.3. Session Boundary Detection Logic\n\n1.  **Real-time Monitoring:**  The existing event listeners for OCR, audio, and UI events will be leveraged.\n\n2.  **Session Tracking:**  Maintain a data structure (likely in memory, possibly augmented with periodic database writes for persistence) to track active sessions.  This structure should map:\n    *   `(app_name, window_name)` -> `(session_id, last_activity_timestamp)`\n\n3.  **New Event Handling:**\n    *   When a new event (OCR, audio, UI) arrives:\n        *   Extract `app_name` and `window_name`.\n        *   Check if an active session exists for this (app, window) combination.\n        *   If a session exists:\n            *   Check if `now() - last_activity_timestamp` exceeds the inactivity timeout.\n            *   If timeout exceeded, end the existing session and create a new one.\n            *   If not timed out, update `last_activity_timestamp` to the event's timestamp.\n        *   If no session exists:\n            *   Create a new session with `start_time` and `end_time` set to the event's timestamp.\n            *   Generate a new `session_id`.\n            *   Insert a new row into the `sessions` table.\n        *   Insert the new data (OCR, audio, UI) into the relevant table, linking it to the active `session_id`.\n\n4.  **Inactivity Timeout:** A configurable timeout (e.g., 5 minutes) will be used to determine session end due to inactivity.\n\n5.  **Periodic Flushing:** To avoid excessive in-memory state, periodically flush closed sessions (those that have exceeded the inactivity timeout) to the database.\n\n6. **Data Migration:** A migration script will be needed to analyze existing data and create initial session records based on timestamp proximity and app/window changes.\n\n### 3.4. Implementation Details\n\n*   **Language/Framework:** Continue using Rust for core logic and database interaction.\n*   **Database:** Continue using SQLite.\n*   **Concurrency:** Use asynchronous operations with `tokio` for handling concurrent events and database interactions.  Leverage `Arc` and `Mutex` for shared state, and channels for communication between tasks.\n*   **Configuration:** Add a new setting for the inactivity timeout.\n*   **Error Handling:** Implement robust error handling with `anyhow` and propagate errors appropriately. Log errors using `tracing`.\n* **Testing:** Thoroughly test session boundary detection with various scenarios, including rapid switching, long inactivity periods, and concurrent events.\n\n## 4. Diagrams\n\n### 4.1. Current Data Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Database\n    User->>Screen: Interacts with screen\n    Screen->>Screenpipe: Captures screen content (OCR)\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Database: Stores OCR data with timestamps\n    Screenpipe->>Database: Stores audio transcriptions with timestamps\n    User->>Screenpipe: Requests data\n    Screenpipe->>Database: Queries data by time range\n    Database->>Screenpipe: Returns data\n    Screenpipe->>User: Returns data\n```\n\n### 4.2. Proposed Database Schema Changes\n\n```mermaid\nclassDiagram\n    class frames {\n        +id : INTEGER [PK]\n        +video_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +name : TEXT\n    }\n    class video_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +device_name : TEXT\n    }\n    class ocr_text {\n        +frame_id : INTEGER [FK]\n        +text : TEXT\n        +text_json : TEXT\n        +app_name : TEXT\n        +window_name : TEXT\n        +ocr_engine : TEXT\n        +focused : BOOLEAN\n        +session_id : INTEGER [FK]\n    }\n    class audio_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +timestamp : TIMESTAMP\n    }\n    class audio_transcriptions {\n        +id : INTEGER [PK]\n        +audio_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +transcription : TEXT\n        +device : TEXT\n        +is_input_device : BOOLEAN\n        +speaker_id : INTEGER\n        +transcription_engine : TEXT\n        +start_time : REAL\n        +end_time : REAL\n        +text_length : INTEGER\n        +session_id : INTEGER [FK]\n    }\n    class ui_monitoring {\n      +id : INTEGER [PK]\n      +text_output : TEXT\n      +timestamp : DATETIME\n      +app : TEXT\n      +window : TEXT\n      +initial_traversal_at : DATETIME\n      +session_id : INTEGER [FK]\n    }\n  class sessions {\n    +id : INTEGER [PK]\n    +app_name : TEXT\n    +window_name : TEXT\n    +start_time : DATETIME\n    +end_time : DATETIME\n    +duration_secs : REAL\n  }\n  frames --|> video_chunks : video_chunk_id\n  ocr_text --|> frames : frame_id\n  audio_transcriptions --|> audio_chunks : audio_chunk_id\n  ocr_text --|> sessions : session_id\n  audio_transcriptions --|> sessions : session_id\n  ui_monitoring --|> sessions : session_id\n```\n\n### 4.3. Modified Data Flow with Session Tracking\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Session Manager\n    participant Database\n\n    User->>Screen: Interacts with App A, Window 1\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to session_id\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: Active session found (session_id)\n    Screenpipe->>Database: Store audio data, link to session_id\n\n    Note over User,Screenpipe: User switches to App B, Window 2\n    User->>Screen: Interacts with App B, Window 2\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App B, Window 2)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: End previous session (App A, Window 1)\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to new session_id\n\n    Note over User,Screenpipe: Inactivity Timeout\n    Screenpipe->>Session Manager: Check for activity\n    Session Manager->>Database: End current session (App B, Window 2)\n```\n\n### 4.4. New API Endpoint (Modified /search)\n\nThe existing `/search` endpoint will be extended to support session-based queries.  No new endpoint is needed.\n\n## 5. Performance Implications\n\n*   **Database:**  The addition of the `sessions` table and foreign keys will add some overhead to write operations.  Proper indexing is crucial to mitigate this.  Read performance for session-based queries should be good with appropriate indexes.\n*   **Memory:**  The in-memory session tracking will require additional memory.  The size of this will depend on the number of concurrent users and the configured timeout.  This should be monitored and potentially optimized (e.g., using a more efficient data structure than a simple `HashMap`).\n*   **CPU:**  The session boundary detection logic will add some CPU overhead.  This should be minimized by efficient checks and the use of asynchronous operations.\n\n## 6. Migration Path\n\n1.  **Add new `sessions` table.**\n2.  **Add `session_id` columns** to `ocr_text`, `audio_transcriptions`, and `ui_monitoring` tables.\n3.  **Backfill `session_id`:**  A migration script will be needed to analyze existing data and create initial session records.  This script will need to:\n    *   Iterate through existing OCR, audio, and UI data in chronological order.\n    *   Apply the session boundary detection logic (described above) to group data into sessions.\n    *   Insert corresponding rows into the `sessions` table.\n    *   Update the `session_id` foreign key in the existing tables.\n\n\n## 7. Alternative Approaches\n\n1.  **Session Table per Content Type:** Instead of a single `sessions` table, we could have separate session tables for each content type (e.g., `ocr_sessions`, `audio_sessions`, `ui_sessions`).  This might simplify queries for a specific content type but could make cross-content type analysis more complex.\n2.  **No Session Table (Denormalized):** We could add `start_time` and `end_time` directly to the existing tables (`ocr_text`, `audio_transcriptions`, `ui_monitoring`). This would avoid the need for joins when querying for sessions, but could lead to data redundancy and potential inconsistencies.\n3.  any other suggestions ????\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1560",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1441",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-12-17T18:24:41.119Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:41.119Z",
            "created_at": "2025-12-17T18:24:41.119Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1441",
              "status": "open",
              "type": "issue",
              "number": 1441,
              "title": "[bounty] general purpose scrapper",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1441",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] general purpose scrapper",
                  "body": "\nv0\n\nshould be able to scrap whatsapp\n\nideally you can use the keyboard / mouse api \n\nhttps://docs.screenpi.pe/docs/sdk-reference#input-control-api\n\n\nbasically many ppl would like to scrap data from desktop app and it's hard, like whatsapp, imessage, or even web but without getting banned or because it's local authentication is already done by user usually and stays local, and much less likely detected \n\n\n\n/bounty 200\n\nplease suggest how you would implement a very simple first version that work for whatsapp and UX\n\n\n\n\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1441"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1441",
              "body": "\nv0\n\nshould be able to scrap whatsapp\n\nideally you can use the keyboard / mouse api \n\nhttps://docs.screenpi.pe/docs/sdk-reference#input-control-api\n\n\nbasically many ppl would like to scrap data from desktop app and it's hard, like whatsapp, imessage, or even web but without getting banned or because it's local authentication is already done by user usually and stays local, and much less likely detected \n\n\n\n/bounty 200\n\nplease suggest how you would implement a very simple first version that work for whatsapp and UX\n\n\n\n\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1441",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1298",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-12-17T18:24:41.304Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:41.304Z",
            "created_at": "2025-12-17T18:24:41.304Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1298",
              "status": "open",
              "type": "issue",
              "number": 1298,
              "title": "[docs] document env var somewhere somehow ",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1298",
                  "user": {
                    "login": "dassio",
                    "id": 733502,
                    "node_id": "MDQ6VXNlcjczMzUwMg==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/733502?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/dassio",
                    "html_url": "https://github.com/dassio",
                    "followers_url": "https://api.github.com/users/dassio/followers",
                    "following_url": "https://api.github.com/users/dassio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/dassio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/dassio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/dassio/subscriptions",
                    "organizations_url": "https://api.github.com/users/dassio/orgs",
                    "repos_url": "https://api.github.com/users/dassio/repos",
                    "events_url": "https://api.github.com/users/dassio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/dassio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[docs] document env var somewhere somehow ",
                  "body": "**describe the feature**\nin the desktop app, you can configure hugging face mirror, but for the screenpipe server cli ,there is no such option , when try to use whisper for audio transcription, need to download mode from hugging face \n\n**why is this needed?**\nhugging face is banned in China\n\n\n**additional context**\n```\nyou are using local processing. all your data stays on your computer.\n\nwarning: telemetry is enabled. only error-level data will be sent to highlight.io.\nto disable, use the --disable-telemetry flag.\n\ncheck latest changes here: https://github.com/mediar-ai/screenpipe/releases\n2025-02-07T14:15:37.861529Z  INFO screenpipe: starting pipes\nfailed to start pipe timeline: No pipe.js/pipe.ts found in the pipe/dist directory\n2025-02-07T14:15:37.864597Z  INFO screenpipe_server::server: Server starting on 127.0.0.1:3030\n2025-02-07T14:15:45.839709Z  INFO screenpipe_server::video: Starting FFmpeg process for file: C:\\Users\\dassi\\.screenpipe\\data\\monitor_490607759_2025-02-07_14-15-45.mp4\n2025-02-07T14:15:48.283937Z  INFO screenpipe_server::resource_monitor: Runtime: 10s, Total Memory: 2% (0.25 GB / 16.09 GB), Total CPU: 88%\n2025-02-07T14:15:58.322953Z  INFO screenpipe_server::resource_monitor: Runtime: 20s, Total Memory: 2% (0.26 GB / 16.09 GB), Total CPU: 92%\n2025-02-07T14:16:00.374953Z ERROR screenpipe: continuous recording error: request error: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n\nCaused by:\n    0: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n    1: connection timed out\n```\n\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1298"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1298",
              "body": "**describe the feature**\nin the desktop app, you can configure hugging face mirror, but for the screenpipe server cli ,there is no such option , when try to use whisper for audio transcription, need to download mode from hugging face \n\n**why is this needed?**\nhugging face is banned in China\n\n\n**additional context**\n```\nyou are using local processing. all your data stays on your computer.\n\nwarning: telemetry is enabled. only error-level data will be sent to highlight.io.\nto disable, use the --disable-telemetry flag.\n\ncheck latest changes here: https://github.com/mediar-ai/screenpipe/releases\n2025-02-07T14:15:37.861529Z  INFO screenpipe: starting pipes\nfailed to start pipe timeline: No pipe.js/pipe.ts found in the pipe/dist directory\n2025-02-07T14:15:37.864597Z  INFO screenpipe_server::server: Server starting on 127.0.0.1:3030\n2025-02-07T14:15:45.839709Z  INFO screenpipe_server::video: Starting FFmpeg process for file: C:\\Users\\dassi\\.screenpipe\\data\\monitor_490607759_2025-02-07_14-15-45.mp4\n2025-02-07T14:15:48.283937Z  INFO screenpipe_server::resource_monitor: Runtime: 10s, Total Memory: 2% (0.25 GB / 16.09 GB), Total CPU: 88%\n2025-02-07T14:15:58.322953Z  INFO screenpipe_server::resource_monitor: Runtime: 20s, Total Memory: 2% (0.26 GB / 16.09 GB), Total CPU: 92%\n2025-02-07T14:16:00.374953Z ERROR screenpipe: continuous recording error: request error: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n\nCaused by:\n    0: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n    1: connection timed out\n```\n\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1298",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1383",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2025-12-17T18:24:41.459Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-17T18:24:41.459Z",
            "created_at": "2025-12-17T18:24:41.459Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1383",
              "status": "open",
              "type": "issue",
              "number": 1383,
              "title": "[bounty] implement deep research in search pipe",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1383",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] implement deep research in search pipe",
                  "body": "\n\ni love perplexity deep research \n\ni think we should have something like this in screenpipe search, which would be something that go beyond surface level, really in depth on your data \n\nnot sure about the UX yet, suggest any design first \n\nshould allow async (eg ask something and come back later to it, stored in some kind of history, maybe related to #1382 check perplexity UI too)\n\n/bounty 200 \n\n\n\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1383"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1383",
              "body": "\n\ni love perplexity deep research \n\ni think we should have something like this in screenpipe search, which would be something that go beyond surface level, really in depth on your data \n\nnot sure about the UX yet, suggest any design first \n\nshould allow async (eg ask something and come back later to it, stored in some kind of history, maybe related to #1382 check perplexity UI too)\n\n/bounty 200 \n\n\n\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1383",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          }
        ],
        "next_cursor": null
      }
    }
  }
}