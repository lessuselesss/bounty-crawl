{
  "result": {
    "data": {
      "json": {
        "items": [
          {
            "id": "keephq#3960",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2026-01-18T17:51:29.153Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:29.153Z",
            "created_at": "2026-01-18T17:51:29.153Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3960",
              "status": "open",
              "type": "issue",
              "number": 3960,
              "title": "[ðŸ”Œ Provider]: Nagios Provider",
              "source": {
                "data": {
                  "id": "source-keephq#3960",
                  "user": {
                    "login": "talboren",
                    "id": 68807791,
                    "node_id": "MDQ6VXNlcjY4ODA3Nzkx",
                    "avatar_url": "https://avatars.githubusercontent.com/u/68807791?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/talboren",
                    "html_url": "https://github.com/talboren",
                    "followers_url": "https://api.github.com/users/talboren/followers",
                    "following_url": "https://api.github.com/users/talboren/following{/other_user}",
                    "gists_url": "https://api.github.com/users/talboren/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/talboren/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/talboren/subscriptions",
                    "organizations_url": "https://api.github.com/users/talboren/orgs",
                    "repos_url": "https://api.github.com/users/talboren/repos",
                    "events_url": "https://api.github.com/users/talboren/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/talboren/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[ðŸ”Œ Provider]: Nagios Provider",
                  "body": "https://www.nagios.org/",
                  "html_url": "https://github.com/keephq/keep/issues/3960"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3960",
              "body": "https://www.nagios.org/",
              "url": "https://github.com/keephq/keep/issues/3960",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#3526",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2026-01-18T17:51:29.317Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:29.317Z",
            "created_at": "2026-01-18T17:51:29.317Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3526",
              "status": "open",
              "type": "issue",
              "number": 3526,
              "title": "[ðŸ”Œ Provider]: Solarwinds",
              "source": {
                "data": {
                  "id": "source-keephq#3526",
                  "user": {
                    "login": "Matvey-Kuk",
                    "id": 3284841,
                    "node_id": "MDQ6VXNlcjMyODQ4NDE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/3284841?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Matvey-Kuk",
                    "html_url": "https://github.com/Matvey-Kuk",
                    "followers_url": "https://api.github.com/users/Matvey-Kuk/followers",
                    "following_url": "https://api.github.com/users/Matvey-Kuk/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Matvey-Kuk/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Matvey-Kuk/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Matvey-Kuk/subscriptions",
                    "organizations_url": "https://api.github.com/users/Matvey-Kuk/orgs",
                    "repos_url": "https://api.github.com/users/Matvey-Kuk/repos",
                    "events_url": "https://api.github.com/users/Matvey-Kuk/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Matvey-Kuk/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[ðŸ”Œ Provider]: Solarwinds",
                  "body": "We're looking for a https://www.solarwinds.com/ provider for Keep.",
                  "html_url": "https://github.com/keephq/keep/issues/3526"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3526",
              "body": "We're looking for a https://www.solarwinds.com/ provider for Keep.",
              "url": "https://github.com/keephq/keep/issues/3526",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#3376",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2026-01-18T17:51:29.599Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:29.599Z",
            "created_at": "2026-01-18T17:51:29.599Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3376",
              "status": "open",
              "type": "issue",
              "number": 3376,
              "title": "[âž• Feature]: Add a way to validate Keep workflows from CI",
              "source": {
                "data": {
                  "id": "source-keephq#3376",
                  "user": {
                    "login": "shahargl",
                    "id": 12069200,
                    "node_id": "MDQ6VXNlcjEyMDY5MjAw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/12069200?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/shahargl",
                    "html_url": "https://github.com/shahargl",
                    "followers_url": "https://api.github.com/users/shahargl/followers",
                    "following_url": "https://api.github.com/users/shahargl/following{/other_user}",
                    "gists_url": "https://api.github.com/users/shahargl/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/shahargl/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/shahargl/subscriptions",
                    "organizations_url": "https://api.github.com/users/shahargl/orgs",
                    "repos_url": "https://api.github.com/users/shahargl/repos",
                    "events_url": "https://api.github.com/users/shahargl/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/shahargl/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[âž• Feature]: Add a way to validate Keep workflows from CI",
                  "body": "https://github.com/keephq/keep/pull/5498 https://github.com/keephq/keep/pull/5149 https://github.com/keephq/keep/pull/4517 https://github.com/keephq/keep/pull/5499 https://github.com/keephq/keep/issue",
                  "html_url": "https://github.com/keephq/keep/issues/3376"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3376",
              "body": "https://github.com/keephq/keep/pull/5498 https://github.com/keephq/keep/pull/5149 https://github.com/keephq/keep/pull/4517 https://github.com/keephq/keep/pull/5499 https://github.com/keephq/keep/issue",
              "url": "https://github.com/keephq/keep/issues/3376",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#3379",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2026-01-18T17:51:29.811Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:29.811Z",
            "created_at": "2026-01-18T17:51:29.811Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3379",
              "status": "open",
              "type": "issue",
              "number": 3379,
              "title": "[ðŸ”Œ Provider]: ServiceNow pull activity from incidents into incidents",
              "source": {
                "data": {
                  "id": "source-keephq#3379",
                  "user": {
                    "login": "talboren",
                    "id": 68807791,
                    "node_id": "MDQ6VXNlcjY4ODA3Nzkx",
                    "avatar_url": "https://avatars.githubusercontent.com/u/68807791?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/talboren",
                    "html_url": "https://github.com/talboren",
                    "followers_url": "https://api.github.com/users/talboren/followers",
                    "following_url": "https://api.github.com/users/talboren/following{/other_user}",
                    "gists_url": "https://api.github.com/users/talboren/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/talboren/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/talboren/subscriptions",
                    "organizations_url": "https://api.github.com/users/talboren/orgs",
                    "repos_url": "https://api.github.com/users/talboren/repos",
                    "events_url": "https://api.github.com/users/talboren/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/talboren/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[ðŸ”Œ Provider]: ServiceNow pull activity from incidents into incidents",
                  "body": "As a user, I would like to pull activity from ServiceNow incident into my Keep incident and the other way around.",
                  "html_url": "https://github.com/keephq/keep/issues/3379"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3379",
              "body": "As a user, I would like to pull activity from ServiceNow incident into my Keep incident and the other way around.",
              "url": "https://github.com/keephq/keep/issues/3379",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#2112",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2026-01-18T17:51:30.351Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:30.351Z",
            "created_at": "2026-01-18T17:51:30.351Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#2112",
              "status": "open",
              "type": "issue",
              "number": 2112,
              "title": "[ðŸ”Œ Provider]: SNMP provider",
              "source": {
                "data": {
                  "id": "source-keephq#2112",
                  "user": {
                    "login": "shahargl",
                    "id": 12069200,
                    "node_id": "MDQ6VXNlcjEyMDY5MjAw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/12069200?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/shahargl",
                    "html_url": "https://github.com/shahargl",
                    "followers_url": "https://api.github.com/users/shahargl/followers",
                    "following_url": "https://api.github.com/users/shahargl/following{/other_user}",
                    "gists_url": "https://api.github.com/users/shahargl/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/shahargl/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/shahargl/subscriptions",
                    "organizations_url": "https://api.github.com/users/shahargl/orgs",
                    "repos_url": "https://api.github.com/users/shahargl/repos",
                    "events_url": "https://api.github.com/users/shahargl/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/shahargl/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[ðŸ”Œ Provider]: SNMP provider",
                  "body": "Send SNMP traps/events into Keep as alerts",
                  "html_url": "https://github.com/keephq/keep/issues/2112"
                },
                "type": "github"
              },
              "hash": "keephq/keep#2112",
              "body": "Send SNMP traps/events into Keep as alerts",
              "url": "https://github.com/keephq/keep/issues/2112",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7655",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-18T17:51:29.077Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:29.077Z",
            "created_at": "2026-01-18T17:51:29.077Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7655",
              "status": "open",
              "type": "issue",
              "number": 7655,
              "title": "[Improvement]: Do not share all environment variables across all containers in a Compose project",
              "source": {
                "data": {
                  "id": "source-coollabsio#7655",
                  "user": {
                    "login": "tadamcz",
                    "id": 43300673,
                    "node_id": "MDQ6VXNlcjQzMzAwNjcz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/43300673?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/tadamcz",
                    "html_url": "https://github.com/tadamcz",
                    "followers_url": "https://api.github.com/users/tadamcz/followers",
                    "following_url": "https://api.github.com/users/tadamcz/following{/other_user}",
                    "gists_url": "https://api.github.com/users/tadamcz/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/tadamcz/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/tadamcz/subscriptions",
                    "organizations_url": "https://api.github.com/users/tadamcz/orgs",
                    "repos_url": "https://api.github.com/users/tadamcz/repos",
                    "events_url": "https://api.github.com/users/tadamcz/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/tadamcz/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Improvement]: Do not share all environment variables across all containers in a Compose project",
                  "body": "### Problem Description\n\nWhen deploying a Docker Compose project, Coolify injects all environment variables into every container, regardless of which container they were defined for.\n\nFrom inspecting the \"Raw Docker compose\" in the UI, I believe this happens like this:\n  1. A single `.env` file is created containing ALL environment variables from the entire Docker Compose project\n  2. This `.env` file is automatically added to every container's `env_file:` directive\n\n### Security Implications\n\nThis seems to be a serious security issue. \n\nAny container in a multi-container Docker Compose project can read the secrets/credentials of every other container.\n\nExamples:\n  - In a Next.js + PostgreSQL + Redis stack, the Redis container has access to POSTGRES_PASSWORD and the PostgreSQL container can see OPENAI_API_KEY meant only for the app\n  - In any multi-database setup, each database container can see the credentials of other databases\n  - If one container is compromised, an attacker gains credentials for all containers in the project\n\n###  Expected Behavior\n\n  Each container should only have access to:\n  - Variables explicitly defined in its `environment: ` section\n  - Variables from env files explicitly declared in its `env_file:` section\n  - Coolify metadata variables (`COOLIFY_*`, `SERVICE_URL_*`, etc.) as needed\n\nVariables specific to other containers (especially credentials) should NOT be accessible to unrelated containers.\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7655"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7655",
              "body": "### Problem Description\n\nWhen deploying a Docker Compose project, Coolify injects all environment variables into every container, regardless of which container they were defined for.\n\nFrom inspecting the \"Raw Docker compose\" in the UI, I believe this happens like this:\n  1. A single `.env` file is created containing ALL environment variables from the entire Docker Compose project\n  2. This `.env` file is automatically added to every container's `env_file:` directive\n\n### Security Implications\n\nThis seems to be a serious security issue. \n\nAny container in a multi-container Docker Compose project can read the secrets/credentials of every other container.\n\nExamples:\n  - In a Next.js + PostgreSQL + Redis stack, the Redis container has access to POSTGRES_PASSWORD and the PostgreSQL container can see OPENAI_API_KEY meant only for the app\n  - In any multi-database setup, each database container can see the credentials of other databases\n  - If one container is compromised, an attacker gains credentials for all containers in the project\n\n###  Expected Behavior\n\n  Each container should only have access to:\n  - Variables explicitly defined in its `environment: ` section\n  - Variables from env files explicitly declared in its `env_file:` section\n  - Coolify metadata variables (`COOLIFY_*`, `SERVICE_URL_*`, etc.) as needed\n\nVariables specific to other containers (especially credentials) should NOT be accessible to unrelated containers.\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n",
              "url": "https://github.com/coollabsio/coolify/issues/7655",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7941",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-18T17:51:29.226Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:29.226Z",
            "created_at": "2026-01-18T17:51:29.226Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7941",
              "status": "open",
              "type": "issue",
              "number": 7941,
              "title": "[Bug]: Error deploying Rocket chat V8 using the default service template",
              "source": {
                "data": {
                  "id": "source-coollabsio#7941",
                  "user": {
                    "login": "paul-hph",
                    "id": 3603487,
                    "node_id": "MDQ6VXNlcjM2MDM0ODc=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/3603487?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/paul-hph",
                    "html_url": "https://github.com/paul-hph",
                    "followers_url": "https://api.github.com/users/paul-hph/followers",
                    "following_url": "https://api.github.com/users/paul-hph/following{/other_user}",
                    "gists_url": "https://api.github.com/users/paul-hph/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/paul-hph/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/paul-hph/subscriptions",
                    "organizations_url": "https://api.github.com/users/paul-hph/orgs",
                    "repos_url": "https://api.github.com/users/paul-hph/repos",
                    "events_url": "https://api.github.com/users/paul-hph/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/paul-hph/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Error deploying Rocket chat V8 using the default service template",
                  "body": "### Error Message and Logs\n\n Container mongodb-nco8s48o8o40gggsg0s0wkcg Error dependency mongodb failed to start\ndependency failed to start: container mongodb-nco8s48o8o40gggsg0s0wkcg is unhealthy\n\n### Steps to Reproduce\n\n1. Create a new project\n2. Select Rocket chat from the available services\n3. Hit \"Deploy\"\n4. Watch the error in the deploy logs\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nAlmaLinux10\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7941"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7941",
              "body": "### Error Message and Logs\n\n Container mongodb-nco8s48o8o40gggsg0s0wkcg Error dependency mongodb failed to start\ndependency failed to start: container mongodb-nco8s48o8o40gggsg0s0wkcg is unhealthy\n\n### Steps to Reproduce\n\n1. Create a new project\n2. Select Rocket chat from the available services\n3. Hit \"Deploy\"\n4. Watch the error in the deploy logs\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nAlmaLinux10\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/7941",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7743",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-18T17:51:29.488Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:29.488Z",
            "created_at": "2026-01-18T17:51:29.488Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7743",
              "status": "open",
              "type": "issue",
              "number": 7743,
              "title": "[Enhancement]: Don't timeout public database proxies after 10 min",
              "source": {
                "data": {
                  "id": "source-coollabsio#7743",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Don't timeout public database proxies after 10 min",
                  "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the TCP proxy in front of Postgres when you mark \"Expose publicly\" times out after about 10m. Switch this to have no timeout or to have a configurable timeout in the GUI.\n\nUse case: I sometimes have `SELECT *` statements that take a very long time (30m+) to download the results for. The connection timing out prevents that from being successful\n\nBounty: $100 USD once merged and live on Coolify Cloud.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com), a charity that supports teenagers who love coding and electronics! We previously funded database SSL support, backups API, and pgBackRest support for Postgres backups (in progress).",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7743"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7743",
              "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the TCP proxy in front of Postgres when you mark \"Expose publicly\" times out after about 10m. Switch this to have no timeout or to have a configurable timeout in the GUI.\n\nUse case: I sometimes have `SELECT *` statements that take a very long time (30m+) to download the results for. The connection timing out prevents that from being successful\n\nBounty: $100 USD once merged and live on Coolify Cloud.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com), a charity that supports teenagers who love coding and electronics! We previously funded database SSL support, backups API, and pgBackRest support for Postgres backups (in progress).",
              "url": "https://github.com/coollabsio/coolify/issues/7743",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7738",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-18T17:51:29.601Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:29.601Z",
            "created_at": "2026-01-18T17:51:29.601Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7738",
              "status": "open",
              "type": "issue",
              "number": 7738,
              "title": "[Enhancement]: Environment variables for each server that can be made available to each application deployed on it",
              "source": {
                "data": {
                  "id": "source-coollabsio#7738",
                  "user": {
                    "login": "pkpio",
                    "id": 816666,
                    "node_id": "MDQ6VXNlcjgxNjY2Ng==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/816666?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/pkpio",
                    "html_url": "https://github.com/pkpio",
                    "followers_url": "https://api.github.com/users/pkpio/followers",
                    "following_url": "https://api.github.com/users/pkpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/pkpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/pkpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/pkpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/pkpio/orgs",
                    "repos_url": "https://api.github.com/users/pkpio/repos",
                    "events_url": "https://api.github.com/users/pkpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/pkpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Environment variables for each server that can be made available to each application deployed on it",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\nWhen deploying a resource using the \"Multiple Servers\" option, currently there is no way to distinguish between the servers from within the application - because the container running on both servers get identical setup. \n\nThis makes debugging harder as application logs cannot identify which server deployment an issue happened - take for instance a failure due to network errors happening specifically on one server (randomly). \n\nA way to define Environment variables for each server and making them available for each application deployed on that server, will fix this limitation (and also generalised in a way for use cases beyond what I described here).",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7738"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7738",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\nWhen deploying a resource using the \"Multiple Servers\" option, currently there is no way to distinguish between the servers from within the application - because the container running on both servers get identical setup. \n\nThis makes debugging harder as application logs cannot identify which server deployment an issue happened - take for instance a failure due to network errors happening specifically on one server (randomly). \n\nA way to define Environment variables for each server and making them available for each application deployed on that server, will fix this limitation (and also generalised in a way for use cases beyond what I described here).",
              "url": "https://github.com/coollabsio/coolify/issues/7738",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7724",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-18T17:51:29.904Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:29.904Z",
            "created_at": "2026-01-18T17:51:29.904Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7724",
              "status": "open",
              "type": "issue",
              "number": 7724,
              "title": "[Bug]: Sporadic Permission denied (publickey,password).",
              "source": {
                "data": {
                  "id": "source-coollabsio#7724",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Sporadic Permission denied (publickey,password).",
                  "body": "### Error Message and Logs\n\n<img width=\"380\" height=\"129\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a615ea52-e26d-435d-8121-e01cd7d7f656\" />\n\nStarting maybe ~2 weeks ago we started getting this error constantly. Generating a new private SSH key and setting it up seems to stop it for a bit, then it starts happening again. I'm 99% sure something is causing Coolify to send the wrong SSH key. When I check server logs, it shows that logins are indeed failing. They are not being blocked by fail2ban or anything like that.\n\nI will pay $250 to anyone who can diagnose and fix this issue. It's causing major issues for us. Acceptance criteria: Fix is merged into Coolify Cloud.\n\n### Steps to Reproduce\n\nI'm sorry, I don't have good reproduction steps. It sporadically seems to happen.\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7724"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7724",
              "body": "### Error Message and Logs\n\n<img width=\"380\" height=\"129\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a615ea52-e26d-435d-8121-e01cd7d7f656\" />\n\nStarting maybe ~2 weeks ago we started getting this error constantly. Generating a new private SSH key and setting it up seems to stop it for a bit, then it starts happening again. I'm 99% sure something is causing Coolify to send the wrong SSH key. When I check server logs, it shows that logins are indeed failing. They are not being blocked by fail2ban or anything like that.\n\nI will pay $250 to anyone who can diagnose and fix this issue. It's causing major issues for us. Acceptance criteria: Fix is merged into Coolify Cloud.\n\n### Steps to Reproduce\n\nI'm sorry, I don't have good reproduction steps. It sporadically seems to happen.\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/7724",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7642",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-18T17:51:30.344Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:30.344Z",
            "created_at": "2026-01-18T17:51:30.344Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7642",
              "status": "open",
              "type": "issue",
              "number": 7642,
              "title": "[Enhancement]: Add surrealDB with and without TIKV",
              "source": {
                "data": {
                  "id": "source-coollabsio#7642",
                  "user": {
                    "login": "Jordan-Hall",
                    "id": 2092344,
                    "node_id": "MDQ6VXNlcjIwOTIzNDQ=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/2092344?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Jordan-Hall",
                    "html_url": "https://github.com/Jordan-Hall",
                    "followers_url": "https://api.github.com/users/Jordan-Hall/followers",
                    "following_url": "https://api.github.com/users/Jordan-Hall/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Jordan-Hall/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Jordan-Hall/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Jordan-Hall/subscriptions",
                    "organizations_url": "https://api.github.com/users/Jordan-Hall/orgs",
                    "repos_url": "https://api.github.com/users/Jordan-Hall/repos",
                    "events_url": "https://api.github.com/users/Jordan-Hall/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Jordan-Hall/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Add surrealDB with and without TIKV",
                  "body": "### Request Type\n\nNew Service\n\n### Description\n\nThey a couple of decussion around surrealdb as a database option but it be nice if it was bulit in with both TIKV and rockdb as an option\n\nhttps://github.com/coollabsio/coolify/discussions/3587\nhttps://github.com/coollabsio/coolify/discussions/4013 ",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7642"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7642",
              "body": "### Request Type\n\nNew Service\n\n### Description\n\nThey a couple of decussion around surrealdb as a database option but it be nice if it was bulit in with both TIKV and rockdb as an option\n\nhttps://github.com/coollabsio/coolify/discussions/3587\nhttps://github.com/coollabsio/coolify/discussions/4013 ",
              "url": "https://github.com/coollabsio/coolify/issues/7642",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7596",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-18T17:51:31.702Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:31.702Z",
            "created_at": "2026-01-18T17:51:31.702Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7596",
              "status": "open",
              "type": "issue",
              "number": 7596,
              "title": "[Enhancement]: new deployment page",
              "source": {
                "data": {
                  "id": "source-coollabsio#7596",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: new deployment page",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n- Add deployments to sidebar\n- Show past deployments (all of them)\n- Add a filter on the top:\n  - Filter by project\n  - Filter by server\n  - Filter by sources\n  - Filter by status (queued, pending, done)\n- Show live updates / refresh?\n- Hide filters if only 1 server / 1 source\n\n## Design inspiration\n\nVercel example:\n\n<img width=\"1362\" height=\"967\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e46d7470-fff1-46c5-8011-63ba82119db2\" />\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7596"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7596",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n- Add deployments to sidebar\n- Show past deployments (all of them)\n- Add a filter on the top:\n  - Filter by project\n  - Filter by server\n  - Filter by sources\n  - Filter by status (queued, pending, done)\n- Show live updates / refresh?\n- Hide filters if only 1 server / 1 source\n\n## Design inspiration\n\nVercel example:\n\n<img width=\"1362\" height=\"967\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e46d7470-fff1-46c5-8011-63ba82119db2\" />\n",
              "url": "https://github.com/coollabsio/coolify/issues/7596",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7528",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-18T17:51:34.027Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:34.027Z",
            "created_at": "2026-01-18T17:51:34.027Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7528",
              "status": "open",
              "type": "issue",
              "number": 7528,
              "title": "[Enhancement]: Enable database detection and backup support for Docker Compose deployments via GitHub App",
              "source": {
                "data": {
                  "id": "source-coollabsio#7528",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Enable database detection and backup support for Docker Compose deployments via GitHub App",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nWhen deploying a Docker Compose file via GitHub App (using the `dockercompose` buildpack), database services are not detected and `ServiceDatabase` records are not created. This means automated backups are not available for databases in these deployments.\n\nHowever, when using \"Empty Docker Compose\" or one-click services (like Supabase), database detection works correctly and backups are available.\n\n### Current Behavior\n\n| Deployment Method | Model | Creates ServiceDatabase | Backups Available |\n|---|---|---|---|\n| Empty Docker Compose | `Service` | âœ… Yes | âœ… Yes |\n| GitHub App (dockercompose buildpack) | `Application` | âŒ No | âŒ No |\n| One-click Services (e.g., Supabase) | `Service` | âœ… Yes | âœ… Yes |\n\n### Expected Behavior\n\nDatabase services in Docker Compose files deployed via GitHub App should be detected and have backup functionality available, similar to Empty Docker Compose deployments.\n\n### Technical Details\n\nThe issue is in `bootstrap/helpers/shared.php` in the `parseDockerComposeFile()` function:\n\n**Service model path (lines 1263-2025):**\n- Calls `isDatabaseImage()` to detect databases\n- Creates `ServiceDatabase` records for detected databases\n- These databases can have scheduled backups\n\n**Application model path (lines 2026-2767):**\n- Does NOT call `isDatabaseImage()`\n- Does NOT create `ServiceDatabase` records\n- All services are treated as application containers\n- No backup support\n\n### Proposed Solution\n\nAdd database detection logic to the Application model parsing path:\n\n1. In `parseDockerComposeFile()` for the Application model (around line 2066), add:\n   ```php\n   $isDatabase = isDatabaseImage($image, $service);\n   data_set($service, 'is_database', $isDatabase);\n   ```\n\n2. Create `ServiceDatabase` records for detected database services, similar to how it's done in the Service model path.\n\n3. Alternatively, consider refactoring to share the database detection logic between both paths.\n\n### Use Case\n\nUsers deploying full-stack applications via GitHub (e.g., Next.js app + PostgreSQL + pgbouncer in a single compose file) expect database backups to work the same way as standalone database deployments or one-click services.\n\n### Related Code\n\n- `bootstrap/helpers/shared.php` - `parseDockerComposeFile()` function\n- `bootstrap/helpers/docker.php` - `isDatabaseImage()` function\n- `app/Models/ServiceDatabase.php` - Database model with backup support\n- `app/Models/ScheduledDatabaseBackup.php` - Backup scheduling\n\n### Environment\n\n- Coolify version: latest\n- Deployment method: GitHub App with dockercompose buildpack\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7528"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7528",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nWhen deploying a Docker Compose file via GitHub App (using the `dockercompose` buildpack), database services are not detected and `ServiceDatabase` records are not created. This means automated backups are not available for databases in these deployments.\n\nHowever, when using \"Empty Docker Compose\" or one-click services (like Supabase), database detection works correctly and backups are available.\n\n### Current Behavior\n\n| Deployment Method | Model | Creates ServiceDatabase | Backups Available |\n|---|---|---|---|\n| Empty Docker Compose | `Service` | âœ… Yes | âœ… Yes |\n| GitHub App (dockercompose buildpack) | `Application` | âŒ No | âŒ No |\n| One-click Services (e.g., Supabase) | `Service` | âœ… Yes | âœ… Yes |\n\n### Expected Behavior\n\nDatabase services in Docker Compose files deployed via GitHub App should be detected and have backup functionality available, similar to Empty Docker Compose deployments.\n\n### Technical Details\n\nThe issue is in `bootstrap/helpers/shared.php` in the `parseDockerComposeFile()` function:\n\n**Service model path (lines 1263-2025):**\n- Calls `isDatabaseImage()` to detect databases\n- Creates `ServiceDatabase` records for detected databases\n- These databases can have scheduled backups\n\n**Application model path (lines 2026-2767):**\n- Does NOT call `isDatabaseImage()`\n- Does NOT create `ServiceDatabase` records\n- All services are treated as application containers\n- No backup support\n\n### Proposed Solution\n\nAdd database detection logic to the Application model parsing path:\n\n1. In `parseDockerComposeFile()` for the Application model (around line 2066), add:\n   ```php\n   $isDatabase = isDatabaseImage($image, $service);\n   data_set($service, 'is_database', $isDatabase);\n   ```\n\n2. Create `ServiceDatabase` records for detected database services, similar to how it's done in the Service model path.\n\n3. Alternatively, consider refactoring to share the database detection logic between both paths.\n\n### Use Case\n\nUsers deploying full-stack applications via GitHub (e.g., Next.js app + PostgreSQL + pgbouncer in a single compose file) expect database backups to work the same way as standalone database deployments or one-click services.\n\n### Related Code\n\n- `bootstrap/helpers/shared.php` - `parseDockerComposeFile()` function\n- `bootstrap/helpers/docker.php` - `isDatabaseImage()` function\n- `app/Models/ServiceDatabase.php` - Database model with backup support\n- `app/Models/ScheduledDatabaseBackup.php` - Backup scheduling\n\n### Environment\n\n- Coolify version: latest\n- Deployment method: GitHub App with dockercompose buildpack\n",
              "url": "https://github.com/coollabsio/coolify/issues/7528",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7473",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-18T17:51:36.665Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:36.665Z",
            "created_at": "2026-01-18T17:51:36.665Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7473",
              "status": "open",
              "type": "issue",
              "number": 7473,
              "title": "[Bug]: Database Backups won't use the custom timeout in ssh command (regression)",
              "source": {
                "data": {
                  "id": "source-coollabsio#7473",
                  "user": {
                    "login": "isokosan",
                    "id": 1430946,
                    "node_id": "MDQ6VXNlcjE0MzA5NDY=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1430946?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/isokosan",
                    "html_url": "https://github.com/isokosan",
                    "followers_url": "https://api.github.com/users/isokosan/followers",
                    "following_url": "https://api.github.com/users/isokosan/following{/other_user}",
                    "gists_url": "https://api.github.com/users/isokosan/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/isokosan/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/isokosan/subscriptions",
                    "organizations_url": "https://api.github.com/users/isokosan/orgs",
                    "repos_url": "https://api.github.com/users/isokosan/repos",
                    "events_url": "https://api.github.com/users/isokosan/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/isokosan/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Database Backups won't use the custom timeout in ssh command (regression)",
                  "body": "### Error Message and Logs\n\nWe had [this issue](https://github.com/coollabsio/coolify/issues/3325) with backups exceeding timeouts and we made a new feature where we can customize the timeout settings in the backups.\n\nThis was working but seems to have regressed as the timeout setting is not being passed to the backup ssh command, instead the default 3600 is being used I'm afraid:\n\nThe process \"timeout 3600 ssh -i /var/www/html/storage/app/ssh/keys/ssh_key@jgcwgggco80sc0occ88skg0s -o StrictHos... truncated ...FoM2ROejJRRmtjT1M0NXNt\" exceeded the timeout of 3600 seconds.\n\n@Cinzya commented that this is about the SSH command now and not the backup itself:\n> I believe this is actually the SSH process timing out and not the backup itself.\n> The SSH process has a hard timeout of 3600. The backup timeout is not really passed to the SSH process to increase that timeout as well. \n> This is either an oversight or there is a specific reason why a SSH process shouldn't linger more then 3600 seconds. \n> But yes, feel free to open a new issue about it. \n\n\n### Steps to Reproduce\n\n1. Configure a database and then backups.\n2. Use the Timeout option in the dashboard to set a custom timeout, eg 10800 (default 3600 seconds)\n3. Click on Backup Now\n4. Check the command that is run by coolify to see the timeout not being passed to the SSH command\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7473"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7473",
              "body": "### Error Message and Logs\n\nWe had [this issue](https://github.com/coollabsio/coolify/issues/3325) with backups exceeding timeouts and we made a new feature where we can customize the timeout settings in the backups.\n\nThis was working but seems to have regressed as the timeout setting is not being passed to the backup ssh command, instead the default 3600 is being used I'm afraid:\n\nThe process \"timeout 3600 ssh -i /var/www/html/storage/app/ssh/keys/ssh_key@jgcwgggco80sc0occ88skg0s -o StrictHos... truncated ...FoM2ROejJRRmtjT1M0NXNt\" exceeded the timeout of 3600 seconds.\n\n@Cinzya commented that this is about the SSH command now and not the backup itself:\n> I believe this is actually the SSH process timing out and not the backup itself.\n> The SSH process has a hard timeout of 3600. The backup timeout is not really passed to the SSH process to increase that timeout as well. \n> This is either an oversight or there is a specific reason why a SSH process shouldn't linger more then 3600 seconds. \n> But yes, feel free to open a new issue about it. \n\n\n### Steps to Reproduce\n\n1. Configure a database and then backups.\n2. Use the Timeout option in the dashboard to set a custom timeout, eg 10800 (default 3600 seconds)\n3. Click on Backup Now\n4. Check the command that is run by coolify to see the timeout not being passed to the SSH command\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/7473",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7458",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-18T17:51:38.386Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:38.386Z",
            "created_at": "2026-01-18T17:51:38.386Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7458",
              "status": "open",
              "type": "issue",
              "number": 7458,
              "title": "[Bug + Multiple Bounties]: Official Selfhosted Supabase MCP Setup hindered by Coolify AND Bounty List",
              "source": {
                "data": {
                  "id": "source-coollabsio#7458",
                  "user": {
                    "login": "rootacc3ss",
                    "id": 192549131,
                    "node_id": "U_kgDOC3oRCw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/192549131?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/rootacc3ss",
                    "html_url": "https://github.com/rootacc3ss",
                    "followers_url": "https://api.github.com/users/rootacc3ss/followers",
                    "following_url": "https://api.github.com/users/rootacc3ss/following{/other_user}",
                    "gists_url": "https://api.github.com/users/rootacc3ss/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/rootacc3ss/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/rootacc3ss/subscriptions",
                    "organizations_url": "https://api.github.com/users/rootacc3ss/orgs",
                    "repos_url": "https://api.github.com/users/rootacc3ss/repos",
                    "events_url": "https://api.github.com/users/rootacc3ss/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/rootacc3ss/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug + Multiple Bounties]: Official Selfhosted Supabase MCP Setup hindered by Coolify AND Bounty List",
                  "body": "### Error Message and Logs\n\n**Bounty! $15.00 on Algora.io; will add ASAP, need to figure out how to use it.**\n\nWhen following these documents from Supabase pertaining to the latest selfhosted Supabase docker setup:\nhttps://supabase.com/docs/guides/self-hosting/enable-mcp\n_you will notice the following..._\n\n1. There is no configuration to turn this on or off with ease, or even commented out docker-compose, nor any notes.\n2. With how we expose Kong via URL by default, the approach in the document could be messy or unsafe\n3. It looks like additional configuration may be required if there are multiple Supabase instances on the same server with individual /mcp exposures as Traefik is handling the routing and everything is using the same ports, etc...\n\n**I am looking for a \"work around\" as the resolution for this bounty.** That is acceptable, but I will require **at minimum a tutorial below** that figures out how to get around this bug/issue and properly documents the following:\n\n- How to configure the MCP and use it on local network\n- How to setup Wireguard to properly allow for usage of this MCP\n- How to configure Cursor/Claude Code/Windsurf to use this MCP\n- **MOST IMPORTANTLY, HOW TO CONNECT TO DIFFERENT SUPABASE INSTANCES ON THE SAME COOLIFY INSTANCE (assuming all of them are running the default Service template)**\n\nCreating a fix within the system we have to spin up and manage a Supabase instance may be difficult due to the template system's restraints, but if you want to work on that complaint of mine and **earn much more than $15**, you can see the bottom of this post. I list off the other bounties I will be offering and putting up cash for upon clearing some wires and hopefully seeing someone (or a few people) dedicate time to it.\n\n### Steps to Reproduce\n\n1. Follow docs linked above\n2. Attempt to edit the docker and piece it all together as tutorial says\n3. ???\n\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nUbuntu 24.04.03\n\n### Additional Information\n\nI am starting this bounty small as I have no clue how this system works and if I will be able to add crypto or not. I want to list these other bounties here firstly to see if there is any immediate response for \n\n**If you claim the small bounty for this, I have a few more I am willing to put in to place -- just let me know if you're interested and make sure to clear whichever one you wish to do with me to I can post the bounty for it:**\n\n- **[$35]** Better Cloudflared/Cloudflare management tools (easy exclusions and inclusions by project, IP, etc... manage domains and subdomains via Cloudflare Zero Trust or DNS settings automatically -- or at least though a portal of some sort)\n- **[$15]** Improved Supabase template (easily configure MCP properly using some sort of fix from this thread, configure mail server for automated mail and OTP with ease, set up external S3 with ease, etc -- I can contribute what I have learned from messing with the template)\n- **[$25]** Working MailCow OR Stalwart+Roundcube \"Service\" template... It's time...\n- **[$XXX]** CoolifyAI -- add API key, get AI assistant w/ knowledge-base similar to the Supabase assistant, ideally with GitHub issue lookup and basic research capability  \n- **[$XXX - $X,XXX]** More proper, fleshed out \"Services\" template system WITH ability to add remote repositories outside of the official Coolify templates; setup scripting w/ select-able options, easily modify docker template or automations/commands with checkboxes, dropdowns and input fields and the works. Ideally, a system in which \"addons\" in these same repositories as the whole \"Services\" themselves can be added on to each individual service; I.e. for Cloudflared, my request above. Or for Supabase, an easy tool to help you visualize the parts missing from Selfhosted that are in Supabase SaaS/Cloud and perhaps an API to interface with it. **This would make Coolify the single self-hosted PaaS with scripting for templates, but also an extension system allowing new functionality.**\n\nIf you are interested in discussing, claiming or collaborating on one of these bounties, see the little repo I made to track this here:\nhttps://github.com/rootacc3ss/coolify-bounties/tree/main",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7458"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7458",
              "body": "### Error Message and Logs\n\n**Bounty! $15.00 on Algora.io; will add ASAP, need to figure out how to use it.**\n\nWhen following these documents from Supabase pertaining to the latest selfhosted Supabase docker setup:\nhttps://supabase.com/docs/guides/self-hosting/enable-mcp\n_you will notice the following..._\n\n1. There is no configuration to turn this on or off with ease, or even commented out docker-compose, nor any notes.\n2. With how we expose Kong via URL by default, the approach in the document could be messy or unsafe\n3. It looks like additional configuration may be required if there are multiple Supabase instances on the same server with individual /mcp exposures as Traefik is handling the routing and everything is using the same ports, etc...\n\n**I am looking for a \"work around\" as the resolution for this bounty.** That is acceptable, but I will require **at minimum a tutorial below** that figures out how to get around this bug/issue and properly documents the following:\n\n- How to configure the MCP and use it on local network\n- How to setup Wireguard to properly allow for usage of this MCP\n- How to configure Cursor/Claude Code/Windsurf to use this MCP\n- **MOST IMPORTANTLY, HOW TO CONNECT TO DIFFERENT SUPABASE INSTANCES ON THE SAME COOLIFY INSTANCE (assuming all of them are running the default Service template)**\n\nCreating a fix within the system we have to spin up and manage a Supabase instance may be difficult due to the template system's restraints, but if you want to work on that complaint of mine and **earn much more than $15**, you can see the bottom of this post. I list off the other bounties I will be offering and putting up cash for upon clearing some wires and hopefully seeing someone (or a few people) dedicate time to it.\n\n### Steps to Reproduce\n\n1. Follow docs linked above\n2. Attempt to edit the docker and piece it all together as tutorial says\n3. ???\n\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nUbuntu 24.04.03\n\n### Additional Information\n\nI am starting this bounty small as I have no clue how this system works and if I will be able to add crypto or not. I want to list these other bounties here firstly to see if there is any immediate response for \n\n**If you claim the small bounty for this, I have a few more I am willing to put in to place -- just let me know if you're interested and make sure to clear whichever one you wish to do with me to I can post the bounty for it:**\n\n- **[$35]** Better Cloudflared/Cloudflare management tools (easy exclusions and inclusions by project, IP, etc... manage domains and subdomains via Cloudflare Zero Trust or DNS settings automatically -- or at least though a portal of some sort)\n- **[$15]** Improved Supabase template (easily configure MCP properly using some sort of fix from this thread, configure mail server for automated mail and OTP with ease, set up external S3 with ease, etc -- I can contribute what I have learned from messing with the template)\n- **[$25]** Working MailCow OR Stalwart+Roundcube \"Service\" template... It's time...\n- **[$XXX]** CoolifyAI -- add API key, get AI assistant w/ knowledge-base similar to the Supabase assistant, ideally with GitHub issue lookup and basic research capability  \n- **[$XXX - $X,XXX]** More proper, fleshed out \"Services\" template system WITH ability to add remote repositories outside of the official Coolify templates; setup scripting w/ select-able options, easily modify docker template or automations/commands with checkboxes, dropdowns and input fields and the works. Ideally, a system in which \"addons\" in these same repositories as the whole \"Services\" themselves can be added on to each individual service; I.e. for Cloudflared, my request above. Or for Supabase, an easy tool to help you visualize the parts missing from Selfhosted that are in Supabase SaaS/Cloud and perhaps an API to interface with it. **This would make Coolify the single self-hosted PaaS with scripting for templates, but also an extension system allowing new functionality.**\n\nIf you are interested in discussing, claiming or collaborating on one of these bounties, see the little repo I made to track this here:\nhttps://github.com/rootacc3ss/coolify-bounties/tree/main",
              "url": "https://github.com/coollabsio/coolify/issues/7458",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#3531",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2026-01-18T17:51:37.881Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:37.882Z",
            "created_at": "2026-01-18T17:51:37.882Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3531",
              "status": "open",
              "type": "issue",
              "number": 3531,
              "title": "Better error response for wrong datetime format in REST filter",
              "source": {
                "data": {
                  "id": "source-qdrant#3531",
                  "user": {
                    "login": "timvisee",
                    "id": 856222,
                    "node_id": "MDQ6VXNlcjg1NjIyMg==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/856222?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/timvisee",
                    "html_url": "https://github.com/timvisee",
                    "followers_url": "https://api.github.com/users/timvisee/followers",
                    "following_url": "https://api.github.com/users/timvisee/following{/other_user}",
                    "gists_url": "https://api.github.com/users/timvisee/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/timvisee/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/timvisee/subscriptions",
                    "organizations_url": "https://api.github.com/users/timvisee/orgs",
                    "repos_url": "https://api.github.com/users/timvisee/repos",
                    "events_url": "https://api.github.com/users/timvisee/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/timvisee/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Better error response for wrong datetime format in REST filter",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\nWe recently merged <https://github.com/qdrant/qdrant/pull/3395> which adds a datetime payload index.\r\n\r\nCurrently, the datetime parser is very strict, only allowing [RFC 3339](https://www.rfc-editor.org/rfc/rfc3339) formats in our REST API. A common format such as `YYYY-MM-DD HH:MM:SS` is currently not accepted.\r\n\r\nIf you'd send the following request:\r\n\r\n```json\r\nPOST collections/test_collection/points/scroll\r\n{\r\n  \"limit\": 10,\r\n  \"filter\": {\r\n    \"must\": [\r\n      {\r\n        \"key\": \"updated\",\r\n        \"datetime_range\": {\r\n          \"gt\": \"2014-01-01T00:00:00\"\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nYou'd receive the following error:\r\n\r\n```\r\nFormat error in JSON body: data did not match any variant of untagged enum Condition at line 1 column 96\r\n```\r\n\r\nThis error is very confusing.\r\n\r\n**Describe the solution you'd like**\r\nWe'd strongly prefer a more descriptive error message instead.\r\n\r\nSomething like this would be a lot better:\r\n\r\n```\r\nFormat error in JSON body: '2014-01-01T00:00:00' does not match any accepted datetime format\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n_None_\r\n\r\n**Additional context**\r\nRelated issue: <https://github.com/qdrant/qdrant/issues/3529>",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3531"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3531",
              "body": "**Is your feature request related to a problem? Please describe.**\r\nWe recently merged <https://github.com/qdrant/qdrant/pull/3395> which adds a datetime payload index.\r\n\r\nCurrently, the datetime parser is very strict, only allowing [RFC 3339](https://www.rfc-editor.org/rfc/rfc3339) formats in our REST API. A common format such as `YYYY-MM-DD HH:MM:SS` is currently not accepted.\r\n\r\nIf you'd send the following request:\r\n\r\n```json\r\nPOST collections/test_collection/points/scroll\r\n{\r\n  \"limit\": 10,\r\n  \"filter\": {\r\n    \"must\": [\r\n      {\r\n        \"key\": \"updated\",\r\n        \"datetime_range\": {\r\n          \"gt\": \"2014-01-01T00:00:00\"\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nYou'd receive the following error:\r\n\r\n```\r\nFormat error in JSON body: data did not match any variant of untagged enum Condition at line 1 column 96\r\n```\r\n\r\nThis error is very confusing.\r\n\r\n**Describe the solution you'd like**\r\nWe'd strongly prefer a more descriptive error message instead.\r\n\r\nSomething like this would be a lot better:\r\n\r\n```\r\nFormat error in JSON body: '2014-01-01T00:00:00' does not match any accepted datetime format\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n_None_\r\n\r\n**Additional context**\r\nRelated issue: <https://github.com/qdrant/qdrant/issues/3529>",
              "url": "https://github.com/qdrant/qdrant/issues/3531",
              "tech": [],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#3322",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2026-01-18T17:51:38.991Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:38.991Z",
            "created_at": "2026-01-18T17:51:38.991Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3322",
              "status": "open",
              "type": "issue",
              "number": 3322,
              "title": "Per-collection metrics for Prometheus",
              "source": {
                "data": {
                  "id": "source-qdrant#3322",
                  "user": {
                    "login": "generall",
                    "id": 1935623,
                    "node_id": "MDQ6VXNlcjE5MzU2MjM=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1935623?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/generall",
                    "html_url": "https://github.com/generall",
                    "followers_url": "https://api.github.com/users/generall/followers",
                    "following_url": "https://api.github.com/users/generall/following{/other_user}",
                    "gists_url": "https://api.github.com/users/generall/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/generall/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/generall/subscriptions",
                    "organizations_url": "https://api.github.com/users/generall/orgs",
                    "repos_url": "https://api.github.com/users/generall/repos",
                    "events_url": "https://api.github.com/users/generall/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/generall/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Per-collection metrics for Prometheus",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, all metrics in `/metrics` are global, meaning that itâ€™s impossible to see differences per collection.\r\n\r\nIn addition to that, all our metrics should have per-collection granularity to allow better aggregation in Prometheus, including:\r\n\r\n- point/vector counts\r\n- REST/gRPC requests\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample:\r\n```\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\"} 0.000046\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection\"} 0.000049\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection-2\"} 0.000046\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreate dedicated endpoint for each collection `/collections/my-collecton/metrics`\r\nbut feedback from DevOps on this idea was negative.\r\n\r\n**Additional context**\r\n\r\nIt might be beneficial to allow users to disable per-collection output. It is especially relevant if there are a lot of collections and metric response could become huge. But this is a nice-to-have requirement.\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently\r\n\r\n",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3322"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3322",
              "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, all metrics in `/metrics` are global, meaning that itâ€™s impossible to see differences per collection.\r\n\r\nIn addition to that, all our metrics should have per-collection granularity to allow better aggregation in Prometheus, including:\r\n\r\n- point/vector counts\r\n- REST/gRPC requests\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample:\r\n```\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\"} 0.000046\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection\"} 0.000049\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection-2\"} 0.000046\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreate dedicated endpoint for each collection `/collections/my-collecton/metrics`\r\nbut feedback from DevOps on this idea was negative.\r\n\r\n**Additional context**\r\n\r\nIt might be beneficial to allow users to disable per-collection output. It is especially relevant if there are a lot of collections and metric response could become huge. But this is a nice-to-have requirement.\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently\r\n\r\n",
              "url": "https://github.com/qdrant/qdrant/issues/3322",
              "tech": [],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1560",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2026-01-18T17:51:29.154Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:29.154Z",
            "created_at": "2026-01-18T17:51:29.154Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1560",
              "status": "open",
              "type": "issue",
              "number": 1560,
              "title": "[feature]  Implement Session Tracking for Application and Window Usage",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1560",
                  "user": {
                    "login": "rodgomesc",
                    "id": 4893591,
                    "node_id": "MDQ6VXNlcjQ4OTM1OTE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/4893591?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/rodgomesc",
                    "html_url": "https://github.com/rodgomesc",
                    "followers_url": "https://api.github.com/users/rodgomesc/followers",
                    "following_url": "https://api.github.com/users/rodgomesc/following{/other_user}",
                    "gists_url": "https://api.github.com/users/rodgomesc/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/rodgomesc/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/rodgomesc/subscriptions",
                    "organizations_url": "https://api.github.com/users/rodgomesc/orgs",
                    "repos_url": "https://api.github.com/users/rodgomesc/repos",
                    "events_url": "https://api.github.com/users/rodgomesc/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/rodgomesc/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[feature]  Implement Session Tracking for Application and Window Usage",
                  "body": "\n## Challenge\n\nI'm working on an application that requires accurate session tracking to analyze user behavior patterns,  and provide meaningful insights across different applications and windows. \n\nIn the existing Screenpipe architecture, OCR data is stored with only timestamp information, lacking precise session boundaries (start/end times) for application usage tracking. This limitation prevents us from properly segmenting user activity into coherent sessions.\n\n## 1. Current Workaround\ninternally I implementing a suboptimal solution that:\n1. Queries all OCR database entries chronologically\n2. Manually identifies session boundaries by analyzing timestamp sequences for each application\n3. Determines session end when detecting a different application in subsequent timestamps\n4. Assumes a session is ongoing if no clear delimiter exists in future timestamps\n\nWith that said I would love to hear any feedbacks that could help solve this problem with a minimal overhead on code changes, and make sure I'm not overthinking the solution: cc @louis030195 , i'm planning to start playing with some day next week\n\n## 2. Requirements\n\n1.  **Session Definition:** A \"session\" should be defined as a continuous period of user interaction with a specific application and window.  A break in activity (e.g., switching to a different application or window) should end the current session and potentially start a new one.  A configurable inactivity timeout (e.g., 5 minutes) should also end a session.\n\n2.  **Data Storage:** The database schema must be modified to store session start and end times, associated with specific applications and windows.  It must maintain links to the relevant OCR and audio data chunks.\n\n3.  **API Endpoint:**  A new or modified API endpoint (e.g., `/sessions`) is needed to query for session data.  This endpoint should support filtering by:\n    *   Date range (start and end timestamps).\n    *   Application name.\n    *   Window name.\n    *   Minimum and maximum session duration.\n    *   Associated tags.\n    *   Pagination (limit and offset).\n\n4.  **Real-time Capability:** The system should be able to detect session boundaries in near real-time as data is being ingested. This implies integration with the existing data capture and processing pipeline.\n\n5. **Configurability:** The inactivity timeout for ending a session should be configurable.\n\n## 3. Proposed Solution\n\n### 3.1. Database Schema Changes\n\nWe'll introduce a new table `sessions` and modify the existing tables.\n\n**New Table: `sessions`**\n\n| Column Name      | Data Type  | Constraints                                  | Description                                                                  |\n| :--------------- | :--------- | :------------------------------------------- | :--------------------------------------------------------------------------- |\n| `id`             | INTEGER    | PRIMARY KEY AUTOINCREMENT                    | Unique identifier for the session.                                       |\n| `app_name`       | TEXT       | NOT NULL                                     | Name of the application.                                                 |\n| `window_name`    | TEXT       |                                               | Title of the window.                                                     |\n| `start_time`     | DATETIME   | NOT NULL                                     | Timestamp of the session start.                                            |\n| `end_time`       | DATETIME   | NOT NULL                                     | Timestamp of the session end.                                              |\n| `duration_secs`  | REAL       | NOT NULL                                     | Duration of the session in seconds.                                        |\n\n**Modified Tables:**\n\n*   **`ocr_text`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`audio_transcriptions`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`ui_monitoring`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n\n**Indexes:**\n\n*   Create indexes on `sessions` table columns (`app_name`, `window_name`, `start_time`, `end_time`) for efficient querying.\n*   Create indexes on the `session_id` columns in `ocr_text`, `audio_transcriptions`, and `ui_monitoring`.\n\n### 3.2. API Enhancements\n\nWe'll modify the existing `/search` endpoint to also support session queries.\n\n**Request:**\n\n```\nGET /search?content_type=session&app_name=Cursor&start_time=2024-11-27T00:00:00Z&end_time=2024-11-28T00:00:00Z&min_duration=60&limit=10&offset=0\n```\n\n*   `content_type=session`: Indicates a session-based search.\n*   `app_name`, `window_name`: Filter by application and window (optional).\n*   `start_time`, `end_time`: Date range for the session (optional, defaults to last 24 hours).\n*   `min_duration`, `max_duration`: Filter by session duration in seconds (optional).\n*   `limit`, `offset`: Pagination parameters.\n\n\nafter discussing with @louis030195 on discord he proposed something like this as the output\n\n**Response:**\n\n```json\n{\n  \"data\": [\n    {\n      \"app_name\": \"Cursor\",\n      \"total_usage_time\": 3600,\n      \"windows\": [\n        {\n          \"window_name\": \"page.tsx\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T12:00:00Z\",\n              \"end_time\": \"2024-07-16T12:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [123, 124, 125],\n              \"tags\": [\"coding\", \"frontend\"]\n            },\n            {\n              \"start_time\": \"2024-07-16T14:00:00Z\",\n              \"end_time\": \"2024-07-16T14:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [223, 224, 225],\n              \"tags\": [\"coding\", \"frontend\"]\n            }\n          ],\n          \"total_usage_time\": 3600\n        }\n      ]\n    },\n    {\n      \"app_name\": \"Arc\",\n      \"total_usage_time\": 1200,\n      \"windows\": [\n        {\n          \"window_name\": \"x.com\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T10:30:00Z\",\n              \"end_time\": \"2024-07-16T10:50:00Z\",\n              \"duration\": 1200,\n              \"content_ids\": [126, 127, 128],\n              \"tags\": [\"browsing\", \"social-media\"]\n            }\n          ],\n          \"total_usage_time\": 1200\n        }\n      ]\n    }\n  ],\n  \"pagination\": {\n    \"limit\": 50,\n    \"offset\": 0,\n    \"total\": 2\n  }\n}\n```\n\n### 3.3. Session Boundary Detection Logic\n\n1.  **Real-time Monitoring:**  The existing event listeners for OCR, audio, and UI events will be leveraged.\n\n2.  **Session Tracking:**  Maintain a data structure (likely in memory, possibly augmented with periodic database writes for persistence) to track active sessions.  This structure should map:\n    *   `(app_name, window_name)` -> `(session_id, last_activity_timestamp)`\n\n3.  **New Event Handling:**\n    *   When a new event (OCR, audio, UI) arrives:\n        *   Extract `app_name` and `window_name`.\n        *   Check if an active session exists for this (app, window) combination.\n        *   If a session exists:\n            *   Check if `now() - last_activity_timestamp` exceeds the inactivity timeout.\n            *   If timeout exceeded, end the existing session and create a new one.\n            *   If not timed out, update `last_activity_timestamp` to the event's timestamp.\n        *   If no session exists:\n            *   Create a new session with `start_time` and `end_time` set to the event's timestamp.\n            *   Generate a new `session_id`.\n            *   Insert a new row into the `sessions` table.\n        *   Insert the new data (OCR, audio, UI) into the relevant table, linking it to the active `session_id`.\n\n4.  **Inactivity Timeout:** A configurable timeout (e.g., 5 minutes) will be used to determine session end due to inactivity.\n\n5.  **Periodic Flushing:** To avoid excessive in-memory state, periodically flush closed sessions (those that have exceeded the inactivity timeout) to the database.\n\n6. **Data Migration:** A migration script will be needed to analyze existing data and create initial session records based on timestamp proximity and app/window changes.\n\n### 3.4. Implementation Details\n\n*   **Language/Framework:** Continue using Rust for core logic and database interaction.\n*   **Database:** Continue using SQLite.\n*   **Concurrency:** Use asynchronous operations with `tokio` for handling concurrent events and database interactions.  Leverage `Arc` and `Mutex` for shared state, and channels for communication between tasks.\n*   **Configuration:** Add a new setting for the inactivity timeout.\n*   **Error Handling:** Implement robust error handling with `anyhow` and propagate errors appropriately. Log errors using `tracing`.\n* **Testing:** Thoroughly test session boundary detection with various scenarios, including rapid switching, long inactivity periods, and concurrent events.\n\n## 4. Diagrams\n\n### 4.1. Current Data Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Database\n    User->>Screen: Interacts with screen\n    Screen->>Screenpipe: Captures screen content (OCR)\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Database: Stores OCR data with timestamps\n    Screenpipe->>Database: Stores audio transcriptions with timestamps\n    User->>Screenpipe: Requests data\n    Screenpipe->>Database: Queries data by time range\n    Database->>Screenpipe: Returns data\n    Screenpipe->>User: Returns data\n```\n\n### 4.2. Proposed Database Schema Changes\n\n```mermaid\nclassDiagram\n    class frames {\n        +id : INTEGER [PK]\n        +video_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +name : TEXT\n    }\n    class video_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +device_name : TEXT\n    }\n    class ocr_text {\n        +frame_id : INTEGER [FK]\n        +text : TEXT\n        +text_json : TEXT\n        +app_name : TEXT\n        +window_name : TEXT\n        +ocr_engine : TEXT\n        +focused : BOOLEAN\n        +session_id : INTEGER [FK]\n    }\n    class audio_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +timestamp : TIMESTAMP\n    }\n    class audio_transcriptions {\n        +id : INTEGER [PK]\n        +audio_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +transcription : TEXT\n        +device : TEXT\n        +is_input_device : BOOLEAN\n        +speaker_id : INTEGER\n        +transcription_engine : TEXT\n        +start_time : REAL\n        +end_time : REAL\n        +text_length : INTEGER\n        +session_id : INTEGER [FK]\n    }\n    class ui_monitoring {\n      +id : INTEGER [PK]\n      +text_output : TEXT\n      +timestamp : DATETIME\n      +app : TEXT\n      +window : TEXT\n      +initial_traversal_at : DATETIME\n      +session_id : INTEGER [FK]\n    }\n  class sessions {\n    +id : INTEGER [PK]\n    +app_name : TEXT\n    +window_name : TEXT\n    +start_time : DATETIME\n    +end_time : DATETIME\n    +duration_secs : REAL\n  }\n  frames --|> video_chunks : video_chunk_id\n  ocr_text --|> frames : frame_id\n  audio_transcriptions --|> audio_chunks : audio_chunk_id\n  ocr_text --|> sessions : session_id\n  audio_transcriptions --|> sessions : session_id\n  ui_monitoring --|> sessions : session_id\n```\n\n### 4.3. Modified Data Flow with Session Tracking\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Session Manager\n    participant Database\n\n    User->>Screen: Interacts with App A, Window 1\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to session_id\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: Active session found (session_id)\n    Screenpipe->>Database: Store audio data, link to session_id\n\n    Note over User,Screenpipe: User switches to App B, Window 2\n    User->>Screen: Interacts with App B, Window 2\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App B, Window 2)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: End previous session (App A, Window 1)\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to new session_id\n\n    Note over User,Screenpipe: Inactivity Timeout\n    Screenpipe->>Session Manager: Check for activity\n    Session Manager->>Database: End current session (App B, Window 2)\n```\n\n### 4.4. New API Endpoint (Modified /search)\n\nThe existing `/search` endpoint will be extended to support session-based queries.  No new endpoint is needed.\n\n## 5. Performance Implications\n\n*   **Database:**  The addition of the `sessions` table and foreign keys will add some overhead to write operations.  Proper indexing is crucial to mitigate this.  Read performance for session-based queries should be good with appropriate indexes.\n*   **Memory:**  The in-memory session tracking will require additional memory.  The size of this will depend on the number of concurrent users and the configured timeout.  This should be monitored and potentially optimized (e.g., using a more efficient data structure than a simple `HashMap`).\n*   **CPU:**  The session boundary detection logic will add some CPU overhead.  This should be minimized by efficient checks and the use of asynchronous operations.\n\n## 6. Migration Path\n\n1.  **Add new `sessions` table.**\n2.  **Add `session_id` columns** to `ocr_text`, `audio_transcriptions`, and `ui_monitoring` tables.\n3.  **Backfill `session_id`:**  A migration script will be needed to analyze existing data and create initial session records.  This script will need to:\n    *   Iterate through existing OCR, audio, and UI data in chronological order.\n    *   Apply the session boundary detection logic (described above) to group data into sessions.\n    *   Insert corresponding rows into the `sessions` table.\n    *   Update the `session_id` foreign key in the existing tables.\n\n\n## 7. Alternative Approaches\n\n1.  **Session Table per Content Type:** Instead of a single `sessions` table, we could have separate session tables for each content type (e.g., `ocr_sessions`, `audio_sessions`, `ui_sessions`).  This might simplify queries for a specific content type but could make cross-content type analysis more complex.\n2.  **No Session Table (Denormalized):** We could add `start_time` and `end_time` directly to the existing tables (`ocr_text`, `audio_transcriptions`, `ui_monitoring`). This would avoid the need for joins when querying for sessions, but could lead to data redundancy and potential inconsistencies.\n3.  any other suggestions ????\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1560"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1560",
              "body": "\n## Challenge\n\nI'm working on an application that requires accurate session tracking to analyze user behavior patterns,  and provide meaningful insights across different applications and windows. \n\nIn the existing Screenpipe architecture, OCR data is stored with only timestamp information, lacking precise session boundaries (start/end times) for application usage tracking. This limitation prevents us from properly segmenting user activity into coherent sessions.\n\n## 1. Current Workaround\ninternally I implementing a suboptimal solution that:\n1. Queries all OCR database entries chronologically\n2. Manually identifies session boundaries by analyzing timestamp sequences for each application\n3. Determines session end when detecting a different application in subsequent timestamps\n4. Assumes a session is ongoing if no clear delimiter exists in future timestamps\n\nWith that said I would love to hear any feedbacks that could help solve this problem with a minimal overhead on code changes, and make sure I'm not overthinking the solution: cc @louis030195 , i'm planning to start playing with some day next week\n\n## 2. Requirements\n\n1.  **Session Definition:** A \"session\" should be defined as a continuous period of user interaction with a specific application and window.  A break in activity (e.g., switching to a different application or window) should end the current session and potentially start a new one.  A configurable inactivity timeout (e.g., 5 minutes) should also end a session.\n\n2.  **Data Storage:** The database schema must be modified to store session start and end times, associated with specific applications and windows.  It must maintain links to the relevant OCR and audio data chunks.\n\n3.  **API Endpoint:**  A new or modified API endpoint (e.g., `/sessions`) is needed to query for session data.  This endpoint should support filtering by:\n    *   Date range (start and end timestamps).\n    *   Application name.\n    *   Window name.\n    *   Minimum and maximum session duration.\n    *   Associated tags.\n    *   Pagination (limit and offset).\n\n4.  **Real-time Capability:** The system should be able to detect session boundaries in near real-time as data is being ingested. This implies integration with the existing data capture and processing pipeline.\n\n5. **Configurability:** The inactivity timeout for ending a session should be configurable.\n\n## 3. Proposed Solution\n\n### 3.1. Database Schema Changes\n\nWe'll introduce a new table `sessions` and modify the existing tables.\n\n**New Table: `sessions`**\n\n| Column Name      | Data Type  | Constraints                                  | Description                                                                  |\n| :--------------- | :--------- | :------------------------------------------- | :--------------------------------------------------------------------------- |\n| `id`             | INTEGER    | PRIMARY KEY AUTOINCREMENT                    | Unique identifier for the session.                                       |\n| `app_name`       | TEXT       | NOT NULL                                     | Name of the application.                                                 |\n| `window_name`    | TEXT       |                                               | Title of the window.                                                     |\n| `start_time`     | DATETIME   | NOT NULL                                     | Timestamp of the session start.                                            |\n| `end_time`       | DATETIME   | NOT NULL                                     | Timestamp of the session end.                                              |\n| `duration_secs`  | REAL       | NOT NULL                                     | Duration of the session in seconds.                                        |\n\n**Modified Tables:**\n\n*   **`ocr_text`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`audio_transcriptions`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`ui_monitoring`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n\n**Indexes:**\n\n*   Create indexes on `sessions` table columns (`app_name`, `window_name`, `start_time`, `end_time`) for efficient querying.\n*   Create indexes on the `session_id` columns in `ocr_text`, `audio_transcriptions`, and `ui_monitoring`.\n\n### 3.2. API Enhancements\n\nWe'll modify the existing `/search` endpoint to also support session queries.\n\n**Request:**\n\n```\nGET /search?content_type=session&app_name=Cursor&start_time=2024-11-27T00:00:00Z&end_time=2024-11-28T00:00:00Z&min_duration=60&limit=10&offset=0\n```\n\n*   `content_type=session`: Indicates a session-based search.\n*   `app_name`, `window_name`: Filter by application and window (optional).\n*   `start_time`, `end_time`: Date range for the session (optional, defaults to last 24 hours).\n*   `min_duration`, `max_duration`: Filter by session duration in seconds (optional).\n*   `limit`, `offset`: Pagination parameters.\n\n\nafter discussing with @louis030195 on discord he proposed something like this as the output\n\n**Response:**\n\n```json\n{\n  \"data\": [\n    {\n      \"app_name\": \"Cursor\",\n      \"total_usage_time\": 3600,\n      \"windows\": [\n        {\n          \"window_name\": \"page.tsx\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T12:00:00Z\",\n              \"end_time\": \"2024-07-16T12:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [123, 124, 125],\n              \"tags\": [\"coding\", \"frontend\"]\n            },\n            {\n              \"start_time\": \"2024-07-16T14:00:00Z\",\n              \"end_time\": \"2024-07-16T14:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [223, 224, 225],\n              \"tags\": [\"coding\", \"frontend\"]\n            }\n          ],\n          \"total_usage_time\": 3600\n        }\n      ]\n    },\n    {\n      \"app_name\": \"Arc\",\n      \"total_usage_time\": 1200,\n      \"windows\": [\n        {\n          \"window_name\": \"x.com\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T10:30:00Z\",\n              \"end_time\": \"2024-07-16T10:50:00Z\",\n              \"duration\": 1200,\n              \"content_ids\": [126, 127, 128],\n              \"tags\": [\"browsing\", \"social-media\"]\n            }\n          ],\n          \"total_usage_time\": 1200\n        }\n      ]\n    }\n  ],\n  \"pagination\": {\n    \"limit\": 50,\n    \"offset\": 0,\n    \"total\": 2\n  }\n}\n```\n\n### 3.3. Session Boundary Detection Logic\n\n1.  **Real-time Monitoring:**  The existing event listeners for OCR, audio, and UI events will be leveraged.\n\n2.  **Session Tracking:**  Maintain a data structure (likely in memory, possibly augmented with periodic database writes for persistence) to track active sessions.  This structure should map:\n    *   `(app_name, window_name)` -> `(session_id, last_activity_timestamp)`\n\n3.  **New Event Handling:**\n    *   When a new event (OCR, audio, UI) arrives:\n        *   Extract `app_name` and `window_name`.\n        *   Check if an active session exists for this (app, window) combination.\n        *   If a session exists:\n            *   Check if `now() - last_activity_timestamp` exceeds the inactivity timeout.\n            *   If timeout exceeded, end the existing session and create a new one.\n            *   If not timed out, update `last_activity_timestamp` to the event's timestamp.\n        *   If no session exists:\n            *   Create a new session with `start_time` and `end_time` set to the event's timestamp.\n            *   Generate a new `session_id`.\n            *   Insert a new row into the `sessions` table.\n        *   Insert the new data (OCR, audio, UI) into the relevant table, linking it to the active `session_id`.\n\n4.  **Inactivity Timeout:** A configurable timeout (e.g., 5 minutes) will be used to determine session end due to inactivity.\n\n5.  **Periodic Flushing:** To avoid excessive in-memory state, periodically flush closed sessions (those that have exceeded the inactivity timeout) to the database.\n\n6. **Data Migration:** A migration script will be needed to analyze existing data and create initial session records based on timestamp proximity and app/window changes.\n\n### 3.4. Implementation Details\n\n*   **Language/Framework:** Continue using Rust for core logic and database interaction.\n*   **Database:** Continue using SQLite.\n*   **Concurrency:** Use asynchronous operations with `tokio` for handling concurrent events and database interactions.  Leverage `Arc` and `Mutex` for shared state, and channels for communication between tasks.\n*   **Configuration:** Add a new setting for the inactivity timeout.\n*   **Error Handling:** Implement robust error handling with `anyhow` and propagate errors appropriately. Log errors using `tracing`.\n* **Testing:** Thoroughly test session boundary detection with various scenarios, including rapid switching, long inactivity periods, and concurrent events.\n\n## 4. Diagrams\n\n### 4.1. Current Data Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Database\n    User->>Screen: Interacts with screen\n    Screen->>Screenpipe: Captures screen content (OCR)\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Database: Stores OCR data with timestamps\n    Screenpipe->>Database: Stores audio transcriptions with timestamps\n    User->>Screenpipe: Requests data\n    Screenpipe->>Database: Queries data by time range\n    Database->>Screenpipe: Returns data\n    Screenpipe->>User: Returns data\n```\n\n### 4.2. Proposed Database Schema Changes\n\n```mermaid\nclassDiagram\n    class frames {\n        +id : INTEGER [PK]\n        +video_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +name : TEXT\n    }\n    class video_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +device_name : TEXT\n    }\n    class ocr_text {\n        +frame_id : INTEGER [FK]\n        +text : TEXT\n        +text_json : TEXT\n        +app_name : TEXT\n        +window_name : TEXT\n        +ocr_engine : TEXT\n        +focused : BOOLEAN\n        +session_id : INTEGER [FK]\n    }\n    class audio_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +timestamp : TIMESTAMP\n    }\n    class audio_transcriptions {\n        +id : INTEGER [PK]\n        +audio_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +transcription : TEXT\n        +device : TEXT\n        +is_input_device : BOOLEAN\n        +speaker_id : INTEGER\n        +transcription_engine : TEXT\n        +start_time : REAL\n        +end_time : REAL\n        +text_length : INTEGER\n        +session_id : INTEGER [FK]\n    }\n    class ui_monitoring {\n      +id : INTEGER [PK]\n      +text_output : TEXT\n      +timestamp : DATETIME\n      +app : TEXT\n      +window : TEXT\n      +initial_traversal_at : DATETIME\n      +session_id : INTEGER [FK]\n    }\n  class sessions {\n    +id : INTEGER [PK]\n    +app_name : TEXT\n    +window_name : TEXT\n    +start_time : DATETIME\n    +end_time : DATETIME\n    +duration_secs : REAL\n  }\n  frames --|> video_chunks : video_chunk_id\n  ocr_text --|> frames : frame_id\n  audio_transcriptions --|> audio_chunks : audio_chunk_id\n  ocr_text --|> sessions : session_id\n  audio_transcriptions --|> sessions : session_id\n  ui_monitoring --|> sessions : session_id\n```\n\n### 4.3. Modified Data Flow with Session Tracking\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Session Manager\n    participant Database\n\n    User->>Screen: Interacts with App A, Window 1\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to session_id\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: Active session found (session_id)\n    Screenpipe->>Database: Store audio data, link to session_id\n\n    Note over User,Screenpipe: User switches to App B, Window 2\n    User->>Screen: Interacts with App B, Window 2\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App B, Window 2)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: End previous session (App A, Window 1)\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to new session_id\n\n    Note over User,Screenpipe: Inactivity Timeout\n    Screenpipe->>Session Manager: Check for activity\n    Session Manager->>Database: End current session (App B, Window 2)\n```\n\n### 4.4. New API Endpoint (Modified /search)\n\nThe existing `/search` endpoint will be extended to support session-based queries.  No new endpoint is needed.\n\n## 5. Performance Implications\n\n*   **Database:**  The addition of the `sessions` table and foreign keys will add some overhead to write operations.  Proper indexing is crucial to mitigate this.  Read performance for session-based queries should be good with appropriate indexes.\n*   **Memory:**  The in-memory session tracking will require additional memory.  The size of this will depend on the number of concurrent users and the configured timeout.  This should be monitored and potentially optimized (e.g., using a more efficient data structure than a simple `HashMap`).\n*   **CPU:**  The session boundary detection logic will add some CPU overhead.  This should be minimized by efficient checks and the use of asynchronous operations.\n\n## 6. Migration Path\n\n1.  **Add new `sessions` table.**\n2.  **Add `session_id` columns** to `ocr_text`, `audio_transcriptions`, and `ui_monitoring` tables.\n3.  **Backfill `session_id`:**  A migration script will be needed to analyze existing data and create initial session records.  This script will need to:\n    *   Iterate through existing OCR, audio, and UI data in chronological order.\n    *   Apply the session boundary detection logic (described above) to group data into sessions.\n    *   Insert corresponding rows into the `sessions` table.\n    *   Update the `session_id` foreign key in the existing tables.\n\n\n## 7. Alternative Approaches\n\n1.  **Session Table per Content Type:** Instead of a single `sessions` table, we could have separate session tables for each content type (e.g., `ocr_sessions`, `audio_sessions`, `ui_sessions`).  This might simplify queries for a specific content type but could make cross-content type analysis more complex.\n2.  **No Session Table (Denormalized):** We could add `start_time` and `end_time` directly to the existing tables (`ocr_text`, `audio_transcriptions`, `ui_monitoring`). This would avoid the need for joins when querying for sessions, but could lead to data redundancy and potential inconsistencies.\n3.  any other suggestions ????\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1560",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1626",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2026-01-18T17:51:29.317Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:29.317Z",
            "created_at": "2026-01-18T17:51:29.317Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1626",
              "status": "open",
              "type": "issue",
              "number": 1626,
              "title": "[bounty] $400 fix audio device randomly stopping sometimes",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1626",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] $400 fix audio device randomly stopping sometimes",
                  "body": "\ndisplay audio / microphone randomly stops on mac sometimes \n\nhad it running for 48h now and display audio somehow stopped a bit later after 50h\n\n/bounty 400 \n\n@EzraEllette any idea?\n\n\ni suggest finding way to reproduce and then some automated test and a fix ",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1626"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1626",
              "body": "\ndisplay audio / microphone randomly stops on mac sometimes \n\nhad it running for 48h now and display audio somehow stopped a bit later after 50h\n\n/bounty 400 \n\n@EzraEllette any idea?\n\n\ni suggest finding way to reproduce and then some automated test and a fix ",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1626",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1560",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2026-01-18T17:51:29.488Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:29.488Z",
            "created_at": "2026-01-18T17:51:29.488Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1560",
              "status": "open",
              "type": "issue",
              "number": 1560,
              "title": "[feature]  Implement Session Tracking for Application and Window Usage",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1560",
                  "user": {
                    "login": "rodgomesc",
                    "id": 4893591,
                    "node_id": "MDQ6VXNlcjQ4OTM1OTE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/4893591?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/rodgomesc",
                    "html_url": "https://github.com/rodgomesc",
                    "followers_url": "https://api.github.com/users/rodgomesc/followers",
                    "following_url": "https://api.github.com/users/rodgomesc/following{/other_user}",
                    "gists_url": "https://api.github.com/users/rodgomesc/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/rodgomesc/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/rodgomesc/subscriptions",
                    "organizations_url": "https://api.github.com/users/rodgomesc/orgs",
                    "repos_url": "https://api.github.com/users/rodgomesc/repos",
                    "events_url": "https://api.github.com/users/rodgomesc/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/rodgomesc/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[feature]  Implement Session Tracking for Application and Window Usage",
                  "body": "\n## Challenge\n\nI'm working on an application that requires accurate session tracking to analyze user behavior patterns,  and provide meaningful insights across different applications and windows. \n\nIn the existing Screenpipe architecture, OCR data is stored with only timestamp information, lacking precise session boundaries (start/end times) for application usage tracking. This limitation prevents us from properly segmenting user activity into coherent sessions.\n\n## 1. Current Workaround\ninternally I implementing a suboptimal solution that:\n1. Queries all OCR database entries chronologically\n2. Manually identifies session boundaries by analyzing timestamp sequences for each application\n3. Determines session end when detecting a different application in subsequent timestamps\n4. Assumes a session is ongoing if no clear delimiter exists in future timestamps\n\nWith that said I would love to hear any feedbacks that could help solve this problem with a minimal overhead on code changes, and make sure I'm not overthinking the solution: cc @louis030195 , i'm planning to start playing with some day next week\n\n## 2. Requirements\n\n1.  **Session Definition:** A \"session\" should be defined as a continuous period of user interaction with a specific application and window.  A break in activity (e.g., switching to a different application or window) should end the current session and potentially start a new one.  A configurable inactivity timeout (e.g., 5 minutes) should also end a session.\n\n2.  **Data Storage:** The database schema must be modified to store session start and end times, associated with specific applications and windows.  It must maintain links to the relevant OCR and audio data chunks.\n\n3.  **API Endpoint:**  A new or modified API endpoint (e.g., `/sessions`) is needed to query for session data.  This endpoint should support filtering by:\n    *   Date range (start and end timestamps).\n    *   Application name.\n    *   Window name.\n    *   Minimum and maximum session duration.\n    *   Associated tags.\n    *   Pagination (limit and offset).\n\n4.  **Real-time Capability:** The system should be able to detect session boundaries in near real-time as data is being ingested. This implies integration with the existing data capture and processing pipeline.\n\n5. **Configurability:** The inactivity timeout for ending a session should be configurable.\n\n## 3. Proposed Solution\n\n### 3.1. Database Schema Changes\n\nWe'll introduce a new table `sessions` and modify the existing tables.\n\n**New Table: `sessions`**\n\n| Column Name      | Data Type  | Constraints                                  | Description                                                                  |\n| :--------------- | :--------- | :------------------------------------------- | :--------------------------------------------------------------------------- |\n| `id`             | INTEGER    | PRIMARY KEY AUTOINCREMENT                    | Unique identifier for the session.                                       |\n| `app_name`       | TEXT       | NOT NULL                                     | Name of the application.                                                 |\n| `window_name`    | TEXT       |                                               | Title of the window.                                                     |\n| `start_time`     | DATETIME   | NOT NULL                                     | Timestamp of the session start.                                            |\n| `end_time`       | DATETIME   | NOT NULL                                     | Timestamp of the session end.                                              |\n| `duration_secs`  | REAL       | NOT NULL                                     | Duration of the session in seconds.                                        |\n\n**Modified Tables:**\n\n*   **`ocr_text`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`audio_transcriptions`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`ui_monitoring`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n\n**Indexes:**\n\n*   Create indexes on `sessions` table columns (`app_name`, `window_name`, `start_time`, `end_time`) for efficient querying.\n*   Create indexes on the `session_id` columns in `ocr_text`, `audio_transcriptions`, and `ui_monitoring`.\n\n### 3.2. API Enhancements\n\nWe'll modify the existing `/search` endpoint to also support session queries.\n\n**Request:**\n\n```\nGET /search?content_type=session&app_name=Cursor&start_time=2024-11-27T00:00:00Z&end_time=2024-11-28T00:00:00Z&min_duration=60&limit=10&offset=0\n```\n\n*   `content_type=session`: Indicates a session-based search.\n*   `app_name`, `window_name`: Filter by application and window (optional).\n*   `start_time`, `end_time`: Date range for the session (optional, defaults to last 24 hours).\n*   `min_duration`, `max_duration`: Filter by session duration in seconds (optional).\n*   `limit`, `offset`: Pagination parameters.\n\n\nafter discussing with @louis030195 on discord he proposed something like this as the output\n\n**Response:**\n\n```json\n{\n  \"data\": [\n    {\n      \"app_name\": \"Cursor\",\n      \"total_usage_time\": 3600,\n      \"windows\": [\n        {\n          \"window_name\": \"page.tsx\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T12:00:00Z\",\n              \"end_time\": \"2024-07-16T12:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [123, 124, 125],\n              \"tags\": [\"coding\", \"frontend\"]\n            },\n            {\n              \"start_time\": \"2024-07-16T14:00:00Z\",\n              \"end_time\": \"2024-07-16T14:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [223, 224, 225],\n              \"tags\": [\"coding\", \"frontend\"]\n            }\n          ],\n          \"total_usage_time\": 3600\n        }\n      ]\n    },\n    {\n      \"app_name\": \"Arc\",\n      \"total_usage_time\": 1200,\n      \"windows\": [\n        {\n          \"window_name\": \"x.com\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T10:30:00Z\",\n              \"end_time\": \"2024-07-16T10:50:00Z\",\n              \"duration\": 1200,\n              \"content_ids\": [126, 127, 128],\n              \"tags\": [\"browsing\", \"social-media\"]\n            }\n          ],\n          \"total_usage_time\": 1200\n        }\n      ]\n    }\n  ],\n  \"pagination\": {\n    \"limit\": 50,\n    \"offset\": 0,\n    \"total\": 2\n  }\n}\n```\n\n### 3.3. Session Boundary Detection Logic\n\n1.  **Real-time Monitoring:**  The existing event listeners for OCR, audio, and UI events will be leveraged.\n\n2.  **Session Tracking:**  Maintain a data structure (likely in memory, possibly augmented with periodic database writes for persistence) to track active sessions.  This structure should map:\n    *   `(app_name, window_name)` -> `(session_id, last_activity_timestamp)`\n\n3.  **New Event Handling:**\n    *   When a new event (OCR, audio, UI) arrives:\n        *   Extract `app_name` and `window_name`.\n        *   Check if an active session exists for this (app, window) combination.\n        *   If a session exists:\n            *   Check if `now() - last_activity_timestamp` exceeds the inactivity timeout.\n            *   If timeout exceeded, end the existing session and create a new one.\n            *   If not timed out, update `last_activity_timestamp` to the event's timestamp.\n        *   If no session exists:\n            *   Create a new session with `start_time` and `end_time` set to the event's timestamp.\n            *   Generate a new `session_id`.\n            *   Insert a new row into the `sessions` table.\n        *   Insert the new data (OCR, audio, UI) into the relevant table, linking it to the active `session_id`.\n\n4.  **Inactivity Timeout:** A configurable timeout (e.g., 5 minutes) will be used to determine session end due to inactivity.\n\n5.  **Periodic Flushing:** To avoid excessive in-memory state, periodically flush closed sessions (those that have exceeded the inactivity timeout) to the database.\n\n6. **Data Migration:** A migration script will be needed to analyze existing data and create initial session records based on timestamp proximity and app/window changes.\n\n### 3.4. Implementation Details\n\n*   **Language/Framework:** Continue using Rust for core logic and database interaction.\n*   **Database:** Continue using SQLite.\n*   **Concurrency:** Use asynchronous operations with `tokio` for handling concurrent events and database interactions.  Leverage `Arc` and `Mutex` for shared state, and channels for communication between tasks.\n*   **Configuration:** Add a new setting for the inactivity timeout.\n*   **Error Handling:** Implement robust error handling with `anyhow` and propagate errors appropriately. Log errors using `tracing`.\n* **Testing:** Thoroughly test session boundary detection with various scenarios, including rapid switching, long inactivity periods, and concurrent events.\n\n## 4. Diagrams\n\n### 4.1. Current Data Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Database\n    User->>Screen: Interacts with screen\n    Screen->>Screenpipe: Captures screen content (OCR)\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Database: Stores OCR data with timestamps\n    Screenpipe->>Database: Stores audio transcriptions with timestamps\n    User->>Screenpipe: Requests data\n    Screenpipe->>Database: Queries data by time range\n    Database->>Screenpipe: Returns data\n    Screenpipe->>User: Returns data\n```\n\n### 4.2. Proposed Database Schema Changes\n\n```mermaid\nclassDiagram\n    class frames {\n        +id : INTEGER [PK]\n        +video_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +name : TEXT\n    }\n    class video_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +device_name : TEXT\n    }\n    class ocr_text {\n        +frame_id : INTEGER [FK]\n        +text : TEXT\n        +text_json : TEXT\n        +app_name : TEXT\n        +window_name : TEXT\n        +ocr_engine : TEXT\n        +focused : BOOLEAN\n        +session_id : INTEGER [FK]\n    }\n    class audio_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +timestamp : TIMESTAMP\n    }\n    class audio_transcriptions {\n        +id : INTEGER [PK]\n        +audio_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +transcription : TEXT\n        +device : TEXT\n        +is_input_device : BOOLEAN\n        +speaker_id : INTEGER\n        +transcription_engine : TEXT\n        +start_time : REAL\n        +end_time : REAL\n        +text_length : INTEGER\n        +session_id : INTEGER [FK]\n    }\n    class ui_monitoring {\n      +id : INTEGER [PK]\n      +text_output : TEXT\n      +timestamp : DATETIME\n      +app : TEXT\n      +window : TEXT\n      +initial_traversal_at : DATETIME\n      +session_id : INTEGER [FK]\n    }\n  class sessions {\n    +id : INTEGER [PK]\n    +app_name : TEXT\n    +window_name : TEXT\n    +start_time : DATETIME\n    +end_time : DATETIME\n    +duration_secs : REAL\n  }\n  frames --|> video_chunks : video_chunk_id\n  ocr_text --|> frames : frame_id\n  audio_transcriptions --|> audio_chunks : audio_chunk_id\n  ocr_text --|> sessions : session_id\n  audio_transcriptions --|> sessions : session_id\n  ui_monitoring --|> sessions : session_id\n```\n\n### 4.3. Modified Data Flow with Session Tracking\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Session Manager\n    participant Database\n\n    User->>Screen: Interacts with App A, Window 1\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to session_id\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: Active session found (session_id)\n    Screenpipe->>Database: Store audio data, link to session_id\n\n    Note over User,Screenpipe: User switches to App B, Window 2\n    User->>Screen: Interacts with App B, Window 2\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App B, Window 2)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: End previous session (App A, Window 1)\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to new session_id\n\n    Note over User,Screenpipe: Inactivity Timeout\n    Screenpipe->>Session Manager: Check for activity\n    Session Manager->>Database: End current session (App B, Window 2)\n```\n\n### 4.4. New API Endpoint (Modified /search)\n\nThe existing `/search` endpoint will be extended to support session-based queries.  No new endpoint is needed.\n\n## 5. Performance Implications\n\n*   **Database:**  The addition of the `sessions` table and foreign keys will add some overhead to write operations.  Proper indexing is crucial to mitigate this.  Read performance for session-based queries should be good with appropriate indexes.\n*   **Memory:**  The in-memory session tracking will require additional memory.  The size of this will depend on the number of concurrent users and the configured timeout.  This should be monitored and potentially optimized (e.g., using a more efficient data structure than a simple `HashMap`).\n*   **CPU:**  The session boundary detection logic will add some CPU overhead.  This should be minimized by efficient checks and the use of asynchronous operations.\n\n## 6. Migration Path\n\n1.  **Add new `sessions` table.**\n2.  **Add `session_id` columns** to `ocr_text`, `audio_transcriptions`, and `ui_monitoring` tables.\n3.  **Backfill `session_id`:**  A migration script will be needed to analyze existing data and create initial session records.  This script will need to:\n    *   Iterate through existing OCR, audio, and UI data in chronological order.\n    *   Apply the session boundary detection logic (described above) to group data into sessions.\n    *   Insert corresponding rows into the `sessions` table.\n    *   Update the `session_id` foreign key in the existing tables.\n\n\n## 7. Alternative Approaches\n\n1.  **Session Table per Content Type:** Instead of a single `sessions` table, we could have separate session tables for each content type (e.g., `ocr_sessions`, `audio_sessions`, `ui_sessions`).  This might simplify queries for a specific content type but could make cross-content type analysis more complex.\n2.  **No Session Table (Denormalized):** We could add `start_time` and `end_time` directly to the existing tables (`ocr_text`, `audio_transcriptions`, `ui_monitoring`). This would avoid the need for joins when querying for sessions, but could lead to data redundancy and potential inconsistencies.\n3.  any other suggestions ????\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1560"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1560",
              "body": "\n## Challenge\n\nI'm working on an application that requires accurate session tracking to analyze user behavior patterns,  and provide meaningful insights across different applications and windows. \n\nIn the existing Screenpipe architecture, OCR data is stored with only timestamp information, lacking precise session boundaries (start/end times) for application usage tracking. This limitation prevents us from properly segmenting user activity into coherent sessions.\n\n## 1. Current Workaround\ninternally I implementing a suboptimal solution that:\n1. Queries all OCR database entries chronologically\n2. Manually identifies session boundaries by analyzing timestamp sequences for each application\n3. Determines session end when detecting a different application in subsequent timestamps\n4. Assumes a session is ongoing if no clear delimiter exists in future timestamps\n\nWith that said I would love to hear any feedbacks that could help solve this problem with a minimal overhead on code changes, and make sure I'm not overthinking the solution: cc @louis030195 , i'm planning to start playing with some day next week\n\n## 2. Requirements\n\n1.  **Session Definition:** A \"session\" should be defined as a continuous period of user interaction with a specific application and window.  A break in activity (e.g., switching to a different application or window) should end the current session and potentially start a new one.  A configurable inactivity timeout (e.g., 5 minutes) should also end a session.\n\n2.  **Data Storage:** The database schema must be modified to store session start and end times, associated with specific applications and windows.  It must maintain links to the relevant OCR and audio data chunks.\n\n3.  **API Endpoint:**  A new or modified API endpoint (e.g., `/sessions`) is needed to query for session data.  This endpoint should support filtering by:\n    *   Date range (start and end timestamps).\n    *   Application name.\n    *   Window name.\n    *   Minimum and maximum session duration.\n    *   Associated tags.\n    *   Pagination (limit and offset).\n\n4.  **Real-time Capability:** The system should be able to detect session boundaries in near real-time as data is being ingested. This implies integration with the existing data capture and processing pipeline.\n\n5. **Configurability:** The inactivity timeout for ending a session should be configurable.\n\n## 3. Proposed Solution\n\n### 3.1. Database Schema Changes\n\nWe'll introduce a new table `sessions` and modify the existing tables.\n\n**New Table: `sessions`**\n\n| Column Name      | Data Type  | Constraints                                  | Description                                                                  |\n| :--------------- | :--------- | :------------------------------------------- | :--------------------------------------------------------------------------- |\n| `id`             | INTEGER    | PRIMARY KEY AUTOINCREMENT                    | Unique identifier for the session.                                       |\n| `app_name`       | TEXT       | NOT NULL                                     | Name of the application.                                                 |\n| `window_name`    | TEXT       |                                               | Title of the window.                                                     |\n| `start_time`     | DATETIME   | NOT NULL                                     | Timestamp of the session start.                                            |\n| `end_time`       | DATETIME   | NOT NULL                                     | Timestamp of the session end.                                              |\n| `duration_secs`  | REAL       | NOT NULL                                     | Duration of the session in seconds.                                        |\n\n**Modified Tables:**\n\n*   **`ocr_text`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`audio_transcriptions`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n*   **`ui_monitoring`**: Add a `session_id` column (INTEGER, FOREIGN KEY referencing `sessions.id`).\n\n**Indexes:**\n\n*   Create indexes on `sessions` table columns (`app_name`, `window_name`, `start_time`, `end_time`) for efficient querying.\n*   Create indexes on the `session_id` columns in `ocr_text`, `audio_transcriptions`, and `ui_monitoring`.\n\n### 3.2. API Enhancements\n\nWe'll modify the existing `/search` endpoint to also support session queries.\n\n**Request:**\n\n```\nGET /search?content_type=session&app_name=Cursor&start_time=2024-11-27T00:00:00Z&end_time=2024-11-28T00:00:00Z&min_duration=60&limit=10&offset=0\n```\n\n*   `content_type=session`: Indicates a session-based search.\n*   `app_name`, `window_name`: Filter by application and window (optional).\n*   `start_time`, `end_time`: Date range for the session (optional, defaults to last 24 hours).\n*   `min_duration`, `max_duration`: Filter by session duration in seconds (optional).\n*   `limit`, `offset`: Pagination parameters.\n\n\nafter discussing with @louis030195 on discord he proposed something like this as the output\n\n**Response:**\n\n```json\n{\n  \"data\": [\n    {\n      \"app_name\": \"Cursor\",\n      \"total_usage_time\": 3600,\n      \"windows\": [\n        {\n          \"window_name\": \"page.tsx\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T12:00:00Z\",\n              \"end_time\": \"2024-07-16T12:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [123, 124, 125],\n              \"tags\": [\"coding\", \"frontend\"]\n            },\n            {\n              \"start_time\": \"2024-07-16T14:00:00Z\",\n              \"end_time\": \"2024-07-16T14:30:00Z\",\n              \"duration\": 1800,\n              \"content_ids\": [223, 224, 225],\n              \"tags\": [\"coding\", \"frontend\"]\n            }\n          ],\n          \"total_usage_time\": 3600\n        }\n      ]\n    },\n    {\n      \"app_name\": \"Arc\",\n      \"total_usage_time\": 1200,\n      \"windows\": [\n        {\n          \"window_name\": \"x.com\",\n          \"sessions\": [\n            {\n              \"start_time\": \"2024-07-16T10:30:00Z\",\n              \"end_time\": \"2024-07-16T10:50:00Z\",\n              \"duration\": 1200,\n              \"content_ids\": [126, 127, 128],\n              \"tags\": [\"browsing\", \"social-media\"]\n            }\n          ],\n          \"total_usage_time\": 1200\n        }\n      ]\n    }\n  ],\n  \"pagination\": {\n    \"limit\": 50,\n    \"offset\": 0,\n    \"total\": 2\n  }\n}\n```\n\n### 3.3. Session Boundary Detection Logic\n\n1.  **Real-time Monitoring:**  The existing event listeners for OCR, audio, and UI events will be leveraged.\n\n2.  **Session Tracking:**  Maintain a data structure (likely in memory, possibly augmented with periodic database writes for persistence) to track active sessions.  This structure should map:\n    *   `(app_name, window_name)` -> `(session_id, last_activity_timestamp)`\n\n3.  **New Event Handling:**\n    *   When a new event (OCR, audio, UI) arrives:\n        *   Extract `app_name` and `window_name`.\n        *   Check if an active session exists for this (app, window) combination.\n        *   If a session exists:\n            *   Check if `now() - last_activity_timestamp` exceeds the inactivity timeout.\n            *   If timeout exceeded, end the existing session and create a new one.\n            *   If not timed out, update `last_activity_timestamp` to the event's timestamp.\n        *   If no session exists:\n            *   Create a new session with `start_time` and `end_time` set to the event's timestamp.\n            *   Generate a new `session_id`.\n            *   Insert a new row into the `sessions` table.\n        *   Insert the new data (OCR, audio, UI) into the relevant table, linking it to the active `session_id`.\n\n4.  **Inactivity Timeout:** A configurable timeout (e.g., 5 minutes) will be used to determine session end due to inactivity.\n\n5.  **Periodic Flushing:** To avoid excessive in-memory state, periodically flush closed sessions (those that have exceeded the inactivity timeout) to the database.\n\n6. **Data Migration:** A migration script will be needed to analyze existing data and create initial session records based on timestamp proximity and app/window changes.\n\n### 3.4. Implementation Details\n\n*   **Language/Framework:** Continue using Rust for core logic and database interaction.\n*   **Database:** Continue using SQLite.\n*   **Concurrency:** Use asynchronous operations with `tokio` for handling concurrent events and database interactions.  Leverage `Arc` and `Mutex` for shared state, and channels for communication between tasks.\n*   **Configuration:** Add a new setting for the inactivity timeout.\n*   **Error Handling:** Implement robust error handling with `anyhow` and propagate errors appropriately. Log errors using `tracing`.\n* **Testing:** Thoroughly test session boundary detection with various scenarios, including rapid switching, long inactivity periods, and concurrent events.\n\n## 4. Diagrams\n\n### 4.1. Current Data Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Database\n    User->>Screen: Interacts with screen\n    Screen->>Screenpipe: Captures screen content (OCR)\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Database: Stores OCR data with timestamps\n    Screenpipe->>Database: Stores audio transcriptions with timestamps\n    User->>Screenpipe: Requests data\n    Screenpipe->>Database: Queries data by time range\n    Database->>Screenpipe: Returns data\n    Screenpipe->>User: Returns data\n```\n\n### 4.2. Proposed Database Schema Changes\n\n```mermaid\nclassDiagram\n    class frames {\n        +id : INTEGER [PK]\n        +video_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +name : TEXT\n    }\n    class video_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +device_name : TEXT\n    }\n    class ocr_text {\n        +frame_id : INTEGER [FK]\n        +text : TEXT\n        +text_json : TEXT\n        +app_name : TEXT\n        +window_name : TEXT\n        +ocr_engine : TEXT\n        +focused : BOOLEAN\n        +session_id : INTEGER [FK]\n    }\n    class audio_chunks {\n        +id : INTEGER [PK]\n        +file_path : TEXT\n        +timestamp : TIMESTAMP\n    }\n    class audio_transcriptions {\n        +id : INTEGER [PK]\n        +audio_chunk_id : INTEGER [FK]\n        +offset_index : INTEGER\n        +timestamp : DATETIME\n        +transcription : TEXT\n        +device : TEXT\n        +is_input_device : BOOLEAN\n        +speaker_id : INTEGER\n        +transcription_engine : TEXT\n        +start_time : REAL\n        +end_time : REAL\n        +text_length : INTEGER\n        +session_id : INTEGER [FK]\n    }\n    class ui_monitoring {\n      +id : INTEGER [PK]\n      +text_output : TEXT\n      +timestamp : DATETIME\n      +app : TEXT\n      +window : TEXT\n      +initial_traversal_at : DATETIME\n      +session_id : INTEGER [FK]\n    }\n  class sessions {\n    +id : INTEGER [PK]\n    +app_name : TEXT\n    +window_name : TEXT\n    +start_time : DATETIME\n    +end_time : DATETIME\n    +duration_secs : REAL\n  }\n  frames --|> video_chunks : video_chunk_id\n  ocr_text --|> frames : frame_id\n  audio_transcriptions --|> audio_chunks : audio_chunk_id\n  ocr_text --|> sessions : session_id\n  audio_transcriptions --|> sessions : session_id\n  ui_monitoring --|> sessions : session_id\n```\n\n### 4.3. Modified Data Flow with Session Tracking\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Screen\n    participant Microphone\n    participant Screenpipe\n    participant Session Manager\n    participant Database\n\n    User->>Screen: Interacts with App A, Window 1\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to session_id\n    User->>Microphone: Speaks\n    Microphone->>Screenpipe: Captures audio\n    Screenpipe->>Session Manager: Check for existing session (App A, Window 1)\n    Session Manager-->>Screenpipe: Active session found (session_id)\n    Screenpipe->>Database: Store audio data, link to session_id\n\n    Note over User,Screenpipe: User switches to App B, Window 2\n    User->>Screen: Interacts with App B, Window 2\n    Screen->>Screenpipe: Captures screen content (OCR)\n    Screenpipe->>Session Manager: Check for existing session (App B, Window 2)\n    Session Manager-->>Screenpipe: No active session\n    Session Manager->>Database: End previous session (App A, Window 1)\n    Session Manager->>Database: Create new session, get session_id\n    Screenpipe->>Database: Store OCR data, link to new session_id\n\n    Note over User,Screenpipe: Inactivity Timeout\n    Screenpipe->>Session Manager: Check for activity\n    Session Manager->>Database: End current session (App B, Window 2)\n```\n\n### 4.4. New API Endpoint (Modified /search)\n\nThe existing `/search` endpoint will be extended to support session-based queries.  No new endpoint is needed.\n\n## 5. Performance Implications\n\n*   **Database:**  The addition of the `sessions` table and foreign keys will add some overhead to write operations.  Proper indexing is crucial to mitigate this.  Read performance for session-based queries should be good with appropriate indexes.\n*   **Memory:**  The in-memory session tracking will require additional memory.  The size of this will depend on the number of concurrent users and the configured timeout.  This should be monitored and potentially optimized (e.g., using a more efficient data structure than a simple `HashMap`).\n*   **CPU:**  The session boundary detection logic will add some CPU overhead.  This should be minimized by efficient checks and the use of asynchronous operations.\n\n## 6. Migration Path\n\n1.  **Add new `sessions` table.**\n2.  **Add `session_id` columns** to `ocr_text`, `audio_transcriptions`, and `ui_monitoring` tables.\n3.  **Backfill `session_id`:**  A migration script will be needed to analyze existing data and create initial session records.  This script will need to:\n    *   Iterate through existing OCR, audio, and UI data in chronological order.\n    *   Apply the session boundary detection logic (described above) to group data into sessions.\n    *   Insert corresponding rows into the `sessions` table.\n    *   Update the `session_id` foreign key in the existing tables.\n\n\n## 7. Alternative Approaches\n\n1.  **Session Table per Content Type:** Instead of a single `sessions` table, we could have separate session tables for each content type (e.g., `ocr_sessions`, `audio_sessions`, `ui_sessions`).  This might simplify queries for a specific content type but could make cross-content type analysis more complex.\n2.  **No Session Table (Denormalized):** We could add `start_time` and `end_time` directly to the existing tables (`ocr_text`, `audio_transcriptions`, `ui_monitoring`). This would avoid the need for joins when querying for sessions, but could lead to data redundancy and potential inconsistencies.\n3.  any other suggestions ????\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1560",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1441",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2026-01-18T17:51:29.760Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:29.760Z",
            "created_at": "2026-01-18T17:51:29.760Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1441",
              "status": "open",
              "type": "issue",
              "number": 1441,
              "title": "[bounty] general purpose scrapper",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1441",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] general purpose scrapper",
                  "body": "\nv0\n\nshould be able to scrap whatsapp\n\nideally you can use the keyboard / mouse api \n\nhttps://docs.screenpi.pe/docs/sdk-reference#input-control-api\n\n\nbasically many ppl would like to scrap data from desktop app and it's hard, like whatsapp, imessage, or even web but without getting banned or because it's local authentication is already done by user usually and stays local, and much less likely detected \n\n\n\n/bounty 200\n\nplease suggest how you would implement a very simple first version that work for whatsapp and UX\n\n\n\n\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1441"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1441",
              "body": "\nv0\n\nshould be able to scrap whatsapp\n\nideally you can use the keyboard / mouse api \n\nhttps://docs.screenpi.pe/docs/sdk-reference#input-control-api\n\n\nbasically many ppl would like to scrap data from desktop app and it's hard, like whatsapp, imessage, or even web but without getting banned or because it's local authentication is already done by user usually and stays local, and much less likely detected \n\n\n\n/bounty 200\n\nplease suggest how you would implement a very simple first version that work for whatsapp and UX\n\n\n\n\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1441",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1298",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2026-01-18T17:51:30.256Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:30.256Z",
            "created_at": "2026-01-18T17:51:30.256Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1298",
              "status": "open",
              "type": "issue",
              "number": 1298,
              "title": "[docs] document env var somewhere somehow ",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1298",
                  "user": {
                    "login": "dassio",
                    "id": 733502,
                    "node_id": "MDQ6VXNlcjczMzUwMg==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/733502?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/dassio",
                    "html_url": "https://github.com/dassio",
                    "followers_url": "https://api.github.com/users/dassio/followers",
                    "following_url": "https://api.github.com/users/dassio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/dassio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/dassio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/dassio/subscriptions",
                    "organizations_url": "https://api.github.com/users/dassio/orgs",
                    "repos_url": "https://api.github.com/users/dassio/repos",
                    "events_url": "https://api.github.com/users/dassio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/dassio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[docs] document env var somewhere somehow ",
                  "body": "**describe the feature**\nin the desktop app, you can configure hugging face mirror, but for the screenpipe server cli ,there is no such option , when try to use whisper for audio transcription, need to download mode from hugging face \n\n**why is this needed?**\nhugging face is banned in China\n\n\n**additional context**\n```\nyou are using local processing. all your data stays on your computer.\n\nwarning: telemetry is enabled. only error-level data will be sent to highlight.io.\nto disable, use the --disable-telemetry flag.\n\ncheck latest changes here: https://github.com/mediar-ai/screenpipe/releases\n2025-02-07T14:15:37.861529Z  INFO screenpipe: starting pipes\nfailed to start pipe timeline: No pipe.js/pipe.ts found in the pipe/dist directory\n2025-02-07T14:15:37.864597Z  INFO screenpipe_server::server: Server starting on 127.0.0.1:3030\n2025-02-07T14:15:45.839709Z  INFO screenpipe_server::video: Starting FFmpeg process for file: C:\\Users\\dassi\\.screenpipe\\data\\monitor_490607759_2025-02-07_14-15-45.mp4\n2025-02-07T14:15:48.283937Z  INFO screenpipe_server::resource_monitor: Runtime: 10s, Total Memory: 2% (0.25 GB / 16.09 GB), Total CPU: 88%\n2025-02-07T14:15:58.322953Z  INFO screenpipe_server::resource_monitor: Runtime: 20s, Total Memory: 2% (0.26 GB / 16.09 GB), Total CPU: 92%\n2025-02-07T14:16:00.374953Z ERROR screenpipe: continuous recording error: request error: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n\nCaused by:\n    0: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n    1: connection timed out\n```\n\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1298"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1298",
              "body": "**describe the feature**\nin the desktop app, you can configure hugging face mirror, but for the screenpipe server cli ,there is no such option , when try to use whisper for audio transcription, need to download mode from hugging face \n\n**why is this needed?**\nhugging face is banned in China\n\n\n**additional context**\n```\nyou are using local processing. all your data stays on your computer.\n\nwarning: telemetry is enabled. only error-level data will be sent to highlight.io.\nto disable, use the --disable-telemetry flag.\n\ncheck latest changes here: https://github.com/mediar-ai/screenpipe/releases\n2025-02-07T14:15:37.861529Z  INFO screenpipe: starting pipes\nfailed to start pipe timeline: No pipe.js/pipe.ts found in the pipe/dist directory\n2025-02-07T14:15:37.864597Z  INFO screenpipe_server::server: Server starting on 127.0.0.1:3030\n2025-02-07T14:15:45.839709Z  INFO screenpipe_server::video: Starting FFmpeg process for file: C:\\Users\\dassi\\.screenpipe\\data\\monitor_490607759_2025-02-07_14-15-45.mp4\n2025-02-07T14:15:48.283937Z  INFO screenpipe_server::resource_monitor: Runtime: 10s, Total Memory: 2% (0.25 GB / 16.09 GB), Total CPU: 88%\n2025-02-07T14:15:58.322953Z  INFO screenpipe_server::resource_monitor: Runtime: 20s, Total Memory: 2% (0.26 GB / 16.09 GB), Total CPU: 92%\n2025-02-07T14:16:00.374953Z ERROR screenpipe: continuous recording error: request error: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n\nCaused by:\n    0: https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/config.json: Connection Failed: Connect error: connection timed out\n    1: connection timed out\n```\n\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1298",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1383",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2026-01-18T17:51:31.702Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:31.702Z",
            "created_at": "2026-01-18T17:51:31.702Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1383",
              "status": "open",
              "type": "issue",
              "number": 1383,
              "title": "[bounty] implement deep research in search pipe",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1383",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] implement deep research in search pipe",
                  "body": "\n\ni love perplexity deep research \n\ni think we should have something like this in screenpipe search, which would be something that go beyond surface level, really in depth on your data \n\nnot sure about the UX yet, suggest any design first \n\nshould allow async (eg ask something and come back later to it, stored in some kind of history, maybe related to #1382 check perplexity UI too)\n\n/bounty 200 \n\n\n\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1383"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1383",
              "body": "\n\ni love perplexity deep research \n\ni think we should have something like this in screenpipe search, which would be something that go beyond surface level, really in depth on your data \n\nnot sure about the UX yet, suggest any design first \n\nshould allow async (eg ask something and come back later to it, stored in some kind of history, maybe related to #1382 check perplexity UI too)\n\n/bounty 200 \n\n\n\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1383",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1382",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2026-01-18T17:51:33.925Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:33.925Z",
            "created_at": "2026-01-18T17:51:33.925Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1382",
              "status": "open",
              "type": "issue",
              "number": 1382,
              "title": "[bounty] implement history for search pipe",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1382",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] implement history for search pipe",
                  "body": "like chatgpt history a bit \n\nwe had this but did not work well\n\ncheck shadcn sidebar and stuff \n\n\n/bounty 100 ",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1382"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1382",
              "body": "like chatgpt history a bit \n\nwe had this but did not work well\n\ncheck shadcn sidebar and stuff \n\n\n/bounty 100 ",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1382",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1380",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2026-01-18T17:51:36.665Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:36.665Z",
            "created_at": "2026-01-18T17:51:36.665Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1380",
              "status": "open",
              "type": "issue",
              "number": 1380,
              "title": "[bounty] implement device control and make --use-all-monitors work",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1380",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] implement device control and make --use-all-monitors work",
                  "body": "\nthis feature is useful to improve the experience for:\n1. people switching audio device and monitor devices regularly (commuting for work etc.) (e.g. `--use-all-monitors` argument to always record all monitors for example)\n2. privacy preserving use cases \n3. control resource usage dynamically \n4. other use cases\n\ndefinition of done:\n- `--use-all-monitors` always record all monitor available, and stop recording when it's unplugged \n- running screenpipe for 3 days, while having meetings, working, etc. and the memory stays under 2.5 gb, and CPU roughly the same (10-30% on my mac book pro m4 max)\n- /vision/start, /vision/stop, /vision/list\n\nmake this work reliably and prove it's not memory leaking \n\n\n\n/bounty 400 \n\n\n\nbonus bounty:\n- `--use-all-default-audio-devices` always record all default audio devices\n- very good tests, good benchmarks of memory over time somehow, idk\n\n\n\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1380"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1380",
              "body": "\nthis feature is useful to improve the experience for:\n1. people switching audio device and monitor devices regularly (commuting for work etc.) (e.g. `--use-all-monitors` argument to always record all monitors for example)\n2. privacy preserving use cases \n3. control resource usage dynamically \n4. other use cases\n\ndefinition of done:\n- `--use-all-monitors` always record all monitor available, and stop recording when it's unplugged \n- running screenpipe for 3 days, while having meetings, working, etc. and the memory stays under 2.5 gb, and CPU roughly the same (10-30% on my mac book pro m4 max)\n- /vision/start, /vision/stop, /vision/list\n\nmake this work reliably and prove it's not memory leaking \n\n\n\n/bounty 400 \n\n\n\nbonus bounty:\n- `--use-all-default-audio-devices` always record all default audio devices\n- very good tests, good benchmarks of memory over time somehow, idk\n\n\n\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1380",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1160",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2026-01-18T17:51:38.385Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:38.385Z",
            "created_at": "2026-01-18T17:51:38.385Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1160",
              "status": "open",
              "type": "issue",
              "number": 1160,
              "title": "[bounty] list webcam, iphone, etc. in list-monitors",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1160",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] list webcam, iphone, etc. in list-monitors",
                  "body": "we should be able to record webcam, iphone cameras, etc. easily in the same way than monitor device\n\n```\nlouisbeaumont@MacBook-Pro-9:~/Documents/brain$ ffmpeg -f avfoundation -list_devices true -i \"\"\nffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers\n  built with Apple clang version 16.0.0 (clang-1600.0.26.4)\n  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n  libavutil      59. 39.100 / 59. 39.100\n  libavcodec     61. 19.100 / 61. 19.100\n  libavformat    61.  7.100 / 61.  7.100\n  libavdevice    61.  3.100 / 61.  3.100\n  libavfilter    10.  4.100 / 10.  4.100\n  libswscale      8.  3.100 /  8.  3.100\n  libswresample   5.  3.100 /  5.  3.100\n  libpostproc    58.  3.100 / 58.  3.100\n2025-01-16 09:03:00.993 ffmpeg[23450:7179261] WARNING: Add NSCameraUseContinuityCameraDeviceType to your Info.plist to use AVCaptureDeviceTypeContinuityCamera.\n2025-01-16 09:03:01.177 ffmpeg[23450:7179261] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n[AVFoundation indev @ 0x1426314d0] AVFoundation video devices:\n[AVFoundation indev @ 0x1426314d0] [0] MacBook Pro Camera\n[AVFoundation indev @ 0x1426314d0] [1] louisbeaumont.me iphone Camera\n[AVFoundation indev @ 0x1426314d0] [2] louisbeaumont.me iphone Desk View Camera\n[AVFoundation indev @ 0x1426314d0] [3] MacBook Pro Desk View Camera\n[AVFoundation indev @ 0x1426314d0] [4] louisbeaumont.me iphone Desk View Camera\n[AVFoundation indev @ 0x1426314d0] [5] louisbeaumont.me iphone Camera\n[AVFoundation indev @ 0x1426314d0] [6] Capture screen 0\n[AVFoundation indev @ 0x1426314d0] AVFoundation audio devices:\n[AVFoundation indev @ 0x1426314d0] [0] louisbeaumont.me iphone Microphone\n[AVFoundation indev @ 0x1426314d0] [1] Immersed\n[AVFoundation indev @ 0x1426314d0] [2] BlackHole 2ch\n[AVFoundation indev @ 0x1426314d0] [3] louisbeaumont.me iphone Microphone\n[AVFoundation indev @ 0x1426314d0] [4] MacBook Pro Microphone\n[AVFoundation indev @ 0x1426314d0] [5] BlackHole 16ch\n[AVFoundation indev @ 0x1426314d0] [6] Aggregate Device\n[AVFoundation indev @ 0x1426314d0] [7] input\n[AVFoundation indev @ 0x1426314d0] [8] EpocCam Microphone\n[in#0 @ 0x142630ef0] Error opening input: Input/output error\nError opening input file .\nError opening input files: Input/output error\nlouisbeaumont@MacBook-Pro-9:~/Documents/brain$ \n```\n\n/bounty 120",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1160"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1160",
              "body": "we should be able to record webcam, iphone cameras, etc. easily in the same way than monitor device\n\n```\nlouisbeaumont@MacBook-Pro-9:~/Documents/brain$ ffmpeg -f avfoundation -list_devices true -i \"\"\nffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers\n  built with Apple clang version 16.0.0 (clang-1600.0.26.4)\n  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n  libavutil      59. 39.100 / 59. 39.100\n  libavcodec     61. 19.100 / 61. 19.100\n  libavformat    61.  7.100 / 61.  7.100\n  libavdevice    61.  3.100 / 61.  3.100\n  libavfilter    10.  4.100 / 10.  4.100\n  libswscale      8.  3.100 /  8.  3.100\n  libswresample   5.  3.100 /  5.  3.100\n  libpostproc    58.  3.100 / 58.  3.100\n2025-01-16 09:03:00.993 ffmpeg[23450:7179261] WARNING: Add NSCameraUseContinuityCameraDeviceType to your Info.plist to use AVCaptureDeviceTypeContinuityCamera.\n2025-01-16 09:03:01.177 ffmpeg[23450:7179261] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n[AVFoundation indev @ 0x1426314d0] AVFoundation video devices:\n[AVFoundation indev @ 0x1426314d0] [0] MacBook Pro Camera\n[AVFoundation indev @ 0x1426314d0] [1] louisbeaumont.me iphone Camera\n[AVFoundation indev @ 0x1426314d0] [2] louisbeaumont.me iphone Desk View Camera\n[AVFoundation indev @ 0x1426314d0] [3] MacBook Pro Desk View Camera\n[AVFoundation indev @ 0x1426314d0] [4] louisbeaumont.me iphone Desk View Camera\n[AVFoundation indev @ 0x1426314d0] [5] louisbeaumont.me iphone Camera\n[AVFoundation indev @ 0x1426314d0] [6] Capture screen 0\n[AVFoundation indev @ 0x1426314d0] AVFoundation audio devices:\n[AVFoundation indev @ 0x1426314d0] [0] louisbeaumont.me iphone Microphone\n[AVFoundation indev @ 0x1426314d0] [1] Immersed\n[AVFoundation indev @ 0x1426314d0] [2] BlackHole 2ch\n[AVFoundation indev @ 0x1426314d0] [3] louisbeaumont.me iphone Microphone\n[AVFoundation indev @ 0x1426314d0] [4] MacBook Pro Microphone\n[AVFoundation indev @ 0x1426314d0] [5] BlackHole 16ch\n[AVFoundation indev @ 0x1426314d0] [6] Aggregate Device\n[AVFoundation indev @ 0x1426314d0] [7] input\n[AVFoundation indev @ 0x1426314d0] [8] EpocCam Microphone\n[in#0 @ 0x142630ef0] Error opening input: Input/output error\nError opening input file .\nError opening input files: Input/output error\nlouisbeaumont@MacBook-Pro-9:~/Documents/brain$ \n```\n\n/bounty 120",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1160",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mediar-ai#1142",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mediar-ai",
              "id": "generated-mediar-ai",
              "name": "Mediar-ai",
              "description": "",
              "members": [],
              "display_name": "Mediar-ai",
              "created_at": "2026-01-18T17:51:39.427Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mediar-ai?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "mediar-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:39.427Z",
            "created_at": "2026-01-18T17:51:39.427Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mediar-ai#1142",
              "status": "open",
              "type": "issue",
              "number": 1142,
              "title": "[bounty] support for video and voice LLM in search, timeline, meeting",
              "source": {
                "data": {
                  "id": "source-mediar-ai#1142",
                  "user": {
                    "login": "louis030195",
                    "id": 25003283,
                    "node_id": "MDQ6VXNlcjI1MDAzMjgz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25003283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/louis030195",
                    "html_url": "https://github.com/louis030195",
                    "followers_url": "https://api.github.com/users/louis030195/followers",
                    "following_url": "https://api.github.com/users/louis030195/following{/other_user}",
                    "gists_url": "https://api.github.com/users/louis030195/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/louis030195/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/louis030195/subscriptions",
                    "organizations_url": "https://api.github.com/users/louis030195/orgs",
                    "repos_url": "https://api.github.com/users/louis030195/repos",
                    "events_url": "https://api.github.com/users/louis030195/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/louis030195/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[bounty] support for video and voice LLM in search, timeline, meeting",
                  "body": "likely need to break down in multiple bounties\r\n\r\n\r\n\r\n\r\n/bounty 400 \r\n\r\n\r\neg\r\n- meeting: use voice LLM to transcribe or summarize audio would increase a lot quality - 10x better than granola etc\r\n- search: use video LLM would be much more powerful and different context windows \r\n- timeline: same\r\n\r\n\r\nsuggest rough design, might create other issues \r\n\r\n\r\n\r\n",
                  "html_url": "https://github.com/mediar-ai/screenpipe/issues/1142"
                },
                "type": "github"
              },
              "hash": "mediar-ai/screenpipe#1142",
              "body": "likely need to break down in multiple bounties\r\n\r\n\r\n\r\n\r\n/bounty 400 \r\n\r\n\r\neg\r\n- meeting: use voice LLM to transcribe or summarize audio would increase a lot quality - 10x better than granola etc\r\n- search: use video LLM would be much more powerful and different context windows \r\n- timeline: same\r\n\r\n\r\nsuggest rough design, might create other issues \r\n\r\n\r\n\r\n",
              "url": "https://github.com/mediar-ai/screenpipe/issues/1142",
              "tech": [],
              "repo_name": "screenpipe",
              "repo_owner": "mediar-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#679",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-18T17:51:39.427Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:39.427Z",
            "created_at": "2026-01-18T17:51:39.427Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#679",
              "status": "open",
              "type": "issue",
              "number": 679,
              "title": "Add Json data type",
              "source": {
                "data": {
                  "id": "source-ZIO#679",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add Json data type",
                  "body": "The following is a sketch of what a proper `Json` data type should look like, including constructors, methods, and related types. Note that `DynamicPatch`, `JsonPatch`, and `JsonSchema` are all out-of-scope for this ticket.\n\n## Sketch\n\n```scala\npackage zio.blocks.schema.json\n\nimport zio.blocks.chunk.Chunk\nimport zio.blocks.schema.{DynamicOptic, DynamicValue, PrimitiveValue, Schema, SchemaError}\n\nimport java.io.{Reader, Writer}\nimport java.nio.ByteBuffer\nimport scala.util.control.NoStackTrace\n\n// =============================================================================\n// JSON ERROR\n// =============================================================================\n\n/**\n * Represents an error that occurred during JSON parsing, encoding, or processing.\n *\n * NOTE: This should replace JsonBinaryCodecError and be moved to `zio.block.schema.json`.\n *\n * @param message A human-readable description of the error\n * @param path The location in the JSON structure where the error occurred,\n *             represented as a [[DynamicOptic]]\n * @param offset Optional byte offset in the input where the error occurred\n * @param line Optional 1-indexed line number where the error occurred\n * @param column Optional 1-indexed column number where the error occurred\n */\nfinal case class JsonError(\n  message: String,\n  path: DynamicOptic,\n  offset: Option[Long],\n  line: Option[Int],\n  column: Option[Int]\n) extends Exception with NoStackTrace {\n\n  override def getMessage: String = {\n    val posInfo = (line, column) match {\n      case (Some(l), Some(c)) => s\" at line $l, column $c\"\n      case _                  => offset.map(o => s\" at offset $o\").getOrElse(\"\")\n    }\n    val pathInfo = if (path.nodes.isEmpty) \"\" else s\" at path $path\"\n    s\"$message$pathInfo$posInfo\"\n  }\n\n  /**\n   * Combines this error with another, preserving both error messages.\n   */\n  def ++(other: JsonError): JsonError =\n    JsonError(s\"${this.message}; ${other.message}\", this.path, this.offset, this.line, this.column)\n}\n\nobject JsonError {\n\n  /**\n   * Creates a JsonError with only a message, using root path and no position info.\n   */\n  def apply(message: String): JsonError =\n    JsonError(message, DynamicOptic.root, None, None, None)\n\n  /**\n   * Creates a JsonError with a message and path, no position info.\n   */\n  def apply(message: String, path: DynamicOptic): JsonError =\n    JsonError(message, path, None, None, None)\n\n  /**\n   * Converts a [[SchemaError]] to a [[JsonError]].\n   */\n  def fromSchemaError(error: SchemaError): JsonError =\n    JsonError(error.message, DynamicOptic.root, None, None, None)\n}\n\n// =============================================================================\n// JSON DECODER / ENCODER (implicit priority resolution)\n// =============================================================================\n\n/**\n * Type class for decoding [[Json]] values into Scala types.\n *\n * Implicit resolution prefers explicitly provided [[JsonBinaryCodec]] instances\n * over schema-derived instances, allowing users to override derived behavior.\n */\nsealed trait JsonDecoder[A] {\n\n  /**\n   * Decodes a [[Json]] value into type `A`.\n   *\n   * @param json The JSON value to decode\n   * @return Either a [[JsonError]] on failure, or the decoded value\n   */\n  def decode(json: Json): Either[JsonError, A]\n}\n\nobject JsonDecoder extends JsonDecoderLowPriority {\n\n  def apply[A](implicit decoder: JsonDecoder[A]): JsonDecoder[A] = decoder\n\n  /**\n   * Higher priority: use an explicitly provided [[JsonBinaryCodec]].\n   */\n  implicit def fromCodec[A](implicit codec: JsonBinaryCodec[A]): JsonDecoder[A] =\n    new JsonDecoder[A] {\n      def decode(json: Json): Either[JsonError, A] = json.decodeWith(codec)\n    }\n}\n\n/**\n * Lower priority implicits for [[JsonDecoder]].\n */\ntrait JsonDecoderLowPriority {\n\n  /**\n   * Lower priority: derive a codec from an implicit [[Schema]].\n   */\n  implicit def fromSchema[A](implicit schema: Schema[A]): JsonDecoder[A] =\n    new JsonDecoder[A] {\n      private lazy val codec: JsonBinaryCodec[A] = schema.derive(JsonBinaryCodecDeriver)\n      def decode(json: Json): Either[JsonError, A] = json.decodeWith(codec)\n    }\n}\n\n/**\n * Type class for encoding Scala types into [[Json]] values.\n *\n * Implicit resolution prefers explicitly provided [[JsonBinaryCodec]] instances\n * over schema-derived instances, allowing users to override derived behavior.\n */\nsealed trait JsonEncoder[A] {\n\n  /**\n   * Encodes a value of type `A` into [[Json]].\n   *\n   * @param value The value to encode\n   * @return The encoded JSON value\n   */\n  def encode(value: A): Json\n}\n\nobject JsonEncoder extends JsonEncoderLowPriority {\n\n  def apply[A](implicit encoder: JsonEncoder[A]): JsonEncoder[A] = encoder\n\n  /**\n   * Higher priority: use an explicitly provided [[JsonBinaryCodec]].\n   */\n  implicit def fromCodec[A](implicit codec: JsonBinaryCodec[A]): JsonEncoder[A] =\n    new JsonEncoder[A] {\n      def encode(value: A): Json = Json.encodeWith(value, codec)\n    }\n}\n\n/**\n * Lower priority implicits for [[JsonEncoder]].\n */\ntrait JsonEncoderLowPriority {\n\n  /**\n   * Lower priority: derive a codec from an implicit [[Schema]].\n   */\n  implicit def fromSchema[A](implicit schema: Schema[A]): JsonEncoder[A] =\n    new JsonEncoder[A] {\n      private lazy val codec: JsonBinaryCodec[A] = schema.derive(JsonBinaryCodecDeriver)\n      def encode(value: A): Json = Json.encodeWith(value, codec)\n    }\n}\n\n// =============================================================================\n// JSON SELECTION\n// =============================================================================\n\n/**\n * Represents a selection of zero or more JSON values, with accumulated errors.\n *\n * `JsonSelection` enables fluent chaining of operations that may fail without\n * requiring immediate error handling. Operations are applied to all values in\n * the selection, and errors are accumulated.\n *\n * {{{\n * val selection: JsonSelection = json.get(p\"users[*].name\")\n * val result: Either[SchemaError, Vector[Json]] = selection.toEither\n * }}}\n */\nfinal case class JsonSelection(toEither: Either[SchemaError, Vector[Json]]) { self =>\n\n  /**\n   * Returns true if this selection contains no values (either empty or errored).\n   */\n  def isEmpty: Boolean = toEither.fold(_ => true, _.isEmpty)\n\n  /**\n   * Returns true if this selection contains at least one value.\n   */\n  def nonEmpty: Boolean = toEither.fold(_ => false, _.nonEmpty)\n\n  /**\n   * Returns the number of values in this selection, or 0 if errored.\n   */\n  def size: Int = toEither.fold(_ => 0, _.size)\n\n  // ---------------------------------------------------------------------------\n  // Transformations\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Applies a function to each JSON value in this selection.\n   *\n   * @param f The transformation function\n   * @return A new selection with transformed values\n   */\n  def map(f: Json => Json): JsonSelection =\n    JsonSelection(toEither.map(_.map(f)))\n\n  /**\n   * Applies a function returning a selection to each value, flattening results.\n   *\n   * @param f The function producing selections\n   * @return A new selection with all results combined\n   */\n  def flatMap(f: Json => JsonSelection): JsonSelection =\n    JsonSelection(toEither.flatMap { jsons =>\n      jsons.foldLeft[Either[SchemaError, Vector[Json]]](Right(Vector.empty)) { (acc, json) =>\n        for {\n          existing <- acc\n          next     <- f(json).toEither\n        } yield existing ++ next\n      }\n    })\n\n  /**\n   * Filters values in this selection by a predicate.\n   *\n   * @param p The predicate to test values\n   * @return A new selection containing only values satisfying the predicate\n   */\n  def filter(p: Json => Boolean): JsonSelection =\n    JsonSelection(toEither.map(_.filter(p)))\n\n  /**\n   * Collects values for which the partial function is defined.\n   *\n   * @param pf A partial function to apply\n   * @return A new selection with collected results\n   */\n  def collect(pf: PartialFunction[Json, Json]): JsonSelection =\n    JsonSelection(toEither.map(_.collect(pf)))\n\n  // ---------------------------------------------------------------------------\n  // Navigation\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Navigates to values at the given path within each selected value.\n   *\n   * @param path The path to navigate\n   * @return A new selection with values at the path\n   */\n  def get(path: DynamicOptic): JsonSelection =\n    flatMap(json => json.get(path))\n\n  /**\n   * Alias for [[get]].\n   */\n  def apply(path: DynamicOptic): JsonSelection = get(path)\n\n  /**\n   * Navigates to array element at given index within each selected value.\n   *\n   * @param index The array index\n   * @return A new selection with elements at the index\n   */\n  def apply(index: Int): JsonSelection =\n    flatMap(json => json.apply(index))\n\n  /**\n   * Navigates to object field with given key within each selected value.\n   *\n   * @param key The object key\n   * @return A new selection with values at the key\n   */\n  def apply(key: String): JsonSelection =\n    flatMap(json => json.apply(key))\n\n  // ---------------------------------------------------------------------------\n  // Type Filtering\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Filters to only JSON objects.\n   */\n  def objects: JsonSelection = filter(_.isObject)\n\n  /**\n   * Filters to only JSON arrays.\n   */\n  def arrays: JsonSelection = filter(_.isArray)\n\n  /**\n   * Filters to only JSON strings.\n   */\n  def strings: JsonSelection = filter(_.isString)\n\n  /**\n   * Filters to only JSON numbers.\n   */\n  def numbers: JsonSelection = filter(_.isNumber)\n\n  /**\n   * Filters to only JSON booleans.\n   */\n  def booleans: JsonSelection = filter(_.isBoolean)\n\n  /**\n   * Filters to only JSON nulls.\n   */\n  def nulls: JsonSelection = filter(_.isNull)\n\n  // ---------------------------------------------------------------------------\n  // Combination\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Combines this selection with another, concatenating values or errors.\n   *\n   * @param other The other selection\n   * @return A combined selection\n   */\n  def ++(other: JsonSelection): JsonSelection =\n    (toEither, other.toEither) match {\n      case (Right(a), Right(b)) => JsonSelection(Right(a ++ b))\n      case (Left(a), Left(b))   => JsonSelection(Left(a ++ b))\n      case (Left(a), _)         => JsonSelection(Left(a))\n      case (_, Left(b))         => JsonSelection(Left(b))\n    }\n\n  // ---------------------------------------------------------------------------\n  // Terminal Operations\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Returns the single value if exactly one, an array of values if there are many, or \n   * otherwise an error.\n   */\n  def one: Either[SchemaError, Json] =\n    toEither.flatMap { jsons =>\n      if (jsons.size == 1) Right(jsons.head)\n      else if (jsons.size > 1) toArray\n      else Left(SchemaError.expectationMismatch(Nil, s\"expected exactly one value, got ${jsons.size}\"))\n    }\n\n  /**\n   * Returns the first value if any, otherwise an error.\n   */\n  def first: Either[SchemaError, Json] =\n    toEither.flatMap { jsons =>\n      jsons.headOption.toRight(SchemaError.expectationMismatch(Nil, \"expected at least one value, got none\"))\n    }\n\n  /**\n   * Returns all values as a [[Json.Array]], or an error.\n   */\n  def toArray: Either[SchemaError, Json] =\n    toEither.map(jsons => Json.Array(jsons))\n\n  /**\n   * Unsafe version of [[one]], throws on error or wrong count.\n   */\n  def oneUnsafe: Json = one.fold(e => throw JsonError.fromSchemaError(e), identity)\n\n  /**\n   * Unsafe version of [[first]], throws on error or empty.\n   */\n  def firstUnsafe: Json = first.fold(e => throw JsonError.fromSchemaError(e), identity)\n}\n\nobject JsonSelection {\n\n  /**\n   * Creates a selection containing a single value.\n   */\n  def apply(json: Json): JsonSelection = JsonSelection(Right(Vector(json)))\n\n  /**\n   * Creates a selection containing multiple values.\n   */\n  def fromVector(jsons: Vector[Json]): JsonSelection = JsonSelection(Right(jsons))\n\n  /**\n   * Creates an empty selection (no values, no error).\n   */\n  val empty: JsonSelection = JsonSelection(Right(Vector.empty))\n\n  /**\n   * Creates a failed selection with the given error.\n   */\n  def fail(error: SchemaError): JsonSelection = JsonSelection(Left(error))\n\n  /**\n   * Creates a failed selection with the given message.\n   */\n  def fail(message: String): JsonSelection =\n    JsonSelection(Left(SchemaError.expectationMismatch(Nil, message)))\n}\n\n// =============================================================================\n// JSON ADT\n// =============================================================================\n\n/**\n * Represents a JSON value.\n *\n * The JSON data model consists of:\n *  - '''Objects''': Unordered collections of key-value pairs\n *  - '''Arrays''': Ordered sequences of values\n *  - '''Strings''': Unicode text\n *  - '''Numbers''': Numeric values (stored as strings for precision)\n *  - '''Booleans''': `true` or `false`\n *  - '''Null''': The null value\n *\n * ==Construction==\n * {{{\n * val obj = Json.Object(\"name\" -> Json.String(\"Alice\"), \"age\" -> Json.number(30))\n * val arr = Json.Array(Json.String(\"a\"), Json.String(\"b\"))\n * val str = Json.String(\"hello\")\n * val num = Json.number(42)\n * val bool = Json.Boolean(true)\n * val nul = Json.Null\n * }}}\n *\n * ==Navigation==\n * {{{\n * json.get(p\"users[0].name\")   // JsonSelection\n * json(\"users\")(0)(\"name\")     // JsonSelection\n * json.fields                  // for objects\n * json.elements                // for arrays\n * }}}\n *\n * ==Pattern Matching==\n * {{{\n * json match {\n *   case Json.Object(fields) => ...\n *   case Json.Array(elements) => ...\n *   case Json.String(value) => ...\n *   case Json.Number(value) => ...\n *   case Json.Boolean(value) => ...\n *   case Json.Null => ...\n * }\n * }}}\n */\nsealed trait Json { self =>\n\n  // ===========================================================================\n  // Type Testing\n  // ===========================================================================\n\n  /**\n   * Returns `true` if this is a JSON object.\n   */\n  def isObject: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON array.\n   */\n  def isArray: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON string.\n   */\n  def isString: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON number.\n   */\n  def isNumber: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON boolean.\n   */\n  def isBoolean: Boolean = false\n\n  /**\n   * Returns `true` if this is JSON null.\n   */\n  def isNull: Boolean = false\n\n  // ===========================================================================\n  // Type Filtering (returns JsonSelection)\n  // ===========================================================================\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is an object,\n   * otherwise an empty selection.\n   */\n  def asObject: JsonSelection = if (isObject) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is an array,\n   * otherwise an empty selection.\n   */\n  def asArray: JsonSelection = if (isArray) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is a string,\n   * otherwise an empty selection.\n   */\n  def asString: JsonSelection = if (isString) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is a number,\n   * otherwise an empty selection.\n   */\n  def asNumber: JsonSelection = if (isNumber) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is a boolean,\n   * otherwise an empty selection.\n   */\n  def asBoolean: JsonSelection = if (isBoolean) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is null,\n   * otherwise an empty selection.\n   */\n  def asNull: JsonSelection = if (isNull) JsonSelection(self) else JsonSelection.empty\n\n  // ===========================================================================\n  // Direct Accessors\n  // ===========================================================================\n\n  /**\n   * If this is an object, returns its fields as key-value pairs.\n   * Otherwise returns an empty sequence.\n   */\n  def fields: Seq[(String, Json)] = Seq.empty\n\n  /**\n   * If this is an array, returns its elements.\n   * Otherwise returns an empty sequence.\n   */\n  def elements: Seq[Json] = Seq.empty\n\n  /**\n   * If this is a string, returns its value.\n   * Otherwise returns `None`.\n   */\n  def stringValue: Option[String] = None\n\n  /**\n   * If this is a number, returns its string representation.\n   * Otherwise returns `None`.\n   */\n  def numberValue: Option[String] = None\n\n  /**\n   * If this is a boolean, returns its value.\n   * Otherwise returns `None`.\n   */\n  def booleanValue: Option[scala.Boolean] = None\n\n  // ===========================================================================\n  // Navigation\n  // ===========================================================================\n\n  /**\n   * Navigates to values at the given path.\n   *\n   * {{{\n   * json.get(p\"users[0].name\")\n   * json.get(DynamicOptic.root.field(\"users\").at(0).field(\"name\"))\n   * }}}\n   *\n   * @param path The path to navigate\n   * @return A [[JsonSelection]] containing values at the path\n   */\n  def get(path: DynamicOptic): JsonSelection = ???\n\n  /**\n   * Alias for [[get]].\n   */\n  def apply(path: DynamicOptic): JsonSelection = get(path)\n\n  /**\n   * If this is an array, returns a selection containing the element at the given index.\n   * Returns an empty selection if not an array or index is out of bounds.\n   *\n   * @param index The array index (0-based)\n   */\n  def apply(index: Int): JsonSelection = self match {\n    case Json.Array(elems) if index >= 0 && index < elems.size =>\n      JsonSelection(elems(index))\n    case _ =>\n      JsonSelection.empty\n  }\n\n  /**\n   * If this is an object, returns a selection containing the value at the given key.\n   * Returns an empty selection if not an object or key is not present.\n   *\n   * @param key The object key\n   */\n  def apply(key: String): JsonSelection = self match {\n    case Json.Object(flds) =>\n      flds.collectFirst { case (k, v) if k == key => v } match {\n        case Some(v) => JsonSelection(v)\n        case None    => JsonSelection.empty\n      }\n    case _ =>\n      JsonSelection.empty\n  }\n\n  // ===========================================================================\n  // Modification (Json => Json)\n  // ===========================================================================\n\n  /**\n   * Modifies values at the given path using the provided function.\n   *\n   * If the path does not exist, returns this JSON unchanged.\n   *\n   * {{{\n   * json.modify(p\"users[*].age\", {\n   *   case Json.Number(n) => Json.number(n.toInt + 1)\n   *   case other => other\n   * })\n   * }}}\n   *\n   * @param path The path to values to modify\n   * @param f The modification function\n   * @return The modified JSON\n   */\n  def modify(path: DynamicOptic, f: Json => Json): Json = ???\n\n  /**\n   * Modifies values at the given path using a partial function.\n   *\n   * Values for which the partial function is not defined are left unchanged.\n   *\n   * @param path The path to values to modify\n   * @param pf The partial modification function\n   * @return Either an error if the path is invalid, or the modified JSON\n   */\n  def modifyOrFail(path: DynamicOptic, pf: PartialFunction[Json, Json]): Either[JsonError, Json] = ???\n\n  /**\n   * Sets the value at the given path.\n   *\n   * If the path does not exist, attempts to create intermediate structure.\n   * For array indices, the array must already exist and have sufficient length.\n   *\n   * {{{\n   * json.set(p\"user.name\", Json.String(\"Bob\"))\n   * }}}\n   *\n   * @param path The path to set\n   * @param value The value to set\n   * @return The modified JSON\n   */\n  def set(path: DynamicOptic, value: Json): Json = ???\n\n  /**\n   * Sets the value at the given path, returning an error if the path is invalid.\n   *\n   * @param path The path to set\n   * @param value The value to set\n   * @return Either an error or the modified JSON\n   */\n  def setOrFail(path: DynamicOptic, value: Json): Either[JsonError, Json] = ???\n\n  /**\n   * Deletes values at the given path.\n   *\n   * For object fields, removes the key-value pair.\n   * For array elements, removes the element and shifts subsequent elements.\n   *\n   * @param path The path to delete\n   * @return The modified JSON\n   */\n  def delete(path: DynamicOptic): Json = ???\n\n  /**\n   * Deletes values at the given path, returning an error if the path is invalid.\n   *\n   * @param path The path to delete\n   * @return Either an error or the modified JSON\n   */\n  def deleteOrFail(path: DynamicOptic): Either[JsonError, Json] = ???\n\n  /**\n   * Inserts a value at the given path.\n   *\n   * For arrays, inserts at the specified index, shifting subsequent elements.\n   * For objects, adds or replaces the key.\n   *\n   * @param path The path where to insert\n   * @param value The value to insert\n   * @return The modified JSON\n   */\n  def insert(path: DynamicOptic, value: Json): Json = ???\n\n  /**\n   * Inserts a value at the given path, returning an error if invalid.\n   *\n   * @param path The path where to insert\n   * @param value The value to insert\n   * @return Either an error or the modified JSON\n   */\n  def insertOrFail(path: DynamicOptic, value: Json): Either[JsonError, Json] = ???\n\n  // ===========================================================================\n  // Merging\n  // ===========================================================================\n\n  /**\n   * Merges this JSON with another using the specified strategy.\n   *\n   * {{{\n   * val merged = json1.merge(json2, MergeStrategy.Deep)\n   * }}}\n   *\n   * @param other The JSON to merge with\n   * @param strategy The merge strategy (default: [[MergeStrategy.Auto]])\n   * @return The merged JSON\n   */\n  def merge(other: Json, strategy: MergeStrategy = MergeStrategy.Auto): Json = ???\n\n  // ===========================================================================\n  // Patching\n  // ===========================================================================\n\n  /**\n   * Applies a [[JsonPatch]] to this JSON.\n   *\n   * @param patch The patch to apply\n   * @return Either an error if the patch cannot be applied, or the patched JSON\n   */\n  def patch(patch: JsonPatch): Either[JsonError, Json] = ???\n\n  /**\n   * Applies a [[JsonPatch]], throwing on failure.\n   *\n   * @param patch The patch to apply\n   * @return The patched JSON\n   * @throws JsonError if the patch cannot be applied\n   */\n  def patchUnsafe(patch: JsonPatch): Json = this.patch(patch).fold(throw _, identity)\n\n  // ===========================================================================\n  // Transformation\n  // ===========================================================================\n\n  /**\n   * Transforms all values in this JSON bottom-up (children before parents).\n   *\n   * @param f The transformation function receiving path and value\n   * @return The transformed JSON\n   */\n  def transformUp(f: (DynamicOptic, Json) => Json): Json = ???\n\n  /**\n   * Transforms all values in this JSON top-down (parents before children).\n   *\n   * @param f The transformation function receiving path and value\n   * @return The transformed JSON\n   */\n  def transformDown(f: (DynamicOptic, Json) => Json): Json = ???\n\n  /**\n   * Transforms all object keys in this JSON.\n   *\n   * @param f The key transformation function receiving path and key\n   * @return The transformed JSON\n   */\n  def transformKeys(f: (DynamicOptic, String) => String): Json = ???\n\n  // ===========================================================================\n  // Filtering\n  // ===========================================================================\n\n  /**\n   * Removes entries matching the predicate.\n   *\n   * For objects, removes matching key-value pairs.\n   * For arrays, removes matching elements.\n   *\n   * @param p The predicate receiving path and value\n   * @return The filtered JSON\n   */\n  def filterNot(p: (DynamicOptic, Json) => scala.Boolean): Json = ???\n\n  /**\n   * Keeps only entries matching the predicate.\n   *\n   * @param p The predicate receiving path and value\n   * @return The filtered JSON\n   */\n  def filter(p: (DynamicOptic, Json) => scala.Boolean): Json =\n    filterNot((path, json) => !p(path, json))\n\n  // ===========================================================================\n  // Projection\n  // ===========================================================================\n\n  /**\n   * Projects this JSON to include only the specified paths.\n   *\n   * Paths that don't exist are ignored. Structure is preserved.\n   *\n   * {{{\n   * json.project(p\"user.name\", p\"user.email\", p\"meta.created\")\n   * }}}\n   *\n   * @param paths The paths to include\n   * @return A new JSON containing only the specified paths\n   */\n  def project(paths: DynamicOptic*): Json = ???\n\n  // ===========================================================================\n  // Splitting / Partitioning\n  // ===========================================================================\n\n  /**\n   * Partitions this JSON into two based on a predicate.\n   *\n   * Returns a tuple where the first element contains entries satisfying\n   * the predicate, and the second contains entries that don't.\n   *\n   * @param p The predicate receiving path and value\n   * @return A tuple of (matching, non-matching) JSON values\n   */\n  def partition(p: (DynamicOptic, Json) => scala.Boolean): (Json, Json) = ???\n\n  // ===========================================================================\n  // Normalization\n  // ===========================================================================\n\n  /**\n   * Returns a normalized version of this JSON.\n   *\n   * Normalization includes:\n   *  - Sorting object keys alphabetically\n   *  - Normalizing number representations\n   *\n   * Useful for comparison and hashing.\n   */\n  def normalize: Json = ???\n\n  /**\n   * Returns this JSON with all object keys sorted alphabetically (recursive).\n   */\n  def sortKeys: Json = self match {\n    case Json.Object(flds) =>\n      Json.Object(flds.map { case (k, v) => (k, v.sortKeys) }.sortBy(_._1))\n    case Json.Array(elems) =>\n      Json.Array(elems.map(_.sortKeys))\n    case other =>\n      other\n  }\n\n  /**\n   * Returns this JSON with all null values removed from objects.\n   */\n  def dropNulls: Json = self match {\n    case Json.Object(flds) =>\n      Json.Object(flds.collect { case (k, v) if !v.isNull => (k, v.dropNulls) })\n    case Json.Array(elems) =>\n      Json.Array(elems.map(_.dropNulls))\n    case other =>\n      other\n  }\n\n  /**\n   * Returns this JSON with empty objects and arrays removed.\n   */\n  def dropEmpty: Json = self match {\n    case Json.Object(flds) =>\n      val filtered = flds.collect {\n        case (k, v) =>\n          val dropped = v.dropEmpty\n          dropped match {\n            case Json.Object(f) if f.isEmpty => None\n            case Json.Array(e) if e.isEmpty  => None\n            case other                       => Some((k, other))\n          }\n      }.flatten\n      Json.Object(filtered)\n    case Json.Array(elems) =>\n      val filtered = elems.map(_.dropEmpty).filter {\n        case Json.Object(f) if f.isEmpty => false\n        case Json.Array(e) if e.isEmpty  => false\n        case _                           => true\n      }\n      Json.Array(filtered)\n    case other =>\n      other\n  }\n\n  // ===========================================================================\n  // Diffing\n  // ===========================================================================\n\n  /**\n   * Computes a [[JsonPatch]] that transforms this JSON into the target.\n   *\n   * {{{\n   * val patch = source.diff(target)\n   * source.patch(patch) == Right(target) // true\n   * }}}\n   *\n   * @param target The target JSON\n   * @return A patch that transforms this into target\n   */\n  def diff(target: Json): JsonPatch = ???\n\n  // ===========================================================================\n  // Folding\n  // ===========================================================================\n\n  /**\n   * Folds over this JSON top-down (parents before children).\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function receiving path, value, and accumulator\n   * @tparam B The accumulator type\n   * @return The final accumulated value\n   */\n  def foldDown[B](z: B)(f: (DynamicOptic, Json, B) => B): B = ???\n\n  /**\n   * Folds over this JSON bottom-up (children before parents).\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function receiving path, value, and accumulator\n   * @tparam B The accumulator type\n   * @return The final accumulated value\n   */\n  def foldUp[B](z: B)(f: (DynamicOptic, Json, B) => B): B = ???\n\n  /**\n   * Folds over this JSON top-down, allowing the fold function to fail.\n   *\n   * Short-circuits on first failure.\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function that may fail\n   * @tparam B The accumulator type\n   * @return Either an error or the final accumulated value\n   */\n  def foldDownOrFail[B](z: B)(f: (DynamicOptic, Json, B) => Either[JsonError, B]): Either[JsonError, B] = ???\n\n  /**\n   * Folds over this JSON bottom-up, allowing the fold function to fail.\n   *\n   * Short-circuits on first failure.\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function that may fail\n   * @tparam B The accumulator type\n   * @return Either an error or the final accumulated value\n   */\n  def foldUpOrFail[B](z: B)(f: (DynamicOptic, Json, B) => Either[JsonError, B]): Either[JsonError, B] = ???\n\n  // ===========================================================================\n  // Querying\n  // ===========================================================================\n\n  /**\n   * Selects all values matching the predicate.\n   *\n   * @param p The predicate receiving path and value\n   * @return A [[JsonSelection]] containing matching values\n   */\n  def query(p: (DynamicOptic, Json) => scala.Boolean): JsonSelection = ???\n\n  // ===========================================================================\n  // Validation\n  // ===========================================================================\n\n  /**\n   * Validates this JSON against a [[JsonSchema]].\n   *\n   * @param schema The schema to validate against\n   * @return `None` if valid, `Some(error)` if invalid\n   */\n  def check(schema: JsonSchema): Option[SchemaError] = ???\n\n  /**\n   * Returns `true` if this JSON conforms to the given [[JsonSchema]].\n   */\n  def conforms(schema: JsonSchema): scala.Boolean = check(schema).isEmpty\n\n  // ===========================================================================\n  // KV Representation\n  // ===========================================================================\n\n  /**\n   * Flattens this JSON to a sequence of path-value pairs.\n   *\n   * Only leaf values (primitives, empty arrays, empty objects) are included.\n   *\n   * {{{\n   * Json.parse(\"\"\"{\"a\": {\"b\": 1}, \"c\": [2, 3]}\"\"\").toKV\n   * // Seq(\n   * //   (p\"a.b\", Json.Number(\"1\")),\n   * //   (p\"c[0]\", Json.Number(\"2\")),\n   * //   (p\"c[1]\", Json.Number(\"3\"))\n   * // )\n   * }}}\n   */\n  def toKV: Seq[(DynamicOptic, Json)] = ???\n\n  // ===========================================================================\n  // Comparison\n  // ===========================================================================\n\n  /**\n   * Compares this JSON to another for ordering.\n   *\n   * Ordering is defined as:\n   *  1. Null < Boolean < Number < String < Array < Object\n   *  2. Within types, natural ordering applies\n   */\n  def compare(that: Json): Int = (self, that) match {\n    case (Json.Null, Json.Null)               => 0\n    case (Json.Null, _)                       => -1\n    case (_, Json.Null)                       => 1\n    case (Json.Boolean(a), Json.Boolean(b))   => a.compare(b)\n    case (Json.Boolean(_), _)                 => -1\n    case (_, Json.Boolean(_))                 => 1\n    case (Json.Number(a), Json.Number(b))     => BigDecimal(a).compare(BigDecimal(b))\n    case (Json.Number(_), _)                  => -1\n    case (_, Json.Number(_))                  => 1\n    case (Json.String(a), Json.String(b))     => a.compare(b)\n    case (Json.String(_), _)                  => -1\n    case (_, Json.String(_))                  => 1\n    case (Json.Array(a), Json.Array(b))       => compareArrays(a, b)\n    case (Json.Array(_), _)                   => -1\n    case (_, Json.Array(_))                   => 1\n    case (Json.Object(a), Json.Object(b))     => compareObjects(a, b)\n  }\n\n  private def compareArrays(a: Vector[Json], b: Vector[Json]): Int = {\n    val len = math.min(a.size, b.size)\n    var i   = 0\n    while (i < len) {\n      val cmp = a(i).compare(b(i))\n      if (cmp != 0) return cmp\n      i += 1\n    }\n    a.size.compare(b.size)\n  }\n\n  private def compareObjects(a: Vector[(String, Json)], b: Vector[(String, Json)]): Int = {\n    val aSorted = a.sortBy(_._1)\n    val bSorted = b.sortBy(_._1)\n    val len     = math.min(aSorted.size, bSorted.size)\n    var i       = 0\n    while (i < len) {\n      val (ak, av) = aSorted(i)\n      val (bk, bv) = bSorted(i)\n      val keyCmp   = ak.compare(bk)\n      if (keyCmp != 0) return keyCmp\n      val valCmp = av.compare(bv)\n      if (valCmp != 0) return valCmp\n      i += 1\n    }\n    aSorted.size.compare(bSorted.size)\n  }\n\n  // ===========================================================================\n  // DynamicValue Interop\n  // ===========================================================================\n\n  /**\n   * Converts this JSON to a [[DynamicValue]].\n   *\n   * This conversion is lossless; all JSON values can be represented as DynamicValue.\n   */\n  def toDynamicValue: DynamicValue = self match {\n    case Json.Null =>\n      DynamicValue.Primitive(PrimitiveValue.Unit)\n    case Json.Boolean(v) =>\n      DynamicValue.Primitive(PrimitiveValue.Boolean(v))\n    case Json.Number(v) =>\n      // Preserve as BigDecimal for maximum precision\n      DynamicValue.Primitive(PrimitiveValue.BigDecimal(BigDecimal(v)))\n    case Json.String(v) =>\n      DynamicValue.Primitive(PrimitiveValue.String(v))\n    case Json.Array(elems) =>\n      DynamicValue.Sequence(elems.map(_.toDynamicValue))\n    case Json.Object(flds) =>\n      DynamicValue.Record(flds.map { case (k, v) => (k, v.toDynamicValue) })\n  }\n\n  // ===========================================================================\n  // Typed Decoding (Json => A)\n  // ===========================================================================\n\n  /**\n   * Decodes this JSON to a typed value.\n   *\n   * Uses implicit [[JsonDecoder]] which prefers explicit codecs over schema derivation.\n   *\n   * {{{\n   * val person: Either[JsonError, Person] = json.as[Person]\n   * }}}\n   *\n   * @tparam A The target type\n   * @return Either an error or the decoded value\n   */\n  def as[A](implicit decoder: JsonDecoder[A]): Either[JsonError, A] = decoder.decode(self)\n\n  /**\n   * Decodes this JSON to a typed value, throwing on failure.\n   *\n   * @tparam A The target type\n   * @return The decoded value\n   * @throws JsonError if decoding fails\n   */\n  def asUnsafe[A](implicit decoder: JsonDecoder[A]): A = as[A].fold(throw _, identity)\n\n  /**\n   * Internal: decode using an explicit codec.\n   */\n  private[json] def decodeWith[A](codec: JsonBinaryCodec[A]): Either[JsonError, A] = ???\n\n  // ===========================================================================\n  // Encoding (Json => String/Bytes)\n  // ===========================================================================\n\n  /**\n   * Encodes this JSON to a compact string (no extra whitespace).\n   */\n  def print: String = encode(WriterConfig)\n\n  /**\n   * Encodes this JSON to a string using the specified configuration.\n   *\n   * @param config Writer configuration (indentation, unicode escaping, etc.)\n   */\n  def print(config: WriterConfig): String = encode(config)\n\n  /**\n   * Alias for [[print]].\n   */\n  def encode: String = encode(WriterConfig)\n\n  /**\n   * Encodes this JSON to a string using the specified configuration.\n   *\n   * @param config Writer configuration\n   */\n  def encode(config: WriterConfig): String = ???\n\n  /**\n   * Encodes this JSON and writes to the provided [[Writer]].\n   *\n   * @param writer The writer to write to\n   */\n  def printTo(writer: Writer): Unit = printTo(writer, WriterConfig)\n\n  /**\n   * Encodes this JSON and writes to the provided [[Writer]] with configuration.\n   *\n   * @param writer The writer to write to\n   * @param config Writer configuration\n   */\n  def printTo(writer: Writer, config: WriterConfig): Unit = ???\n\n  /**\n   * Encodes this JSON to a byte array (UTF-8).\n   */\n  def encodeToBytes: Array[Byte] = encodeToBytes(WriterConfig)\n\n  /**\n   * Encodes this JSON to a byte array (UTF-8) with configuration.\n   *\n   * @param config Writer configuration\n   */\n  def encodeToBytes(config: WriterConfig): Array[Byte] = ???\n\n  /**\n   * Encodes this JSON to a [[Chunk]] of bytes (UTF-8).\n   */\n  def encodeToChunk: Chunk[Byte] = encodeToChunk(WriterConfig)\n\n  /**\n   * Encodes this JSON to a [[Chunk]] of bytes (UTF-8) with configuration.\n   *\n   * @param config Writer configuration\n   */\n  def encodeToChunk(config: WriterConfig): Chunk[Byte] = ???\n\n  /**\n   * Encodes this JSON into the provided [[ByteBuffer]].\n   *\n   * @param buffer The buffer to write to\n   */\n  def encodeTo(buffer: ByteBuffer): Unit = encodeTo(buffer, WriterConfig)\n\n  /**\n   * Encodes this JSON into the provided [[ByteBuffer]] with configuration.\n   *\n   * @param buffer The buffer to write to\n   * @param config Writer configuration\n   */\n  def encodeTo(buffer: ByteBuffer, config: WriterConfig): Unit = ???\n\n  // ===========================================================================\n  // Standard Methods\n  // ===========================================================================\n\n  override def hashCode(): Int = self match {\n    case Json.Null           => 0\n    case Json.Boolean(v)     => v.hashCode()\n    case Json.Number(v)      => BigDecimal(v).hashCode()\n    case Json.String(v)      => v.hashCode()\n    case Json.Array(elems)   => elems.hashCode()\n    case Json.Object(flds)   => flds.sortBy(_._1).hashCode()\n  }\n\n  override def equals(that: Any): Boolean = that match {\n    case other: Json => compare(other) == 0\n    case _           => false\n  }\n\n  override def toString: String = print\n}\n\nobject Json {\n\n  // ===========================================================================\n  // ADT Cases\n  // ===========================================================================\n\n  /**\n   * A JSON object: an unordered collection of key-value pairs.\n   *\n   * @param fields The key-value pairs. Keys should be unique; if duplicates\n   *               are present, behavior of accessors is undefined.\n   */\n  final case class Object(fields: Vector[(String, Json)]) extends Json {\n    override def isObject: scala.Boolean                = true\n    override def fields: Seq[(String, Json)]            = fields\n  }\n\n  object Object {\n\n    /**\n     * Creates an empty JSON object.\n     */\n    val empty: Object = Object(Vector.empty)\n\n    /**\n     * Creates a JSON object from key-value pairs.\n     */\n    def apply(fields: (String, Json)*): Object = Object(fields.toVector)\n  }\n\n  /**\n   * A JSON array: an ordered sequence of values.\n   *\n   * @param elements The array elements\n   */\n  final case class Array(elements: Vector[Json]) extends Json {\n    override def isArray: scala.Boolean  = true\n    override def elements: Seq[Json]     = elements\n  }\n\n  object Array {\n\n    /**\n     * Creates an empty JSON array.\n     */\n    val empty: Array = Array(Vector.empty)\n\n    /**\n     * Creates a JSON array from elements.\n     */\n    def apply(elements: Json*): Array = Array(elements.toVector)\n  }\n\n  /**\n   * A JSON string.\n   *\n   * @param value The string value (unescaped)\n   */\n  final case class String(value: java.lang.String) extends Json {\n    override def isString: scala.Boolean              = true\n    override def stringValue: Option[java.lang.String] = Some(value)\n  }\n\n  /**\n   * A JSON number.\n   *\n   * Stored as a string to preserve exact representation (precision, trailing zeros, etc.).\n   * Provides lazy conversion to numeric types.\n   *\n   * @param value The number as a string (should be valid JSON number syntax)\n   */\n  final case class Number(value: java.lang.String) extends Json {\n    override def isNumber: scala.Boolean                = true\n    override def numberValue: Option[java.lang.String]  = Some(value)\n\n    /**\n     * Converts to `Int`, truncating if necessary.\n     */\n    lazy val toInt: Int = toBigDecimal.toInt\n\n    /**\n     * Converts to `Long`, truncating if necessary.\n     */\n    lazy val toLong: Long = toBigDecimal.toLong\n\n    /**\n     * Converts to `Float`.\n     */\n    lazy val toFloat: Float = value.toFloat\n\n    /**\n     * Converts to `Double`.\n     */\n    lazy val toDouble: Double = value.toDouble\n\n    /**\n     * Converts to `BigInt`, truncating fractional part.\n     */\n    lazy val toBigInt: BigInt = toBigDecimal.toBigInt\n\n    /**\n     * Converts to `BigDecimal` (lossless).\n     */\n    lazy val toBigDecimal: BigDecimal = BigDecimal(value)\n  }\n\n  /**\n   * A JSON boolean.\n   *\n   * @param value The boolean value\n   */\n  final case class Boolean(value: scala.Boolean) extends Json {\n    override def isBoolean: scala.Boolean              = true\n    override def booleanValue: Option[scala.Boolean]   = Some(value)\n  }\n\n  object Boolean {\n    val True: Boolean  = Boolean(true)\n    val False: Boolean = Boolean(false)\n  }\n\n  /**\n   * The JSON null value.\n   */\n  case object Null extends Json {\n    override def isNull: scala.Boolean = true\n  }\n\n  // ===========================================================================\n  // Convenience Constructors\n  // ===========================================================================\n\n  /**\n   * Creates a JSON number from an `Int`.\n   */\n  def number(n: Int): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Long`.\n   */\n  def number(n: Long): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Float`.\n   */\n  def number(n: Float): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Double`.\n   */\n  def number(n: Double): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `BigInt`.\n   */\n  def number(n: BigInt): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `BigDecimal`.\n   */\n  def number(n: BigDecimal): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Short`.\n   */\n  def number(n: Short): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Byte`.\n   */\n  def number(n: Byte): Number = Number(n.toString)\n\n  // ===========================================================================\n  // Parsing / Decoding (String/Bytes => Json)\n  // ===========================================================================\n\n  /**\n   * Parses a JSON value from a string.\n   *\n   * @param s The JSON string\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(s: java.lang.String): Either[JsonError, Json] = decode(s)\n\n  /**\n   * Parses a JSON value from a `CharSequence`.\n   *\n   * @param s The JSON character sequence\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(s: CharSequence): Either[JsonError, Json] = decode(s)\n\n  /**\n   * Parses a JSON value from a byte array (UTF-8).\n   *\n   * @param bytes The JSON bytes\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(bytes: scala.Array[Byte]): Either[JsonError, Json] = decode(bytes)\n\n  /**\n   * Parses a JSON value from a [[Chunk]] of bytes (UTF-8).\n   *\n   * @param chunk The JSON bytes\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(chunk: Chunk[Byte]): Either[JsonError, Json] = decode(chunk)\n\n  /**\n   * Parses a JSON value from a [[ByteBuffer]] (UTF-8).\n   *\n   * @param buffer The JSON bytes\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(buffer: ByteBuffer): Either[JsonError, Json] = decode(buffer)\n\n  /**\n   * Parses a JSON value from a [[Reader]].\n   *\n   * @param reader The reader to read from\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(reader: Reader): Either[JsonError, Json] = decode(reader)\n\n  /**\n   * Decodes a JSON value from a string.\n   */\n  def decode(s: java.lang.String): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a `CharSequence`.\n   */\n  def decode(s: CharSequence): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a byte array (UTF-8).\n   */\n  def decode(bytes: scala.Array[Byte]): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a [[Chunk]] of bytes (UTF-8).\n   */\n  def decode(chunk: Chunk[Byte]): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a [[ByteBuffer]] (UTF-8).\n   */\n  def decode(buffer: ByteBuffer): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a [[Reader]].\n   */\n  def decode(reader: Reader): Either[JsonError, Json] = ???\n\n  /**\n   * Parses a JSON value from a string, throwing on failure.\n   *\n   * @param s The JSON string\n   * @return The parsed JSON\n   * @throws JsonError if parsing fails\n   */\n  def parseUnsafe(s: java.lang.String): Json = decode(s).fold(throw _, identity)\n\n  /**\n   * Alias for [[parseUnsafe]].\n   */\n  def decodeUnsafe(s: java.lang.String): Json = parseUnsafe(s)\n\n  // ===========================================================================\n  // Typed Encoding (A => Json)\n  // ===========================================================================\n\n  /**\n   * Encodes a typed value to JSON.\n   *\n   * Uses implicit [[JsonEncoder]] which prefers explicit codecs over schema derivation.\n   *\n   * {{{\n   * val json = Json.from(Person(\"Alice\", 30))\n   * }}}\n   *\n   * @param value The value to encode\n   * @return The encoded JSON\n   */\n  def from[A](value: A)(implicit encoder: JsonEncoder[A]): Json = encoder.encode(value)\n\n  /**\n   * Internal: encode using an explicit codec.\n   */\n  private[json] def encodeWith[A](value: A, codec: JsonBinaryCodec[A]): Json = ???\n\n  // ===========================================================================\n  // DynamicValue Interop\n  // ===========================================================================\n\n  /**\n   * Converts a [[DynamicValue]] to JSON.\n   *\n   * This conversion is lossy for `DynamicValue` types that have no JSON equivalent:\n   *  - `PrimitiveValue` types like `java.time.*` are converted to strings\n   *  - `DynamicValue.Variant` uses a discriminator field\n   *\n   * @param value The dynamic value to convert\n   * @return The JSON representation\n   */\n  def fromDynamicValue(value: DynamicValue): Json = value match {\n    case DynamicValue.Primitive(pv) => fromPrimitiveValue(pv)\n    case DynamicValue.Record(flds) =>\n      Object(flds.map { case (k, v) => (k, fromDynamicValue(v)) })\n    case DynamicValue.Variant(caseName, v) =>\n      Object(Vector(\"_type\" -> String(caseName), \"_value\" -> fromDynamicValue(v)))\n    case DynamicValue.Sequence(elems) =>\n      Array(elems.map(fromDynamicValue))\n    case DynamicValue.Map(entries) =>\n      Array(entries.map { case (k, v) =>\n        Object(Vector(\"key\" -> fromDynamicValue(k), \"value\" -> fromDynamicValue(v)))\n      })\n  }\n\n  private def fromPrimitiveValue(pv: PrimitiveValue): Json = pv match {\n    case PrimitiveValue.Unit              => Null\n    case PrimitiveValue.Boolean(v)        => Boolean(v)\n    case PrimitiveValue.Byte(v)           => number(v)\n    case PrimitiveValue.Short(v)          => number(v)\n    case PrimitiveValue.Int(v)            => number(v)\n    case PrimitiveValue.Long(v)           => number(v)\n    case PrimitiveValue.Float(v)          => number(v)\n    case PrimitiveValue.Double(v)         => number(v)\n    case PrimitiveValue.Char(v)           => String(v.toString)\n    case PrimitiveValue.String(v)         => String(v)\n    case PrimitiveValue.BigInt(v)         => number(v)\n    case PrimitiveValue.BigDecimal(v)     => number(v)\n    case PrimitiveValue.DayOfWeek(v)      => String(v.toString)\n    case PrimitiveValue.Duration(v)       => String(v.toString)\n    case PrimitiveValue.Instant(v)        => String(v.toString)\n    case PrimitiveValue.LocalDate(v)      => String(v.toString)\n    case PrimitiveValue.LocalDateTime(v)  => String(v.toString)\n    case PrimitiveValue.LocalTime(v)      => String(v.toString)\n    case PrimitiveValue.Month(v)          => String(v.toString)\n    case PrimitiveValue.MonthDay(v)       => String(v.toString)\n    case PrimitiveValue.OffsetDateTime(v) => String(v.toString)\n    case PrimitiveValue.OffsetTime(v)     => String(v.toString)\n    case PrimitiveValue.Period(v)         => String(v.toString)\n    case PrimitiveValue.Year(v)           => String(v.toString)\n    case PrimitiveValue.YearMonth(v)      => String(v.toString)\n    case PrimitiveValue.ZoneId(v)         => String(v.getId)\n    case PrimitiveValue.ZoneOffset(v)     => String(v.toString)\n    case PrimitiveValue.ZonedDateTime(v)  => String(v.toString)\n    case PrimitiveValue.Currency(v)       => String(v.getCurrencyCode)\n    case PrimitiveValue.UUID(v)           => String(v.toString)\n  }\n\n  // ===========================================================================\n  // KV Interop\n  // ===========================================================================\n\n  /**\n   * Assembles JSON from a sequence of path-value pairs.\n   *\n   * {{{\n   * Json.fromKV(Seq(\n   *   p\"a.b\" -> Json.number(1),\n   *   p\"a.c\" -> Json.String(\"x\"),\n   *   p\"d[0]\" -> Json.Boolean(true)\n   * ))\n   * // {\"a\": {\"b\": 1, \"c\": \"x\"}, \"d\": [true]}\n   * }}}\n   *\n   * @param kvs The path-value pairs\n   * @return Either an error (for conflicting paths) or the assembled JSON\n   */\n  def fromKV(kvs: Seq[(DynamicOptic, Json)]): Either[JsonError, Json] = ???\n\n  /**\n   * Assembles JSON from path-value pairs, throwing on conflict.\n   */\n  def fromKVUnsafe(kvs: Seq[(DynamicOptic, Json)]): Json = fromKV(kvs).fold(throw _, identity)\n\n  // ===========================================================================\n  // Patch Interop\n  // ===========================================================================\n\n  /**\n   * Serializes a [[JsonPatch]] to its JSON representation.\n   *\n   * The format follows RFC 6902 (JSON Patch) for standard operations,\n   * with extensions for LCS-based sequence diffs.\n   *\n   * @param patch The patch to serialize\n   * @return The JSON representation of the patch\n   */\n  def fromJsonPatch(patch: JsonPatch): Json = ???\n\n  /**\n   * Deserializes a JSON representation into a [[JsonPatch]].\n   *\n   * @param json The JSON patch representation\n   * @return Either an error or the parsed patch\n   */\n  def toJsonPatch(json: Json): Either[JsonError, JsonPatch] = ???\n\n  // ===========================================================================\n  // Ordering\n  // ===========================================================================\n\n  /**\n   * Ordering for JSON values.\n   *\n   * Order: Null < Boolean < Number < String < Array < Object\n   */\n  implicit val ordering: Ordering[Json] = (x: Json, y: Json) => x.compare(y)\n}\n\n// =============================================================================\n// MERGE STRATEGY\n// =============================================================================\n\n/**\n * Strategy for merging JSON values.\n */\nsealed trait MergeStrategy\n\nobject MergeStrategy {\n\n  /**\n   * Automatically determines merge behavior based on value types:\n   *  - Objects: deep merge (recurse into matching keys)\n   *  - Arrays: concatenate\n   *  - Primitives: right wins\n   */\n  case object Auto extends MergeStrategy\n\n  /**\n   * Deep merge for objects; concatenate arrays.\n   */\n  case object Deep extends MergeStrategy\n\n  /**\n   * Shallow merge: right value wins for any key conflict.\n   */\n  case object Shallow extends MergeStrategy\n\n  /**\n   * Concatenate arrays; for objects and primitives, right wins.\n   */\n  case object Concat extends MergeStrategy\n\n  /**\n   * Right value always wins (replacement).\n   */\n  case object Replace extends MergeStrategy\n\n  /**\n   * Custom merge function.\n   *\n   * @param f A function receiving path and both values, returning merged result\n   */\n  final case class Custom(f: (DynamicOptic, Json, Json) => Json) extends MergeStrategy\n}\n\n// =============================================================================\n// STRING INTERPOLATORS\n// =============================================================================\n\n/**\n * Provides string interpolators for JSON paths and literals.\n *\n * Import with:\n * {{{\n * import zio.blocks.schema.json.interpolators._\n * }}}\n *\n * ==Path Syntax==\n *\n * The `p` interpolator creates [[DynamicOptic]] paths using a JSONPath-compatible dialect:\n *\n * {{{\n * p\"foo.bar\"           // fields \"foo\" then \"bar\"\n * p\"users[0]\"          // field \"users\", then index 0\n * p\"users[0].name\"     // field \"users\", index 0, field \"name\"\n * p\"items[*]\"          // field \"items\", then all array elements\n * p\"config{*}\"         // field \"config\", then all object values\n * p\"config{*:}\"        // field \"config\", then all object keys\n * p\"[0,2,5]\"           // indices 0, 2, and 5\n * p\"[0:5]\"             // slice: indices 0 through 4\n * p\"[::2]\"             // slice: every other element\n * p\"`field.name`\"      // field with dots in name (backtick escaping)\n * p\"\"\"[\"field\"]\"\"\"     // alternate field syntax (bracket notation)\n * }}}\n *\n * ===JSONPath Compatibility===\n *\n * This syntax is a dialect of JSONPath (RFC 9535). Most JSONPath expressions work:\n *  - `$.foo.bar` - root prefix is optional and ignored\n *  - `.field`, `[\"field\"]` - field access\n *  - `[n]`, `[*]`, `[m,n]`, `[m:n]` - array access\n *\n * '''Not supported:'''\n *  - `..` (recursive descent)\n *  - `[?()]` (filter expressions)\n *\n * ===Extensions beyond JSONPath:===\n *  - `{*}` - all object values (explicit, vs `[*]` which is array-focused in JSONPath)\n *  - `{*:}` - all object keys (not expressible in standard JSONPath)\n *  - Backtick escaping for field names\n */\nobject interpolators {\n\n  implicit class JsonPathInterpolator(val sc: StringContext) extends AnyVal {\n\n    /**\n     * Creates a [[DynamicOptic]] from a path string at compile time.\n     *\n     * @return The parsed [[DynamicOptic]]\n     */\n    def p(args: Any*): DynamicOptic = macro PathMacros.pathInterpolator\n  }\n\n  implicit class JsonLiteralInterpolator(val sc: StringContext) extends AnyVal {\n\n    /**\n     * Creates a [[Json]] value from a JSON literal at compile time.\n     *\n     * {{{\n     * j\"\"\"{\"name\": \"Alice\", \"age\": 30}\"\"\"\n     * j\"[1, 2, 3]\"\n     * j\"null\"\n     * }}}\n     *\n     * Interpolated values are converted to JSON:\n     * {{{\n     * val name = \"Bob\"\n     * val age = 25\n     * j\"\"\"{\"name\": $name, \"age\": $age}\"\"\"\n     * }}}\n     *\n     * @return The parsed [[Json]] value\n     */\n    def j(args: Any*): Json = macro PathMacros.jsonInterpolator\n  }\n}\n\n/**\n * Macro implementations for string interpolators.\n * \n * Separate implementations would be needed for Scala 2 and Scala 3.\n */\nobject PathMacros {\n  import scala.reflect.macros.blackbox\n\n  def pathInterpolator(c: blackbox.Context)(args: c.Expr[Any]*): c.Expr[DynamicOptic] = ???\n\n  def jsonInterpolator(c: blackbox.Context)(args: c.Expr[Any]*): c.Expr[Json] = ???\n}\n\n// =============================================================================\n// PLACEHOLDER TYPES (assumed to exist)\n// =============================================================================\n\n/**\n * Represents a JSON Schema for validation.\n *\n * Placeholder - actual implementation TBD.\n */\nsealed trait JsonSchema\n\nobject JsonSchema {\n  // Placeholder\n}\n\n/**\n * Represents a patch that can be applied to JSON values.\n *\n * Supports RFC 6902 operations (add, remove, replace, move, copy, test)\n * plus extensions for LCS-based sequence diffs and string diffs.\n *\n * Placeholder - actual implementation TBD.\n */\nsealed trait JsonPatch {\n\n  /**\n   * Converts this JSON patch to a [[DynamicPatch]].\n   */\n  def toDynamicPatch: DynamicPatch\n}\n\nobject JsonPatch {\n\n  /**\n   * Creates an empty patch (no operations).\n   */\n  val empty: JsonPatch = ???\n\n  /**\n   * Creates a patch from a [[DynamicPatch]].\n   *\n   * May fail if the DynamicPatch contains operations not representable in JSON.\n   */\n  def fromDynamicPatch(patch: DynamicPatch): Either[JsonError, JsonPatch] = ???\n}\n\n/**\n * Represents a patch that can be applied to [[DynamicValue]].\n *\n * Placeholder - actual implementation TBD.\n */\nsealed trait DynamicPatch\n\nobject DynamicPatch {\n\n  /**\n   * Creates an empty patch (no operations).\n   */\n  val empty: DynamicPatch = ???\n}\n```",
                  "html_url": "https://github.com/zio/zio-blocks/issues/679"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#679",
              "body": "The following is a sketch of what a proper `Json` data type should look like, including constructors, methods, and related types. Note that `DynamicPatch`, `JsonPatch`, and `JsonSchema` are all out-of-scope for this ticket.\n\n## Sketch\n\n```scala\npackage zio.blocks.schema.json\n\nimport zio.blocks.chunk.Chunk\nimport zio.blocks.schema.{DynamicOptic, DynamicValue, PrimitiveValue, Schema, SchemaError}\n\nimport java.io.{Reader, Writer}\nimport java.nio.ByteBuffer\nimport scala.util.control.NoStackTrace\n\n// =============================================================================\n// JSON ERROR\n// =============================================================================\n\n/**\n * Represents an error that occurred during JSON parsing, encoding, or processing.\n *\n * NOTE: This should replace JsonBinaryCodecError and be moved to `zio.block.schema.json`.\n *\n * @param message A human-readable description of the error\n * @param path The location in the JSON structure where the error occurred,\n *             represented as a [[DynamicOptic]]\n * @param offset Optional byte offset in the input where the error occurred\n * @param line Optional 1-indexed line number where the error occurred\n * @param column Optional 1-indexed column number where the error occurred\n */\nfinal case class JsonError(\n  message: String,\n  path: DynamicOptic,\n  offset: Option[Long],\n  line: Option[Int],\n  column: Option[Int]\n) extends Exception with NoStackTrace {\n\n  override def getMessage: String = {\n    val posInfo = (line, column) match {\n      case (Some(l), Some(c)) => s\" at line $l, column $c\"\n      case _                  => offset.map(o => s\" at offset $o\").getOrElse(\"\")\n    }\n    val pathInfo = if (path.nodes.isEmpty) \"\" else s\" at path $path\"\n    s\"$message$pathInfo$posInfo\"\n  }\n\n  /**\n   * Combines this error with another, preserving both error messages.\n   */\n  def ++(other: JsonError): JsonError =\n    JsonError(s\"${this.message}; ${other.message}\", this.path, this.offset, this.line, this.column)\n}\n\nobject JsonError {\n\n  /**\n   * Creates a JsonError with only a message, using root path and no position info.\n   */\n  def apply(message: String): JsonError =\n    JsonError(message, DynamicOptic.root, None, None, None)\n\n  /**\n   * Creates a JsonError with a message and path, no position info.\n   */\n  def apply(message: String, path: DynamicOptic): JsonError =\n    JsonError(message, path, None, None, None)\n\n  /**\n   * Converts a [[SchemaError]] to a [[JsonError]].\n   */\n  def fromSchemaError(error: SchemaError): JsonError =\n    JsonError(error.message, DynamicOptic.root, None, None, None)\n}\n\n// =============================================================================\n// JSON DECODER / ENCODER (implicit priority resolution)\n// =============================================================================\n\n/**\n * Type class for decoding [[Json]] values into Scala types.\n *\n * Implicit resolution prefers explicitly provided [[JsonBinaryCodec]] instances\n * over schema-derived instances, allowing users to override derived behavior.\n */\nsealed trait JsonDecoder[A] {\n\n  /**\n   * Decodes a [[Json]] value into type `A`.\n   *\n   * @param json The JSON value to decode\n   * @return Either a [[JsonError]] on failure, or the decoded value\n   */\n  def decode(json: Json): Either[JsonError, A]\n}\n\nobject JsonDecoder extends JsonDecoderLowPriority {\n\n  def apply[A](implicit decoder: JsonDecoder[A]): JsonDecoder[A] = decoder\n\n  /**\n   * Higher priority: use an explicitly provided [[JsonBinaryCodec]].\n   */\n  implicit def fromCodec[A](implicit codec: JsonBinaryCodec[A]): JsonDecoder[A] =\n    new JsonDecoder[A] {\n      def decode(json: Json): Either[JsonError, A] = json.decodeWith(codec)\n    }\n}\n\n/**\n * Lower priority implicits for [[JsonDecoder]].\n */\ntrait JsonDecoderLowPriority {\n\n  /**\n   * Lower priority: derive a codec from an implicit [[Schema]].\n   */\n  implicit def fromSchema[A](implicit schema: Schema[A]): JsonDecoder[A] =\n    new JsonDecoder[A] {\n      private lazy val codec: JsonBinaryCodec[A] = schema.derive(JsonBinaryCodecDeriver)\n      def decode(json: Json): Either[JsonError, A] = json.decodeWith(codec)\n    }\n}\n\n/**\n * Type class for encoding Scala types into [[Json]] values.\n *\n * Implicit resolution prefers explicitly provided [[JsonBinaryCodec]] instances\n * over schema-derived instances, allowing users to override derived behavior.\n */\nsealed trait JsonEncoder[A] {\n\n  /**\n   * Encodes a value of type `A` into [[Json]].\n   *\n   * @param value The value to encode\n   * @return The encoded JSON value\n   */\n  def encode(value: A): Json\n}\n\nobject JsonEncoder extends JsonEncoderLowPriority {\n\n  def apply[A](implicit encoder: JsonEncoder[A]): JsonEncoder[A] = encoder\n\n  /**\n   * Higher priority: use an explicitly provided [[JsonBinaryCodec]].\n   */\n  implicit def fromCodec[A](implicit codec: JsonBinaryCodec[A]): JsonEncoder[A] =\n    new JsonEncoder[A] {\n      def encode(value: A): Json = Json.encodeWith(value, codec)\n    }\n}\n\n/**\n * Lower priority implicits for [[JsonEncoder]].\n */\ntrait JsonEncoderLowPriority {\n\n  /**\n   * Lower priority: derive a codec from an implicit [[Schema]].\n   */\n  implicit def fromSchema[A](implicit schema: Schema[A]): JsonEncoder[A] =\n    new JsonEncoder[A] {\n      private lazy val codec: JsonBinaryCodec[A] = schema.derive(JsonBinaryCodecDeriver)\n      def encode(value: A): Json = Json.encodeWith(value, codec)\n    }\n}\n\n// =============================================================================\n// JSON SELECTION\n// =============================================================================\n\n/**\n * Represents a selection of zero or more JSON values, with accumulated errors.\n *\n * `JsonSelection` enables fluent chaining of operations that may fail without\n * requiring immediate error handling. Operations are applied to all values in\n * the selection, and errors are accumulated.\n *\n * {{{\n * val selection: JsonSelection = json.get(p\"users[*].name\")\n * val result: Either[SchemaError, Vector[Json]] = selection.toEither\n * }}}\n */\nfinal case class JsonSelection(toEither: Either[SchemaError, Vector[Json]]) { self =>\n\n  /**\n   * Returns true if this selection contains no values (either empty or errored).\n   */\n  def isEmpty: Boolean = toEither.fold(_ => true, _.isEmpty)\n\n  /**\n   * Returns true if this selection contains at least one value.\n   */\n  def nonEmpty: Boolean = toEither.fold(_ => false, _.nonEmpty)\n\n  /**\n   * Returns the number of values in this selection, or 0 if errored.\n   */\n  def size: Int = toEither.fold(_ => 0, _.size)\n\n  // ---------------------------------------------------------------------------\n  // Transformations\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Applies a function to each JSON value in this selection.\n   *\n   * @param f The transformation function\n   * @return A new selection with transformed values\n   */\n  def map(f: Json => Json): JsonSelection =\n    JsonSelection(toEither.map(_.map(f)))\n\n  /**\n   * Applies a function returning a selection to each value, flattening results.\n   *\n   * @param f The function producing selections\n   * @return A new selection with all results combined\n   */\n  def flatMap(f: Json => JsonSelection): JsonSelection =\n    JsonSelection(toEither.flatMap { jsons =>\n      jsons.foldLeft[Either[SchemaError, Vector[Json]]](Right(Vector.empty)) { (acc, json) =>\n        for {\n          existing <- acc\n          next     <- f(json).toEither\n        } yield existing ++ next\n      }\n    })\n\n  /**\n   * Filters values in this selection by a predicate.\n   *\n   * @param p The predicate to test values\n   * @return A new selection containing only values satisfying the predicate\n   */\n  def filter(p: Json => Boolean): JsonSelection =\n    JsonSelection(toEither.map(_.filter(p)))\n\n  /**\n   * Collects values for which the partial function is defined.\n   *\n   * @param pf A partial function to apply\n   * @return A new selection with collected results\n   */\n  def collect(pf: PartialFunction[Json, Json]): JsonSelection =\n    JsonSelection(toEither.map(_.collect(pf)))\n\n  // ---------------------------------------------------------------------------\n  // Navigation\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Navigates to values at the given path within each selected value.\n   *\n   * @param path The path to navigate\n   * @return A new selection with values at the path\n   */\n  def get(path: DynamicOptic): JsonSelection =\n    flatMap(json => json.get(path))\n\n  /**\n   * Alias for [[get]].\n   */\n  def apply(path: DynamicOptic): JsonSelection = get(path)\n\n  /**\n   * Navigates to array element at given index within each selected value.\n   *\n   * @param index The array index\n   * @return A new selection with elements at the index\n   */\n  def apply(index: Int): JsonSelection =\n    flatMap(json => json.apply(index))\n\n  /**\n   * Navigates to object field with given key within each selected value.\n   *\n   * @param key The object key\n   * @return A new selection with values at the key\n   */\n  def apply(key: String): JsonSelection =\n    flatMap(json => json.apply(key))\n\n  // ---------------------------------------------------------------------------\n  // Type Filtering\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Filters to only JSON objects.\n   */\n  def objects: JsonSelection = filter(_.isObject)\n\n  /**\n   * Filters to only JSON arrays.\n   */\n  def arrays: JsonSelection = filter(_.isArray)\n\n  /**\n   * Filters to only JSON strings.\n   */\n  def strings: JsonSelection = filter(_.isString)\n\n  /**\n   * Filters to only JSON numbers.\n   */\n  def numbers: JsonSelection = filter(_.isNumber)\n\n  /**\n   * Filters to only JSON booleans.\n   */\n  def booleans: JsonSelection = filter(_.isBoolean)\n\n  /**\n   * Filters to only JSON nulls.\n   */\n  def nulls: JsonSelection = filter(_.isNull)\n\n  // ---------------------------------------------------------------------------\n  // Combination\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Combines this selection with another, concatenating values or errors.\n   *\n   * @param other The other selection\n   * @return A combined selection\n   */\n  def ++(other: JsonSelection): JsonSelection =\n    (toEither, other.toEither) match {\n      case (Right(a), Right(b)) => JsonSelection(Right(a ++ b))\n      case (Left(a), Left(b))   => JsonSelection(Left(a ++ b))\n      case (Left(a), _)         => JsonSelection(Left(a))\n      case (_, Left(b))         => JsonSelection(Left(b))\n    }\n\n  // ---------------------------------------------------------------------------\n  // Terminal Operations\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Returns the single value if exactly one, an array of values if there are many, or \n   * otherwise an error.\n   */\n  def one: Either[SchemaError, Json] =\n    toEither.flatMap { jsons =>\n      if (jsons.size == 1) Right(jsons.head)\n      else if (jsons.size > 1) toArray\n      else Left(SchemaError.expectationMismatch(Nil, s\"expected exactly one value, got ${jsons.size}\"))\n    }\n\n  /**\n   * Returns the first value if any, otherwise an error.\n   */\n  def first: Either[SchemaError, Json] =\n    toEither.flatMap { jsons =>\n      jsons.headOption.toRight(SchemaError.expectationMismatch(Nil, \"expected at least one value, got none\"))\n    }\n\n  /**\n   * Returns all values as a [[Json.Array]], or an error.\n   */\n  def toArray: Either[SchemaError, Json] =\n    toEither.map(jsons => Json.Array(jsons))\n\n  /**\n   * Unsafe version of [[one]], throws on error or wrong count.\n   */\n  def oneUnsafe: Json = one.fold(e => throw JsonError.fromSchemaError(e), identity)\n\n  /**\n   * Unsafe version of [[first]], throws on error or empty.\n   */\n  def firstUnsafe: Json = first.fold(e => throw JsonError.fromSchemaError(e), identity)\n}\n\nobject JsonSelection {\n\n  /**\n   * Creates a selection containing a single value.\n   */\n  def apply(json: Json): JsonSelection = JsonSelection(Right(Vector(json)))\n\n  /**\n   * Creates a selection containing multiple values.\n   */\n  def fromVector(jsons: Vector[Json]): JsonSelection = JsonSelection(Right(jsons))\n\n  /**\n   * Creates an empty selection (no values, no error).\n   */\n  val empty: JsonSelection = JsonSelection(Right(Vector.empty))\n\n  /**\n   * Creates a failed selection with the given error.\n   */\n  def fail(error: SchemaError): JsonSelection = JsonSelection(Left(error))\n\n  /**\n   * Creates a failed selection with the given message.\n   */\n  def fail(message: String): JsonSelection =\n    JsonSelection(Left(SchemaError.expectationMismatch(Nil, message)))\n}\n\n// =============================================================================\n// JSON ADT\n// =============================================================================\n\n/**\n * Represents a JSON value.\n *\n * The JSON data model consists of:\n *  - '''Objects''': Unordered collections of key-value pairs\n *  - '''Arrays''': Ordered sequences of values\n *  - '''Strings''': Unicode text\n *  - '''Numbers''': Numeric values (stored as strings for precision)\n *  - '''Booleans''': `true` or `false`\n *  - '''Null''': The null value\n *\n * ==Construction==\n * {{{\n * val obj = Json.Object(\"name\" -> Json.String(\"Alice\"), \"age\" -> Json.number(30))\n * val arr = Json.Array(Json.String(\"a\"), Json.String(\"b\"))\n * val str = Json.String(\"hello\")\n * val num = Json.number(42)\n * val bool = Json.Boolean(true)\n * val nul = Json.Null\n * }}}\n *\n * ==Navigation==\n * {{{\n * json.get(p\"users[0].name\")   // JsonSelection\n * json(\"users\")(0)(\"name\")     // JsonSelection\n * json.fields                  // for objects\n * json.elements                // for arrays\n * }}}\n *\n * ==Pattern Matching==\n * {{{\n * json match {\n *   case Json.Object(fields) => ...\n *   case Json.Array(elements) => ...\n *   case Json.String(value) => ...\n *   case Json.Number(value) => ...\n *   case Json.Boolean(value) => ...\n *   case Json.Null => ...\n * }\n * }}}\n */\nsealed trait Json { self =>\n\n  // ===========================================================================\n  // Type Testing\n  // ===========================================================================\n\n  /**\n   * Returns `true` if this is a JSON object.\n   */\n  def isObject: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON array.\n   */\n  def isArray: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON string.\n   */\n  def isString: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON number.\n   */\n  def isNumber: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON boolean.\n   */\n  def isBoolean: Boolean = false\n\n  /**\n   * Returns `true` if this is JSON null.\n   */\n  def isNull: Boolean = false\n\n  // ===========================================================================\n  // Type Filtering (returns JsonSelection)\n  // ===========================================================================\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is an object,\n   * otherwise an empty selection.\n   */\n  def asObject: JsonSelection = if (isObject) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is an array,\n   * otherwise an empty selection.\n   */\n  def asArray: JsonSelection = if (isArray) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is a string,\n   * otherwise an empty selection.\n   */\n  def asString: JsonSelection = if (isString) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is a number,\n   * otherwise an empty selection.\n   */\n  def asNumber: JsonSelection = if (isNumber) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is a boolean,\n   * otherwise an empty selection.\n   */\n  def asBoolean: JsonSelection = if (isBoolean) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is null,\n   * otherwise an empty selection.\n   */\n  def asNull: JsonSelection = if (isNull) JsonSelection(self) else JsonSelection.empty\n\n  // ===========================================================================\n  // Direct Accessors\n  // ===========================================================================\n\n  /**\n   * If this is an object, returns its fields as key-value pairs.\n   * Otherwise returns an empty sequence.\n   */\n  def fields: Seq[(String, Json)] = Seq.empty\n\n  /**\n   * If this is an array, returns its elements.\n   * Otherwise returns an empty sequence.\n   */\n  def elements: Seq[Json] = Seq.empty\n\n  /**\n   * If this is a string, returns its value.\n   * Otherwise returns `None`.\n   */\n  def stringValue: Option[String] = None\n\n  /**\n   * If this is a number, returns its string representation.\n   * Otherwise returns `None`.\n   */\n  def numberValue: Option[String] = None\n\n  /**\n   * If this is a boolean, returns its value.\n   * Otherwise returns `None`.\n   */\n  def booleanValue: Option[scala.Boolean] = None\n\n  // ===========================================================================\n  // Navigation\n  // ===========================================================================\n\n  /**\n   * Navigates to values at the given path.\n   *\n   * {{{\n   * json.get(p\"users[0].name\")\n   * json.get(DynamicOptic.root.field(\"users\").at(0).field(\"name\"))\n   * }}}\n   *\n   * @param path The path to navigate\n   * @return A [[JsonSelection]] containing values at the path\n   */\n  def get(path: DynamicOptic): JsonSelection = ???\n\n  /**\n   * Alias for [[get]].\n   */\n  def apply(path: DynamicOptic): JsonSelection = get(path)\n\n  /**\n   * If this is an array, returns a selection containing the element at the given index.\n   * Returns an empty selection if not an array or index is out of bounds.\n   *\n   * @param index The array index (0-based)\n   */\n  def apply(index: Int): JsonSelection = self match {\n    case Json.Array(elems) if index >= 0 && index < elems.size =>\n      JsonSelection(elems(index))\n    case _ =>\n      JsonSelection.empty\n  }\n\n  /**\n   * If this is an object, returns a selection containing the value at the given key.\n   * Returns an empty selection if not an object or key is not present.\n   *\n   * @param key The object key\n   */\n  def apply(key: String): JsonSelection = self match {\n    case Json.Object(flds) =>\n      flds.collectFirst { case (k, v) if k == key => v } match {\n        case Some(v) => JsonSelection(v)\n        case None    => JsonSelection.empty\n      }\n    case _ =>\n      JsonSelection.empty\n  }\n\n  // ===========================================================================\n  // Modification (Json => Json)\n  // ===========================================================================\n\n  /**\n   * Modifies values at the given path using the provided function.\n   *\n   * If the path does not exist, returns this JSON unchanged.\n   *\n   * {{{\n   * json.modify(p\"users[*].age\", {\n   *   case Json.Number(n) => Json.number(n.toInt + 1)\n   *   case other => other\n   * })\n   * }}}\n   *\n   * @param path The path to values to modify\n   * @param f The modification function\n   * @return The modified JSON\n   */\n  def modify(path: DynamicOptic, f: Json => Json): Json = ???\n\n  /**\n   * Modifies values at the given path using a partial function.\n   *\n   * Values for which the partial function is not defined are left unchanged.\n   *\n   * @param path The path to values to modify\n   * @param pf The partial modification function\n   * @return Either an error if the path is invalid, or the modified JSON\n   */\n  def modifyOrFail(path: DynamicOptic, pf: PartialFunction[Json, Json]): Either[JsonError, Json] = ???\n\n  /**\n   * Sets the value at the given path.\n   *\n   * If the path does not exist, attempts to create intermediate structure.\n   * For array indices, the array must already exist and have sufficient length.\n   *\n   * {{{\n   * json.set(p\"user.name\", Json.String(\"Bob\"))\n   * }}}\n   *\n   * @param path The path to set\n   * @param value The value to set\n   * @return The modified JSON\n   */\n  def set(path: DynamicOptic, value: Json): Json = ???\n\n  /**\n   * Sets the value at the given path, returning an error if the path is invalid.\n   *\n   * @param path The path to set\n   * @param value The value to set\n   * @return Either an error or the modified JSON\n   */\n  def setOrFail(path: DynamicOptic, value: Json): Either[JsonError, Json] = ???\n\n  /**\n   * Deletes values at the given path.\n   *\n   * For object fields, removes the key-value pair.\n   * For array elements, removes the element and shifts subsequent elements.\n   *\n   * @param path The path to delete\n   * @return The modified JSON\n   */\n  def delete(path: DynamicOptic): Json = ???\n\n  /**\n   * Deletes values at the given path, returning an error if the path is invalid.\n   *\n   * @param path The path to delete\n   * @return Either an error or the modified JSON\n   */\n  def deleteOrFail(path: DynamicOptic): Either[JsonError, Json] = ???\n\n  /**\n   * Inserts a value at the given path.\n   *\n   * For arrays, inserts at the specified index, shifting subsequent elements.\n   * For objects, adds or replaces the key.\n   *\n   * @param path The path where to insert\n   * @param value The value to insert\n   * @return The modified JSON\n   */\n  def insert(path: DynamicOptic, value: Json): Json = ???\n\n  /**\n   * Inserts a value at the given path, returning an error if invalid.\n   *\n   * @param path The path where to insert\n   * @param value The value to insert\n   * @return Either an error or the modified JSON\n   */\n  def insertOrFail(path: DynamicOptic, value: Json): Either[JsonError, Json] = ???\n\n  // ===========================================================================\n  // Merging\n  // ===========================================================================\n\n  /**\n   * Merges this JSON with another using the specified strategy.\n   *\n   * {{{\n   * val merged = json1.merge(json2, MergeStrategy.Deep)\n   * }}}\n   *\n   * @param other The JSON to merge with\n   * @param strategy The merge strategy (default: [[MergeStrategy.Auto]])\n   * @return The merged JSON\n   */\n  def merge(other: Json, strategy: MergeStrategy = MergeStrategy.Auto): Json = ???\n\n  // ===========================================================================\n  // Patching\n  // ===========================================================================\n\n  /**\n   * Applies a [[JsonPatch]] to this JSON.\n   *\n   * @param patch The patch to apply\n   * @return Either an error if the patch cannot be applied, or the patched JSON\n   */\n  def patch(patch: JsonPatch): Either[JsonError, Json] = ???\n\n  /**\n   * Applies a [[JsonPatch]], throwing on failure.\n   *\n   * @param patch The patch to apply\n   * @return The patched JSON\n   * @throws JsonError if the patch cannot be applied\n   */\n  def patchUnsafe(patch: JsonPatch): Json = this.patch(patch).fold(throw _, identity)\n\n  // ===========================================================================\n  // Transformation\n  // ===========================================================================\n\n  /**\n   * Transforms all values in this JSON bottom-up (children before parents).\n   *\n   * @param f The transformation function receiving path and value\n   * @return The transformed JSON\n   */\n  def transformUp(f: (DynamicOptic, Json) => Json): Json = ???\n\n  /**\n   * Transforms all values in this JSON top-down (parents before children).\n   *\n   * @param f The transformation function receiving path and value\n   * @return The transformed JSON\n   */\n  def transformDown(f: (DynamicOptic, Json) => Json): Json = ???\n\n  /**\n   * Transforms all object keys in this JSON.\n   *\n   * @param f The key transformation function receiving path and key\n   * @return The transformed JSON\n   */\n  def transformKeys(f: (DynamicOptic, String) => String): Json = ???\n\n  // ===========================================================================\n  // Filtering\n  // ===========================================================================\n\n  /**\n   * Removes entries matching the predicate.\n   *\n   * For objects, removes matching key-value pairs.\n   * For arrays, removes matching elements.\n   *\n   * @param p The predicate receiving path and value\n   * @return The filtered JSON\n   */\n  def filterNot(p: (DynamicOptic, Json) => scala.Boolean): Json = ???\n\n  /**\n   * Keeps only entries matching the predicate.\n   *\n   * @param p The predicate receiving path and value\n   * @return The filtered JSON\n   */\n  def filter(p: (DynamicOptic, Json) => scala.Boolean): Json =\n    filterNot((path, json) => !p(path, json))\n\n  // ===========================================================================\n  // Projection\n  // ===========================================================================\n\n  /**\n   * Projects this JSON to include only the specified paths.\n   *\n   * Paths that don't exist are ignored. Structure is preserved.\n   *\n   * {{{\n   * json.project(p\"user.name\", p\"user.email\", p\"meta.created\")\n   * }}}\n   *\n   * @param paths The paths to include\n   * @return A new JSON containing only the specified paths\n   */\n  def project(paths: DynamicOptic*): Json = ???\n\n  // ===========================================================================\n  // Splitting / Partitioning\n  // ===========================================================================\n\n  /**\n   * Partitions this JSON into two based on a predicate.\n   *\n   * Returns a tuple where the first element contains entries satisfying\n   * the predicate, and the second contains entries that don't.\n   *\n   * @param p The predicate receiving path and value\n   * @return A tuple of (matching, non-matching) JSON values\n   */\n  def partition(p: (DynamicOptic, Json) => scala.Boolean): (Json, Json) = ???\n\n  // ===========================================================================\n  // Normalization\n  // ===========================================================================\n\n  /**\n   * Returns a normalized version of this JSON.\n   *\n   * Normalization includes:\n   *  - Sorting object keys alphabetically\n   *  - Normalizing number representations\n   *\n   * Useful for comparison and hashing.\n   */\n  def normalize: Json = ???\n\n  /**\n   * Returns this JSON with all object keys sorted alphabetically (recursive).\n   */\n  def sortKeys: Json = self match {\n    case Json.Object(flds) =>\n      Json.Object(flds.map { case (k, v) => (k, v.sortKeys) }.sortBy(_._1))\n    case Json.Array(elems) =>\n      Json.Array(elems.map(_.sortKeys))\n    case other =>\n      other\n  }\n\n  /**\n   * Returns this JSON with all null values removed from objects.\n   */\n  def dropNulls: Json = self match {\n    case Json.Object(flds) =>\n      Json.Object(flds.collect { case (k, v) if !v.isNull => (k, v.dropNulls) })\n    case Json.Array(elems) =>\n      Json.Array(elems.map(_.dropNulls))\n    case other =>\n      other\n  }\n\n  /**\n   * Returns this JSON with empty objects and arrays removed.\n   */\n  def dropEmpty: Json = self match {\n    case Json.Object(flds) =>\n      val filtered = flds.collect {\n        case (k, v) =>\n          val dropped = v.dropEmpty\n          dropped match {\n            case Json.Object(f) if f.isEmpty => None\n            case Json.Array(e) if e.isEmpty  => None\n            case other                       => Some((k, other))\n          }\n      }.flatten\n      Json.Object(filtered)\n    case Json.Array(elems) =>\n      val filtered = elems.map(_.dropEmpty).filter {\n        case Json.Object(f) if f.isEmpty => false\n        case Json.Array(e) if e.isEmpty  => false\n        case _                           => true\n      }\n      Json.Array(filtered)\n    case other =>\n      other\n  }\n\n  // ===========================================================================\n  // Diffing\n  // ===========================================================================\n\n  /**\n   * Computes a [[JsonPatch]] that transforms this JSON into the target.\n   *\n   * {{{\n   * val patch = source.diff(target)\n   * source.patch(patch) == Right(target) // true\n   * }}}\n   *\n   * @param target The target JSON\n   * @return A patch that transforms this into target\n   */\n  def diff(target: Json): JsonPatch = ???\n\n  // ===========================================================================\n  // Folding\n  // ===========================================================================\n\n  /**\n   * Folds over this JSON top-down (parents before children).\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function receiving path, value, and accumulator\n   * @tparam B The accumulator type\n   * @return The final accumulated value\n   */\n  def foldDown[B](z: B)(f: (DynamicOptic, Json, B) => B): B = ???\n\n  /**\n   * Folds over this JSON bottom-up (children before parents).\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function receiving path, value, and accumulator\n   * @tparam B The accumulator type\n   * @return The final accumulated value\n   */\n  def foldUp[B](z: B)(f: (DynamicOptic, Json, B) => B): B = ???\n\n  /**\n   * Folds over this JSON top-down, allowing the fold function to fail.\n   *\n   * Short-circuits on first failure.\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function that may fail\n   * @tparam B The accumulator type\n   * @return Either an error or the final accumulated value\n   */\n  def foldDownOrFail[B](z: B)(f: (DynamicOptic, Json, B) => Either[JsonError, B]): Either[JsonError, B] = ???\n\n  /**\n   * Folds over this JSON bottom-up, allowing the fold function to fail.\n   *\n   * Short-circuits on first failure.\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function that may fail\n   * @tparam B The accumulator type\n   * @return Either an error or the final accumulated value\n   */\n  def foldUpOrFail[B](z: B)(f: (DynamicOptic, Json, B) => Either[JsonError, B]): Either[JsonError, B] = ???\n\n  // ===========================================================================\n  // Querying\n  // ===========================================================================\n\n  /**\n   * Selects all values matching the predicate.\n   *\n   * @param p The predicate receiving path and value\n   * @return A [[JsonSelection]] containing matching values\n   */\n  def query(p: (DynamicOptic, Json) => scala.Boolean): JsonSelection = ???\n\n  // ===========================================================================\n  // Validation\n  // ===========================================================================\n\n  /**\n   * Validates this JSON against a [[JsonSchema]].\n   *\n   * @param schema The schema to validate against\n   * @return `None` if valid, `Some(error)` if invalid\n   */\n  def check(schema: JsonSchema): Option[SchemaError] = ???\n\n  /**\n   * Returns `true` if this JSON conforms to the given [[JsonSchema]].\n   */\n  def conforms(schema: JsonSchema): scala.Boolean = check(schema).isEmpty\n\n  // ===========================================================================\n  // KV Representation\n  // ===========================================================================\n\n  /**\n   * Flattens this JSON to a sequence of path-value pairs.\n   *\n   * Only leaf values (primitives, empty arrays, empty objects) are included.\n   *\n   * {{{\n   * Json.parse(\"\"\"{\"a\": {\"b\": 1}, \"c\": [2, 3]}\"\"\").toKV\n   * // Seq(\n   * //   (p\"a.b\", Json.Number(\"1\")),\n   * //   (p\"c[0]\", Json.Number(\"2\")),\n   * //   (p\"c[1]\", Json.Number(\"3\"))\n   * // )\n   * }}}\n   */\n  def toKV: Seq[(DynamicOptic, Json)] = ???\n\n  // ===========================================================================\n  // Comparison\n  // ===========================================================================\n\n  /**\n   * Compares this JSON to another for ordering.\n   *\n   * Ordering is defined as:\n   *  1. Null < Boolean < Number < String < Array < Object\n   *  2. Within types, natural ordering applies\n   */\n  def compare(that: Json): Int = (self, that) match {\n    case (Json.Null, Json.Null)               => 0\n    case (Json.Null, _)                       => -1\n    case (_, Json.Null)                       => 1\n    case (Json.Boolean(a), Json.Boolean(b))   => a.compare(b)\n    case (Json.Boolean(_), _)                 => -1\n    case (_, Json.Boolean(_))                 => 1\n    case (Json.Number(a), Json.Number(b))     => BigDecimal(a).compare(BigDecimal(b))\n    case (Json.Number(_), _)                  => -1\n    case (_, Json.Number(_))                  => 1\n    case (Json.String(a), Json.String(b))     => a.compare(b)\n    case (Json.String(_), _)                  => -1\n    case (_, Json.String(_))                  => 1\n    case (Json.Array(a), Json.Array(b))       => compareArrays(a, b)\n    case (Json.Array(_), _)                   => -1\n    case (_, Json.Array(_))                   => 1\n    case (Json.Object(a), Json.Object(b))     => compareObjects(a, b)\n  }\n\n  private def compareArrays(a: Vector[Json], b: Vector[Json]): Int = {\n    val len = math.min(a.size, b.size)\n    var i   = 0\n    while (i < len) {\n      val cmp = a(i).compare(b(i))\n      if (cmp != 0) return cmp\n      i += 1\n    }\n    a.size.compare(b.size)\n  }\n\n  private def compareObjects(a: Vector[(String, Json)], b: Vector[(String, Json)]): Int = {\n    val aSorted = a.sortBy(_._1)\n    val bSorted = b.sortBy(_._1)\n    val len     = math.min(aSorted.size, bSorted.size)\n    var i       = 0\n    while (i < len) {\n      val (ak, av) = aSorted(i)\n      val (bk, bv) = bSorted(i)\n      val keyCmp   = ak.compare(bk)\n      if (keyCmp != 0) return keyCmp\n      val valCmp = av.compare(bv)\n      if (valCmp != 0) return valCmp\n      i += 1\n    }\n    aSorted.size.compare(bSorted.size)\n  }\n\n  // ===========================================================================\n  // DynamicValue Interop\n  // ===========================================================================\n\n  /**\n   * Converts this JSON to a [[DynamicValue]].\n   *\n   * This conversion is lossless; all JSON values can be represented as DynamicValue.\n   */\n  def toDynamicValue: DynamicValue = self match {\n    case Json.Null =>\n      DynamicValue.Primitive(PrimitiveValue.Unit)\n    case Json.Boolean(v) =>\n      DynamicValue.Primitive(PrimitiveValue.Boolean(v))\n    case Json.Number(v) =>\n      // Preserve as BigDecimal for maximum precision\n      DynamicValue.Primitive(PrimitiveValue.BigDecimal(BigDecimal(v)))\n    case Json.String(v) =>\n      DynamicValue.Primitive(PrimitiveValue.String(v))\n    case Json.Array(elems) =>\n      DynamicValue.Sequence(elems.map(_.toDynamicValue))\n    case Json.Object(flds) =>\n      DynamicValue.Record(flds.map { case (k, v) => (k, v.toDynamicValue) })\n  }\n\n  // ===========================================================================\n  // Typed Decoding (Json => A)\n  // ===========================================================================\n\n  /**\n   * Decodes this JSON to a typed value.\n   *\n   * Uses implicit [[JsonDecoder]] which prefers explicit codecs over schema derivation.\n   *\n   * {{{\n   * val person: Either[JsonError, Person] = json.as[Person]\n   * }}}\n   *\n   * @tparam A The target type\n   * @return Either an error or the decoded value\n   */\n  def as[A](implicit decoder: JsonDecoder[A]): Either[JsonError, A] = decoder.decode(self)\n\n  /**\n   * Decodes this JSON to a typed value, throwing on failure.\n   *\n   * @tparam A The target type\n   * @return The decoded value\n   * @throws JsonError if decoding fails\n   */\n  def asUnsafe[A](implicit decoder: JsonDecoder[A]): A = as[A].fold(throw _, identity)\n\n  /**\n   * Internal: decode using an explicit codec.\n   */\n  private[json] def decodeWith[A](codec: JsonBinaryCodec[A]): Either[JsonError, A] = ???\n\n  // ===========================================================================\n  // Encoding (Json => String/Bytes)\n  // ===========================================================================\n\n  /**\n   * Encodes this JSON to a compact string (no extra whitespace).\n   */\n  def print: String = encode(WriterConfig)\n\n  /**\n   * Encodes this JSON to a string using the specified configuration.\n   *\n   * @param config Writer configuration (indentation, unicode escaping, etc.)\n   */\n  def print(config: WriterConfig): String = encode(config)\n\n  /**\n   * Alias for [[print]].\n   */\n  def encode: String = encode(WriterConfig)\n\n  /**\n   * Encodes this JSON to a string using the specified configuration.\n   *\n   * @param config Writer configuration\n   */\n  def encode(config: WriterConfig): String = ???\n\n  /**\n   * Encodes this JSON and writes to the provided [[Writer]].\n   *\n   * @param writer The writer to write to\n   */\n  def printTo(writer: Writer): Unit = printTo(writer, WriterConfig)\n\n  /**\n   * Encodes this JSON and writes to the provided [[Writer]] with configuration.\n   *\n   * @param writer The writer to write to\n   * @param config Writer configuration\n   */\n  def printTo(writer: Writer, config: WriterConfig): Unit = ???\n\n  /**\n   * Encodes this JSON to a byte array (UTF-8).\n   */\n  def encodeToBytes: Array[Byte] = encodeToBytes(WriterConfig)\n\n  /**\n   * Encodes this JSON to a byte array (UTF-8) with configuration.\n   *\n   * @param config Writer configuration\n   */\n  def encodeToBytes(config: WriterConfig): Array[Byte] = ???\n\n  /**\n   * Encodes this JSON to a [[Chunk]] of bytes (UTF-8).\n   */\n  def encodeToChunk: Chunk[Byte] = encodeToChunk(WriterConfig)\n\n  /**\n   * Encodes this JSON to a [[Chunk]] of bytes (UTF-8) with configuration.\n   *\n   * @param config Writer configuration\n   */\n  def encodeToChunk(config: WriterConfig): Chunk[Byte] = ???\n\n  /**\n   * Encodes this JSON into the provided [[ByteBuffer]].\n   *\n   * @param buffer The buffer to write to\n   */\n  def encodeTo(buffer: ByteBuffer): Unit = encodeTo(buffer, WriterConfig)\n\n  /**\n   * Encodes this JSON into the provided [[ByteBuffer]] with configuration.\n   *\n   * @param buffer The buffer to write to\n   * @param config Writer configuration\n   */\n  def encodeTo(buffer: ByteBuffer, config: WriterConfig): Unit = ???\n\n  // ===========================================================================\n  // Standard Methods\n  // ===========================================================================\n\n  override def hashCode(): Int = self match {\n    case Json.Null           => 0\n    case Json.Boolean(v)     => v.hashCode()\n    case Json.Number(v)      => BigDecimal(v).hashCode()\n    case Json.String(v)      => v.hashCode()\n    case Json.Array(elems)   => elems.hashCode()\n    case Json.Object(flds)   => flds.sortBy(_._1).hashCode()\n  }\n\n  override def equals(that: Any): Boolean = that match {\n    case other: Json => compare(other) == 0\n    case _           => false\n  }\n\n  override def toString: String = print\n}\n\nobject Json {\n\n  // ===========================================================================\n  // ADT Cases\n  // ===========================================================================\n\n  /**\n   * A JSON object: an unordered collection of key-value pairs.\n   *\n   * @param fields The key-value pairs. Keys should be unique; if duplicates\n   *               are present, behavior of accessors is undefined.\n   */\n  final case class Object(fields: Vector[(String, Json)]) extends Json {\n    override def isObject: scala.Boolean                = true\n    override def fields: Seq[(String, Json)]            = fields\n  }\n\n  object Object {\n\n    /**\n     * Creates an empty JSON object.\n     */\n    val empty: Object = Object(Vector.empty)\n\n    /**\n     * Creates a JSON object from key-value pairs.\n     */\n    def apply(fields: (String, Json)*): Object = Object(fields.toVector)\n  }\n\n  /**\n   * A JSON array: an ordered sequence of values.\n   *\n   * @param elements The array elements\n   */\n  final case class Array(elements: Vector[Json]) extends Json {\n    override def isArray: scala.Boolean  = true\n    override def elements: Seq[Json]     = elements\n  }\n\n  object Array {\n\n    /**\n     * Creates an empty JSON array.\n     */\n    val empty: Array = Array(Vector.empty)\n\n    /**\n     * Creates a JSON array from elements.\n     */\n    def apply(elements: Json*): Array = Array(elements.toVector)\n  }\n\n  /**\n   * A JSON string.\n   *\n   * @param value The string value (unescaped)\n   */\n  final case class String(value: java.lang.String) extends Json {\n    override def isString: scala.Boolean              = true\n    override def stringValue: Option[java.lang.String] = Some(value)\n  }\n\n  /**\n   * A JSON number.\n   *\n   * Stored as a string to preserve exact representation (precision, trailing zeros, etc.).\n   * Provides lazy conversion to numeric types.\n   *\n   * @param value The number as a string (should be valid JSON number syntax)\n   */\n  final case class Number(value: java.lang.String) extends Json {\n    override def isNumber: scala.Boolean                = true\n    override def numberValue: Option[java.lang.String]  = Some(value)\n\n    /**\n     * Converts to `Int`, truncating if necessary.\n     */\n    lazy val toInt: Int = toBigDecimal.toInt\n\n    /**\n     * Converts to `Long`, truncating if necessary.\n     */\n    lazy val toLong: Long = toBigDecimal.toLong\n\n    /**\n     * Converts to `Float`.\n     */\n    lazy val toFloat: Float = value.toFloat\n\n    /**\n     * Converts to `Double`.\n     */\n    lazy val toDouble: Double = value.toDouble\n\n    /**\n     * Converts to `BigInt`, truncating fractional part.\n     */\n    lazy val toBigInt: BigInt = toBigDecimal.toBigInt\n\n    /**\n     * Converts to `BigDecimal` (lossless).\n     */\n    lazy val toBigDecimal: BigDecimal = BigDecimal(value)\n  }\n\n  /**\n   * A JSON boolean.\n   *\n   * @param value The boolean value\n   */\n  final case class Boolean(value: scala.Boolean) extends Json {\n    override def isBoolean: scala.Boolean              = true\n    override def booleanValue: Option[scala.Boolean]   = Some(value)\n  }\n\n  object Boolean {\n    val True: Boolean  = Boolean(true)\n    val False: Boolean = Boolean(false)\n  }\n\n  /**\n   * The JSON null value.\n   */\n  case object Null extends Json {\n    override def isNull: scala.Boolean = true\n  }\n\n  // ===========================================================================\n  // Convenience Constructors\n  // ===========================================================================\n\n  /**\n   * Creates a JSON number from an `Int`.\n   */\n  def number(n: Int): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Long`.\n   */\n  def number(n: Long): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Float`.\n   */\n  def number(n: Float): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Double`.\n   */\n  def number(n: Double): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `BigInt`.\n   */\n  def number(n: BigInt): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `BigDecimal`.\n   */\n  def number(n: BigDecimal): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Short`.\n   */\n  def number(n: Short): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Byte`.\n   */\n  def number(n: Byte): Number = Number(n.toString)\n\n  // ===========================================================================\n  // Parsing / Decoding (String/Bytes => Json)\n  // ===========================================================================\n\n  /**\n   * Parses a JSON value from a string.\n   *\n   * @param s The JSON string\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(s: java.lang.String): Either[JsonError, Json] = decode(s)\n\n  /**\n   * Parses a JSON value from a `CharSequence`.\n   *\n   * @param s The JSON character sequence\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(s: CharSequence): Either[JsonError, Json] = decode(s)\n\n  /**\n   * Parses a JSON value from a byte array (UTF-8).\n   *\n   * @param bytes The JSON bytes\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(bytes: scala.Array[Byte]): Either[JsonError, Json] = decode(bytes)\n\n  /**\n   * Parses a JSON value from a [[Chunk]] of bytes (UTF-8).\n   *\n   * @param chunk The JSON bytes\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(chunk: Chunk[Byte]): Either[JsonError, Json] = decode(chunk)\n\n  /**\n   * Parses a JSON value from a [[ByteBuffer]] (UTF-8).\n   *\n   * @param buffer The JSON bytes\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(buffer: ByteBuffer): Either[JsonError, Json] = decode(buffer)\n\n  /**\n   * Parses a JSON value from a [[Reader]].\n   *\n   * @param reader The reader to read from\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(reader: Reader): Either[JsonError, Json] = decode(reader)\n\n  /**\n   * Decodes a JSON value from a string.\n   */\n  def decode(s: java.lang.String): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a `CharSequence`.\n   */\n  def decode(s: CharSequence): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a byte array (UTF-8).\n   */\n  def decode(bytes: scala.Array[Byte]): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a [[Chunk]] of bytes (UTF-8).\n   */\n  def decode(chunk: Chunk[Byte]): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a [[ByteBuffer]] (UTF-8).\n   */\n  def decode(buffer: ByteBuffer): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a [[Reader]].\n   */\n  def decode(reader: Reader): Either[JsonError, Json] = ???\n\n  /**\n   * Parses a JSON value from a string, throwing on failure.\n   *\n   * @param s The JSON string\n   * @return The parsed JSON\n   * @throws JsonError if parsing fails\n   */\n  def parseUnsafe(s: java.lang.String): Json = decode(s).fold(throw _, identity)\n\n  /**\n   * Alias for [[parseUnsafe]].\n   */\n  def decodeUnsafe(s: java.lang.String): Json = parseUnsafe(s)\n\n  // ===========================================================================\n  // Typed Encoding (A => Json)\n  // ===========================================================================\n\n  /**\n   * Encodes a typed value to JSON.\n   *\n   * Uses implicit [[JsonEncoder]] which prefers explicit codecs over schema derivation.\n   *\n   * {{{\n   * val json = Json.from(Person(\"Alice\", 30))\n   * }}}\n   *\n   * @param value The value to encode\n   * @return The encoded JSON\n   */\n  def from[A](value: A)(implicit encoder: JsonEncoder[A]): Json = encoder.encode(value)\n\n  /**\n   * Internal: encode using an explicit codec.\n   */\n  private[json] def encodeWith[A](value: A, codec: JsonBinaryCodec[A]): Json = ???\n\n  // ===========================================================================\n  // DynamicValue Interop\n  // ===========================================================================\n\n  /**\n   * Converts a [[DynamicValue]] to JSON.\n   *\n   * This conversion is lossy for `DynamicValue` types that have no JSON equivalent:\n   *  - `PrimitiveValue` types like `java.time.*` are converted to strings\n   *  - `DynamicValue.Variant` uses a discriminator field\n   *\n   * @param value The dynamic value to convert\n   * @return The JSON representation\n   */\n  def fromDynamicValue(value: DynamicValue): Json = value match {\n    case DynamicValue.Primitive(pv) => fromPrimitiveValue(pv)\n    case DynamicValue.Record(flds) =>\n      Object(flds.map { case (k, v) => (k, fromDynamicValue(v)) })\n    case DynamicValue.Variant(caseName, v) =>\n      Object(Vector(\"_type\" -> String(caseName), \"_value\" -> fromDynamicValue(v)))\n    case DynamicValue.Sequence(elems) =>\n      Array(elems.map(fromDynamicValue))\n    case DynamicValue.Map(entries) =>\n      Array(entries.map { case (k, v) =>\n        Object(Vector(\"key\" -> fromDynamicValue(k), \"value\" -> fromDynamicValue(v)))\n      })\n  }\n\n  private def fromPrimitiveValue(pv: PrimitiveValue): Json = pv match {\n    case PrimitiveValue.Unit              => Null\n    case PrimitiveValue.Boolean(v)        => Boolean(v)\n    case PrimitiveValue.Byte(v)           => number(v)\n    case PrimitiveValue.Short(v)          => number(v)\n    case PrimitiveValue.Int(v)            => number(v)\n    case PrimitiveValue.Long(v)           => number(v)\n    case PrimitiveValue.Float(v)          => number(v)\n    case PrimitiveValue.Double(v)         => number(v)\n    case PrimitiveValue.Char(v)           => String(v.toString)\n    case PrimitiveValue.String(v)         => String(v)\n    case PrimitiveValue.BigInt(v)         => number(v)\n    case PrimitiveValue.BigDecimal(v)     => number(v)\n    case PrimitiveValue.DayOfWeek(v)      => String(v.toString)\n    case PrimitiveValue.Duration(v)       => String(v.toString)\n    case PrimitiveValue.Instant(v)        => String(v.toString)\n    case PrimitiveValue.LocalDate(v)      => String(v.toString)\n    case PrimitiveValue.LocalDateTime(v)  => String(v.toString)\n    case PrimitiveValue.LocalTime(v)      => String(v.toString)\n    case PrimitiveValue.Month(v)          => String(v.toString)\n    case PrimitiveValue.MonthDay(v)       => String(v.toString)\n    case PrimitiveValue.OffsetDateTime(v) => String(v.toString)\n    case PrimitiveValue.OffsetTime(v)     => String(v.toString)\n    case PrimitiveValue.Period(v)         => String(v.toString)\n    case PrimitiveValue.Year(v)           => String(v.toString)\n    case PrimitiveValue.YearMonth(v)      => String(v.toString)\n    case PrimitiveValue.ZoneId(v)         => String(v.getId)\n    case PrimitiveValue.ZoneOffset(v)     => String(v.toString)\n    case PrimitiveValue.ZonedDateTime(v)  => String(v.toString)\n    case PrimitiveValue.Currency(v)       => String(v.getCurrencyCode)\n    case PrimitiveValue.UUID(v)           => String(v.toString)\n  }\n\n  // ===========================================================================\n  // KV Interop\n  // ===========================================================================\n\n  /**\n   * Assembles JSON from a sequence of path-value pairs.\n   *\n   * {{{\n   * Json.fromKV(Seq(\n   *   p\"a.b\" -> Json.number(1),\n   *   p\"a.c\" -> Json.String(\"x\"),\n   *   p\"d[0]\" -> Json.Boolean(true)\n   * ))\n   * // {\"a\": {\"b\": 1, \"c\": \"x\"}, \"d\": [true]}\n   * }}}\n   *\n   * @param kvs The path-value pairs\n   * @return Either an error (for conflicting paths) or the assembled JSON\n   */\n  def fromKV(kvs: Seq[(DynamicOptic, Json)]): Either[JsonError, Json] = ???\n\n  /**\n   * Assembles JSON from path-value pairs, throwing on conflict.\n   */\n  def fromKVUnsafe(kvs: Seq[(DynamicOptic, Json)]): Json = fromKV(kvs).fold(throw _, identity)\n\n  // ===========================================================================\n  // Patch Interop\n  // ===========================================================================\n\n  /**\n   * Serializes a [[JsonPatch]] to its JSON representation.\n   *\n   * The format follows RFC 6902 (JSON Patch) for standard operations,\n   * with extensions for LCS-based sequence diffs.\n   *\n   * @param patch The patch to serialize\n   * @return The JSON representation of the patch\n   */\n  def fromJsonPatch(patch: JsonPatch): Json = ???\n\n  /**\n   * Deserializes a JSON representation into a [[JsonPatch]].\n   *\n   * @param json The JSON patch representation\n   * @return Either an error or the parsed patch\n   */\n  def toJsonPatch(json: Json): Either[JsonError, JsonPatch] = ???\n\n  // ===========================================================================\n  // Ordering\n  // ===========================================================================\n\n  /**\n   * Ordering for JSON values.\n   *\n   * Order: Null < Boolean < Number < String < Array < Object\n   */\n  implicit val ordering: Ordering[Json] = (x: Json, y: Json) => x.compare(y)\n}\n\n// =============================================================================\n// MERGE STRATEGY\n// =============================================================================\n\n/**\n * Strategy for merging JSON values.\n */\nsealed trait MergeStrategy\n\nobject MergeStrategy {\n\n  /**\n   * Automatically determines merge behavior based on value types:\n   *  - Objects: deep merge (recurse into matching keys)\n   *  - Arrays: concatenate\n   *  - Primitives: right wins\n   */\n  case object Auto extends MergeStrategy\n\n  /**\n   * Deep merge for objects; concatenate arrays.\n   */\n  case object Deep extends MergeStrategy\n\n  /**\n   * Shallow merge: right value wins for any key conflict.\n   */\n  case object Shallow extends MergeStrategy\n\n  /**\n   * Concatenate arrays; for objects and primitives, right wins.\n   */\n  case object Concat extends MergeStrategy\n\n  /**\n   * Right value always wins (replacement).\n   */\n  case object Replace extends MergeStrategy\n\n  /**\n   * Custom merge function.\n   *\n   * @param f A function receiving path and both values, returning merged result\n   */\n  final case class Custom(f: (DynamicOptic, Json, Json) => Json) extends MergeStrategy\n}\n\n// =============================================================================\n// STRING INTERPOLATORS\n// =============================================================================\n\n/**\n * Provides string interpolators for JSON paths and literals.\n *\n * Import with:\n * {{{\n * import zio.blocks.schema.json.interpolators._\n * }}}\n *\n * ==Path Syntax==\n *\n * The `p` interpolator creates [[DynamicOptic]] paths using a JSONPath-compatible dialect:\n *\n * {{{\n * p\"foo.bar\"           // fields \"foo\" then \"bar\"\n * p\"users[0]\"          // field \"users\", then index 0\n * p\"users[0].name\"     // field \"users\", index 0, field \"name\"\n * p\"items[*]\"          // field \"items\", then all array elements\n * p\"config{*}\"         // field \"config\", then all object values\n * p\"config{*:}\"        // field \"config\", then all object keys\n * p\"[0,2,5]\"           // indices 0, 2, and 5\n * p\"[0:5]\"             // slice: indices 0 through 4\n * p\"[::2]\"             // slice: every other element\n * p\"`field.name`\"      // field with dots in name (backtick escaping)\n * p\"\"\"[\"field\"]\"\"\"     // alternate field syntax (bracket notation)\n * }}}\n *\n * ===JSONPath Compatibility===\n *\n * This syntax is a dialect of JSONPath (RFC 9535). Most JSONPath expressions work:\n *  - `$.foo.bar` - root prefix is optional and ignored\n *  - `.field`, `[\"field\"]` - field access\n *  - `[n]`, `[*]`, `[m,n]`, `[m:n]` - array access\n *\n * '''Not supported:'''\n *  - `..` (recursive descent)\n *  - `[?()]` (filter expressions)\n *\n * ===Extensions beyond JSONPath:===\n *  - `{*}` - all object values (explicit, vs `[*]` which is array-focused in JSONPath)\n *  - `{*:}` - all object keys (not expressible in standard JSONPath)\n *  - Backtick escaping for field names\n */\nobject interpolators {\n\n  implicit class JsonPathInterpolator(val sc: StringContext) extends AnyVal {\n\n    /**\n     * Creates a [[DynamicOptic]] from a path string at compile time.\n     *\n     * @return The parsed [[DynamicOptic]]\n     */\n    def p(args: Any*): DynamicOptic = macro PathMacros.pathInterpolator\n  }\n\n  implicit class JsonLiteralInterpolator(val sc: StringContext) extends AnyVal {\n\n    /**\n     * Creates a [[Json]] value from a JSON literal at compile time.\n     *\n     * {{{\n     * j\"\"\"{\"name\": \"Alice\", \"age\": 30}\"\"\"\n     * j\"[1, 2, 3]\"\n     * j\"null\"\n     * }}}\n     *\n     * Interpolated values are converted to JSON:\n     * {{{\n     * val name = \"Bob\"\n     * val age = 25\n     * j\"\"\"{\"name\": $name, \"age\": $age}\"\"\"\n     * }}}\n     *\n     * @return The parsed [[Json]] value\n     */\n    def j(args: Any*): Json = macro PathMacros.jsonInterpolator\n  }\n}\n\n/**\n * Macro implementations for string interpolators.\n * \n * Separate implementations would be needed for Scala 2 and Scala 3.\n */\nobject PathMacros {\n  import scala.reflect.macros.blackbox\n\n  def pathInterpolator(c: blackbox.Context)(args: c.Expr[Any]*): c.Expr[DynamicOptic] = ???\n\n  def jsonInterpolator(c: blackbox.Context)(args: c.Expr[Any]*): c.Expr[Json] = ???\n}\n\n// =============================================================================\n// PLACEHOLDER TYPES (assumed to exist)\n// =============================================================================\n\n/**\n * Represents a JSON Schema for validation.\n *\n * Placeholder - actual implementation TBD.\n */\nsealed trait JsonSchema\n\nobject JsonSchema {\n  // Placeholder\n}\n\n/**\n * Represents a patch that can be applied to JSON values.\n *\n * Supports RFC 6902 operations (add, remove, replace, move, copy, test)\n * plus extensions for LCS-based sequence diffs and string diffs.\n *\n * Placeholder - actual implementation TBD.\n */\nsealed trait JsonPatch {\n\n  /**\n   * Converts this JSON patch to a [[DynamicPatch]].\n   */\n  def toDynamicPatch: DynamicPatch\n}\n\nobject JsonPatch {\n\n  /**\n   * Creates an empty patch (no operations).\n   */\n  val empty: JsonPatch = ???\n\n  /**\n   * Creates a patch from a [[DynamicPatch]].\n   *\n   * May fail if the DynamicPatch contains operations not representable in JSON.\n   */\n  def fromDynamicPatch(patch: DynamicPatch): Either[JsonError, JsonPatch] = ???\n}\n\n/**\n * Represents a patch that can be applied to [[DynamicValue]].\n *\n * Placeholder - actual implementation TBD.\n */\nsealed trait DynamicPatch\n\nobject DynamicPatch {\n\n  /**\n   * Creates an empty patch (no operations).\n   */\n  val empty: DynamicPatch = ???\n}\n```",
              "url": "https://github.com/zio/zio-blocks/issues/679",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#685",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-18T17:51:42.407Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:42.407Z",
            "created_at": "2026-01-18T17:51:42.407Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#685",
              "status": "open",
              "type": "issue",
              "number": 685,
              "title": "Add JsonPatch - Depends on #679",
              "source": {
                "data": {
                  "id": "source-ZIO#685",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add JsonPatch - Depends on #679",
                  "body": "<html><head></head><body><h1>Add <code>JsonPatch</code> type for diffing and patching JSON values</h1>\n<h2>Summary</h2>\n<p>Implement a <code>JsonPatch</code> type that enables computing diffs between JSON values and applying patches to transform one JSON value into another. This type should mirror the existing <code>DynamicPatch</code> implementation, adapted for JSON's simpler data model.</p>\n<h2>Motivation</h2>\n<p><code>DynamicValue</code> has a well-designed <code>DynamicPatch</code> system with:</p>\n<ul>\n<li>Monoid composition (<code>++</code> with <code>empty</code> identity)</li>\n<li>LCS-based sequence diffing</li>\n<li>Primitive delta operations (numeric deltas, string edits)</li>\n<li>Comprehensive algebraic laws verified by property tests</li>\n</ul>\n<p>The proposed <code>Json</code> type (see #TBD) needs equivalent patching capabilities. Rather than converting <code>Json â†” DynamicValue</code> for every patch operation, a native <code>JsonPatch</code> provides:</p>\n<ul>\n<li>Type safety (no conversion errors for JSON-incompatible DynamicPatch operations)</li>\n<li>API consistency with the <code>Json</code> type</li>\n<li>Potential for JSON-specific optimizations</li>\n</ul>\n<h2>Design Sketch</h2>\n<p>A design sketch is available at <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala</code></a>. This sketch is <strong>a guide, not a specification</strong> â€” implementers should use judgment and deviate where appropriate.</p>\n<h3>Core Types</h3>\n<p>The design mirrors <code>DynamicPatch</code> with JSON-specific adaptations:</p>\n\nDynamicPatch | JsonPatch | Notes\n-- | -- | --\nDynamicPatch(Vector[DynamicPatchOp]) | JsonPatch(Vector[JsonPatchOp]) | Same structure\nOperation.Set | Op.Set | Same\nOperation.PrimitiveDelta | Op.PrimitiveDelta | Simplified for JSON types\nOperation.SequenceEdit | Op.ArrayEdit | Renamed\nOperation.MapEdit | Op.ObjectEdit | String keys only\nOperation.Patch | Op.Nested | Same\nSeqOp | ArrayOp | Same operations\nMapOp | ObjectOp | String keys only\nPrimitiveOp (14 variants) | PrimitiveOp (2 variants) | See below\n\n\n<h3>StringOp</h3>\n<p>Mirror <code>DynamicPatch.StringOp</code> exactly:</p>\n<ul>\n<li><code>Insert(index: Int, text: String)</code></li>\n<li><code>Delete(index: Int, length: Int)</code></li>\n<li><code>Append(text: String)</code></li>\n<li><code>Modify(index: Int, length: Int, text: String)</code></li>\n</ul>\n<h3>ArrayOp</h3>\n<p>Mirror <code>DynamicPatch.SeqOp</code>:</p>\n<ul>\n<li><code>Insert(index: Int, values: Vector[Json])</code></li>\n<li><code>Append(values: Vector[Json])</code></li>\n<li><code>Delete(index: Int, count: Int)</code></li>\n<li><code>Modify(index: Int, op: Op)</code></li>\n</ul>\n<h3>ObjectOp</h3>\n<p>Mirror <code>DynamicPatch.MapOp</code> with string keys:</p>\n<ul>\n<li><code>Add(key: String, value: Json)</code></li>\n<li><code>Remove(key: String)</code></li>\n<li><code>Modify(key: String, patch: JsonPatch)</code></li>\n</ul>\n<h2>Requirements</h2>\n<h3>Functional Requirements</h3>\n<ul>\n<li>[ ] <strong>F1</strong>: <code>JsonPatch.diff(source, target)</code> computes a patch transforming source to target</li>\n<li>[ ] <strong>F2</strong>: <code>patch.apply(json, mode)</code> applies a patch with configurable failure handling</li>\n<li>[ ] <strong>F3</strong>: <code>patch1 ++ patch2</code> composes patches (apply first, then second)</li>\n<li>[ ] <strong>F4</strong>: <code>JsonPatch.empty</code> is the identity element for composition</li>\n<li>[ ] <strong>F5</strong>: Support <code>JsonPatchMode.Strict</code>, <code>Lenient</code>, and <code>Clobber</code> modes</li>\n<li>[ ] <strong>F6</strong>: Bidirectional conversion: <code>toDynamicPatch</code> / <code>fromDynamicPatch</code></li>\n</ul>\n<h3>Algebraic Laws</h3>\n<p>All laws must be verified with property-based tests (see <code>PatchLawsSpec</code> for reference):</p>\n<ul>\n<li>[ ] <strong>L1</strong>: Left identity â€” <code>(empty ++ p)(j) == p(j)</code></li>\n<li>[ ] <strong>L2</strong>: Right identity â€” <code>(p ++ empty)(j) == p(j)</code></li>\n<li>[ ] <strong>L3</strong>: Associativity â€” <code>((p1 ++ p2) ++ p3)(j) == (p1 ++ (p2 ++ p3))(j)</code></li>\n<li>[ ] <strong>L4</strong>: Roundtrip â€” <code>diff(a, b)(a) == Right(b)</code></li>\n<li>[ ] <strong>L5</strong>: Identity diff â€” <code>diff(j, j).isEmpty</code></li>\n<li>[ ] <strong>L6</strong>: Diff composition â€” <code>(diff(a, b) ++ diff(b, c))(a) == Right(c)</code></li>\n<li>[ ] <strong>L7</strong>: Lenient subsumes Strict â€” if <code>p(j, Strict) == Right(r)</code> then <code>p(j, Lenient) == Right(r)</code></li>\n</ul>\n<h3>Testing Requirements</h3>\n<ul>\n<li>[ ] <strong>T1</strong>: Property-based tests for all algebraic laws (see <code>PatchLawsSpec</code>)</li>\n<li>[ ] <strong>T2</strong>: Test each operation type (<code>Set</code>, <code>PrimitiveDelta</code>, <code>ArrayEdit</code>, <code>ObjectEdit</code>, <code>Nested</code>)</li>\n<li>[ ] <strong>T3</strong>: Test each <code>ArrayOp</code> variant (<code>Insert</code>, <code>Append</code>, <code>Delete</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T4</strong>: Test each <code>ObjectOp</code> variant (<code>Add</code>, <code>Remove</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T5</strong>: Test each <code>StringOp</code> variant (<code>Insert</code>, <code>Delete</code>, <code>Append</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T6</strong>: Test <code>NumberDelta</code> with positive, negative, zero, and decimal deltas</li>\n<li>[ ] <strong>T7</strong>: Test all three <code>JsonPatchMode</code> behaviors</li>\n<li>[ ] <strong>T8</strong>: Test <code>toDynamicPatch</code> / <code>fromDynamicPatch</code> roundtrip</li>\n<li>[ ] <strong>T9</strong>: Test edge cases: empty arrays, empty objects, empty strings, nested structures</li>\n<li>[ ] <strong>T10</strong>: Test error cases: invalid paths, type mismatches, out-of-bounds indices</li>\n</ul>\n<h3>Documentation Requirements</h3>\n<ul>\n<li>[ ] <strong>D1</strong>: ScalaDoc for all public types and methods</li>\n<li>[ ] <strong>D2</strong>: Usage examples in ScalaDoc (see sketch for examples)</li>\n<li>[ ] <strong>D3</strong>: Document algebraic laws in type-level comments</li>\n<li>[ ] <strong>D4</strong>: Document relationship to <code>DynamicPatch</code></li>\n</ul>\n<h3>Implementation Notes</h3>\n<ol>\n<li>\n<p><strong>Follow <code>DynamicPatch</code> patterns</strong>: The implementation in <code>DynamicPatch.scala</code> is the reference. Study <code>Differ.scala</code> for diff algorithms (especially LCS for sequences and strings).</p>\n</li>\n<li>\n<p><strong>Reuse algorithms where possible</strong>: Consider whether <code>JsonPatch</code> can delegate to <code>DynamicPatch</code> internally, or share algorithm implementations.</p>\n</li>\n<li>\n<p><strong>Keep it minimal</strong>: Resist adding operations not present in <code>DynamicPatch</code>. The design is intentionally minimal and principled.</p>\n</li>\n<li>\n<p><strong>Performance considerations</strong>: The register-based design of ZIO Blocks prioritizes performance. Avoid unnecessary allocations in hot paths.</p>\n</li>\n</ol>\n<h2>Out of Scope</h2>\n<p>The following are explicitly <strong>not</strong> part of this issue:</p>\n<ul>\n<li>RFC 6902 JSON Patch serialization format (separate issue)</li>\n<li>Patch inversion / undo support (separate issue)</li>\n<li>Patch optimization / compaction (separate issue)</li>\n<li>Integration with <code>Json</code> type methods like <code>json.diff(other)</code> (depends on <code>Json</code> implementation)</li>\n</ul>\n<h2>Related</h2>\n<ul>\n<li><code>DynamicPatch</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala</code></a></li>\n<li><code>Differ</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala</code></a></li>\n<li><code>PatchLawsSpec</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala\"><code>schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala</code></a></li>\n<li><code>PatchMode</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala</code></a></li>\n</ul>\n<h2>Acceptance Criteria</h2>\n<ul>\n<li>[ ] All functional requirements (F1-F6) implemented</li>\n<li>[ ] All algebraic laws (L1-L7) pass property-based tests</li>\n<li>[ ] All testing requirements (T1-T10) have corresponding test cases</li>\n<li>[ ] All documentation requirements (D1-D4) complete</li>\n<li>[ ] Code reviewed and approved</li>\n<li>[ ] CI passing</li>\n</ul></body></html># Add `JsonPatch` type for diffing and patching JSON values\n\n## Summary\n\nImplement a `JsonPatch` type that enables computing diffs between JSON values and applying patches to transform one JSON value into another. This type should mirror the existing `DynamicPatch` implementation, adapted for JSON's simpler data model.\n\n## Motivation\n\n`DynamicValue` has a well-designed `DynamicPatch` system with:\n- Monoid composition (`++` with `empty` identity)\n- LCS-based sequence diffing\n- Primitive delta operations (numeric deltas, string edits)\n- Comprehensive algebraic laws verified by property tests\n\nThe proposed `Json` type (see #TBD) needs equivalent patching capabilities. Rather than converting `Json â†” DynamicValue` for every patch operation, a native `JsonPatch` provides:\n- Type safety (no conversion errors for JSON-incompatible DynamicPatch operations)\n- API consistency with the `Json` type\n- Potential for JSON-specific optimizations\n\n## Design Sketch\n\nA design sketch is available at [`[schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala). This sketch is **a guide, not a specification** â€” implementers should use judgment and deviate where appropriate.\n\n### Core Types\n\nThe design mirrors `DynamicPatch` with JSON-specific adaptations:\n\n| DynamicPatch | JsonPatch | Notes |\n|--------------|-----------|-------|\n| `DynamicPatch(Vector[DynamicPatchOp])` | `JsonPatch(Vector[JsonPatchOp])` | Same structure |\n| `Operation.Set` | `Op.Set` | Same |\n| `Operation.PrimitiveDelta` | `Op.PrimitiveDelta` | Simplified for JSON types |\n| `Operation.SequenceEdit` | `Op.ArrayEdit` | Renamed |\n| `Operation.MapEdit` | `Op.ObjectEdit` | String keys only |\n| `Operation.Patch` | `Op.Nested` | Same |\n| `SeqOp` | `ArrayOp` | Same operations |\n| `MapOp` | `ObjectOp` | String keys only |\n| `PrimitiveOp` (14 variants) | `PrimitiveOp` (2 variants) | See below |\n\n### Primitive Operations\n\nJSON has a simpler type system than `DynamicValue`:\n\n| JSON Type | Delta Operation | Notes |\n|-----------|-----------------|-------|\n| Number | `NumberDelta(BigDecimal)` | Unifies all numeric deltas |\n| String | `StringEdit(Vector[StringOp])` | Same as `DynamicPatch` |\n| Boolean | Use `Op.Set` | No delta (same as `DynamicPatch`) |\n| Null | Use `Op.Set` | No delta |\n\n### StringOp\n\nMirror `DynamicPatch.StringOp` exactly:\n- `Insert(index: Int, text: String)`\n- `Delete(index: Int, length: Int)`\n- `Append(text: String)`\n- `Modify(index: Int, length: Int, text: String)`\n\n### ArrayOp\n\nMirror `DynamicPatch.SeqOp`:\n- `Insert(index: Int, values: Vector[Json])`\n- `Append(values: Vector[Json])`\n- `Delete(index: Int, count: Int)`\n- `Modify(index: Int, op: Op)`\n\n### ObjectOp\n\nMirror `DynamicPatch.MapOp` with string keys:\n- `Add(key: String, value: Json)`\n- `Remove(key: String)`\n- `Modify(key: String, patch: JsonPatch)`\n\n## Requirements\n\n### Functional Requirements\n\n- [ ] **F1**: `JsonPatch.diff(source, target)` computes a patch transforming source to target\n- [ ] **F2**: `patch.apply(json, mode)` applies a patch with configurable failure handling\n- [ ] **F3**: `patch1 ++ patch2` composes patches (apply first, then second)\n- [ ] **F4**: `JsonPatch.empty` is the identity element for composition\n- [ ] **F5**: Support `JsonPatchMode.Strict`, `Lenient`, and `Clobber` modes\n- [ ] **F6**: Bidirectional conversion: `toDynamicPatch` / `fromDynamicPatch`\n\n### Algebraic Laws\n\nAll laws must be verified with property-based tests (see `PatchLawsSpec` for reference):\n\n- [ ] **L1**: Left identity â€” `(empty ++ p)(j) == p(j)`\n- [ ] **L2**: Right identity â€” `(p ++ empty)(j) == p(j)`\n- [ ] **L3**: Associativity â€” `((p1 ++ p2) ++ p3)(j) == (p1 ++ (p2 ++ p3))(j)`\n- [ ] **L4**: Roundtrip â€” `diff(a, b)(a) == Right(b)`\n- [ ] **L5**: Identity diff â€” `diff(j, j).isEmpty`\n- [ ] **L6**: Diff composition â€” `(diff(a, b) ++ diff(b, c))(a) == Right(c)`\n- [ ] **L7**: Lenient subsumes Strict â€” if `p(j, Strict) == Right(r)` then `p(j, Lenient) == Right(r)`\n\n### Testing Requirements\n\n- [ ] **T1**: Property-based tests for all algebraic laws (see `PatchLawsSpec`)\n- [ ] **T2**: Test each operation type (`Set`, `PrimitiveDelta`, `ArrayEdit`, `ObjectEdit`, `Nested`)\n- [ ] **T3**: Test each `ArrayOp` variant (`Insert`, `Append`, `Delete`, `Modify`)\n- [ ] **T4**: Test each `ObjectOp` variant (`Add`, `Remove`, `Modify`)\n- [ ] **T5**: Test each `StringOp` variant (`Insert`, `Delete`, `Append`, `Modify`)\n- [ ] **T6**: Test `NumberDelta` with positive, negative, zero, and decimal deltas\n- [ ] **T7**: Test all three `JsonPatchMode` behaviors\n- [ ] **T8**: Test `toDynamicPatch` / `fromDynamicPatch` roundtrip\n- [ ] **T9**: Test edge cases: empty arrays, empty objects, empty strings, nested structures\n- [ ] **T10**: Test error cases: invalid paths, type mismatches, out-of-bounds indices\n\n### Documentation Requirements\n\n- [ ] **D1**: ScalaDoc for all public types and methods\n- [ ] **D2**: Usage examples in ScalaDoc (see sketch for examples)\n- [ ] **D3**: Document algebraic laws in type-level comments\n- [ ] **D4**: Document relationship to `DynamicPatch`\n\n## Related\n\n- `DynamicPatch` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala)\n- `Differ` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala)\n- `PatchLawsSpec` â€” [`[schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala](https://claude.ai/chat/schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala)`](./schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala)\n- `PatchMode` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala)\n\n## Acceptance Criteria\n\n- [ ] All functional requirements (F1-F6) implemented\n- [ ] All algebraic laws (L1-L7) pass property-based tests\n- [ ] All testing requirements (T1-T10) have corresponding test cases\n- [ ] All documentation requirements (D1-D4) complete\n- [ ] Code reviewed and approved\n- [ ] CI passing\n\n# Sketch\n\n```scala\npackage zio.blocks.schema.json\n\nimport zio.blocks.schema.DynamicOptic\nimport zio.blocks.schema.patch.DynamicPatch\n\n// =============================================================================\n// JSON PATCH\n// =============================================================================\n\n/**\n * An untyped patch that operates on [[Json]] values.\n *\n * `JsonPatch` is the JSON-specific counterpart to [[DynamicPatch]]. It represents\n * a sequence of operations that transform one JSON value into another. Patches\n * are serializable and composable.\n *\n * ==Design==\n *\n * This type directly mirrors [[DynamicPatch]] but is specialized for JSON's\n * simpler data model:\n *  - JSON has 4 leaf types (String, Number, Boolean, Null) vs 30 PrimitiveValues\n *  - JSON objects have string keys only (no arbitrary-keyed maps)\n *  - JSON has no native Variant type\n *\n * ==Algebraic Laws==\n *\n * '''Monoid Laws''' (under `++` composition):\n * {{{\n * // 1. LEFT IDENTITY\n * âˆ€ p: JsonPatch, j: Json.\n *   (JsonPatch.empty ++ p)(j, mode) == p(j, mode)\n *\n * // 2. RIGHT IDENTITY\n * âˆ€ p: JsonPatch, j: Json.\n *   (p ++ JsonPatch.empty)(j, mode) == p(j, mode)\n *\n * // 3. ASSOCIATIVITY\n * âˆ€ p1, p2, p3: JsonPatch, j: Json.\n *   ((p1 ++ p2) ++ p3)(j, mode) == (p1 ++ (p2 ++ p3))(j, mode)\n * }}}\n *\n * '''Diff/Apply Laws''':\n * {{{\n * // 4. ROUNDTRIP\n * âˆ€ source, target: Json.\n *   JsonPatch.diff(source, target)(source, Strict) == Right(target)\n *\n * // 5. IDENTITY DIFF\n * âˆ€ j: Json.\n *   JsonPatch.diff(j, j).isEmpty == true\n *\n * // 6. DIFF COMPOSITION\n * âˆ€ a, b, c: Json.\n *   (JsonPatch.diff(a, b) ++ JsonPatch.diff(b, c))(a, Strict) == Right(c)\n * }}}\n *\n * '''PatchMode Laws''':\n * {{{\n * // 7. STRICT FAILS ON ERROR\n * // Strict mode fails on first precondition violation\n *\n * // 8. LENIENT SKIPS ERRORS\n * // Lenient mode skips failing operations, always returns Right\n *\n * // 9. LENIENT SUBSUMES STRICT\n * âˆ€ p: JsonPatch, j: Json.\n *   p(j, Strict) == Right(r) implies p(j, Lenient) == Right(r)\n *\n * // 10. CLOBBER FORCES SUCCESS\n * // Clobber mode creates missing paths, always returns Right\n * }}}\n *\n * @param ops The sequence of patch operations\n */\nfinal case class JsonPatch(ops: Vector[JsonPatch.JsonPatchOp]) {\n\n  /**\n   * Applies this patch to a JSON value.\n   *\n   * @param json The JSON value to patch\n   * @param mode The patch mode (default: Strict)\n   * @return Either an error or the patched value\n   */\n  def apply(json: Json, mode: JsonPatchMode = JsonPatchMode.Strict): Either[JsonError, Json]\n\n  /**\n   * Composes this patch with another. Applies this patch first, then `that`.\n   *\n   * This is the monoid `combine` operation.\n   */\n  def ++(that: JsonPatch): JsonPatch = JsonPatch(ops ++ that.ops)\n\n  /**\n   * Returns true if this patch contains no operations.\n   */\n  def isEmpty: Boolean = ops.isEmpty\n\n  /**\n   * Converts this JSON patch to a [[DynamicPatch]].\n   */\n  def toDynamicPatch: DynamicPatch\n}\n\nobject JsonPatch {\n\n  /**\n   * Empty patch â€” the identity element for `++` composition.\n   */\n  val empty: JsonPatch = JsonPatch(Vector.empty)\n\n  /**\n   * Creates a patch with a single operation at the root path.\n   */\n  def root(op: Op): JsonPatch =\n    JsonPatch(Vector(JsonPatchOp(DynamicOptic.root, op)))\n\n  /**\n   * Creates a patch with a single operation at the given path.\n   */\n  def apply(path: DynamicOptic, op: Op): JsonPatch =\n    JsonPatch(Vector(JsonPatchOp(path, op)))\n\n  /**\n   * Computes a patch that transforms `oldJson` into `newJson`.\n   *\n   * Law: `diff(old, new)(old, Strict) == Right(new)`\n   */\n  def diff(oldJson: Json, newJson: Json): JsonPatch\n\n  /**\n   * Creates a JSON patch from a [[DynamicPatch]].\n   *\n   * May fail if the DynamicPatch contains operations not representable in JSON\n   * (e.g., non-string map keys, temporal deltas, variant operations).\n   */\n  def fromDynamicPatch(patch: DynamicPatch): Either[JsonError, JsonPatch]\n\n  // ===========================================================================\n  // JsonPatchOp â€” a single operation at a path\n  // ===========================================================================\n\n  /**\n   * A single patch operation: a path and what to do there.\n   *\n   * Mirrors [[DynamicPatch.DynamicPatchOp]].\n   */\n  final case class JsonPatchOp(path: DynamicOptic, op: Op)\n\n  // ===========================================================================\n  // Op â€” the operation to perform at a path\n  // ===========================================================================\n\n  /**\n   * The operation to perform at a target location.\n   *\n   * Mirrors [[DynamicPatch.Operation]] but specialized for JSON.\n   */\n  sealed trait Op\n\n  object Op {\n\n    /**\n     * Set a value directly (replacement).\n     *\n     * Mirrors [[DynamicPatch.Operation.Set]].\n     */\n    final case class Set(value: Json) extends Op\n\n    /**\n     * Apply a primitive delta operation.\n     *\n     * Used for numeric deltas and string edits.\n     * Mirrors [[DynamicPatch.Operation.PrimitiveDelta]].\n     */\n    final case class PrimitiveDelta(op: PrimitiveOp) extends Op\n\n    /**\n     * Apply array edit operations.\n     *\n     * Used for inserting, appending, deleting, or modifying array elements.\n     * Mirrors [[DynamicPatch.Operation.SequenceEdit]].\n     */\n    final case class ArrayEdit(ops: Vector[ArrayOp]) extends Op\n\n    /**\n     * Apply object edit operations.\n     *\n     * Used for adding, removing, or modifying object fields.\n     * Mirrors [[DynamicPatch.Operation.MapEdit]] but with string keys.\n     */\n    final case class ObjectEdit(ops: Vector[ObjectOp]) extends Op\n\n    /**\n     * Apply a nested patch.\n     *\n     * Used to group operations sharing a common path prefix.\n     * Mirrors [[DynamicPatch.Operation.Patch]].\n     */\n    final case class Nested(patch: JsonPatch) extends Op\n  }\n\n  // ===========================================================================\n  // PrimitiveOp â€” delta operations for JSON primitives\n  // ===========================================================================\n\n  /**\n   * Delta operations for JSON primitive values.\n   *\n   * JSON has only one numeric type, so we use BigDecimal for deltas.\n   * Boolean has no delta (use Set to toggle).\n   * Null has no delta (use Set to change).\n   *\n   * Mirrors [[DynamicPatch.PrimitiveOp]] but simplified for JSON's type system.\n   */\n  sealed trait PrimitiveOp\n\n  object PrimitiveOp {\n\n    /**\n     * Add a delta to a JSON number.\n     *\n     * Applied by: `currentValue + delta`\n     *\n     * Mirrors the numeric delta operations in [[DynamicPatch.PrimitiveOp]]\n     * (IntDelta, LongDelta, DoubleDelta, etc.) unified into one type.\n     */\n    final case class NumberDelta(delta: BigDecimal) extends PrimitiveOp\n\n    /**\n     * Apply string edit operations.\n     *\n     * Mirrors [[DynamicPatch.PrimitiveOp.StringEdit]].\n     */\n    final case class StringEdit(ops: Vector[StringOp]) extends PrimitiveOp\n  }\n\n  // ===========================================================================\n  // StringOp â€” edit operations for strings\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON strings.\n   *\n   * Mirrors [[DynamicPatch.StringOp]] exactly.\n   */\n  sealed trait StringOp\n\n  object StringOp {\n\n    /**\n     * Insert text at the given index.\n     */\n    final case class Insert(index: Int, text: String) extends StringOp\n\n    /**\n     * Delete characters starting at the given index.\n     */\n    final case class Delete(index: Int, length: Int) extends StringOp\n\n    /**\n     * Append text to the end of the string.\n     */\n    final case class Append(text: String) extends StringOp\n\n    /**\n     * Replace characters starting at index with new text.\n     */\n    final case class Modify(index: Int, length: Int, text: String) extends StringOp\n  }\n\n  // ===========================================================================\n  // ArrayOp â€” edit operations for arrays\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON arrays.\n   *\n   * Mirrors [[DynamicPatch.SeqOp]] but with Json values.\n   */\n  sealed trait ArrayOp\n\n  object ArrayOp {\n\n    /**\n     * Insert values at the given index.\n     */\n    final case class Insert(index: Int, values: Vector[Json]) extends ArrayOp\n\n    /**\n     * Append values to the end of the array.\n     */\n    final case class Append(values: Vector[Json]) extends ArrayOp\n\n    /**\n     * Delete elements starting at the given index.\n     */\n    final case class Delete(index: Int, count: Int) extends ArrayOp\n\n    /**\n     * Modify the element at the given index with a nested operation.\n     */\n    final case class Modify(index: Int, op: Op) extends ArrayOp\n  }\n\n  // ===========================================================================\n  // ObjectOp â€” edit operations for objects\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON objects.\n   *\n   * Mirrors [[DynamicPatch.MapOp]] but with string keys (JSON constraint).\n   */\n  sealed trait ObjectOp\n\n  object ObjectOp {\n\n    /**\n     * Add a field to the object.\n     */\n    final case class Add(key: String, value: Json) extends ObjectOp\n\n    /**\n     * Remove a field from the object.\n     */\n    final case class Remove(key: String) extends ObjectOp\n\n    /**\n     * Modify a field's value with a nested patch.\n     */\n    final case class Modify(key: String, patch: JsonPatch) extends ObjectOp\n  }\n}\n\n// =============================================================================\n// PATCH MODE\n// =============================================================================\n\n/**\n * Controls how patch application handles failures.\n *\n * Mirrors [[zio.blocks.schema.patch.PatchMode]].\n */\nsealed trait JsonPatchMode\n\nobject JsonPatchMode {\n\n  /**\n   * Fail on precondition violations.\n   */\n  case object Strict extends JsonPatchMode\n\n  /**\n   * Skip operations that fail preconditions.\n   */\n  case object Lenient extends JsonPatchMode\n\n  /**\n   * Replace/overwrite on conflicts (create missing paths).\n   */\n  case object Clobber extends JsonPatchMode\n}\n\n// =============================================================================\n// USAGE EXAMPLES\n// =============================================================================\n\n/*\n * ==Example 1: Basic Patching==\n *\n * {{{\n * import zio.blocks.schema.json._\n *\n * val json = Json.Object(Vector(\n *   \"name\" -> Json.String(\"Alice\"),\n *   \"age\" -> Json.Number(\"30\")\n * ))\n *\n * // Replace name\n * val patch = JsonPatch.root(JsonPatch.Op.Set(Json.String(\"Bob\")))\n *   // Or at a specific path:\n *   // JsonPatch(DynamicOptic.root.field(\"name\"), JsonPatch.Op.Set(Json.String(\"Bob\")))\n *\n * val result = patch(json, JsonPatchMode.Strict)\n * }}}\n *\n * ==Example 2: Diff and Apply (Roundtrip Law)==\n *\n * {{{\n * val source = Json.Object(Vector(\"x\" -> Json.Number(\"1\")))\n * val target = Json.Object(Vector(\"x\" -> Json.Number(\"5\")))\n *\n * val patch = JsonPatch.diff(source, target)\n *\n * // Roundtrip law\n * assert(patch(source, JsonPatchMode.Strict) == Right(target))\n *\n * // Identity diff law\n * assert(JsonPatch.diff(source, source).isEmpty)\n * }}}\n *\n * ==Example 3: Monoid Laws==\n *\n * {{{\n * val p1 = JsonPatch.diff(a, b)\n * val p2 = JsonPatch.diff(b, c)\n * val p3 = JsonPatch.diff(c, d)\n *\n * // Left identity\n * assert((JsonPatch.empty ++ p1)(a, Strict) == p1(a, Strict))\n *\n * // Right identity\n * assert((p1 ++ JsonPatch.empty)(a, Strict) == p1(a, Strict))\n *\n * // Associativity\n * assert(((p1 ++ p2) ++ p3)(a, Strict) == (p1 ++ (p2 ++ p3))(a, Strict))\n * }}}\n *\n * ==Example 4: Numeric Delta==\n *\n * {{{\n * val json = Json.Number(\"10\")\n *\n * // Add 5 to the number (more efficient than Set for large structures)\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.PrimitiveDelta(JsonPatch.PrimitiveOp.NumberDelta(BigDecimal(5)))\n * )\n *\n * assert(patch(json, Strict) == Right(Json.Number(\"15\")))\n * }}}\n *\n * ==Example 5: String Edit==\n *\n * {{{\n * val json = Json.String(\"hello world\")\n *\n * // Change \"hello\" to \"hi\" using LCS-based edits\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.PrimitiveDelta(\n *     JsonPatch.PrimitiveOp.StringEdit(Vector(\n *       JsonPatch.StringOp.Delete(0, 5),\n *       JsonPatch.StringOp.Insert(0, \"hi\")\n *     ))\n *   )\n * )\n *\n * assert(patch(json, Strict) == Right(Json.String(\"hi world\")))\n * }}}\n *\n * ==Example 6: Array Edit==\n *\n * {{{\n * val json = Json.Array(Vector(Json.Number(\"1\"), Json.Number(\"2\"), Json.Number(\"3\")))\n *\n * // Delete element at index 1, append new element\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ArrayEdit(Vector(\n *     JsonPatch.ArrayOp.Delete(1, 1),\n *     JsonPatch.ArrayOp.Append(Vector(Json.Number(\"4\")))\n *   ))\n * )\n *\n * // Result: [1, 3, 4]\n * }}}\n *\n * ==Example 7: Object Edit==\n *\n * {{{\n * val json = Json.Object(Vector(\"a\" -> Json.Number(\"1\"), \"b\" -> Json.Number(\"2\")))\n *\n * // Remove field \"a\", add field \"c\"\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ObjectEdit(Vector(\n *     JsonPatch.ObjectOp.Remove(\"a\"),\n *     JsonPatch.ObjectOp.Add(\"c\", Json.Number(\"3\"))\n *   ))\n * )\n *\n * // Result: {\"b\": 2, \"c\": 3}\n * }}}\n *\n * ==Example 8: Nested Patch==\n *\n * {{{\n * val json = Json.Object(Vector(\n *   \"user\" -> Json.Object(Vector(\n *     \"name\" -> Json.String(\"Alice\"),\n *     \"age\" -> Json.Number(\"30\")\n *   ))\n * ))\n *\n * // Patch nested inside \"user\"\n * val innerPatch = JsonPatch(Vector(\n *   JsonPatch.JsonPatchOp(\n *     DynamicOptic.root.field(\"age\"),\n *     JsonPatch.Op.PrimitiveDelta(JsonPatch.PrimitiveOp.NumberDelta(BigDecimal(1)))\n *   )\n * ))\n *\n * val patch = JsonPatch(\n *   DynamicOptic.root.field(\"user\"),\n *   JsonPatch.Op.Nested(innerPatch)\n * )\n *\n * // Increments user.age by 1\n * }}}\n *\n * ==Example 9: Diff Composition Law==\n *\n * {{{\n * val a = Json.Number(\"1\")\n * val b = Json.Number(\"5\")\n * val c = Json.Number(\"10\")\n *\n * val p1 = JsonPatch.diff(a, b)  // delta +4\n * val p2 = JsonPatch.diff(b, c)  // delta +5\n *\n * // Composition law: applying composed patch equals applying sequentially\n * assert((p1 ++ p2)(a, Strict) == Right(c))\n * }}}\n *\n * ==Example 10: PatchMode Behavior==\n *\n * {{{\n * val json = Json.Object(Vector(\"a\" -> Json.Number(\"1\")))\n *\n * // Try to remove non-existent field\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ObjectEdit(Vector(JsonPatch.ObjectOp.Remove(\"nonexistent\")))\n * )\n *\n * // Strict: fails\n * assert(patch(json, JsonPatchMode.Strict).isLeft)\n *\n * // Lenient: skips, returns unchanged\n * assert(patch(json, JsonPatchMode.Lenient) == Right(json))\n *\n * // Clobber: skips (nothing to clobber), returns unchanged\n * assert(patch(json, JsonPatchMode.Clobber) == Right(json))\n * }}}\n */\n```",
                  "html_url": "https://github.com/zio/zio-blocks/issues/685"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#685",
              "body": "<html><head></head><body><h1>Add <code>JsonPatch</code> type for diffing and patching JSON values</h1>\n<h2>Summary</h2>\n<p>Implement a <code>JsonPatch</code> type that enables computing diffs between JSON values and applying patches to transform one JSON value into another. This type should mirror the existing <code>DynamicPatch</code> implementation, adapted for JSON's simpler data model.</p>\n<h2>Motivation</h2>\n<p><code>DynamicValue</code> has a well-designed <code>DynamicPatch</code> system with:</p>\n<ul>\n<li>Monoid composition (<code>++</code> with <code>empty</code> identity)</li>\n<li>LCS-based sequence diffing</li>\n<li>Primitive delta operations (numeric deltas, string edits)</li>\n<li>Comprehensive algebraic laws verified by property tests</li>\n</ul>\n<p>The proposed <code>Json</code> type (see #TBD) needs equivalent patching capabilities. Rather than converting <code>Json â†” DynamicValue</code> for every patch operation, a native <code>JsonPatch</code> provides:</p>\n<ul>\n<li>Type safety (no conversion errors for JSON-incompatible DynamicPatch operations)</li>\n<li>API consistency with the <code>Json</code> type</li>\n<li>Potential for JSON-specific optimizations</li>\n</ul>\n<h2>Design Sketch</h2>\n<p>A design sketch is available at <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala</code></a>. This sketch is <strong>a guide, not a specification</strong> â€” implementers should use judgment and deviate where appropriate.</p>\n<h3>Core Types</h3>\n<p>The design mirrors <code>DynamicPatch</code> with JSON-specific adaptations:</p>\n\nDynamicPatch | JsonPatch | Notes\n-- | -- | --\nDynamicPatch(Vector[DynamicPatchOp]) | JsonPatch(Vector[JsonPatchOp]) | Same structure\nOperation.Set | Op.Set | Same\nOperation.PrimitiveDelta | Op.PrimitiveDelta | Simplified for JSON types\nOperation.SequenceEdit | Op.ArrayEdit | Renamed\nOperation.MapEdit | Op.ObjectEdit | String keys only\nOperation.Patch | Op.Nested | Same\nSeqOp | ArrayOp | Same operations\nMapOp | ObjectOp | String keys only\nPrimitiveOp (14 variants) | PrimitiveOp (2 variants) | See below\n\n\n<h3>StringOp</h3>\n<p>Mirror <code>DynamicPatch.StringOp</code> exactly:</p>\n<ul>\n<li><code>Insert(index: Int, text: String)</code></li>\n<li><code>Delete(index: Int, length: Int)</code></li>\n<li><code>Append(text: String)</code></li>\n<li><code>Modify(index: Int, length: Int, text: String)</code></li>\n</ul>\n<h3>ArrayOp</h3>\n<p>Mirror <code>DynamicPatch.SeqOp</code>:</p>\n<ul>\n<li><code>Insert(index: Int, values: Vector[Json])</code></li>\n<li><code>Append(values: Vector[Json])</code></li>\n<li><code>Delete(index: Int, count: Int)</code></li>\n<li><code>Modify(index: Int, op: Op)</code></li>\n</ul>\n<h3>ObjectOp</h3>\n<p>Mirror <code>DynamicPatch.MapOp</code> with string keys:</p>\n<ul>\n<li><code>Add(key: String, value: Json)</code></li>\n<li><code>Remove(key: String)</code></li>\n<li><code>Modify(key: String, patch: JsonPatch)</code></li>\n</ul>\n<h2>Requirements</h2>\n<h3>Functional Requirements</h3>\n<ul>\n<li>[ ] <strong>F1</strong>: <code>JsonPatch.diff(source, target)</code> computes a patch transforming source to target</li>\n<li>[ ] <strong>F2</strong>: <code>patch.apply(json, mode)</code> applies a patch with configurable failure handling</li>\n<li>[ ] <strong>F3</strong>: <code>patch1 ++ patch2</code> composes patches (apply first, then second)</li>\n<li>[ ] <strong>F4</strong>: <code>JsonPatch.empty</code> is the identity element for composition</li>\n<li>[ ] <strong>F5</strong>: Support <code>JsonPatchMode.Strict</code>, <code>Lenient</code>, and <code>Clobber</code> modes</li>\n<li>[ ] <strong>F6</strong>: Bidirectional conversion: <code>toDynamicPatch</code> / <code>fromDynamicPatch</code></li>\n</ul>\n<h3>Algebraic Laws</h3>\n<p>All laws must be verified with property-based tests (see <code>PatchLawsSpec</code> for reference):</p>\n<ul>\n<li>[ ] <strong>L1</strong>: Left identity â€” <code>(empty ++ p)(j) == p(j)</code></li>\n<li>[ ] <strong>L2</strong>: Right identity â€” <code>(p ++ empty)(j) == p(j)</code></li>\n<li>[ ] <strong>L3</strong>: Associativity â€” <code>((p1 ++ p2) ++ p3)(j) == (p1 ++ (p2 ++ p3))(j)</code></li>\n<li>[ ] <strong>L4</strong>: Roundtrip â€” <code>diff(a, b)(a) == Right(b)</code></li>\n<li>[ ] <strong>L5</strong>: Identity diff â€” <code>diff(j, j).isEmpty</code></li>\n<li>[ ] <strong>L6</strong>: Diff composition â€” <code>(diff(a, b) ++ diff(b, c))(a) == Right(c)</code></li>\n<li>[ ] <strong>L7</strong>: Lenient subsumes Strict â€” if <code>p(j, Strict) == Right(r)</code> then <code>p(j, Lenient) == Right(r)</code></li>\n</ul>\n<h3>Testing Requirements</h3>\n<ul>\n<li>[ ] <strong>T1</strong>: Property-based tests for all algebraic laws (see <code>PatchLawsSpec</code>)</li>\n<li>[ ] <strong>T2</strong>: Test each operation type (<code>Set</code>, <code>PrimitiveDelta</code>, <code>ArrayEdit</code>, <code>ObjectEdit</code>, <code>Nested</code>)</li>\n<li>[ ] <strong>T3</strong>: Test each <code>ArrayOp</code> variant (<code>Insert</code>, <code>Append</code>, <code>Delete</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T4</strong>: Test each <code>ObjectOp</code> variant (<code>Add</code>, <code>Remove</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T5</strong>: Test each <code>StringOp</code> variant (<code>Insert</code>, <code>Delete</code>, <code>Append</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T6</strong>: Test <code>NumberDelta</code> with positive, negative, zero, and decimal deltas</li>\n<li>[ ] <strong>T7</strong>: Test all three <code>JsonPatchMode</code> behaviors</li>\n<li>[ ] <strong>T8</strong>: Test <code>toDynamicPatch</code> / <code>fromDynamicPatch</code> roundtrip</li>\n<li>[ ] <strong>T9</strong>: Test edge cases: empty arrays, empty objects, empty strings, nested structures</li>\n<li>[ ] <strong>T10</strong>: Test error cases: invalid paths, type mismatches, out-of-bounds indices</li>\n</ul>\n<h3>Documentation Requirements</h3>\n<ul>\n<li>[ ] <strong>D1</strong>: ScalaDoc for all public types and methods</li>\n<li>[ ] <strong>D2</strong>: Usage examples in ScalaDoc (see sketch for examples)</li>\n<li>[ ] <strong>D3</strong>: Document algebraic laws in type-level comments</li>\n<li>[ ] <strong>D4</strong>: Document relationship to <code>DynamicPatch</code></li>\n</ul>\n<h3>Implementation Notes</h3>\n<ol>\n<li>\n<p><strong>Follow <code>DynamicPatch</code> patterns</strong>: The implementation in <code>DynamicPatch.scala</code> is the reference. Study <code>Differ.scala</code> for diff algorithms (especially LCS for sequences and strings).</p>\n</li>\n<li>\n<p><strong>Reuse algorithms where possible</strong>: Consider whether <code>JsonPatch</code> can delegate to <code>DynamicPatch</code> internally, or share algorithm implementations.</p>\n</li>\n<li>\n<p><strong>Keep it minimal</strong>: Resist adding operations not present in <code>DynamicPatch</code>. The design is intentionally minimal and principled.</p>\n</li>\n<li>\n<p><strong>Performance considerations</strong>: The register-based design of ZIO Blocks prioritizes performance. Avoid unnecessary allocations in hot paths.</p>\n</li>\n</ol>\n<h2>Out of Scope</h2>\n<p>The following are explicitly <strong>not</strong> part of this issue:</p>\n<ul>\n<li>RFC 6902 JSON Patch serialization format (separate issue)</li>\n<li>Patch inversion / undo support (separate issue)</li>\n<li>Patch optimization / compaction (separate issue)</li>\n<li>Integration with <code>Json</code> type methods like <code>json.diff(other)</code> (depends on <code>Json</code> implementation)</li>\n</ul>\n<h2>Related</h2>\n<ul>\n<li><code>DynamicPatch</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala</code></a></li>\n<li><code>Differ</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala</code></a></li>\n<li><code>PatchLawsSpec</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala\"><code>schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala</code></a></li>\n<li><code>PatchMode</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala</code></a></li>\n</ul>\n<h2>Acceptance Criteria</h2>\n<ul>\n<li>[ ] All functional requirements (F1-F6) implemented</li>\n<li>[ ] All algebraic laws (L1-L7) pass property-based tests</li>\n<li>[ ] All testing requirements (T1-T10) have corresponding test cases</li>\n<li>[ ] All documentation requirements (D1-D4) complete</li>\n<li>[ ] Code reviewed and approved</li>\n<li>[ ] CI passing</li>\n</ul></body></html># Add `JsonPatch` type for diffing and patching JSON values\n\n## Summary\n\nImplement a `JsonPatch` type that enables computing diffs between JSON values and applying patches to transform one JSON value into another. This type should mirror the existing `DynamicPatch` implementation, adapted for JSON's simpler data model.\n\n## Motivation\n\n`DynamicValue` has a well-designed `DynamicPatch` system with:\n- Monoid composition (`++` with `empty` identity)\n- LCS-based sequence diffing\n- Primitive delta operations (numeric deltas, string edits)\n- Comprehensive algebraic laws verified by property tests\n\nThe proposed `Json` type (see #TBD) needs equivalent patching capabilities. Rather than converting `Json â†” DynamicValue` for every patch operation, a native `JsonPatch` provides:\n- Type safety (no conversion errors for JSON-incompatible DynamicPatch operations)\n- API consistency with the `Json` type\n- Potential for JSON-specific optimizations\n\n## Design Sketch\n\nA design sketch is available at [`[schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala). This sketch is **a guide, not a specification** â€” implementers should use judgment and deviate where appropriate.\n\n### Core Types\n\nThe design mirrors `DynamicPatch` with JSON-specific adaptations:\n\n| DynamicPatch | JsonPatch | Notes |\n|--------------|-----------|-------|\n| `DynamicPatch(Vector[DynamicPatchOp])` | `JsonPatch(Vector[JsonPatchOp])` | Same structure |\n| `Operation.Set` | `Op.Set` | Same |\n| `Operation.PrimitiveDelta` | `Op.PrimitiveDelta` | Simplified for JSON types |\n| `Operation.SequenceEdit` | `Op.ArrayEdit` | Renamed |\n| `Operation.MapEdit` | `Op.ObjectEdit` | String keys only |\n| `Operation.Patch` | `Op.Nested` | Same |\n| `SeqOp` | `ArrayOp` | Same operations |\n| `MapOp` | `ObjectOp` | String keys only |\n| `PrimitiveOp` (14 variants) | `PrimitiveOp` (2 variants) | See below |\n\n### Primitive Operations\n\nJSON has a simpler type system than `DynamicValue`:\n\n| JSON Type | Delta Operation | Notes |\n|-----------|-----------------|-------|\n| Number | `NumberDelta(BigDecimal)` | Unifies all numeric deltas |\n| String | `StringEdit(Vector[StringOp])` | Same as `DynamicPatch` |\n| Boolean | Use `Op.Set` | No delta (same as `DynamicPatch`) |\n| Null | Use `Op.Set` | No delta |\n\n### StringOp\n\nMirror `DynamicPatch.StringOp` exactly:\n- `Insert(index: Int, text: String)`\n- `Delete(index: Int, length: Int)`\n- `Append(text: String)`\n- `Modify(index: Int, length: Int, text: String)`\n\n### ArrayOp\n\nMirror `DynamicPatch.SeqOp`:\n- `Insert(index: Int, values: Vector[Json])`\n- `Append(values: Vector[Json])`\n- `Delete(index: Int, count: Int)`\n- `Modify(index: Int, op: Op)`\n\n### ObjectOp\n\nMirror `DynamicPatch.MapOp` with string keys:\n- `Add(key: String, value: Json)`\n- `Remove(key: String)`\n- `Modify(key: String, patch: JsonPatch)`\n\n## Requirements\n\n### Functional Requirements\n\n- [ ] **F1**: `JsonPatch.diff(source, target)` computes a patch transforming source to target\n- [ ] **F2**: `patch.apply(json, mode)` applies a patch with configurable failure handling\n- [ ] **F3**: `patch1 ++ patch2` composes patches (apply first, then second)\n- [ ] **F4**: `JsonPatch.empty` is the identity element for composition\n- [ ] **F5**: Support `JsonPatchMode.Strict`, `Lenient`, and `Clobber` modes\n- [ ] **F6**: Bidirectional conversion: `toDynamicPatch` / `fromDynamicPatch`\n\n### Algebraic Laws\n\nAll laws must be verified with property-based tests (see `PatchLawsSpec` for reference):\n\n- [ ] **L1**: Left identity â€” `(empty ++ p)(j) == p(j)`\n- [ ] **L2**: Right identity â€” `(p ++ empty)(j) == p(j)`\n- [ ] **L3**: Associativity â€” `((p1 ++ p2) ++ p3)(j) == (p1 ++ (p2 ++ p3))(j)`\n- [ ] **L4**: Roundtrip â€” `diff(a, b)(a) == Right(b)`\n- [ ] **L5**: Identity diff â€” `diff(j, j).isEmpty`\n- [ ] **L6**: Diff composition â€” `(diff(a, b) ++ diff(b, c))(a) == Right(c)`\n- [ ] **L7**: Lenient subsumes Strict â€” if `p(j, Strict) == Right(r)` then `p(j, Lenient) == Right(r)`\n\n### Testing Requirements\n\n- [ ] **T1**: Property-based tests for all algebraic laws (see `PatchLawsSpec`)\n- [ ] **T2**: Test each operation type (`Set`, `PrimitiveDelta`, `ArrayEdit`, `ObjectEdit`, `Nested`)\n- [ ] **T3**: Test each `ArrayOp` variant (`Insert`, `Append`, `Delete`, `Modify`)\n- [ ] **T4**: Test each `ObjectOp` variant (`Add`, `Remove`, `Modify`)\n- [ ] **T5**: Test each `StringOp` variant (`Insert`, `Delete`, `Append`, `Modify`)\n- [ ] **T6**: Test `NumberDelta` with positive, negative, zero, and decimal deltas\n- [ ] **T7**: Test all three `JsonPatchMode` behaviors\n- [ ] **T8**: Test `toDynamicPatch` / `fromDynamicPatch` roundtrip\n- [ ] **T9**: Test edge cases: empty arrays, empty objects, empty strings, nested structures\n- [ ] **T10**: Test error cases: invalid paths, type mismatches, out-of-bounds indices\n\n### Documentation Requirements\n\n- [ ] **D1**: ScalaDoc for all public types and methods\n- [ ] **D2**: Usage examples in ScalaDoc (see sketch for examples)\n- [ ] **D3**: Document algebraic laws in type-level comments\n- [ ] **D4**: Document relationship to `DynamicPatch`\n\n## Related\n\n- `DynamicPatch` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala)\n- `Differ` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala)\n- `PatchLawsSpec` â€” [`[schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala](https://claude.ai/chat/schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala)`](./schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala)\n- `PatchMode` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala)\n\n## Acceptance Criteria\n\n- [ ] All functional requirements (F1-F6) implemented\n- [ ] All algebraic laws (L1-L7) pass property-based tests\n- [ ] All testing requirements (T1-T10) have corresponding test cases\n- [ ] All documentation requirements (D1-D4) complete\n- [ ] Code reviewed and approved\n- [ ] CI passing\n\n# Sketch\n\n```scala\npackage zio.blocks.schema.json\n\nimport zio.blocks.schema.DynamicOptic\nimport zio.blocks.schema.patch.DynamicPatch\n\n// =============================================================================\n// JSON PATCH\n// =============================================================================\n\n/**\n * An untyped patch that operates on [[Json]] values.\n *\n * `JsonPatch` is the JSON-specific counterpart to [[DynamicPatch]]. It represents\n * a sequence of operations that transform one JSON value into another. Patches\n * are serializable and composable.\n *\n * ==Design==\n *\n * This type directly mirrors [[DynamicPatch]] but is specialized for JSON's\n * simpler data model:\n *  - JSON has 4 leaf types (String, Number, Boolean, Null) vs 30 PrimitiveValues\n *  - JSON objects have string keys only (no arbitrary-keyed maps)\n *  - JSON has no native Variant type\n *\n * ==Algebraic Laws==\n *\n * '''Monoid Laws''' (under `++` composition):\n * {{{\n * // 1. LEFT IDENTITY\n * âˆ€ p: JsonPatch, j: Json.\n *   (JsonPatch.empty ++ p)(j, mode) == p(j, mode)\n *\n * // 2. RIGHT IDENTITY\n * âˆ€ p: JsonPatch, j: Json.\n *   (p ++ JsonPatch.empty)(j, mode) == p(j, mode)\n *\n * // 3. ASSOCIATIVITY\n * âˆ€ p1, p2, p3: JsonPatch, j: Json.\n *   ((p1 ++ p2) ++ p3)(j, mode) == (p1 ++ (p2 ++ p3))(j, mode)\n * }}}\n *\n * '''Diff/Apply Laws''':\n * {{{\n * // 4. ROUNDTRIP\n * âˆ€ source, target: Json.\n *   JsonPatch.diff(source, target)(source, Strict) == Right(target)\n *\n * // 5. IDENTITY DIFF\n * âˆ€ j: Json.\n *   JsonPatch.diff(j, j).isEmpty == true\n *\n * // 6. DIFF COMPOSITION\n * âˆ€ a, b, c: Json.\n *   (JsonPatch.diff(a, b) ++ JsonPatch.diff(b, c))(a, Strict) == Right(c)\n * }}}\n *\n * '''PatchMode Laws''':\n * {{{\n * // 7. STRICT FAILS ON ERROR\n * // Strict mode fails on first precondition violation\n *\n * // 8. LENIENT SKIPS ERRORS\n * // Lenient mode skips failing operations, always returns Right\n *\n * // 9. LENIENT SUBSUMES STRICT\n * âˆ€ p: JsonPatch, j: Json.\n *   p(j, Strict) == Right(r) implies p(j, Lenient) == Right(r)\n *\n * // 10. CLOBBER FORCES SUCCESS\n * // Clobber mode creates missing paths, always returns Right\n * }}}\n *\n * @param ops The sequence of patch operations\n */\nfinal case class JsonPatch(ops: Vector[JsonPatch.JsonPatchOp]) {\n\n  /**\n   * Applies this patch to a JSON value.\n   *\n   * @param json The JSON value to patch\n   * @param mode The patch mode (default: Strict)\n   * @return Either an error or the patched value\n   */\n  def apply(json: Json, mode: JsonPatchMode = JsonPatchMode.Strict): Either[JsonError, Json]\n\n  /**\n   * Composes this patch with another. Applies this patch first, then `that`.\n   *\n   * This is the monoid `combine` operation.\n   */\n  def ++(that: JsonPatch): JsonPatch = JsonPatch(ops ++ that.ops)\n\n  /**\n   * Returns true if this patch contains no operations.\n   */\n  def isEmpty: Boolean = ops.isEmpty\n\n  /**\n   * Converts this JSON patch to a [[DynamicPatch]].\n   */\n  def toDynamicPatch: DynamicPatch\n}\n\nobject JsonPatch {\n\n  /**\n   * Empty patch â€” the identity element for `++` composition.\n   */\n  val empty: JsonPatch = JsonPatch(Vector.empty)\n\n  /**\n   * Creates a patch with a single operation at the root path.\n   */\n  def root(op: Op): JsonPatch =\n    JsonPatch(Vector(JsonPatchOp(DynamicOptic.root, op)))\n\n  /**\n   * Creates a patch with a single operation at the given path.\n   */\n  def apply(path: DynamicOptic, op: Op): JsonPatch =\n    JsonPatch(Vector(JsonPatchOp(path, op)))\n\n  /**\n   * Computes a patch that transforms `oldJson` into `newJson`.\n   *\n   * Law: `diff(old, new)(old, Strict) == Right(new)`\n   */\n  def diff(oldJson: Json, newJson: Json): JsonPatch\n\n  /**\n   * Creates a JSON patch from a [[DynamicPatch]].\n   *\n   * May fail if the DynamicPatch contains operations not representable in JSON\n   * (e.g., non-string map keys, temporal deltas, variant operations).\n   */\n  def fromDynamicPatch(patch: DynamicPatch): Either[JsonError, JsonPatch]\n\n  // ===========================================================================\n  // JsonPatchOp â€” a single operation at a path\n  // ===========================================================================\n\n  /**\n   * A single patch operation: a path and what to do there.\n   *\n   * Mirrors [[DynamicPatch.DynamicPatchOp]].\n   */\n  final case class JsonPatchOp(path: DynamicOptic, op: Op)\n\n  // ===========================================================================\n  // Op â€” the operation to perform at a path\n  // ===========================================================================\n\n  /**\n   * The operation to perform at a target location.\n   *\n   * Mirrors [[DynamicPatch.Operation]] but specialized for JSON.\n   */\n  sealed trait Op\n\n  object Op {\n\n    /**\n     * Set a value directly (replacement).\n     *\n     * Mirrors [[DynamicPatch.Operation.Set]].\n     */\n    final case class Set(value: Json) extends Op\n\n    /**\n     * Apply a primitive delta operation.\n     *\n     * Used for numeric deltas and string edits.\n     * Mirrors [[DynamicPatch.Operation.PrimitiveDelta]].\n     */\n    final case class PrimitiveDelta(op: PrimitiveOp) extends Op\n\n    /**\n     * Apply array edit operations.\n     *\n     * Used for inserting, appending, deleting, or modifying array elements.\n     * Mirrors [[DynamicPatch.Operation.SequenceEdit]].\n     */\n    final case class ArrayEdit(ops: Vector[ArrayOp]) extends Op\n\n    /**\n     * Apply object edit operations.\n     *\n     * Used for adding, removing, or modifying object fields.\n     * Mirrors [[DynamicPatch.Operation.MapEdit]] but with string keys.\n     */\n    final case class ObjectEdit(ops: Vector[ObjectOp]) extends Op\n\n    /**\n     * Apply a nested patch.\n     *\n     * Used to group operations sharing a common path prefix.\n     * Mirrors [[DynamicPatch.Operation.Patch]].\n     */\n    final case class Nested(patch: JsonPatch) extends Op\n  }\n\n  // ===========================================================================\n  // PrimitiveOp â€” delta operations for JSON primitives\n  // ===========================================================================\n\n  /**\n   * Delta operations for JSON primitive values.\n   *\n   * JSON has only one numeric type, so we use BigDecimal for deltas.\n   * Boolean has no delta (use Set to toggle).\n   * Null has no delta (use Set to change).\n   *\n   * Mirrors [[DynamicPatch.PrimitiveOp]] but simplified for JSON's type system.\n   */\n  sealed trait PrimitiveOp\n\n  object PrimitiveOp {\n\n    /**\n     * Add a delta to a JSON number.\n     *\n     * Applied by: `currentValue + delta`\n     *\n     * Mirrors the numeric delta operations in [[DynamicPatch.PrimitiveOp]]\n     * (IntDelta, LongDelta, DoubleDelta, etc.) unified into one type.\n     */\n    final case class NumberDelta(delta: BigDecimal) extends PrimitiveOp\n\n    /**\n     * Apply string edit operations.\n     *\n     * Mirrors [[DynamicPatch.PrimitiveOp.StringEdit]].\n     */\n    final case class StringEdit(ops: Vector[StringOp]) extends PrimitiveOp\n  }\n\n  // ===========================================================================\n  // StringOp â€” edit operations for strings\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON strings.\n   *\n   * Mirrors [[DynamicPatch.StringOp]] exactly.\n   */\n  sealed trait StringOp\n\n  object StringOp {\n\n    /**\n     * Insert text at the given index.\n     */\n    final case class Insert(index: Int, text: String) extends StringOp\n\n    /**\n     * Delete characters starting at the given index.\n     */\n    final case class Delete(index: Int, length: Int) extends StringOp\n\n    /**\n     * Append text to the end of the string.\n     */\n    final case class Append(text: String) extends StringOp\n\n    /**\n     * Replace characters starting at index with new text.\n     */\n    final case class Modify(index: Int, length: Int, text: String) extends StringOp\n  }\n\n  // ===========================================================================\n  // ArrayOp â€” edit operations for arrays\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON arrays.\n   *\n   * Mirrors [[DynamicPatch.SeqOp]] but with Json values.\n   */\n  sealed trait ArrayOp\n\n  object ArrayOp {\n\n    /**\n     * Insert values at the given index.\n     */\n    final case class Insert(index: Int, values: Vector[Json]) extends ArrayOp\n\n    /**\n     * Append values to the end of the array.\n     */\n    final case class Append(values: Vector[Json]) extends ArrayOp\n\n    /**\n     * Delete elements starting at the given index.\n     */\n    final case class Delete(index: Int, count: Int) extends ArrayOp\n\n    /**\n     * Modify the element at the given index with a nested operation.\n     */\n    final case class Modify(index: Int, op: Op) extends ArrayOp\n  }\n\n  // ===========================================================================\n  // ObjectOp â€” edit operations for objects\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON objects.\n   *\n   * Mirrors [[DynamicPatch.MapOp]] but with string keys (JSON constraint).\n   */\n  sealed trait ObjectOp\n\n  object ObjectOp {\n\n    /**\n     * Add a field to the object.\n     */\n    final case class Add(key: String, value: Json) extends ObjectOp\n\n    /**\n     * Remove a field from the object.\n     */\n    final case class Remove(key: String) extends ObjectOp\n\n    /**\n     * Modify a field's value with a nested patch.\n     */\n    final case class Modify(key: String, patch: JsonPatch) extends ObjectOp\n  }\n}\n\n// =============================================================================\n// PATCH MODE\n// =============================================================================\n\n/**\n * Controls how patch application handles failures.\n *\n * Mirrors [[zio.blocks.schema.patch.PatchMode]].\n */\nsealed trait JsonPatchMode\n\nobject JsonPatchMode {\n\n  /**\n   * Fail on precondition violations.\n   */\n  case object Strict extends JsonPatchMode\n\n  /**\n   * Skip operations that fail preconditions.\n   */\n  case object Lenient extends JsonPatchMode\n\n  /**\n   * Replace/overwrite on conflicts (create missing paths).\n   */\n  case object Clobber extends JsonPatchMode\n}\n\n// =============================================================================\n// USAGE EXAMPLES\n// =============================================================================\n\n/*\n * ==Example 1: Basic Patching==\n *\n * {{{\n * import zio.blocks.schema.json._\n *\n * val json = Json.Object(Vector(\n *   \"name\" -> Json.String(\"Alice\"),\n *   \"age\" -> Json.Number(\"30\")\n * ))\n *\n * // Replace name\n * val patch = JsonPatch.root(JsonPatch.Op.Set(Json.String(\"Bob\")))\n *   // Or at a specific path:\n *   // JsonPatch(DynamicOptic.root.field(\"name\"), JsonPatch.Op.Set(Json.String(\"Bob\")))\n *\n * val result = patch(json, JsonPatchMode.Strict)\n * }}}\n *\n * ==Example 2: Diff and Apply (Roundtrip Law)==\n *\n * {{{\n * val source = Json.Object(Vector(\"x\" -> Json.Number(\"1\")))\n * val target = Json.Object(Vector(\"x\" -> Json.Number(\"5\")))\n *\n * val patch = JsonPatch.diff(source, target)\n *\n * // Roundtrip law\n * assert(patch(source, JsonPatchMode.Strict) == Right(target))\n *\n * // Identity diff law\n * assert(JsonPatch.diff(source, source).isEmpty)\n * }}}\n *\n * ==Example 3: Monoid Laws==\n *\n * {{{\n * val p1 = JsonPatch.diff(a, b)\n * val p2 = JsonPatch.diff(b, c)\n * val p3 = JsonPatch.diff(c, d)\n *\n * // Left identity\n * assert((JsonPatch.empty ++ p1)(a, Strict) == p1(a, Strict))\n *\n * // Right identity\n * assert((p1 ++ JsonPatch.empty)(a, Strict) == p1(a, Strict))\n *\n * // Associativity\n * assert(((p1 ++ p2) ++ p3)(a, Strict) == (p1 ++ (p2 ++ p3))(a, Strict))\n * }}}\n *\n * ==Example 4: Numeric Delta==\n *\n * {{{\n * val json = Json.Number(\"10\")\n *\n * // Add 5 to the number (more efficient than Set for large structures)\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.PrimitiveDelta(JsonPatch.PrimitiveOp.NumberDelta(BigDecimal(5)))\n * )\n *\n * assert(patch(json, Strict) == Right(Json.Number(\"15\")))\n * }}}\n *\n * ==Example 5: String Edit==\n *\n * {{{\n * val json = Json.String(\"hello world\")\n *\n * // Change \"hello\" to \"hi\" using LCS-based edits\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.PrimitiveDelta(\n *     JsonPatch.PrimitiveOp.StringEdit(Vector(\n *       JsonPatch.StringOp.Delete(0, 5),\n *       JsonPatch.StringOp.Insert(0, \"hi\")\n *     ))\n *   )\n * )\n *\n * assert(patch(json, Strict) == Right(Json.String(\"hi world\")))\n * }}}\n *\n * ==Example 6: Array Edit==\n *\n * {{{\n * val json = Json.Array(Vector(Json.Number(\"1\"), Json.Number(\"2\"), Json.Number(\"3\")))\n *\n * // Delete element at index 1, append new element\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ArrayEdit(Vector(\n *     JsonPatch.ArrayOp.Delete(1, 1),\n *     JsonPatch.ArrayOp.Append(Vector(Json.Number(\"4\")))\n *   ))\n * )\n *\n * // Result: [1, 3, 4]\n * }}}\n *\n * ==Example 7: Object Edit==\n *\n * {{{\n * val json = Json.Object(Vector(\"a\" -> Json.Number(\"1\"), \"b\" -> Json.Number(\"2\")))\n *\n * // Remove field \"a\", add field \"c\"\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ObjectEdit(Vector(\n *     JsonPatch.ObjectOp.Remove(\"a\"),\n *     JsonPatch.ObjectOp.Add(\"c\", Json.Number(\"3\"))\n *   ))\n * )\n *\n * // Result: {\"b\": 2, \"c\": 3}\n * }}}\n *\n * ==Example 8: Nested Patch==\n *\n * {{{\n * val json = Json.Object(Vector(\n *   \"user\" -> Json.Object(Vector(\n *     \"name\" -> Json.String(\"Alice\"),\n *     \"age\" -> Json.Number(\"30\")\n *   ))\n * ))\n *\n * // Patch nested inside \"user\"\n * val innerPatch = JsonPatch(Vector(\n *   JsonPatch.JsonPatchOp(\n *     DynamicOptic.root.field(\"age\"),\n *     JsonPatch.Op.PrimitiveDelta(JsonPatch.PrimitiveOp.NumberDelta(BigDecimal(1)))\n *   )\n * ))\n *\n * val patch = JsonPatch(\n *   DynamicOptic.root.field(\"user\"),\n *   JsonPatch.Op.Nested(innerPatch)\n * )\n *\n * // Increments user.age by 1\n * }}}\n *\n * ==Example 9: Diff Composition Law==\n *\n * {{{\n * val a = Json.Number(\"1\")\n * val b = Json.Number(\"5\")\n * val c = Json.Number(\"10\")\n *\n * val p1 = JsonPatch.diff(a, b)  // delta +4\n * val p2 = JsonPatch.diff(b, c)  // delta +5\n *\n * // Composition law: applying composed patch equals applying sequentially\n * assert((p1 ++ p2)(a, Strict) == Right(c))\n * }}}\n *\n * ==Example 10: PatchMode Behavior==\n *\n * {{{\n * val json = Json.Object(Vector(\"a\" -> Json.Number(\"1\")))\n *\n * // Try to remove non-existent field\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ObjectEdit(Vector(JsonPatch.ObjectOp.Remove(\"nonexistent\")))\n * )\n *\n * // Strict: fails\n * assert(patch(json, JsonPatchMode.Strict).isLeft)\n *\n * // Lenient: skips, returns unchanged\n * assert(patch(json, JsonPatchMode.Lenient) == Right(json))\n *\n * // Clobber: skips (nothing to clobber), returns unchanged\n * assert(patch(json, JsonPatchMode.Clobber) == Right(json))\n * }}}\n */\n```",
              "url": "https://github.com/zio/zio-blocks/issues/685",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#517",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-18T17:51:47.561Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:47.561Z",
            "created_at": "2026-01-18T17:51:47.561Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#517",
              "status": "open",
              "type": "issue",
              "number": 517,
              "title": "Add structural schemas",
              "source": {
                "data": {
                  "id": "source-ZIO#517",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add structural schemas",
                  "body": "# Structural Type Schema Support\n\n## Overview\n\nExtend `Schema[A]` to support structural types, enabling schema derivation for types defined by their structure rather than their nominal identity. This allows for duck-typed schema validation and conversion between nominal and structural representations.\n\n## Core Concepts\n\n### Direct Structural Schema Derivation\n\nSchemas can be derived directly for structural types:\n\n```scala\n// Scala 3\ntype Person = { def name: String; def age: Int }\nval schema = Schema.derived[Person]\n\n// Scala 2\ntype Person = { def name: String; def age: Int }\nval schema = Schema.derived[Person]\n```\n\n**Note**: Both Scala 2 and Scala 3 use `def` for uniformity, even though Scala 3 supports `val` in structural types.\n\n**Implementation**: Schemas have bindings, which allow construction / deconstruction of values. Values for structural types are backed by:\n- **Scala 3**: `Selectable` \n- **Scala 2**: `Dynamic`\n\n### Nominal to Structural Conversion\n\nConvert nominal type schemas to their structural equivalents:\n\n```scala\ncase class Person(name: String, age: Int)\n\n// Get the structural schema corresponding to Person's shape\nval structuralSchema: Schema[{ def name: String; def age: Int }] = \n  Schema.derived[Person].structural\n```\n\n### Schema API Extension\n\n```scala\ncase class Schema[A](/* existing fields */) {\n  /**\n   * Convert this schema to a structural type schema.\n   * \n   * The structural type represents the \"shape\" of A without its nominal identity.\n   * This enables duck typing and structural validation.\n   * \n   * @param toStructural Macro-generated conversion to structural representation\n   * @return Schema for the structural type corresponding to A\n   */\n  def structural(implicit toStructural: ToStructural[A]): Schema[toStructural.StructuralType] = \n    toStructural.apply(this)\n}\n\n/**\n * Type class for converting nominal schemas to structural schemas.\n * Generated by macro for all supported types. Macro fails if a structural\n * type cannot be generated.\n *\n * NOTE: This approach has to be tested to yield inferrable types, and revised\n * if necessary. Inferrable types (from calling Schema#structural) are a must-have.\n */\ntrait ToStructural[A] {\n  type StructuralType\n  def apply(schema: Schema[A]): Schema[StructuralType]\n}\n\nobject ToStructural {\n  type Aux[A, S] = ToStructural[A] { type StructuralType = S }\n  \n  // Scala 3\n  transparent inline given [A]: ToStructural[A] = ${toStructuralMacro[A]}\n  \n  // Scala 2\n  implicit def materialize[A]: ToStructural[A] = macro toStructuralImpl[A]\n}\n```\n\n---\n\n## Examples\n\n### 1. Simple Product Types\n\n#### Case Class to Structural\n\n```scala\n// Both Scala 2 and Scala 3\ncase class Person(name: String, age: Int)\n\n// Original nominal schema\nval nominalSchema: Schema[Person] = Schema.derived[Person]\n\n// Convert to structural\nval structuralSchema: Schema[{ def name: String; def age: Int }] = \n  nominalSchema.structural\n\n// Direct structural derivation (equivalent)\nval directStructural: Schema[{ def name: String; def age: Int }] = \n  Schema.derived[{ def name: String; def age: Int }]\n```\n\n### 2. Nested Structures\n\n```scala\ncase class Address(street: String, city: String, zip: Int)\ncase class Person(name: String, age: Int, address: Address)\n\nval structuralSchema = Schema.derived[Person].structural\n// Type: Schema[{ \n//   def name: String\n//   def age: Int\n//   def address: { def street: String; def city: String; def zip: Int }\n// }]\n```\n\n### 3. Collections and Options\n\n```scala\ncase class Team(name: String, members: List[String], leader: Option[String])\n\nval structuralSchema = Schema.derived[Team].structural\n// Type: Schema[{\n//   def name: String\n//   def members: List[String]\n//   def leader: Option[String]\n// }]\n```\n\n### 4. Tuples to Structural\n\n```scala\n// Tuples can be converted to structural types\nval tupleSchema: Schema[(String, Int, Boolean)] = Schema.derived[(String, Int, Boolean)]\n\nval structuralSchema = tupleSchema.structural\n// Type: Schema[{ def _1: String; def _2: Int; def _3: Boolean }]\n```\n\n### 5. Sum Types (Sealed Traits) - Scala 3 Only\n\nSealed traits become union types of structural representations, with tag information stored at the type level:\n\n```scala\n// Scala 3 only\nsealed trait Result\ncase class Success(value: Int) extends Result\ncase class Failure(error: String) extends Result\n\nval structuralSchema = Schema.derived[Result].structural\n// Type: Schema[\n//   { type Tag = \"Success\"; def value: Int } | { type Tag = \"Failure\"; def error: String }\n// ]\n```\n\n**Note**: Sum type to structural conversion is **not supported in Scala 2** because it requires union types. Attempting to call `.structural` on a sealed trait schema in Scala 2 will result in a compile-time error.\n\n### 6. Enums (Scala 3 Only)\n\n```scala\nenum Status:\n  case Active, Inactive, Suspended\n\nval structuralSchema = Schema.derived[Status].structural\n// Type: Schema[{type Tag = \"Active\"} | {type Tag = \"Inactive\"} | {type Tag = \"Suspended\"}]\n```\n\n### 7. Opaque Types (Scala 3)\n\n```scala\nopaque type UserId = String\nobject UserId:\n  def apply(value: String): Either[String, UserId] = \n    if value.nonEmpty then Right(value) else Left(\"Empty user ID\")\n\ncase class User(id: UserId, name: String)\n\nval structuralSchema = Schema.derived[User].structural\n// Type: Schema[{ def id: String; def name: String }]\n// Opaque type is unwrapped to its underlying type\n```\n\n### 8. Bidirectional Conversion\n\nStructural schemas work seamlessly with `Into`/`As` (if this ticket is implemented **after** that ticket):\n\n```scala\ncase class Person(name: String, age: Int)\n\nval structuralSchema = Schema.derived[Person].structural\n\n// Create structural value (Scala 3)\nval structuralPerson = new Selectable {\n  def selectDynamic(field: String): Any = field match {\n    case \"name\" => \"Alice\"\n    case \"age\" => 30\n  }\n}\n\n// Convert structural to nominal using Into\nval person: Either[SchemaError, Person] = \n  Into[{ def name: String; def age: Int }, Person].into(structuralPerson)\n// => Right(Person(\"Alice\", 30))\n\n// Convert nominal to structural\nval backToStructural: Either[SchemaError, { def name: String; def age: Int }] = \n  Into[Person, { def name: String; def age: Int }].into(Person(\"Bob\", 25))\n```\n\n### 9. Empty and Single-Field Products\n\n```scala\n// Empty case class\ncase class Empty()\nval emptyStructural = Schema.derived[Empty].structural\n// Type: Schema[{}]\n\n// Single field\ncase class Id(value: String)\nval idStructural = Schema.derived[Id].structural\n// Type: Schema[{ def value: String }]\n```\n\n### 10. Large Products\n\n```scala\ncase class LargeRecord(\n  f1: String, f2: Int, f3: Boolean, f4: Double, f5: Long,\n  f6: String, f7: Int, f8: Boolean, f9: Double, f10: Long,\n  f11: String, f12: Int, f13: Boolean, f14: Double, f15: Long,\n  f16: String, f17: Int, f18: Boolean, f19: Double, f20: Long,\n  f21: String\n)\n\nval structuralSchema = Schema.derived[LargeRecord].structural\n// Type: Schema[{\n//   def f1: String; def f2: Int; def f3: Boolean; ...\n//   def f21: String\n// }]\n```\n\n---\n\n## Type Name Handling\n\n### Current Limitation\n\nSchemas currently use `TypeName[A]` to identify types. Structural types don't have meaningful nominal type names, which creates a mismatch.\n\n### Temporary Solution\n\nUntil `TypeName[A]` is replaced with `TypeId[A]` (see issue #471), structural schemas will use a normalized string representation of the structural type as a fake type name:\n\n```scala\ncase class Person(name: String, age: Int)\n\nval schema = Schema.derived[Person]\nschema.typeName // => TypeName for \"Person\"\n\nval structural = schema.structural\nstructural.typeName // => TypeName for \"{age:Int,name:String}\"\n// Normalized: fields sorted alphabetically, types fully qualified\n```\n\n### Normalization Rules\n\n1. **Field ordering**: Alphabetical by field name\n2. **Type qualification**: Use simple names for primitives and standard library types\n3. **Whitespace**: No whitespace in generated names\n4. **Collections**: Standard notation (e.g., `List[Int]`)\n5. **Options**: Explicit `Option[T]` notation\n6. **Nested structures**: Recursive application of rules\n7. **Deterministic**: Same structure always produces same normalized name\n\n### Examples\n\n```scala\n// Simple product\ncase class Point(x: Int, y: Int)\nSchema.derived[Point].structural.typeName \n// => \"{x:Int,y:Int}\"\n\n// Nested product\ncase class Address(street: String, zip: Int)\ncase class Person(name: String, address: Address)\nSchema.derived[Person].structural.typeName\n// => \"{address:{street:String,zip:Int},name:String}\"\n\n// With collections\ncase class Team(name: String, members: List[String])\nSchema.derived[Team].structural.typeName\n// => \"{members:List[String],name:String}\"\n\n// Union type (Scala 3)\nsealed trait Result\ncase class Success(value: Int) extends Result\ncase class Failure(error: String) extends Result\nSchema.derived[Result].structural.typeName\n// => \"{error:String}|{value:Int}\"\n```\n\n### Future: TypeId[A]\n\nThe upcoming `TypeId[A]` replacement will properly handle structural types by representing them by their structure rather than a string-based hack. See issue #471 for details.\n\n---\n\n## Limitations and Edge Cases\n\n### 1. Generic Types\n\n**Behavior depends on existing Schema derivation support for generic types.**\n\nIf `Schema.derived[Container[Int]]` already works, then structural conversion should work:\n\n```scala\ncase class Container[T](value: T)\n\n// If this works:\nval schema = Schema.derived[Container[Int]]\n\n// Then this should work:\nval structural = schema.structural\n// Type: Schema[{ def value: Int }]\n```\n\nIf generic type derivation is not currently supported, this ticket **does not require implementing it**. The macro should produce a clear compile-time error for unsupported generic types.\n\n### 2. Recursive Types\n\nRecursive types will **fail at compile-time** because Scala does not support infinite types:\n\n```scala\ncase class Tree(value: Int, children: List[Tree])\n\n// This will FAIL at compile-time:\nval structural = Schema.derived[Tree].structural\n// Compile error: Cannot generate infinite structural type\n\n// The structural type would need to be:\n// { def value: Int; def children: List[{ def value: Int; def children: List[...] }] }\n// which is infinite and unsupported\n```\n\nThe macro must detect recursive types and produce a helpful error message:\n\n```\nCompile error: Cannot generate structural type for recursive type Tree.\nStructural types cannot represent recursive structures.\n```\n\n### 3. Mutually Recursive Types\n\nSimilarly, mutually recursive types are unsupported:\n\n```scala\ncase class Node(id: Int, edges: List[Edge])\ncase class Edge(from: Int, to: Node)\n\n// This will FAIL at compile-time:\nval nodeStructural = Schema.derived[Node].structural\n// Compile error: Cannot generate structural type for mutually recursive types\n```\n\n### 4. Sum Types in Scala 2\n\nSealed traits and sum types **cannot be converted to structural types in Scala 2** because they require union types:\n\n```scala\n// Scala 2\nsealed trait Result\ncase class Success(value: Int) extends Result\ncase class Failure(error: String) extends Result\n\n// This will FAIL at compile-time in Scala 2:\nval structural = Schema.derived[Result].structural\n// Compile error: Cannot generate structural type for sum types in Scala 2.\n// Union types are required, which are only available in Scala 3.\n```\n\nThe macro must detect sum types in Scala 2 and produce a clear error.\n\n### 5. Case Objects\n\nCase objects become empty structural types:\n\n```scala\ncase object Singleton\n\nval structural = Schema.derived[Singleton.type].structural\n// Type: Schema[{}]\n```\n\nFor sum types with case objects (Scala 3):\n\n```scala\nsealed trait Status\ncase object Active extends Status\ncase object Inactive extends Status\n\nval structural = Schema.derived[Status].structural\n// Type: Schema[{} | {}]\n// Not particularly useful, but valid\n```\n\n### 6. Structural Types as Source\n\nDeriving schemas directly for structural types is supported:\n\n```scala\ntype PersonStructure = { def name: String; def age: Int }\n\nval schema = Schema.derived[PersonStructure]\n// Should work if structural type derivation is implemented\n```\n\nThe schema's bindings will use `Selectable` (Scala 3) or `Dynamic` (Scala 2) to construct and deconstruct values.\n\n---\n\n## Integration with Into/As\n\nStructural schemas compose naturally with `Into`/`As` conversions.\n\n### Nominal â†’ Structural\n\n```scala\ncase class Person(name: String, age: Int)\n\n// Auto-derived conversion\nval nominalToStructural: Into[Person, { def name: String; def age: Int }] = \n  Into.derived\n\nval person = Person(\"Alice\", 30)\nval structural = nominalToStructural.into(person)\n// => Right(<Selectable/Dynamic instance>)\n```\n\n### Structural â†’ Nominal\n\n```scala\ntype PersonStructure = { def name: String; def age: Int }\ncase class Person(name: String, age: Int)\n\n// Auto-derived conversion\nval structuralToNominal: Into[PersonStructure, Person] = \n  Into.derived\n\nval structural: PersonStructure = new Selectable {\n  def selectDynamic(field: String): Any = field match {\n    case \"name\" => \"Bob\"\n    case \"age\" => 25\n  }\n}\n\nval person = structuralToNominal.into(structural)\n// => Right(Person(\"Bob\", 25))\n```\n\n### Bidirectional (As)\n\n```scala\ncase class Person(name: String, age: Int)\n\n// Bidirectional conversion\nval personAs: As[Person, { def name: String; def age: Int }] = \n  As.derived\n\n// Nominal â†’ Structural\nval structural = personAs.into(Person(\"Alice\", 30))\n\n// Structural â†’ Nominal\nval nominal = structural.flatMap(personAs.from)\n// Round-trip successful\n```\n\n### Schema-Guided Conversion\n\n```scala\ncase class PersonV1(firstName: String, lastName: String, age: Int)\ncase class PersonV2(name: String, age: Int)\n\n// Use structural type as intermediary\ntype PersonStructure = { def name: String; def age: Int }\n\n// Step 1: Transform V1 to structural (custom logic)\nval v1ToStructural: Into[PersonV1, PersonStructure] = \n  new Into[PersonV1, PersonStructure] {\n    def into(v1: PersonV1): Either[SchemaError, PersonStructure] = {\n      Right(new Selectable {\n        def selectDynamic(field: String): Any = field match {\n          case \"name\" => s\"${v1.firstName} ${v1.lastName}\"\n          case \"age\" => v1.age\n        }\n      })\n    }\n  }\n\n// Step 2: Auto-convert structural to V2\nval structuralToV2: Into[PersonStructure, PersonV2] = Into.derived\n\n// Composed migration\ndef migrate(v1: PersonV1): Either[SchemaError, PersonV2] = {\n  v1ToStructural.into(v1).flatMap(structuralToV2.into)\n}\n```\n\n---\n\n## Testing Requirements\n\n### Test Matrix\n\n1. **Direct Structural Derivation**\n   - Simple products (case classes)\n   - Nested products\n   - Collections (List, Vector, Set, Map, Option, Either)\n   - Tuples (2-22 elements)\n   - Empty case classes\n   - Single-field case classes\n   - Large products (20+ fields)\n   - Case objects\n\n2. **Nominal to Structural Conversion**\n   - Case class â†’ structural\n   - Tuple â†’ structural\n   - Nested case classes â†’ nested structural\n   - Case class with collections â†’ structural with collections\n   - Empty case class â†’ empty structural\n\n3. **Sum Types (Scala 3 Only)**\n   - Sealed trait â†’ union type structural\n   - Sealed trait with case objects\n   - Enum â†’ union type structural\n   - Nested sum types\n\n4. **Type Name Generation**\n   - Simple product normalized name\n   - Nested product normalized name\n   - Name determinism (same structure = same name)\n   - Alphabetical field ordering in names\n   - Union type names (Scala 3)\n\n5. **Selectable/Dynamic Implementation**\n   - Scala 3 Selectable field access\n   - Scala 2 Dynamic field access\n   - Field access correctness\n   - Missing field behavior\n   - Extra field behavior\n\n6. **Integration with Into/As**\n   - Nominal â†’ Structural via Into\n   - Structural â†’ Nominal via Into\n   - Round-trip via As\n   - Composed conversions with structural intermediary\n\n7. **Error Cases (Compile-Time)**\n   - Recursive types produce error\n   - Mutually recursive types produce error\n   - Sum types in Scala 2 produce error\n   - Unsupported types produce helpful errors\n\n8. **Generic Types** (if supported by existing Schema derivation)\n   - Fully applied generic â†’ structural\n   - Generic with nested structural fields\n\n### Scala 2 vs Scala 3 Test Separation\n\n```\nsrc/test/scala/\n  structural/\n    common/\n      SimpleProductSpec.scala\n      NestedProductSpec.scala\n      CollectionsSpec.scala\n      TuplesSpec.scala\n      EmptyProductSpec.scala\n      SingleFieldSpec.scala\n      LargeProductSpec.scala\n      TypeNameNormalizationSpec.scala\n      IntoIntegrationSpec.scala\n      AsIntegrationSpec.scala\n      \n    scala3/\n      UnionTypesSpec.scala\n      SealedTraitToUnionSpec.scala\n      EnumToUnionSpec.scala\n      SelectableImplementationSpec.scala\n      \n    scala2/\n      DynamicImplementationSpec.scala\n      SumTypeErrorSpec.scala (verifies compile error)\n      \n    errors/\n      RecursiveTypeErrorSpec.scala\n      MutualRecursionErrorSpec.scala\n      UnsupportedTypeErrorSpec.scala\n```\n\n### Test Examples\n\n```scala\n// Test: Simple product to structural\ntest(\"case class converts to structural schema\") {\n  case class Person(name: String, age: Int)\n  \n  val structural = Schema.derived[Person].structural\n  \n  // Type check (this is a compile-time test)\n  val _: Schema[{ def name: String; def age: Int }] = structural\n  \n  assert(structural.typeName.toString.contains(\"name\"))\n  assert(structural.typeName.toString.contains(\"age\"))\n}\n\n// Test: Nested products\ntest(\"nested case classes convert to nested structural\") {\n  case class Address(street: String, zip: Int)\n  case class Person(name: String, address: Address)\n  \n  val structural = Schema.derived[Person].structural\n  \n  val _: Schema[{ \n    def name: String\n    def address: { def street: String; def zip: Int }\n  }] = structural\n}\n\n// Test: Tuple to structural\ntest(\"tuple converts to structural with _N fields\") {\n  val structural = Schema.derived[(String, Int, Boolean)].structural\n  \n  val _: Schema[{ def _1: String; def _2: Int; def _3: Boolean }] = structural\n}\n\n// Test: Union type (Scala 3 only)\ntest(\"sealed trait converts to union type structural\") {\n  sealed trait Result\n  case class Success(value: Int) extends Result\n  case class Failure(error: String) extends Result\n  \n  val structural = Schema.derived[Result].structural\n  \n  val _: Schema[{ def value: Int } | { def error: String }] = structural\n}\n\n// Test: Type name normalization\ntest(\"structural type names are normalized and deterministic\") {\n  case class Person(name: String, age: Int)\n  case class User(age: Int, name: String) // Different field order\n  \n  val personStructural = Schema.derived[Person].structural\n  val userStructural = Schema.derived[User].structural\n  \n  // Same structure, same normalized name\n  assert(personStructural.typeName == userStructural.typeName)\n  \n  // Alphabetical ordering\n  assert(personStructural.typeName.toString.contains(\"age\"))\n  assert(personStructural.typeName.toString.indexOf(\"age\") < \n         personStructural.typeName.toString.indexOf(\"name\"))\n}\n\n// Test: Integration with Into\ntest(\"structural to nominal conversion via Into\") {\n  case class Person(name: String, age: Int)\n  type PersonStructure = { def name: String; def age: Int }\n  \n  val structural: PersonStructure = new Selectable {\n    def selectDynamic(field: String): Any = field match {\n      case \"name\" => \"Alice\"\n      case \"age\" => 30\n    }\n  }\n  \n  val person = Into[PersonStructure, Person].into(structural)\n  assert(person == Right(Person(\"Alice\", 30)))\n}\n\n// Test: Round-trip via As\ntest(\"nominal to structural and back preserves data\") {\n  case class Person(name: String, age: Int)\n  type PersonStructure = { def name: String; def age: Int }\n  \n  val original = Person(\"Alice\", 30)\n  \n  val toStructural = As[Person, PersonStructure].into(original)\n  val backToNominal = toStructural.flatMap(As[Person, PersonStructure].from)\n  \n  assert(backToNominal == Right(original))\n}\n\n// Test: Recursive type compile error\ntest(\"recursive types produce compile error\") {\n  case class Tree(value: Int, children: List[Tree])\n  \n  assertDoesNotCompile(\"Schema.derived[Tree].structural\")\n}\n\n// Test: Sum type in Scala 2 compile error\ntest(\"sum types in Scala 2 produce compile error\") {\n  sealed trait Result\n  case class Success(value: Int) extends Result\n  \n  // Scala 2 only\n  assertDoesNotCompile(\"Schema.derived[Result].structural\")\n}\n```\n\n---\n\n## Implementation Notes\n\n### Macro Behavior\n\nThe macro must:\n\n1. **Detect product types** (case classes, tuples) and generate structural types with `def` members\n2. **Detect sum types** (sealed traits, enums) and:\n   - In Scala 3: Generate union types of structural representations\n   - In Scala 2: Fail with clear error message\n3. **Detect recursive types** and fail with clear error message\n4. **Normalize structural type representations** for type name generation\n5. **Generate `ToStructural` instance** with:\n   - `StructuralType` type member set to the generated structural type\n   - `apply` method that transforms the schema appropriately\n6. **Preserve field metadata** from original schema where applicable\n7. **Generate appropriate bindings** using `Selectable` (Scala 3) or `Dynamic` (Scala 2)\n\n### Schema Transformation\n\nWhen converting `Schema[A]` to `Schema[StructuralType]`:\n\n1. **Preserve field information**: Field names, types, optional/required status\n2. **Update type name**: Use normalized structural representation\n3. **Transform bindings**: Replace nominal constructors/deconstructors with structural equivalents\n4. **Preserve validation**: Maintain any validation logic that applies to field values\n5. **Handle nested schemas**: Recursively transform nested product types\n\n### Error Messages\n\nProvide clear compile-time errors:\n\n```scala\n// Recursive type\ncase class Tree(value: Int, children: List[Tree])\nSchema.derived[Tree].structural\n\n// Error:\n\"\"\"\nCannot generate structural type for recursive type Tree.\nStructural types cannot represent recursive structures.\nScala's type system does not support infinite types.\n\"\"\"\n\n// Sum type in Scala 2\nsealed trait Result\ncase class Success(value: Int) extends Result\nSchema.derived[Result].structural\n\n// Error (Scala 2 only):\n\"\"\"\nCannot generate structural type for sum type Result.\nStructural representation of sum types requires union types,\nwhich are only available in Scala 3.\nConsider upgrading to Scala 3 or using a different approach.\n\"\"\"\n```\n\n---\n\n## Deliverables\n\n1. âœ… `ToStructural[A]` trait and macro for Scala 2.13\n2. âœ… `ToStructural[A]` trait and macro for Scala 3.5\n3. âœ… `structural` method on `Schema[A]`\n4. âœ… Support for product types (case classes, tuples)\n5. âœ… Support for sum types (sealed traits, enums) in Scala 3 only\n6. âœ… Normalized type name generation\n7. âœ… `Selectable` bindings (Scala 3) and `Dynamic` bindings (Scala 2)\n8. âœ… Integration with `Into`/`As` for structural â†” nominal conversions\n9. âœ… Comprehensive test suite (300+ test cases)\n10. âœ… Clear error messages for unsupported cases\n11. âœ… Documentation with examples",
                  "html_url": "https://github.com/zio/zio-blocks/issues/517"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#517",
              "body": "# Structural Type Schema Support\n\n## Overview\n\nExtend `Schema[A]` to support structural types, enabling schema derivation for types defined by their structure rather than their nominal identity. This allows for duck-typed schema validation and conversion between nominal and structural representations.\n\n## Core Concepts\n\n### Direct Structural Schema Derivation\n\nSchemas can be derived directly for structural types:\n\n```scala\n// Scala 3\ntype Person = { def name: String; def age: Int }\nval schema = Schema.derived[Person]\n\n// Scala 2\ntype Person = { def name: String; def age: Int }\nval schema = Schema.derived[Person]\n```\n\n**Note**: Both Scala 2 and Scala 3 use `def` for uniformity, even though Scala 3 supports `val` in structural types.\n\n**Implementation**: Schemas have bindings, which allow construction / deconstruction of values. Values for structural types are backed by:\n- **Scala 3**: `Selectable` \n- **Scala 2**: `Dynamic`\n\n### Nominal to Structural Conversion\n\nConvert nominal type schemas to their structural equivalents:\n\n```scala\ncase class Person(name: String, age: Int)\n\n// Get the structural schema corresponding to Person's shape\nval structuralSchema: Schema[{ def name: String; def age: Int }] = \n  Schema.derived[Person].structural\n```\n\n### Schema API Extension\n\n```scala\ncase class Schema[A](/* existing fields */) {\n  /**\n   * Convert this schema to a structural type schema.\n   * \n   * The structural type represents the \"shape\" of A without its nominal identity.\n   * This enables duck typing and structural validation.\n   * \n   * @param toStructural Macro-generated conversion to structural representation\n   * @return Schema for the structural type corresponding to A\n   */\n  def structural(implicit toStructural: ToStructural[A]): Schema[toStructural.StructuralType] = \n    toStructural.apply(this)\n}\n\n/**\n * Type class for converting nominal schemas to structural schemas.\n * Generated by macro for all supported types. Macro fails if a structural\n * type cannot be generated.\n *\n * NOTE: This approach has to be tested to yield inferrable types, and revised\n * if necessary. Inferrable types (from calling Schema#structural) are a must-have.\n */\ntrait ToStructural[A] {\n  type StructuralType\n  def apply(schema: Schema[A]): Schema[StructuralType]\n}\n\nobject ToStructural {\n  type Aux[A, S] = ToStructural[A] { type StructuralType = S }\n  \n  // Scala 3\n  transparent inline given [A]: ToStructural[A] = ${toStructuralMacro[A]}\n  \n  // Scala 2\n  implicit def materialize[A]: ToStructural[A] = macro toStructuralImpl[A]\n}\n```\n\n---\n\n## Examples\n\n### 1. Simple Product Types\n\n#### Case Class to Structural\n\n```scala\n// Both Scala 2 and Scala 3\ncase class Person(name: String, age: Int)\n\n// Original nominal schema\nval nominalSchema: Schema[Person] = Schema.derived[Person]\n\n// Convert to structural\nval structuralSchema: Schema[{ def name: String; def age: Int }] = \n  nominalSchema.structural\n\n// Direct structural derivation (equivalent)\nval directStructural: Schema[{ def name: String; def age: Int }] = \n  Schema.derived[{ def name: String; def age: Int }]\n```\n\n### 2. Nested Structures\n\n```scala\ncase class Address(street: String, city: String, zip: Int)\ncase class Person(name: String, age: Int, address: Address)\n\nval structuralSchema = Schema.derived[Person].structural\n// Type: Schema[{ \n//   def name: String\n//   def age: Int\n//   def address: { def street: String; def city: String; def zip: Int }\n// }]\n```\n\n### 3. Collections and Options\n\n```scala\ncase class Team(name: String, members: List[String], leader: Option[String])\n\nval structuralSchema = Schema.derived[Team].structural\n// Type: Schema[{\n//   def name: String\n//   def members: List[String]\n//   def leader: Option[String]\n// }]\n```\n\n### 4. Tuples to Structural\n\n```scala\n// Tuples can be converted to structural types\nval tupleSchema: Schema[(String, Int, Boolean)] = Schema.derived[(String, Int, Boolean)]\n\nval structuralSchema = tupleSchema.structural\n// Type: Schema[{ def _1: String; def _2: Int; def _3: Boolean }]\n```\n\n### 5. Sum Types (Sealed Traits) - Scala 3 Only\n\nSealed traits become union types of structural representations, with tag information stored at the type level:\n\n```scala\n// Scala 3 only\nsealed trait Result\ncase class Success(value: Int) extends Result\ncase class Failure(error: String) extends Result\n\nval structuralSchema = Schema.derived[Result].structural\n// Type: Schema[\n//   { type Tag = \"Success\"; def value: Int } | { type Tag = \"Failure\"; def error: String }\n// ]\n```\n\n**Note**: Sum type to structural conversion is **not supported in Scala 2** because it requires union types. Attempting to call `.structural` on a sealed trait schema in Scala 2 will result in a compile-time error.\n\n### 6. Enums (Scala 3 Only)\n\n```scala\nenum Status:\n  case Active, Inactive, Suspended\n\nval structuralSchema = Schema.derived[Status].structural\n// Type: Schema[{type Tag = \"Active\"} | {type Tag = \"Inactive\"} | {type Tag = \"Suspended\"}]\n```\n\n### 7. Opaque Types (Scala 3)\n\n```scala\nopaque type UserId = String\nobject UserId:\n  def apply(value: String): Either[String, UserId] = \n    if value.nonEmpty then Right(value) else Left(\"Empty user ID\")\n\ncase class User(id: UserId, name: String)\n\nval structuralSchema = Schema.derived[User].structural\n// Type: Schema[{ def id: String; def name: String }]\n// Opaque type is unwrapped to its underlying type\n```\n\n### 8. Bidirectional Conversion\n\nStructural schemas work seamlessly with `Into`/`As` (if this ticket is implemented **after** that ticket):\n\n```scala\ncase class Person(name: String, age: Int)\n\nval structuralSchema = Schema.derived[Person].structural\n\n// Create structural value (Scala 3)\nval structuralPerson = new Selectable {\n  def selectDynamic(field: String): Any = field match {\n    case \"name\" => \"Alice\"\n    case \"age\" => 30\n  }\n}\n\n// Convert structural to nominal using Into\nval person: Either[SchemaError, Person] = \n  Into[{ def name: String; def age: Int }, Person].into(structuralPerson)\n// => Right(Person(\"Alice\", 30))\n\n// Convert nominal to structural\nval backToStructural: Either[SchemaError, { def name: String; def age: Int }] = \n  Into[Person, { def name: String; def age: Int }].into(Person(\"Bob\", 25))\n```\n\n### 9. Empty and Single-Field Products\n\n```scala\n// Empty case class\ncase class Empty()\nval emptyStructural = Schema.derived[Empty].structural\n// Type: Schema[{}]\n\n// Single field\ncase class Id(value: String)\nval idStructural = Schema.derived[Id].structural\n// Type: Schema[{ def value: String }]\n```\n\n### 10. Large Products\n\n```scala\ncase class LargeRecord(\n  f1: String, f2: Int, f3: Boolean, f4: Double, f5: Long,\n  f6: String, f7: Int, f8: Boolean, f9: Double, f10: Long,\n  f11: String, f12: Int, f13: Boolean, f14: Double, f15: Long,\n  f16: String, f17: Int, f18: Boolean, f19: Double, f20: Long,\n  f21: String\n)\n\nval structuralSchema = Schema.derived[LargeRecord].structural\n// Type: Schema[{\n//   def f1: String; def f2: Int; def f3: Boolean; ...\n//   def f21: String\n// }]\n```\n\n---\n\n## Type Name Handling\n\n### Current Limitation\n\nSchemas currently use `TypeName[A]` to identify types. Structural types don't have meaningful nominal type names, which creates a mismatch.\n\n### Temporary Solution\n\nUntil `TypeName[A]` is replaced with `TypeId[A]` (see issue #471), structural schemas will use a normalized string representation of the structural type as a fake type name:\n\n```scala\ncase class Person(name: String, age: Int)\n\nval schema = Schema.derived[Person]\nschema.typeName // => TypeName for \"Person\"\n\nval structural = schema.structural\nstructural.typeName // => TypeName for \"{age:Int,name:String}\"\n// Normalized: fields sorted alphabetically, types fully qualified\n```\n\n### Normalization Rules\n\n1. **Field ordering**: Alphabetical by field name\n2. **Type qualification**: Use simple names for primitives and standard library types\n3. **Whitespace**: No whitespace in generated names\n4. **Collections**: Standard notation (e.g., `List[Int]`)\n5. **Options**: Explicit `Option[T]` notation\n6. **Nested structures**: Recursive application of rules\n7. **Deterministic**: Same structure always produces same normalized name\n\n### Examples\n\n```scala\n// Simple product\ncase class Point(x: Int, y: Int)\nSchema.derived[Point].structural.typeName \n// => \"{x:Int,y:Int}\"\n\n// Nested product\ncase class Address(street: String, zip: Int)\ncase class Person(name: String, address: Address)\nSchema.derived[Person].structural.typeName\n// => \"{address:{street:String,zip:Int},name:String}\"\n\n// With collections\ncase class Team(name: String, members: List[String])\nSchema.derived[Team].structural.typeName\n// => \"{members:List[String],name:String}\"\n\n// Union type (Scala 3)\nsealed trait Result\ncase class Success(value: Int) extends Result\ncase class Failure(error: String) extends Result\nSchema.derived[Result].structural.typeName\n// => \"{error:String}|{value:Int}\"\n```\n\n### Future: TypeId[A]\n\nThe upcoming `TypeId[A]` replacement will properly handle structural types by representing them by their structure rather than a string-based hack. See issue #471 for details.\n\n---\n\n## Limitations and Edge Cases\n\n### 1. Generic Types\n\n**Behavior depends on existing Schema derivation support for generic types.**\n\nIf `Schema.derived[Container[Int]]` already works, then structural conversion should work:\n\n```scala\ncase class Container[T](value: T)\n\n// If this works:\nval schema = Schema.derived[Container[Int]]\n\n// Then this should work:\nval structural = schema.structural\n// Type: Schema[{ def value: Int }]\n```\n\nIf generic type derivation is not currently supported, this ticket **does not require implementing it**. The macro should produce a clear compile-time error for unsupported generic types.\n\n### 2. Recursive Types\n\nRecursive types will **fail at compile-time** because Scala does not support infinite types:\n\n```scala\ncase class Tree(value: Int, children: List[Tree])\n\n// This will FAIL at compile-time:\nval structural = Schema.derived[Tree].structural\n// Compile error: Cannot generate infinite structural type\n\n// The structural type would need to be:\n// { def value: Int; def children: List[{ def value: Int; def children: List[...] }] }\n// which is infinite and unsupported\n```\n\nThe macro must detect recursive types and produce a helpful error message:\n\n```\nCompile error: Cannot generate structural type for recursive type Tree.\nStructural types cannot represent recursive structures.\n```\n\n### 3. Mutually Recursive Types\n\nSimilarly, mutually recursive types are unsupported:\n\n```scala\ncase class Node(id: Int, edges: List[Edge])\ncase class Edge(from: Int, to: Node)\n\n// This will FAIL at compile-time:\nval nodeStructural = Schema.derived[Node].structural\n// Compile error: Cannot generate structural type for mutually recursive types\n```\n\n### 4. Sum Types in Scala 2\n\nSealed traits and sum types **cannot be converted to structural types in Scala 2** because they require union types:\n\n```scala\n// Scala 2\nsealed trait Result\ncase class Success(value: Int) extends Result\ncase class Failure(error: String) extends Result\n\n// This will FAIL at compile-time in Scala 2:\nval structural = Schema.derived[Result].structural\n// Compile error: Cannot generate structural type for sum types in Scala 2.\n// Union types are required, which are only available in Scala 3.\n```\n\nThe macro must detect sum types in Scala 2 and produce a clear error.\n\n### 5. Case Objects\n\nCase objects become empty structural types:\n\n```scala\ncase object Singleton\n\nval structural = Schema.derived[Singleton.type].structural\n// Type: Schema[{}]\n```\n\nFor sum types with case objects (Scala 3):\n\n```scala\nsealed trait Status\ncase object Active extends Status\ncase object Inactive extends Status\n\nval structural = Schema.derived[Status].structural\n// Type: Schema[{} | {}]\n// Not particularly useful, but valid\n```\n\n### 6. Structural Types as Source\n\nDeriving schemas directly for structural types is supported:\n\n```scala\ntype PersonStructure = { def name: String; def age: Int }\n\nval schema = Schema.derived[PersonStructure]\n// Should work if structural type derivation is implemented\n```\n\nThe schema's bindings will use `Selectable` (Scala 3) or `Dynamic` (Scala 2) to construct and deconstruct values.\n\n---\n\n## Integration with Into/As\n\nStructural schemas compose naturally with `Into`/`As` conversions.\n\n### Nominal â†’ Structural\n\n```scala\ncase class Person(name: String, age: Int)\n\n// Auto-derived conversion\nval nominalToStructural: Into[Person, { def name: String; def age: Int }] = \n  Into.derived\n\nval person = Person(\"Alice\", 30)\nval structural = nominalToStructural.into(person)\n// => Right(<Selectable/Dynamic instance>)\n```\n\n### Structural â†’ Nominal\n\n```scala\ntype PersonStructure = { def name: String; def age: Int }\ncase class Person(name: String, age: Int)\n\n// Auto-derived conversion\nval structuralToNominal: Into[PersonStructure, Person] = \n  Into.derived\n\nval structural: PersonStructure = new Selectable {\n  def selectDynamic(field: String): Any = field match {\n    case \"name\" => \"Bob\"\n    case \"age\" => 25\n  }\n}\n\nval person = structuralToNominal.into(structural)\n// => Right(Person(\"Bob\", 25))\n```\n\n### Bidirectional (As)\n\n```scala\ncase class Person(name: String, age: Int)\n\n// Bidirectional conversion\nval personAs: As[Person, { def name: String; def age: Int }] = \n  As.derived\n\n// Nominal â†’ Structural\nval structural = personAs.into(Person(\"Alice\", 30))\n\n// Structural â†’ Nominal\nval nominal = structural.flatMap(personAs.from)\n// Round-trip successful\n```\n\n### Schema-Guided Conversion\n\n```scala\ncase class PersonV1(firstName: String, lastName: String, age: Int)\ncase class PersonV2(name: String, age: Int)\n\n// Use structural type as intermediary\ntype PersonStructure = { def name: String; def age: Int }\n\n// Step 1: Transform V1 to structural (custom logic)\nval v1ToStructural: Into[PersonV1, PersonStructure] = \n  new Into[PersonV1, PersonStructure] {\n    def into(v1: PersonV1): Either[SchemaError, PersonStructure] = {\n      Right(new Selectable {\n        def selectDynamic(field: String): Any = field match {\n          case \"name\" => s\"${v1.firstName} ${v1.lastName}\"\n          case \"age\" => v1.age\n        }\n      })\n    }\n  }\n\n// Step 2: Auto-convert structural to V2\nval structuralToV2: Into[PersonStructure, PersonV2] = Into.derived\n\n// Composed migration\ndef migrate(v1: PersonV1): Either[SchemaError, PersonV2] = {\n  v1ToStructural.into(v1).flatMap(structuralToV2.into)\n}\n```\n\n---\n\n## Testing Requirements\n\n### Test Matrix\n\n1. **Direct Structural Derivation**\n   - Simple products (case classes)\n   - Nested products\n   - Collections (List, Vector, Set, Map, Option, Either)\n   - Tuples (2-22 elements)\n   - Empty case classes\n   - Single-field case classes\n   - Large products (20+ fields)\n   - Case objects\n\n2. **Nominal to Structural Conversion**\n   - Case class â†’ structural\n   - Tuple â†’ structural\n   - Nested case classes â†’ nested structural\n   - Case class with collections â†’ structural with collections\n   - Empty case class â†’ empty structural\n\n3. **Sum Types (Scala 3 Only)**\n   - Sealed trait â†’ union type structural\n   - Sealed trait with case objects\n   - Enum â†’ union type structural\n   - Nested sum types\n\n4. **Type Name Generation**\n   - Simple product normalized name\n   - Nested product normalized name\n   - Name determinism (same structure = same name)\n   - Alphabetical field ordering in names\n   - Union type names (Scala 3)\n\n5. **Selectable/Dynamic Implementation**\n   - Scala 3 Selectable field access\n   - Scala 2 Dynamic field access\n   - Field access correctness\n   - Missing field behavior\n   - Extra field behavior\n\n6. **Integration with Into/As**\n   - Nominal â†’ Structural via Into\n   - Structural â†’ Nominal via Into\n   - Round-trip via As\n   - Composed conversions with structural intermediary\n\n7. **Error Cases (Compile-Time)**\n   - Recursive types produce error\n   - Mutually recursive types produce error\n   - Sum types in Scala 2 produce error\n   - Unsupported types produce helpful errors\n\n8. **Generic Types** (if supported by existing Schema derivation)\n   - Fully applied generic â†’ structural\n   - Generic with nested structural fields\n\n### Scala 2 vs Scala 3 Test Separation\n\n```\nsrc/test/scala/\n  structural/\n    common/\n      SimpleProductSpec.scala\n      NestedProductSpec.scala\n      CollectionsSpec.scala\n      TuplesSpec.scala\n      EmptyProductSpec.scala\n      SingleFieldSpec.scala\n      LargeProductSpec.scala\n      TypeNameNormalizationSpec.scala\n      IntoIntegrationSpec.scala\n      AsIntegrationSpec.scala\n      \n    scala3/\n      UnionTypesSpec.scala\n      SealedTraitToUnionSpec.scala\n      EnumToUnionSpec.scala\n      SelectableImplementationSpec.scala\n      \n    scala2/\n      DynamicImplementationSpec.scala\n      SumTypeErrorSpec.scala (verifies compile error)\n      \n    errors/\n      RecursiveTypeErrorSpec.scala\n      MutualRecursionErrorSpec.scala\n      UnsupportedTypeErrorSpec.scala\n```\n\n### Test Examples\n\n```scala\n// Test: Simple product to structural\ntest(\"case class converts to structural schema\") {\n  case class Person(name: String, age: Int)\n  \n  val structural = Schema.derived[Person].structural\n  \n  // Type check (this is a compile-time test)\n  val _: Schema[{ def name: String; def age: Int }] = structural\n  \n  assert(structural.typeName.toString.contains(\"name\"))\n  assert(structural.typeName.toString.contains(\"age\"))\n}\n\n// Test: Nested products\ntest(\"nested case classes convert to nested structural\") {\n  case class Address(street: String, zip: Int)\n  case class Person(name: String, address: Address)\n  \n  val structural = Schema.derived[Person].structural\n  \n  val _: Schema[{ \n    def name: String\n    def address: { def street: String; def zip: Int }\n  }] = structural\n}\n\n// Test: Tuple to structural\ntest(\"tuple converts to structural with _N fields\") {\n  val structural = Schema.derived[(String, Int, Boolean)].structural\n  \n  val _: Schema[{ def _1: String; def _2: Int; def _3: Boolean }] = structural\n}\n\n// Test: Union type (Scala 3 only)\ntest(\"sealed trait converts to union type structural\") {\n  sealed trait Result\n  case class Success(value: Int) extends Result\n  case class Failure(error: String) extends Result\n  \n  val structural = Schema.derived[Result].structural\n  \n  val _: Schema[{ def value: Int } | { def error: String }] = structural\n}\n\n// Test: Type name normalization\ntest(\"structural type names are normalized and deterministic\") {\n  case class Person(name: String, age: Int)\n  case class User(age: Int, name: String) // Different field order\n  \n  val personStructural = Schema.derived[Person].structural\n  val userStructural = Schema.derived[User].structural\n  \n  // Same structure, same normalized name\n  assert(personStructural.typeName == userStructural.typeName)\n  \n  // Alphabetical ordering\n  assert(personStructural.typeName.toString.contains(\"age\"))\n  assert(personStructural.typeName.toString.indexOf(\"age\") < \n         personStructural.typeName.toString.indexOf(\"name\"))\n}\n\n// Test: Integration with Into\ntest(\"structural to nominal conversion via Into\") {\n  case class Person(name: String, age: Int)\n  type PersonStructure = { def name: String; def age: Int }\n  \n  val structural: PersonStructure = new Selectable {\n    def selectDynamic(field: String): Any = field match {\n      case \"name\" => \"Alice\"\n      case \"age\" => 30\n    }\n  }\n  \n  val person = Into[PersonStructure, Person].into(structural)\n  assert(person == Right(Person(\"Alice\", 30)))\n}\n\n// Test: Round-trip via As\ntest(\"nominal to structural and back preserves data\") {\n  case class Person(name: String, age: Int)\n  type PersonStructure = { def name: String; def age: Int }\n  \n  val original = Person(\"Alice\", 30)\n  \n  val toStructural = As[Person, PersonStructure].into(original)\n  val backToNominal = toStructural.flatMap(As[Person, PersonStructure].from)\n  \n  assert(backToNominal == Right(original))\n}\n\n// Test: Recursive type compile error\ntest(\"recursive types produce compile error\") {\n  case class Tree(value: Int, children: List[Tree])\n  \n  assertDoesNotCompile(\"Schema.derived[Tree].structural\")\n}\n\n// Test: Sum type in Scala 2 compile error\ntest(\"sum types in Scala 2 produce compile error\") {\n  sealed trait Result\n  case class Success(value: Int) extends Result\n  \n  // Scala 2 only\n  assertDoesNotCompile(\"Schema.derived[Result].structural\")\n}\n```\n\n---\n\n## Implementation Notes\n\n### Macro Behavior\n\nThe macro must:\n\n1. **Detect product types** (case classes, tuples) and generate structural types with `def` members\n2. **Detect sum types** (sealed traits, enums) and:\n   - In Scala 3: Generate union types of structural representations\n   - In Scala 2: Fail with clear error message\n3. **Detect recursive types** and fail with clear error message\n4. **Normalize structural type representations** for type name generation\n5. **Generate `ToStructural` instance** with:\n   - `StructuralType` type member set to the generated structural type\n   - `apply` method that transforms the schema appropriately\n6. **Preserve field metadata** from original schema where applicable\n7. **Generate appropriate bindings** using `Selectable` (Scala 3) or `Dynamic` (Scala 2)\n\n### Schema Transformation\n\nWhen converting `Schema[A]` to `Schema[StructuralType]`:\n\n1. **Preserve field information**: Field names, types, optional/required status\n2. **Update type name**: Use normalized structural representation\n3. **Transform bindings**: Replace nominal constructors/deconstructors with structural equivalents\n4. **Preserve validation**: Maintain any validation logic that applies to field values\n5. **Handle nested schemas**: Recursively transform nested product types\n\n### Error Messages\n\nProvide clear compile-time errors:\n\n```scala\n// Recursive type\ncase class Tree(value: Int, children: List[Tree])\nSchema.derived[Tree].structural\n\n// Error:\n\"\"\"\nCannot generate structural type for recursive type Tree.\nStructural types cannot represent recursive structures.\nScala's type system does not support infinite types.\n\"\"\"\n\n// Sum type in Scala 2\nsealed trait Result\ncase class Success(value: Int) extends Result\nSchema.derived[Result].structural\n\n// Error (Scala 2 only):\n\"\"\"\nCannot generate structural type for sum type Result.\nStructural representation of sum types requires union types,\nwhich are only available in Scala 3.\nConsider upgrading to Scala 3 or using a different approach.\n\"\"\"\n```\n\n---\n\n## Deliverables\n\n1. âœ… `ToStructural[A]` trait and macro for Scala 2.13\n2. âœ… `ToStructural[A]` trait and macro for Scala 3.5\n3. âœ… `structural` method on `Schema[A]`\n4. âœ… Support for product types (case classes, tuples)\n5. âœ… Support for sum types (sealed traits, enums) in Scala 3 only\n6. âœ… Normalized type name generation\n7. âœ… `Selectable` bindings (Scala 3) and `Dynamic` bindings (Scala 2)\n8. âœ… Integration with `Into`/`As` for structural â†” nominal conversions\n9. âœ… Comprehensive test suite (300+ test cases)\n10. âœ… Clear error messages for unsupported cases\n11. âœ… Documentation with examples",
              "url": "https://github.com/zio/zio-blocks/issues/517",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#685",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-18T17:51:50.759Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:50.759Z",
            "created_at": "2026-01-18T17:51:50.759Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#685",
              "status": "open",
              "type": "issue",
              "number": 685,
              "title": "Add JsonPatch - Depends on #679",
              "source": {
                "data": {
                  "id": "source-ZIO#685",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add JsonPatch - Depends on #679",
                  "body": "<html><head></head><body><h1>Add <code>JsonPatch</code> type for diffing and patching JSON values</h1>\n<h2>Summary</h2>\n<p>Implement a <code>JsonPatch</code> type that enables computing diffs between JSON values and applying patches to transform one JSON value into another. This type should mirror the existing <code>DynamicPatch</code> implementation, adapted for JSON's simpler data model.</p>\n<h2>Motivation</h2>\n<p><code>DynamicValue</code> has a well-designed <code>DynamicPatch</code> system with:</p>\n<ul>\n<li>Monoid composition (<code>++</code> with <code>empty</code> identity)</li>\n<li>LCS-based sequence diffing</li>\n<li>Primitive delta operations (numeric deltas, string edits)</li>\n<li>Comprehensive algebraic laws verified by property tests</li>\n</ul>\n<p>The proposed <code>Json</code> type (see #TBD) needs equivalent patching capabilities. Rather than converting <code>Json â†” DynamicValue</code> for every patch operation, a native <code>JsonPatch</code> provides:</p>\n<ul>\n<li>Type safety (no conversion errors for JSON-incompatible DynamicPatch operations)</li>\n<li>API consistency with the <code>Json</code> type</li>\n<li>Potential for JSON-specific optimizations</li>\n</ul>\n<h2>Design Sketch</h2>\n<p>A design sketch is available at <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala</code></a>. This sketch is <strong>a guide, not a specification</strong> â€” implementers should use judgment and deviate where appropriate.</p>\n<h3>Core Types</h3>\n<p>The design mirrors <code>DynamicPatch</code> with JSON-specific adaptations:</p>\n\nDynamicPatch | JsonPatch | Notes\n-- | -- | --\nDynamicPatch(Vector[DynamicPatchOp]) | JsonPatch(Vector[JsonPatchOp]) | Same structure\nOperation.Set | Op.Set | Same\nOperation.PrimitiveDelta | Op.PrimitiveDelta | Simplified for JSON types\nOperation.SequenceEdit | Op.ArrayEdit | Renamed\nOperation.MapEdit | Op.ObjectEdit | String keys only\nOperation.Patch | Op.Nested | Same\nSeqOp | ArrayOp | Same operations\nMapOp | ObjectOp | String keys only\nPrimitiveOp (14 variants) | PrimitiveOp (2 variants) | See below\n\n\n<h3>StringOp</h3>\n<p>Mirror <code>DynamicPatch.StringOp</code> exactly:</p>\n<ul>\n<li><code>Insert(index: Int, text: String)</code></li>\n<li><code>Delete(index: Int, length: Int)</code></li>\n<li><code>Append(text: String)</code></li>\n<li><code>Modify(index: Int, length: Int, text: String)</code></li>\n</ul>\n<h3>ArrayOp</h3>\n<p>Mirror <code>DynamicPatch.SeqOp</code>:</p>\n<ul>\n<li><code>Insert(index: Int, values: Vector[Json])</code></li>\n<li><code>Append(values: Vector[Json])</code></li>\n<li><code>Delete(index: Int, count: Int)</code></li>\n<li><code>Modify(index: Int, op: Op)</code></li>\n</ul>\n<h3>ObjectOp</h3>\n<p>Mirror <code>DynamicPatch.MapOp</code> with string keys:</p>\n<ul>\n<li><code>Add(key: String, value: Json)</code></li>\n<li><code>Remove(key: String)</code></li>\n<li><code>Modify(key: String, patch: JsonPatch)</code></li>\n</ul>\n<h2>Requirements</h2>\n<h3>Functional Requirements</h3>\n<ul>\n<li>[ ] <strong>F1</strong>: <code>JsonPatch.diff(source, target)</code> computes a patch transforming source to target</li>\n<li>[ ] <strong>F2</strong>: <code>patch.apply(json, mode)</code> applies a patch with configurable failure handling</li>\n<li>[ ] <strong>F3</strong>: <code>patch1 ++ patch2</code> composes patches (apply first, then second)</li>\n<li>[ ] <strong>F4</strong>: <code>JsonPatch.empty</code> is the identity element for composition</li>\n<li>[ ] <strong>F5</strong>: Support <code>JsonPatchMode.Strict</code>, <code>Lenient</code>, and <code>Clobber</code> modes</li>\n<li>[ ] <strong>F6</strong>: Bidirectional conversion: <code>toDynamicPatch</code> / <code>fromDynamicPatch</code></li>\n</ul>\n<h3>Algebraic Laws</h3>\n<p>All laws must be verified with property-based tests (see <code>PatchLawsSpec</code> for reference):</p>\n<ul>\n<li>[ ] <strong>L1</strong>: Left identity â€” <code>(empty ++ p)(j) == p(j)</code></li>\n<li>[ ] <strong>L2</strong>: Right identity â€” <code>(p ++ empty)(j) == p(j)</code></li>\n<li>[ ] <strong>L3</strong>: Associativity â€” <code>((p1 ++ p2) ++ p3)(j) == (p1 ++ (p2 ++ p3))(j)</code></li>\n<li>[ ] <strong>L4</strong>: Roundtrip â€” <code>diff(a, b)(a) == Right(b)</code></li>\n<li>[ ] <strong>L5</strong>: Identity diff â€” <code>diff(j, j).isEmpty</code></li>\n<li>[ ] <strong>L6</strong>: Diff composition â€” <code>(diff(a, b) ++ diff(b, c))(a) == Right(c)</code></li>\n<li>[ ] <strong>L7</strong>: Lenient subsumes Strict â€” if <code>p(j, Strict) == Right(r)</code> then <code>p(j, Lenient) == Right(r)</code></li>\n</ul>\n<h3>Testing Requirements</h3>\n<ul>\n<li>[ ] <strong>T1</strong>: Property-based tests for all algebraic laws (see <code>PatchLawsSpec</code>)</li>\n<li>[ ] <strong>T2</strong>: Test each operation type (<code>Set</code>, <code>PrimitiveDelta</code>, <code>ArrayEdit</code>, <code>ObjectEdit</code>, <code>Nested</code>)</li>\n<li>[ ] <strong>T3</strong>: Test each <code>ArrayOp</code> variant (<code>Insert</code>, <code>Append</code>, <code>Delete</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T4</strong>: Test each <code>ObjectOp</code> variant (<code>Add</code>, <code>Remove</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T5</strong>: Test each <code>StringOp</code> variant (<code>Insert</code>, <code>Delete</code>, <code>Append</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T6</strong>: Test <code>NumberDelta</code> with positive, negative, zero, and decimal deltas</li>\n<li>[ ] <strong>T7</strong>: Test all three <code>JsonPatchMode</code> behaviors</li>\n<li>[ ] <strong>T8</strong>: Test <code>toDynamicPatch</code> / <code>fromDynamicPatch</code> roundtrip</li>\n<li>[ ] <strong>T9</strong>: Test edge cases: empty arrays, empty objects, empty strings, nested structures</li>\n<li>[ ] <strong>T10</strong>: Test error cases: invalid paths, type mismatches, out-of-bounds indices</li>\n</ul>\n<h3>Documentation Requirements</h3>\n<ul>\n<li>[ ] <strong>D1</strong>: ScalaDoc for all public types and methods</li>\n<li>[ ] <strong>D2</strong>: Usage examples in ScalaDoc (see sketch for examples)</li>\n<li>[ ] <strong>D3</strong>: Document algebraic laws in type-level comments</li>\n<li>[ ] <strong>D4</strong>: Document relationship to <code>DynamicPatch</code></li>\n</ul>\n<h3>Implementation Notes</h3>\n<ol>\n<li>\n<p><strong>Follow <code>DynamicPatch</code> patterns</strong>: The implementation in <code>DynamicPatch.scala</code> is the reference. Study <code>Differ.scala</code> for diff algorithms (especially LCS for sequences and strings).</p>\n</li>\n<li>\n<p><strong>Reuse algorithms where possible</strong>: Consider whether <code>JsonPatch</code> can delegate to <code>DynamicPatch</code> internally, or share algorithm implementations.</p>\n</li>\n<li>\n<p><strong>Keep it minimal</strong>: Resist adding operations not present in <code>DynamicPatch</code>. The design is intentionally minimal and principled.</p>\n</li>\n<li>\n<p><strong>Performance considerations</strong>: The register-based design of ZIO Blocks prioritizes performance. Avoid unnecessary allocations in hot paths.</p>\n</li>\n</ol>\n<h2>Out of Scope</h2>\n<p>The following are explicitly <strong>not</strong> part of this issue:</p>\n<ul>\n<li>RFC 6902 JSON Patch serialization format (separate issue)</li>\n<li>Patch inversion / undo support (separate issue)</li>\n<li>Patch optimization / compaction (separate issue)</li>\n<li>Integration with <code>Json</code> type methods like <code>json.diff(other)</code> (depends on <code>Json</code> implementation)</li>\n</ul>\n<h2>Related</h2>\n<ul>\n<li><code>DynamicPatch</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala</code></a></li>\n<li><code>Differ</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala</code></a></li>\n<li><code>PatchLawsSpec</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala\"><code>schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala</code></a></li>\n<li><code>PatchMode</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala</code></a></li>\n</ul>\n<h2>Acceptance Criteria</h2>\n<ul>\n<li>[ ] All functional requirements (F1-F6) implemented</li>\n<li>[ ] All algebraic laws (L1-L7) pass property-based tests</li>\n<li>[ ] All testing requirements (T1-T10) have corresponding test cases</li>\n<li>[ ] All documentation requirements (D1-D4) complete</li>\n<li>[ ] Code reviewed and approved</li>\n<li>[ ] CI passing</li>\n</ul></body></html># Add `JsonPatch` type for diffing and patching JSON values\n\n## Summary\n\nImplement a `JsonPatch` type that enables computing diffs between JSON values and applying patches to transform one JSON value into another. This type should mirror the existing `DynamicPatch` implementation, adapted for JSON's simpler data model.\n\n## Motivation\n\n`DynamicValue` has a well-designed `DynamicPatch` system with:\n- Monoid composition (`++` with `empty` identity)\n- LCS-based sequence diffing\n- Primitive delta operations (numeric deltas, string edits)\n- Comprehensive algebraic laws verified by property tests\n\nThe proposed `Json` type (see #TBD) needs equivalent patching capabilities. Rather than converting `Json â†” DynamicValue` for every patch operation, a native `JsonPatch` provides:\n- Type safety (no conversion errors for JSON-incompatible DynamicPatch operations)\n- API consistency with the `Json` type\n- Potential for JSON-specific optimizations\n\n## Design Sketch\n\nA design sketch is available at [`[schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala). This sketch is **a guide, not a specification** â€” implementers should use judgment and deviate where appropriate.\n\n### Core Types\n\nThe design mirrors `DynamicPatch` with JSON-specific adaptations:\n\n| DynamicPatch | JsonPatch | Notes |\n|--------------|-----------|-------|\n| `DynamicPatch(Vector[DynamicPatchOp])` | `JsonPatch(Vector[JsonPatchOp])` | Same structure |\n| `Operation.Set` | `Op.Set` | Same |\n| `Operation.PrimitiveDelta` | `Op.PrimitiveDelta` | Simplified for JSON types |\n| `Operation.SequenceEdit` | `Op.ArrayEdit` | Renamed |\n| `Operation.MapEdit` | `Op.ObjectEdit` | String keys only |\n| `Operation.Patch` | `Op.Nested` | Same |\n| `SeqOp` | `ArrayOp` | Same operations |\n| `MapOp` | `ObjectOp` | String keys only |\n| `PrimitiveOp` (14 variants) | `PrimitiveOp` (2 variants) | See below |\n\n### Primitive Operations\n\nJSON has a simpler type system than `DynamicValue`:\n\n| JSON Type | Delta Operation | Notes |\n|-----------|-----------------|-------|\n| Number | `NumberDelta(BigDecimal)` | Unifies all numeric deltas |\n| String | `StringEdit(Vector[StringOp])` | Same as `DynamicPatch` |\n| Boolean | Use `Op.Set` | No delta (same as `DynamicPatch`) |\n| Null | Use `Op.Set` | No delta |\n\n### StringOp\n\nMirror `DynamicPatch.StringOp` exactly:\n- `Insert(index: Int, text: String)`\n- `Delete(index: Int, length: Int)`\n- `Append(text: String)`\n- `Modify(index: Int, length: Int, text: String)`\n\n### ArrayOp\n\nMirror `DynamicPatch.SeqOp`:\n- `Insert(index: Int, values: Vector[Json])`\n- `Append(values: Vector[Json])`\n- `Delete(index: Int, count: Int)`\n- `Modify(index: Int, op: Op)`\n\n### ObjectOp\n\nMirror `DynamicPatch.MapOp` with string keys:\n- `Add(key: String, value: Json)`\n- `Remove(key: String)`\n- `Modify(key: String, patch: JsonPatch)`\n\n## Requirements\n\n### Functional Requirements\n\n- [ ] **F1**: `JsonPatch.diff(source, target)` computes a patch transforming source to target\n- [ ] **F2**: `patch.apply(json, mode)` applies a patch with configurable failure handling\n- [ ] **F3**: `patch1 ++ patch2` composes patches (apply first, then second)\n- [ ] **F4**: `JsonPatch.empty` is the identity element for composition\n- [ ] **F5**: Support `JsonPatchMode.Strict`, `Lenient`, and `Clobber` modes\n- [ ] **F6**: Bidirectional conversion: `toDynamicPatch` / `fromDynamicPatch`\n\n### Algebraic Laws\n\nAll laws must be verified with property-based tests (see `PatchLawsSpec` for reference):\n\n- [ ] **L1**: Left identity â€” `(empty ++ p)(j) == p(j)`\n- [ ] **L2**: Right identity â€” `(p ++ empty)(j) == p(j)`\n- [ ] **L3**: Associativity â€” `((p1 ++ p2) ++ p3)(j) == (p1 ++ (p2 ++ p3))(j)`\n- [ ] **L4**: Roundtrip â€” `diff(a, b)(a) == Right(b)`\n- [ ] **L5**: Identity diff â€” `diff(j, j).isEmpty`\n- [ ] **L6**: Diff composition â€” `(diff(a, b) ++ diff(b, c))(a) == Right(c)`\n- [ ] **L7**: Lenient subsumes Strict â€” if `p(j, Strict) == Right(r)` then `p(j, Lenient) == Right(r)`\n\n### Testing Requirements\n\n- [ ] **T1**: Property-based tests for all algebraic laws (see `PatchLawsSpec`)\n- [ ] **T2**: Test each operation type (`Set`, `PrimitiveDelta`, `ArrayEdit`, `ObjectEdit`, `Nested`)\n- [ ] **T3**: Test each `ArrayOp` variant (`Insert`, `Append`, `Delete`, `Modify`)\n- [ ] **T4**: Test each `ObjectOp` variant (`Add`, `Remove`, `Modify`)\n- [ ] **T5**: Test each `StringOp` variant (`Insert`, `Delete`, `Append`, `Modify`)\n- [ ] **T6**: Test `NumberDelta` with positive, negative, zero, and decimal deltas\n- [ ] **T7**: Test all three `JsonPatchMode` behaviors\n- [ ] **T8**: Test `toDynamicPatch` / `fromDynamicPatch` roundtrip\n- [ ] **T9**: Test edge cases: empty arrays, empty objects, empty strings, nested structures\n- [ ] **T10**: Test error cases: invalid paths, type mismatches, out-of-bounds indices\n\n### Documentation Requirements\n\n- [ ] **D1**: ScalaDoc for all public types and methods\n- [ ] **D2**: Usage examples in ScalaDoc (see sketch for examples)\n- [ ] **D3**: Document algebraic laws in type-level comments\n- [ ] **D4**: Document relationship to `DynamicPatch`\n\n## Related\n\n- `DynamicPatch` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala)\n- `Differ` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala)\n- `PatchLawsSpec` â€” [`[schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala](https://claude.ai/chat/schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala)`](./schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala)\n- `PatchMode` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala)\n\n## Acceptance Criteria\n\n- [ ] All functional requirements (F1-F6) implemented\n- [ ] All algebraic laws (L1-L7) pass property-based tests\n- [ ] All testing requirements (T1-T10) have corresponding test cases\n- [ ] All documentation requirements (D1-D4) complete\n- [ ] Code reviewed and approved\n- [ ] CI passing\n\n# Sketch\n\n```scala\npackage zio.blocks.schema.json\n\nimport zio.blocks.schema.DynamicOptic\nimport zio.blocks.schema.patch.DynamicPatch\n\n// =============================================================================\n// JSON PATCH\n// =============================================================================\n\n/**\n * An untyped patch that operates on [[Json]] values.\n *\n * `JsonPatch` is the JSON-specific counterpart to [[DynamicPatch]]. It represents\n * a sequence of operations that transform one JSON value into another. Patches\n * are serializable and composable.\n *\n * ==Design==\n *\n * This type directly mirrors [[DynamicPatch]] but is specialized for JSON's\n * simpler data model:\n *  - JSON has 4 leaf types (String, Number, Boolean, Null) vs 30 PrimitiveValues\n *  - JSON objects have string keys only (no arbitrary-keyed maps)\n *  - JSON has no native Variant type\n *\n * ==Algebraic Laws==\n *\n * '''Monoid Laws''' (under `++` composition):\n * {{{\n * // 1. LEFT IDENTITY\n * âˆ€ p: JsonPatch, j: Json.\n *   (JsonPatch.empty ++ p)(j, mode) == p(j, mode)\n *\n * // 2. RIGHT IDENTITY\n * âˆ€ p: JsonPatch, j: Json.\n *   (p ++ JsonPatch.empty)(j, mode) == p(j, mode)\n *\n * // 3. ASSOCIATIVITY\n * âˆ€ p1, p2, p3: JsonPatch, j: Json.\n *   ((p1 ++ p2) ++ p3)(j, mode) == (p1 ++ (p2 ++ p3))(j, mode)\n * }}}\n *\n * '''Diff/Apply Laws''':\n * {{{\n * // 4. ROUNDTRIP\n * âˆ€ source, target: Json.\n *   JsonPatch.diff(source, target)(source, Strict) == Right(target)\n *\n * // 5. IDENTITY DIFF\n * âˆ€ j: Json.\n *   JsonPatch.diff(j, j).isEmpty == true\n *\n * // 6. DIFF COMPOSITION\n * âˆ€ a, b, c: Json.\n *   (JsonPatch.diff(a, b) ++ JsonPatch.diff(b, c))(a, Strict) == Right(c)\n * }}}\n *\n * '''PatchMode Laws''':\n * {{{\n * // 7. STRICT FAILS ON ERROR\n * // Strict mode fails on first precondition violation\n *\n * // 8. LENIENT SKIPS ERRORS\n * // Lenient mode skips failing operations, always returns Right\n *\n * // 9. LENIENT SUBSUMES STRICT\n * âˆ€ p: JsonPatch, j: Json.\n *   p(j, Strict) == Right(r) implies p(j, Lenient) == Right(r)\n *\n * // 10. CLOBBER FORCES SUCCESS\n * // Clobber mode creates missing paths, always returns Right\n * }}}\n *\n * @param ops The sequence of patch operations\n */\nfinal case class JsonPatch(ops: Vector[JsonPatch.JsonPatchOp]) {\n\n  /**\n   * Applies this patch to a JSON value.\n   *\n   * @param json The JSON value to patch\n   * @param mode The patch mode (default: Strict)\n   * @return Either an error or the patched value\n   */\n  def apply(json: Json, mode: JsonPatchMode = JsonPatchMode.Strict): Either[JsonError, Json]\n\n  /**\n   * Composes this patch with another. Applies this patch first, then `that`.\n   *\n   * This is the monoid `combine` operation.\n   */\n  def ++(that: JsonPatch): JsonPatch = JsonPatch(ops ++ that.ops)\n\n  /**\n   * Returns true if this patch contains no operations.\n   */\n  def isEmpty: Boolean = ops.isEmpty\n\n  /**\n   * Converts this JSON patch to a [[DynamicPatch]].\n   */\n  def toDynamicPatch: DynamicPatch\n}\n\nobject JsonPatch {\n\n  /**\n   * Empty patch â€” the identity element for `++` composition.\n   */\n  val empty: JsonPatch = JsonPatch(Vector.empty)\n\n  /**\n   * Creates a patch with a single operation at the root path.\n   */\n  def root(op: Op): JsonPatch =\n    JsonPatch(Vector(JsonPatchOp(DynamicOptic.root, op)))\n\n  /**\n   * Creates a patch with a single operation at the given path.\n   */\n  def apply(path: DynamicOptic, op: Op): JsonPatch =\n    JsonPatch(Vector(JsonPatchOp(path, op)))\n\n  /**\n   * Computes a patch that transforms `oldJson` into `newJson`.\n   *\n   * Law: `diff(old, new)(old, Strict) == Right(new)`\n   */\n  def diff(oldJson: Json, newJson: Json): JsonPatch\n\n  /**\n   * Creates a JSON patch from a [[DynamicPatch]].\n   *\n   * May fail if the DynamicPatch contains operations not representable in JSON\n   * (e.g., non-string map keys, temporal deltas, variant operations).\n   */\n  def fromDynamicPatch(patch: DynamicPatch): Either[JsonError, JsonPatch]\n\n  // ===========================================================================\n  // JsonPatchOp â€” a single operation at a path\n  // ===========================================================================\n\n  /**\n   * A single patch operation: a path and what to do there.\n   *\n   * Mirrors [[DynamicPatch.DynamicPatchOp]].\n   */\n  final case class JsonPatchOp(path: DynamicOptic, op: Op)\n\n  // ===========================================================================\n  // Op â€” the operation to perform at a path\n  // ===========================================================================\n\n  /**\n   * The operation to perform at a target location.\n   *\n   * Mirrors [[DynamicPatch.Operation]] but specialized for JSON.\n   */\n  sealed trait Op\n\n  object Op {\n\n    /**\n     * Set a value directly (replacement).\n     *\n     * Mirrors [[DynamicPatch.Operation.Set]].\n     */\n    final case class Set(value: Json) extends Op\n\n    /**\n     * Apply a primitive delta operation.\n     *\n     * Used for numeric deltas and string edits.\n     * Mirrors [[DynamicPatch.Operation.PrimitiveDelta]].\n     */\n    final case class PrimitiveDelta(op: PrimitiveOp) extends Op\n\n    /**\n     * Apply array edit operations.\n     *\n     * Used for inserting, appending, deleting, or modifying array elements.\n     * Mirrors [[DynamicPatch.Operation.SequenceEdit]].\n     */\n    final case class ArrayEdit(ops: Vector[ArrayOp]) extends Op\n\n    /**\n     * Apply object edit operations.\n     *\n     * Used for adding, removing, or modifying object fields.\n     * Mirrors [[DynamicPatch.Operation.MapEdit]] but with string keys.\n     */\n    final case class ObjectEdit(ops: Vector[ObjectOp]) extends Op\n\n    /**\n     * Apply a nested patch.\n     *\n     * Used to group operations sharing a common path prefix.\n     * Mirrors [[DynamicPatch.Operation.Patch]].\n     */\n    final case class Nested(patch: JsonPatch) extends Op\n  }\n\n  // ===========================================================================\n  // PrimitiveOp â€” delta operations for JSON primitives\n  // ===========================================================================\n\n  /**\n   * Delta operations for JSON primitive values.\n   *\n   * JSON has only one numeric type, so we use BigDecimal for deltas.\n   * Boolean has no delta (use Set to toggle).\n   * Null has no delta (use Set to change).\n   *\n   * Mirrors [[DynamicPatch.PrimitiveOp]] but simplified for JSON's type system.\n   */\n  sealed trait PrimitiveOp\n\n  object PrimitiveOp {\n\n    /**\n     * Add a delta to a JSON number.\n     *\n     * Applied by: `currentValue + delta`\n     *\n     * Mirrors the numeric delta operations in [[DynamicPatch.PrimitiveOp]]\n     * (IntDelta, LongDelta, DoubleDelta, etc.) unified into one type.\n     */\n    final case class NumberDelta(delta: BigDecimal) extends PrimitiveOp\n\n    /**\n     * Apply string edit operations.\n     *\n     * Mirrors [[DynamicPatch.PrimitiveOp.StringEdit]].\n     */\n    final case class StringEdit(ops: Vector[StringOp]) extends PrimitiveOp\n  }\n\n  // ===========================================================================\n  // StringOp â€” edit operations for strings\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON strings.\n   *\n   * Mirrors [[DynamicPatch.StringOp]] exactly.\n   */\n  sealed trait StringOp\n\n  object StringOp {\n\n    /**\n     * Insert text at the given index.\n     */\n    final case class Insert(index: Int, text: String) extends StringOp\n\n    /**\n     * Delete characters starting at the given index.\n     */\n    final case class Delete(index: Int, length: Int) extends StringOp\n\n    /**\n     * Append text to the end of the string.\n     */\n    final case class Append(text: String) extends StringOp\n\n    /**\n     * Replace characters starting at index with new text.\n     */\n    final case class Modify(index: Int, length: Int, text: String) extends StringOp\n  }\n\n  // ===========================================================================\n  // ArrayOp â€” edit operations for arrays\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON arrays.\n   *\n   * Mirrors [[DynamicPatch.SeqOp]] but with Json values.\n   */\n  sealed trait ArrayOp\n\n  object ArrayOp {\n\n    /**\n     * Insert values at the given index.\n     */\n    final case class Insert(index: Int, values: Vector[Json]) extends ArrayOp\n\n    /**\n     * Append values to the end of the array.\n     */\n    final case class Append(values: Vector[Json]) extends ArrayOp\n\n    /**\n     * Delete elements starting at the given index.\n     */\n    final case class Delete(index: Int, count: Int) extends ArrayOp\n\n    /**\n     * Modify the element at the given index with a nested operation.\n     */\n    final case class Modify(index: Int, op: Op) extends ArrayOp\n  }\n\n  // ===========================================================================\n  // ObjectOp â€” edit operations for objects\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON objects.\n   *\n   * Mirrors [[DynamicPatch.MapOp]] but with string keys (JSON constraint).\n   */\n  sealed trait ObjectOp\n\n  object ObjectOp {\n\n    /**\n     * Add a field to the object.\n     */\n    final case class Add(key: String, value: Json) extends ObjectOp\n\n    /**\n     * Remove a field from the object.\n     */\n    final case class Remove(key: String) extends ObjectOp\n\n    /**\n     * Modify a field's value with a nested patch.\n     */\n    final case class Modify(key: String, patch: JsonPatch) extends ObjectOp\n  }\n}\n\n// =============================================================================\n// PATCH MODE\n// =============================================================================\n\n/**\n * Controls how patch application handles failures.\n *\n * Mirrors [[zio.blocks.schema.patch.PatchMode]].\n */\nsealed trait JsonPatchMode\n\nobject JsonPatchMode {\n\n  /**\n   * Fail on precondition violations.\n   */\n  case object Strict extends JsonPatchMode\n\n  /**\n   * Skip operations that fail preconditions.\n   */\n  case object Lenient extends JsonPatchMode\n\n  /**\n   * Replace/overwrite on conflicts (create missing paths).\n   */\n  case object Clobber extends JsonPatchMode\n}\n\n// =============================================================================\n// USAGE EXAMPLES\n// =============================================================================\n\n/*\n * ==Example 1: Basic Patching==\n *\n * {{{\n * import zio.blocks.schema.json._\n *\n * val json = Json.Object(Vector(\n *   \"name\" -> Json.String(\"Alice\"),\n *   \"age\" -> Json.Number(\"30\")\n * ))\n *\n * // Replace name\n * val patch = JsonPatch.root(JsonPatch.Op.Set(Json.String(\"Bob\")))\n *   // Or at a specific path:\n *   // JsonPatch(DynamicOptic.root.field(\"name\"), JsonPatch.Op.Set(Json.String(\"Bob\")))\n *\n * val result = patch(json, JsonPatchMode.Strict)\n * }}}\n *\n * ==Example 2: Diff and Apply (Roundtrip Law)==\n *\n * {{{\n * val source = Json.Object(Vector(\"x\" -> Json.Number(\"1\")))\n * val target = Json.Object(Vector(\"x\" -> Json.Number(\"5\")))\n *\n * val patch = JsonPatch.diff(source, target)\n *\n * // Roundtrip law\n * assert(patch(source, JsonPatchMode.Strict) == Right(target))\n *\n * // Identity diff law\n * assert(JsonPatch.diff(source, source).isEmpty)\n * }}}\n *\n * ==Example 3: Monoid Laws==\n *\n * {{{\n * val p1 = JsonPatch.diff(a, b)\n * val p2 = JsonPatch.diff(b, c)\n * val p3 = JsonPatch.diff(c, d)\n *\n * // Left identity\n * assert((JsonPatch.empty ++ p1)(a, Strict) == p1(a, Strict))\n *\n * // Right identity\n * assert((p1 ++ JsonPatch.empty)(a, Strict) == p1(a, Strict))\n *\n * // Associativity\n * assert(((p1 ++ p2) ++ p3)(a, Strict) == (p1 ++ (p2 ++ p3))(a, Strict))\n * }}}\n *\n * ==Example 4: Numeric Delta==\n *\n * {{{\n * val json = Json.Number(\"10\")\n *\n * // Add 5 to the number (more efficient than Set for large structures)\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.PrimitiveDelta(JsonPatch.PrimitiveOp.NumberDelta(BigDecimal(5)))\n * )\n *\n * assert(patch(json, Strict) == Right(Json.Number(\"15\")))\n * }}}\n *\n * ==Example 5: String Edit==\n *\n * {{{\n * val json = Json.String(\"hello world\")\n *\n * // Change \"hello\" to \"hi\" using LCS-based edits\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.PrimitiveDelta(\n *     JsonPatch.PrimitiveOp.StringEdit(Vector(\n *       JsonPatch.StringOp.Delete(0, 5),\n *       JsonPatch.StringOp.Insert(0, \"hi\")\n *     ))\n *   )\n * )\n *\n * assert(patch(json, Strict) == Right(Json.String(\"hi world\")))\n * }}}\n *\n * ==Example 6: Array Edit==\n *\n * {{{\n * val json = Json.Array(Vector(Json.Number(\"1\"), Json.Number(\"2\"), Json.Number(\"3\")))\n *\n * // Delete element at index 1, append new element\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ArrayEdit(Vector(\n *     JsonPatch.ArrayOp.Delete(1, 1),\n *     JsonPatch.ArrayOp.Append(Vector(Json.Number(\"4\")))\n *   ))\n * )\n *\n * // Result: [1, 3, 4]\n * }}}\n *\n * ==Example 7: Object Edit==\n *\n * {{{\n * val json = Json.Object(Vector(\"a\" -> Json.Number(\"1\"), \"b\" -> Json.Number(\"2\")))\n *\n * // Remove field \"a\", add field \"c\"\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ObjectEdit(Vector(\n *     JsonPatch.ObjectOp.Remove(\"a\"),\n *     JsonPatch.ObjectOp.Add(\"c\", Json.Number(\"3\"))\n *   ))\n * )\n *\n * // Result: {\"b\": 2, \"c\": 3}\n * }}}\n *\n * ==Example 8: Nested Patch==\n *\n * {{{\n * val json = Json.Object(Vector(\n *   \"user\" -> Json.Object(Vector(\n *     \"name\" -> Json.String(\"Alice\"),\n *     \"age\" -> Json.Number(\"30\")\n *   ))\n * ))\n *\n * // Patch nested inside \"user\"\n * val innerPatch = JsonPatch(Vector(\n *   JsonPatch.JsonPatchOp(\n *     DynamicOptic.root.field(\"age\"),\n *     JsonPatch.Op.PrimitiveDelta(JsonPatch.PrimitiveOp.NumberDelta(BigDecimal(1)))\n *   )\n * ))\n *\n * val patch = JsonPatch(\n *   DynamicOptic.root.field(\"user\"),\n *   JsonPatch.Op.Nested(innerPatch)\n * )\n *\n * // Increments user.age by 1\n * }}}\n *\n * ==Example 9: Diff Composition Law==\n *\n * {{{\n * val a = Json.Number(\"1\")\n * val b = Json.Number(\"5\")\n * val c = Json.Number(\"10\")\n *\n * val p1 = JsonPatch.diff(a, b)  // delta +4\n * val p2 = JsonPatch.diff(b, c)  // delta +5\n *\n * // Composition law: applying composed patch equals applying sequentially\n * assert((p1 ++ p2)(a, Strict) == Right(c))\n * }}}\n *\n * ==Example 10: PatchMode Behavior==\n *\n * {{{\n * val json = Json.Object(Vector(\"a\" -> Json.Number(\"1\")))\n *\n * // Try to remove non-existent field\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ObjectEdit(Vector(JsonPatch.ObjectOp.Remove(\"nonexistent\")))\n * )\n *\n * // Strict: fails\n * assert(patch(json, JsonPatchMode.Strict).isLeft)\n *\n * // Lenient: skips, returns unchanged\n * assert(patch(json, JsonPatchMode.Lenient) == Right(json))\n *\n * // Clobber: skips (nothing to clobber), returns unchanged\n * assert(patch(json, JsonPatchMode.Clobber) == Right(json))\n * }}}\n */\n```",
                  "html_url": "https://github.com/zio/zio-blocks/issues/685"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#685",
              "body": "<html><head></head><body><h1>Add <code>JsonPatch</code> type for diffing and patching JSON values</h1>\n<h2>Summary</h2>\n<p>Implement a <code>JsonPatch</code> type that enables computing diffs between JSON values and applying patches to transform one JSON value into another. This type should mirror the existing <code>DynamicPatch</code> implementation, adapted for JSON's simpler data model.</p>\n<h2>Motivation</h2>\n<p><code>DynamicValue</code> has a well-designed <code>DynamicPatch</code> system with:</p>\n<ul>\n<li>Monoid composition (<code>++</code> with <code>empty</code> identity)</li>\n<li>LCS-based sequence diffing</li>\n<li>Primitive delta operations (numeric deltas, string edits)</li>\n<li>Comprehensive algebraic laws verified by property tests</li>\n</ul>\n<p>The proposed <code>Json</code> type (see #TBD) needs equivalent patching capabilities. Rather than converting <code>Json â†” DynamicValue</code> for every patch operation, a native <code>JsonPatch</code> provides:</p>\n<ul>\n<li>Type safety (no conversion errors for JSON-incompatible DynamicPatch operations)</li>\n<li>API consistency with the <code>Json</code> type</li>\n<li>Potential for JSON-specific optimizations</li>\n</ul>\n<h2>Design Sketch</h2>\n<p>A design sketch is available at <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala</code></a>. This sketch is <strong>a guide, not a specification</strong> â€” implementers should use judgment and deviate where appropriate.</p>\n<h3>Core Types</h3>\n<p>The design mirrors <code>DynamicPatch</code> with JSON-specific adaptations:</p>\n\nDynamicPatch | JsonPatch | Notes\n-- | -- | --\nDynamicPatch(Vector[DynamicPatchOp]) | JsonPatch(Vector[JsonPatchOp]) | Same structure\nOperation.Set | Op.Set | Same\nOperation.PrimitiveDelta | Op.PrimitiveDelta | Simplified for JSON types\nOperation.SequenceEdit | Op.ArrayEdit | Renamed\nOperation.MapEdit | Op.ObjectEdit | String keys only\nOperation.Patch | Op.Nested | Same\nSeqOp | ArrayOp | Same operations\nMapOp | ObjectOp | String keys only\nPrimitiveOp (14 variants) | PrimitiveOp (2 variants) | See below\n\n\n<h3>StringOp</h3>\n<p>Mirror <code>DynamicPatch.StringOp</code> exactly:</p>\n<ul>\n<li><code>Insert(index: Int, text: String)</code></li>\n<li><code>Delete(index: Int, length: Int)</code></li>\n<li><code>Append(text: String)</code></li>\n<li><code>Modify(index: Int, length: Int, text: String)</code></li>\n</ul>\n<h3>ArrayOp</h3>\n<p>Mirror <code>DynamicPatch.SeqOp</code>:</p>\n<ul>\n<li><code>Insert(index: Int, values: Vector[Json])</code></li>\n<li><code>Append(values: Vector[Json])</code></li>\n<li><code>Delete(index: Int, count: Int)</code></li>\n<li><code>Modify(index: Int, op: Op)</code></li>\n</ul>\n<h3>ObjectOp</h3>\n<p>Mirror <code>DynamicPatch.MapOp</code> with string keys:</p>\n<ul>\n<li><code>Add(key: String, value: Json)</code></li>\n<li><code>Remove(key: String)</code></li>\n<li><code>Modify(key: String, patch: JsonPatch)</code></li>\n</ul>\n<h2>Requirements</h2>\n<h3>Functional Requirements</h3>\n<ul>\n<li>[ ] <strong>F1</strong>: <code>JsonPatch.diff(source, target)</code> computes a patch transforming source to target</li>\n<li>[ ] <strong>F2</strong>: <code>patch.apply(json, mode)</code> applies a patch with configurable failure handling</li>\n<li>[ ] <strong>F3</strong>: <code>patch1 ++ patch2</code> composes patches (apply first, then second)</li>\n<li>[ ] <strong>F4</strong>: <code>JsonPatch.empty</code> is the identity element for composition</li>\n<li>[ ] <strong>F5</strong>: Support <code>JsonPatchMode.Strict</code>, <code>Lenient</code>, and <code>Clobber</code> modes</li>\n<li>[ ] <strong>F6</strong>: Bidirectional conversion: <code>toDynamicPatch</code> / <code>fromDynamicPatch</code></li>\n</ul>\n<h3>Algebraic Laws</h3>\n<p>All laws must be verified with property-based tests (see <code>PatchLawsSpec</code> for reference):</p>\n<ul>\n<li>[ ] <strong>L1</strong>: Left identity â€” <code>(empty ++ p)(j) == p(j)</code></li>\n<li>[ ] <strong>L2</strong>: Right identity â€” <code>(p ++ empty)(j) == p(j)</code></li>\n<li>[ ] <strong>L3</strong>: Associativity â€” <code>((p1 ++ p2) ++ p3)(j) == (p1 ++ (p2 ++ p3))(j)</code></li>\n<li>[ ] <strong>L4</strong>: Roundtrip â€” <code>diff(a, b)(a) == Right(b)</code></li>\n<li>[ ] <strong>L5</strong>: Identity diff â€” <code>diff(j, j).isEmpty</code></li>\n<li>[ ] <strong>L6</strong>: Diff composition â€” <code>(diff(a, b) ++ diff(b, c))(a) == Right(c)</code></li>\n<li>[ ] <strong>L7</strong>: Lenient subsumes Strict â€” if <code>p(j, Strict) == Right(r)</code> then <code>p(j, Lenient) == Right(r)</code></li>\n</ul>\n<h3>Testing Requirements</h3>\n<ul>\n<li>[ ] <strong>T1</strong>: Property-based tests for all algebraic laws (see <code>PatchLawsSpec</code>)</li>\n<li>[ ] <strong>T2</strong>: Test each operation type (<code>Set</code>, <code>PrimitiveDelta</code>, <code>ArrayEdit</code>, <code>ObjectEdit</code>, <code>Nested</code>)</li>\n<li>[ ] <strong>T3</strong>: Test each <code>ArrayOp</code> variant (<code>Insert</code>, <code>Append</code>, <code>Delete</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T4</strong>: Test each <code>ObjectOp</code> variant (<code>Add</code>, <code>Remove</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T5</strong>: Test each <code>StringOp</code> variant (<code>Insert</code>, <code>Delete</code>, <code>Append</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T6</strong>: Test <code>NumberDelta</code> with positive, negative, zero, and decimal deltas</li>\n<li>[ ] <strong>T7</strong>: Test all three <code>JsonPatchMode</code> behaviors</li>\n<li>[ ] <strong>T8</strong>: Test <code>toDynamicPatch</code> / <code>fromDynamicPatch</code> roundtrip</li>\n<li>[ ] <strong>T9</strong>: Test edge cases: empty arrays, empty objects, empty strings, nested structures</li>\n<li>[ ] <strong>T10</strong>: Test error cases: invalid paths, type mismatches, out-of-bounds indices</li>\n</ul>\n<h3>Documentation Requirements</h3>\n<ul>\n<li>[ ] <strong>D1</strong>: ScalaDoc for all public types and methods</li>\n<li>[ ] <strong>D2</strong>: Usage examples in ScalaDoc (see sketch for examples)</li>\n<li>[ ] <strong>D3</strong>: Document algebraic laws in type-level comments</li>\n<li>[ ] <strong>D4</strong>: Document relationship to <code>DynamicPatch</code></li>\n</ul>\n<h3>Implementation Notes</h3>\n<ol>\n<li>\n<p><strong>Follow <code>DynamicPatch</code> patterns</strong>: The implementation in <code>DynamicPatch.scala</code> is the reference. Study <code>Differ.scala</code> for diff algorithms (especially LCS for sequences and strings).</p>\n</li>\n<li>\n<p><strong>Reuse algorithms where possible</strong>: Consider whether <code>JsonPatch</code> can delegate to <code>DynamicPatch</code> internally, or share algorithm implementations.</p>\n</li>\n<li>\n<p><strong>Keep it minimal</strong>: Resist adding operations not present in <code>DynamicPatch</code>. The design is intentionally minimal and principled.</p>\n</li>\n<li>\n<p><strong>Performance considerations</strong>: The register-based design of ZIO Blocks prioritizes performance. Avoid unnecessary allocations in hot paths.</p>\n</li>\n</ol>\n<h2>Out of Scope</h2>\n<p>The following are explicitly <strong>not</strong> part of this issue:</p>\n<ul>\n<li>RFC 6902 JSON Patch serialization format (separate issue)</li>\n<li>Patch inversion / undo support (separate issue)</li>\n<li>Patch optimization / compaction (separate issue)</li>\n<li>Integration with <code>Json</code> type methods like <code>json.diff(other)</code> (depends on <code>Json</code> implementation)</li>\n</ul>\n<h2>Related</h2>\n<ul>\n<li><code>DynamicPatch</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala</code></a></li>\n<li><code>Differ</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala</code></a></li>\n<li><code>PatchLawsSpec</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala\"><code>schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala</code></a></li>\n<li><code>PatchMode</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala</code></a></li>\n</ul>\n<h2>Acceptance Criteria</h2>\n<ul>\n<li>[ ] All functional requirements (F1-F6) implemented</li>\n<li>[ ] All algebraic laws (L1-L7) pass property-based tests</li>\n<li>[ ] All testing requirements (T1-T10) have corresponding test cases</li>\n<li>[ ] All documentation requirements (D1-D4) complete</li>\n<li>[ ] Code reviewed and approved</li>\n<li>[ ] CI passing</li>\n</ul></body></html># Add `JsonPatch` type for diffing and patching JSON values\n\n## Summary\n\nImplement a `JsonPatch` type that enables computing diffs between JSON values and applying patches to transform one JSON value into another. This type should mirror the existing `DynamicPatch` implementation, adapted for JSON's simpler data model.\n\n## Motivation\n\n`DynamicValue` has a well-designed `DynamicPatch` system with:\n- Monoid composition (`++` with `empty` identity)\n- LCS-based sequence diffing\n- Primitive delta operations (numeric deltas, string edits)\n- Comprehensive algebraic laws verified by property tests\n\nThe proposed `Json` type (see #TBD) needs equivalent patching capabilities. Rather than converting `Json â†” DynamicValue` for every patch operation, a native `JsonPatch` provides:\n- Type safety (no conversion errors for JSON-incompatible DynamicPatch operations)\n- API consistency with the `Json` type\n- Potential for JSON-specific optimizations\n\n## Design Sketch\n\nA design sketch is available at [`[schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala). This sketch is **a guide, not a specification** â€” implementers should use judgment and deviate where appropriate.\n\n### Core Types\n\nThe design mirrors `DynamicPatch` with JSON-specific adaptations:\n\n| DynamicPatch | JsonPatch | Notes |\n|--------------|-----------|-------|\n| `DynamicPatch(Vector[DynamicPatchOp])` | `JsonPatch(Vector[JsonPatchOp])` | Same structure |\n| `Operation.Set` | `Op.Set` | Same |\n| `Operation.PrimitiveDelta` | `Op.PrimitiveDelta` | Simplified for JSON types |\n| `Operation.SequenceEdit` | `Op.ArrayEdit` | Renamed |\n| `Operation.MapEdit` | `Op.ObjectEdit` | String keys only |\n| `Operation.Patch` | `Op.Nested` | Same |\n| `SeqOp` | `ArrayOp` | Same operations |\n| `MapOp` | `ObjectOp` | String keys only |\n| `PrimitiveOp` (14 variants) | `PrimitiveOp` (2 variants) | See below |\n\n### Primitive Operations\n\nJSON has a simpler type system than `DynamicValue`:\n\n| JSON Type | Delta Operation | Notes |\n|-----------|-----------------|-------|\n| Number | `NumberDelta(BigDecimal)` | Unifies all numeric deltas |\n| String | `StringEdit(Vector[StringOp])` | Same as `DynamicPatch` |\n| Boolean | Use `Op.Set` | No delta (same as `DynamicPatch`) |\n| Null | Use `Op.Set` | No delta |\n\n### StringOp\n\nMirror `DynamicPatch.StringOp` exactly:\n- `Insert(index: Int, text: String)`\n- `Delete(index: Int, length: Int)`\n- `Append(text: String)`\n- `Modify(index: Int, length: Int, text: String)`\n\n### ArrayOp\n\nMirror `DynamicPatch.SeqOp`:\n- `Insert(index: Int, values: Vector[Json])`\n- `Append(values: Vector[Json])`\n- `Delete(index: Int, count: Int)`\n- `Modify(index: Int, op: Op)`\n\n### ObjectOp\n\nMirror `DynamicPatch.MapOp` with string keys:\n- `Add(key: String, value: Json)`\n- `Remove(key: String)`\n- `Modify(key: String, patch: JsonPatch)`\n\n## Requirements\n\n### Functional Requirements\n\n- [ ] **F1**: `JsonPatch.diff(source, target)` computes a patch transforming source to target\n- [ ] **F2**: `patch.apply(json, mode)` applies a patch with configurable failure handling\n- [ ] **F3**: `patch1 ++ patch2` composes patches (apply first, then second)\n- [ ] **F4**: `JsonPatch.empty` is the identity element for composition\n- [ ] **F5**: Support `JsonPatchMode.Strict`, `Lenient`, and `Clobber` modes\n- [ ] **F6**: Bidirectional conversion: `toDynamicPatch` / `fromDynamicPatch`\n\n### Algebraic Laws\n\nAll laws must be verified with property-based tests (see `PatchLawsSpec` for reference):\n\n- [ ] **L1**: Left identity â€” `(empty ++ p)(j) == p(j)`\n- [ ] **L2**: Right identity â€” `(p ++ empty)(j) == p(j)`\n- [ ] **L3**: Associativity â€” `((p1 ++ p2) ++ p3)(j) == (p1 ++ (p2 ++ p3))(j)`\n- [ ] **L4**: Roundtrip â€” `diff(a, b)(a) == Right(b)`\n- [ ] **L5**: Identity diff â€” `diff(j, j).isEmpty`\n- [ ] **L6**: Diff composition â€” `(diff(a, b) ++ diff(b, c))(a) == Right(c)`\n- [ ] **L7**: Lenient subsumes Strict â€” if `p(j, Strict) == Right(r)` then `p(j, Lenient) == Right(r)`\n\n### Testing Requirements\n\n- [ ] **T1**: Property-based tests for all algebraic laws (see `PatchLawsSpec`)\n- [ ] **T2**: Test each operation type (`Set`, `PrimitiveDelta`, `ArrayEdit`, `ObjectEdit`, `Nested`)\n- [ ] **T3**: Test each `ArrayOp` variant (`Insert`, `Append`, `Delete`, `Modify`)\n- [ ] **T4**: Test each `ObjectOp` variant (`Add`, `Remove`, `Modify`)\n- [ ] **T5**: Test each `StringOp` variant (`Insert`, `Delete`, `Append`, `Modify`)\n- [ ] **T6**: Test `NumberDelta` with positive, negative, zero, and decimal deltas\n- [ ] **T7**: Test all three `JsonPatchMode` behaviors\n- [ ] **T8**: Test `toDynamicPatch` / `fromDynamicPatch` roundtrip\n- [ ] **T9**: Test edge cases: empty arrays, empty objects, empty strings, nested structures\n- [ ] **T10**: Test error cases: invalid paths, type mismatches, out-of-bounds indices\n\n### Documentation Requirements\n\n- [ ] **D1**: ScalaDoc for all public types and methods\n- [ ] **D2**: Usage examples in ScalaDoc (see sketch for examples)\n- [ ] **D3**: Document algebraic laws in type-level comments\n- [ ] **D4**: Document relationship to `DynamicPatch`\n\n## Related\n\n- `DynamicPatch` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala)\n- `Differ` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala)\n- `PatchLawsSpec` â€” [`[schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala](https://claude.ai/chat/schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala)`](./schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala)\n- `PatchMode` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala)\n\n## Acceptance Criteria\n\n- [ ] All functional requirements (F1-F6) implemented\n- [ ] All algebraic laws (L1-L7) pass property-based tests\n- [ ] All testing requirements (T1-T10) have corresponding test cases\n- [ ] All documentation requirements (D1-D4) complete\n- [ ] Code reviewed and approved\n- [ ] CI passing\n\n# Sketch\n\n```scala\npackage zio.blocks.schema.json\n\nimport zio.blocks.schema.DynamicOptic\nimport zio.blocks.schema.patch.DynamicPatch\n\n// =============================================================================\n// JSON PATCH\n// =============================================================================\n\n/**\n * An untyped patch that operates on [[Json]] values.\n *\n * `JsonPatch` is the JSON-specific counterpart to [[DynamicPatch]]. It represents\n * a sequence of operations that transform one JSON value into another. Patches\n * are serializable and composable.\n *\n * ==Design==\n *\n * This type directly mirrors [[DynamicPatch]] but is specialized for JSON's\n * simpler data model:\n *  - JSON has 4 leaf types (String, Number, Boolean, Null) vs 30 PrimitiveValues\n *  - JSON objects have string keys only (no arbitrary-keyed maps)\n *  - JSON has no native Variant type\n *\n * ==Algebraic Laws==\n *\n * '''Monoid Laws''' (under `++` composition):\n * {{{\n * // 1. LEFT IDENTITY\n * âˆ€ p: JsonPatch, j: Json.\n *   (JsonPatch.empty ++ p)(j, mode) == p(j, mode)\n *\n * // 2. RIGHT IDENTITY\n * âˆ€ p: JsonPatch, j: Json.\n *   (p ++ JsonPatch.empty)(j, mode) == p(j, mode)\n *\n * // 3. ASSOCIATIVITY\n * âˆ€ p1, p2, p3: JsonPatch, j: Json.\n *   ((p1 ++ p2) ++ p3)(j, mode) == (p1 ++ (p2 ++ p3))(j, mode)\n * }}}\n *\n * '''Diff/Apply Laws''':\n * {{{\n * // 4. ROUNDTRIP\n * âˆ€ source, target: Json.\n *   JsonPatch.diff(source, target)(source, Strict) == Right(target)\n *\n * // 5. IDENTITY DIFF\n * âˆ€ j: Json.\n *   JsonPatch.diff(j, j).isEmpty == true\n *\n * // 6. DIFF COMPOSITION\n * âˆ€ a, b, c: Json.\n *   (JsonPatch.diff(a, b) ++ JsonPatch.diff(b, c))(a, Strict) == Right(c)\n * }}}\n *\n * '''PatchMode Laws''':\n * {{{\n * // 7. STRICT FAILS ON ERROR\n * // Strict mode fails on first precondition violation\n *\n * // 8. LENIENT SKIPS ERRORS\n * // Lenient mode skips failing operations, always returns Right\n *\n * // 9. LENIENT SUBSUMES STRICT\n * âˆ€ p: JsonPatch, j: Json.\n *   p(j, Strict) == Right(r) implies p(j, Lenient) == Right(r)\n *\n * // 10. CLOBBER FORCES SUCCESS\n * // Clobber mode creates missing paths, always returns Right\n * }}}\n *\n * @param ops The sequence of patch operations\n */\nfinal case class JsonPatch(ops: Vector[JsonPatch.JsonPatchOp]) {\n\n  /**\n   * Applies this patch to a JSON value.\n   *\n   * @param json The JSON value to patch\n   * @param mode The patch mode (default: Strict)\n   * @return Either an error or the patched value\n   */\n  def apply(json: Json, mode: JsonPatchMode = JsonPatchMode.Strict): Either[JsonError, Json]\n\n  /**\n   * Composes this patch with another. Applies this patch first, then `that`.\n   *\n   * This is the monoid `combine` operation.\n   */\n  def ++(that: JsonPatch): JsonPatch = JsonPatch(ops ++ that.ops)\n\n  /**\n   * Returns true if this patch contains no operations.\n   */\n  def isEmpty: Boolean = ops.isEmpty\n\n  /**\n   * Converts this JSON patch to a [[DynamicPatch]].\n   */\n  def toDynamicPatch: DynamicPatch\n}\n\nobject JsonPatch {\n\n  /**\n   * Empty patch â€” the identity element for `++` composition.\n   */\n  val empty: JsonPatch = JsonPatch(Vector.empty)\n\n  /**\n   * Creates a patch with a single operation at the root path.\n   */\n  def root(op: Op): JsonPatch =\n    JsonPatch(Vector(JsonPatchOp(DynamicOptic.root, op)))\n\n  /**\n   * Creates a patch with a single operation at the given path.\n   */\n  def apply(path: DynamicOptic, op: Op): JsonPatch =\n    JsonPatch(Vector(JsonPatchOp(path, op)))\n\n  /**\n   * Computes a patch that transforms `oldJson` into `newJson`.\n   *\n   * Law: `diff(old, new)(old, Strict) == Right(new)`\n   */\n  def diff(oldJson: Json, newJson: Json): JsonPatch\n\n  /**\n   * Creates a JSON patch from a [[DynamicPatch]].\n   *\n   * May fail if the DynamicPatch contains operations not representable in JSON\n   * (e.g., non-string map keys, temporal deltas, variant operations).\n   */\n  def fromDynamicPatch(patch: DynamicPatch): Either[JsonError, JsonPatch]\n\n  // ===========================================================================\n  // JsonPatchOp â€” a single operation at a path\n  // ===========================================================================\n\n  /**\n   * A single patch operation: a path and what to do there.\n   *\n   * Mirrors [[DynamicPatch.DynamicPatchOp]].\n   */\n  final case class JsonPatchOp(path: DynamicOptic, op: Op)\n\n  // ===========================================================================\n  // Op â€” the operation to perform at a path\n  // ===========================================================================\n\n  /**\n   * The operation to perform at a target location.\n   *\n   * Mirrors [[DynamicPatch.Operation]] but specialized for JSON.\n   */\n  sealed trait Op\n\n  object Op {\n\n    /**\n     * Set a value directly (replacement).\n     *\n     * Mirrors [[DynamicPatch.Operation.Set]].\n     */\n    final case class Set(value: Json) extends Op\n\n    /**\n     * Apply a primitive delta operation.\n     *\n     * Used for numeric deltas and string edits.\n     * Mirrors [[DynamicPatch.Operation.PrimitiveDelta]].\n     */\n    final case class PrimitiveDelta(op: PrimitiveOp) extends Op\n\n    /**\n     * Apply array edit operations.\n     *\n     * Used for inserting, appending, deleting, or modifying array elements.\n     * Mirrors [[DynamicPatch.Operation.SequenceEdit]].\n     */\n    final case class ArrayEdit(ops: Vector[ArrayOp]) extends Op\n\n    /**\n     * Apply object edit operations.\n     *\n     * Used for adding, removing, or modifying object fields.\n     * Mirrors [[DynamicPatch.Operation.MapEdit]] but with string keys.\n     */\n    final case class ObjectEdit(ops: Vector[ObjectOp]) extends Op\n\n    /**\n     * Apply a nested patch.\n     *\n     * Used to group operations sharing a common path prefix.\n     * Mirrors [[DynamicPatch.Operation.Patch]].\n     */\n    final case class Nested(patch: JsonPatch) extends Op\n  }\n\n  // ===========================================================================\n  // PrimitiveOp â€” delta operations for JSON primitives\n  // ===========================================================================\n\n  /**\n   * Delta operations for JSON primitive values.\n   *\n   * JSON has only one numeric type, so we use BigDecimal for deltas.\n   * Boolean has no delta (use Set to toggle).\n   * Null has no delta (use Set to change).\n   *\n   * Mirrors [[DynamicPatch.PrimitiveOp]] but simplified for JSON's type system.\n   */\n  sealed trait PrimitiveOp\n\n  object PrimitiveOp {\n\n    /**\n     * Add a delta to a JSON number.\n     *\n     * Applied by: `currentValue + delta`\n     *\n     * Mirrors the numeric delta operations in [[DynamicPatch.PrimitiveOp]]\n     * (IntDelta, LongDelta, DoubleDelta, etc.) unified into one type.\n     */\n    final case class NumberDelta(delta: BigDecimal) extends PrimitiveOp\n\n    /**\n     * Apply string edit operations.\n     *\n     * Mirrors [[DynamicPatch.PrimitiveOp.StringEdit]].\n     */\n    final case class StringEdit(ops: Vector[StringOp]) extends PrimitiveOp\n  }\n\n  // ===========================================================================\n  // StringOp â€” edit operations for strings\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON strings.\n   *\n   * Mirrors [[DynamicPatch.StringOp]] exactly.\n   */\n  sealed trait StringOp\n\n  object StringOp {\n\n    /**\n     * Insert text at the given index.\n     */\n    final case class Insert(index: Int, text: String) extends StringOp\n\n    /**\n     * Delete characters starting at the given index.\n     */\n    final case class Delete(index: Int, length: Int) extends StringOp\n\n    /**\n     * Append text to the end of the string.\n     */\n    final case class Append(text: String) extends StringOp\n\n    /**\n     * Replace characters starting at index with new text.\n     */\n    final case class Modify(index: Int, length: Int, text: String) extends StringOp\n  }\n\n  // ===========================================================================\n  // ArrayOp â€” edit operations for arrays\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON arrays.\n   *\n   * Mirrors [[DynamicPatch.SeqOp]] but with Json values.\n   */\n  sealed trait ArrayOp\n\n  object ArrayOp {\n\n    /**\n     * Insert values at the given index.\n     */\n    final case class Insert(index: Int, values: Vector[Json]) extends ArrayOp\n\n    /**\n     * Append values to the end of the array.\n     */\n    final case class Append(values: Vector[Json]) extends ArrayOp\n\n    /**\n     * Delete elements starting at the given index.\n     */\n    final case class Delete(index: Int, count: Int) extends ArrayOp\n\n    /**\n     * Modify the element at the given index with a nested operation.\n     */\n    final case class Modify(index: Int, op: Op) extends ArrayOp\n  }\n\n  // ===========================================================================\n  // ObjectOp â€” edit operations for objects\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON objects.\n   *\n   * Mirrors [[DynamicPatch.MapOp]] but with string keys (JSON constraint).\n   */\n  sealed trait ObjectOp\n\n  object ObjectOp {\n\n    /**\n     * Add a field to the object.\n     */\n    final case class Add(key: String, value: Json) extends ObjectOp\n\n    /**\n     * Remove a field from the object.\n     */\n    final case class Remove(key: String) extends ObjectOp\n\n    /**\n     * Modify a field's value with a nested patch.\n     */\n    final case class Modify(key: String, patch: JsonPatch) extends ObjectOp\n  }\n}\n\n// =============================================================================\n// PATCH MODE\n// =============================================================================\n\n/**\n * Controls how patch application handles failures.\n *\n * Mirrors [[zio.blocks.schema.patch.PatchMode]].\n */\nsealed trait JsonPatchMode\n\nobject JsonPatchMode {\n\n  /**\n   * Fail on precondition violations.\n   */\n  case object Strict extends JsonPatchMode\n\n  /**\n   * Skip operations that fail preconditions.\n   */\n  case object Lenient extends JsonPatchMode\n\n  /**\n   * Replace/overwrite on conflicts (create missing paths).\n   */\n  case object Clobber extends JsonPatchMode\n}\n\n// =============================================================================\n// USAGE EXAMPLES\n// =============================================================================\n\n/*\n * ==Example 1: Basic Patching==\n *\n * {{{\n * import zio.blocks.schema.json._\n *\n * val json = Json.Object(Vector(\n *   \"name\" -> Json.String(\"Alice\"),\n *   \"age\" -> Json.Number(\"30\")\n * ))\n *\n * // Replace name\n * val patch = JsonPatch.root(JsonPatch.Op.Set(Json.String(\"Bob\")))\n *   // Or at a specific path:\n *   // JsonPatch(DynamicOptic.root.field(\"name\"), JsonPatch.Op.Set(Json.String(\"Bob\")))\n *\n * val result = patch(json, JsonPatchMode.Strict)\n * }}}\n *\n * ==Example 2: Diff and Apply (Roundtrip Law)==\n *\n * {{{\n * val source = Json.Object(Vector(\"x\" -> Json.Number(\"1\")))\n * val target = Json.Object(Vector(\"x\" -> Json.Number(\"5\")))\n *\n * val patch = JsonPatch.diff(source, target)\n *\n * // Roundtrip law\n * assert(patch(source, JsonPatchMode.Strict) == Right(target))\n *\n * // Identity diff law\n * assert(JsonPatch.diff(source, source).isEmpty)\n * }}}\n *\n * ==Example 3: Monoid Laws==\n *\n * {{{\n * val p1 = JsonPatch.diff(a, b)\n * val p2 = JsonPatch.diff(b, c)\n * val p3 = JsonPatch.diff(c, d)\n *\n * // Left identity\n * assert((JsonPatch.empty ++ p1)(a, Strict) == p1(a, Strict))\n *\n * // Right identity\n * assert((p1 ++ JsonPatch.empty)(a, Strict) == p1(a, Strict))\n *\n * // Associativity\n * assert(((p1 ++ p2) ++ p3)(a, Strict) == (p1 ++ (p2 ++ p3))(a, Strict))\n * }}}\n *\n * ==Example 4: Numeric Delta==\n *\n * {{{\n * val json = Json.Number(\"10\")\n *\n * // Add 5 to the number (more efficient than Set for large structures)\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.PrimitiveDelta(JsonPatch.PrimitiveOp.NumberDelta(BigDecimal(5)))\n * )\n *\n * assert(patch(json, Strict) == Right(Json.Number(\"15\")))\n * }}}\n *\n * ==Example 5: String Edit==\n *\n * {{{\n * val json = Json.String(\"hello world\")\n *\n * // Change \"hello\" to \"hi\" using LCS-based edits\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.PrimitiveDelta(\n *     JsonPatch.PrimitiveOp.StringEdit(Vector(\n *       JsonPatch.StringOp.Delete(0, 5),\n *       JsonPatch.StringOp.Insert(0, \"hi\")\n *     ))\n *   )\n * )\n *\n * assert(patch(json, Strict) == Right(Json.String(\"hi world\")))\n * }}}\n *\n * ==Example 6: Array Edit==\n *\n * {{{\n * val json = Json.Array(Vector(Json.Number(\"1\"), Json.Number(\"2\"), Json.Number(\"3\")))\n *\n * // Delete element at index 1, append new element\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ArrayEdit(Vector(\n *     JsonPatch.ArrayOp.Delete(1, 1),\n *     JsonPatch.ArrayOp.Append(Vector(Json.Number(\"4\")))\n *   ))\n * )\n *\n * // Result: [1, 3, 4]\n * }}}\n *\n * ==Example 7: Object Edit==\n *\n * {{{\n * val json = Json.Object(Vector(\"a\" -> Json.Number(\"1\"), \"b\" -> Json.Number(\"2\")))\n *\n * // Remove field \"a\", add field \"c\"\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ObjectEdit(Vector(\n *     JsonPatch.ObjectOp.Remove(\"a\"),\n *     JsonPatch.ObjectOp.Add(\"c\", Json.Number(\"3\"))\n *   ))\n * )\n *\n * // Result: {\"b\": 2, \"c\": 3}\n * }}}\n *\n * ==Example 8: Nested Patch==\n *\n * {{{\n * val json = Json.Object(Vector(\n *   \"user\" -> Json.Object(Vector(\n *     \"name\" -> Json.String(\"Alice\"),\n *     \"age\" -> Json.Number(\"30\")\n *   ))\n * ))\n *\n * // Patch nested inside \"user\"\n * val innerPatch = JsonPatch(Vector(\n *   JsonPatch.JsonPatchOp(\n *     DynamicOptic.root.field(\"age\"),\n *     JsonPatch.Op.PrimitiveDelta(JsonPatch.PrimitiveOp.NumberDelta(BigDecimal(1)))\n *   )\n * ))\n *\n * val patch = JsonPatch(\n *   DynamicOptic.root.field(\"user\"),\n *   JsonPatch.Op.Nested(innerPatch)\n * )\n *\n * // Increments user.age by 1\n * }}}\n *\n * ==Example 9: Diff Composition Law==\n *\n * {{{\n * val a = Json.Number(\"1\")\n * val b = Json.Number(\"5\")\n * val c = Json.Number(\"10\")\n *\n * val p1 = JsonPatch.diff(a, b)  // delta +4\n * val p2 = JsonPatch.diff(b, c)  // delta +5\n *\n * // Composition law: applying composed patch equals applying sequentially\n * assert((p1 ++ p2)(a, Strict) == Right(c))\n * }}}\n *\n * ==Example 10: PatchMode Behavior==\n *\n * {{{\n * val json = Json.Object(Vector(\"a\" -> Json.Number(\"1\")))\n *\n * // Try to remove non-existent field\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ObjectEdit(Vector(JsonPatch.ObjectOp.Remove(\"nonexistent\")))\n * )\n *\n * // Strict: fails\n * assert(patch(json, JsonPatchMode.Strict).isLeft)\n *\n * // Lenient: skips, returns unchanged\n * assert(patch(json, JsonPatchMode.Lenient) == Right(json))\n *\n * // Clobber: skips (nothing to clobber), returns unchanged\n * assert(patch(json, JsonPatchMode.Clobber) == Right(json))\n * }}}\n */\n```",
              "url": "https://github.com/zio/zio-blocks/issues/685",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#683",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-18T17:51:52.851Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:52.851Z",
            "created_at": "2026-01-18T17:51:52.851Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#683",
              "status": "open",
              "type": "issue",
              "number": 683,
              "title": "Port BSON Support to ZIO Schema 2",
              "source": {
                "data": {
                  "id": "source-ZIO#683",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Port BSON Support to ZIO Schema 2",
                  "body": "In a separate top-level project (schema-bson), port the [old ZIO Schema BSON support](https://github.com/zio/zio-schema/tree/main/zio-schema-bson/src) to ZIO Schema 2.\n\nMust have at least as many tests as the old version, with any known bugs in the implementation identified and fixed.",
                  "html_url": "https://github.com/zio/zio-blocks/issues/683"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#683",
              "body": "In a separate top-level project (schema-bson), port the [old ZIO Schema BSON support](https://github.com/zio/zio-schema/tree/main/zio-schema-bson/src) to ZIO Schema 2.\n\nMust have at least as many tests as the old version, with any known bugs in the implementation identified and fixed.",
              "url": "https://github.com/zio/zio-blocks/issues/683",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#682",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-18T17:51:53.135Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:53.135Z",
            "created_at": "2026-01-18T17:51:53.135Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#682",
              "status": "open",
              "type": "issue",
              "number": 682,
              "title": "Port Message Pack Support to ZIO Schema 2",
              "source": {
                "data": {
                  "id": "source-ZIO#682",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Port Message Pack Support to ZIO Schema 2",
                  "body": "In a separate top-level project (schema-messagepack), port the [old ZIO Schema Message Pack support](https://github.com/zio/zio-schema/tree/main/zio-schema-msg-pack/src) to ZIO Schema 2.\n\nMust have at least as many tests as the old version, with any known bugs in the implementation identified and fixed.",
                  "html_url": "https://github.com/zio/zio-blocks/issues/682"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#682",
              "body": "In a separate top-level project (schema-messagepack), port the [old ZIO Schema Message Pack support](https://github.com/zio/zio-schema/tree/main/zio-schema-msg-pack/src) to ZIO Schema 2.\n\nMust have at least as many tests as the old version, with any known bugs in the implementation identified and fixed.",
              "url": "https://github.com/zio/zio-blocks/issues/682",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#681",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-18T17:51:53.291Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:53.291Z",
            "created_at": "2026-01-18T17:51:53.291Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#681",
              "status": "open",
              "type": "issue",
              "number": 681,
              "title": "Port Thrift Support to ZIO Schema 2",
              "source": {
                "data": {
                  "id": "source-ZIO#681",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Port Thrift Support to ZIO Schema 2",
                  "body": "In a separate top-level project (schema-thrift), port the [old ZIO Schema Thrift support](https://github.com/zio/zio-schema/tree/main/zio-schema-thrift/src) to ZIO Schema 2.\n\nMust have at least as many tests as the old version, with any known bugs in the implementation identified and fixed.",
                  "html_url": "https://github.com/zio/zio-blocks/issues/681"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#681",
              "body": "In a separate top-level project (schema-thrift), port the [old ZIO Schema Thrift support](https://github.com/zio/zio-schema/tree/main/zio-schema-thrift/src) to ZIO Schema 2.\n\nMust have at least as many tests as the old version, with any known bugs in the implementation identified and fixed.",
              "url": "https://github.com/zio/zio-blocks/issues/681",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#679",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-18T17:51:53.308Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:53.308Z",
            "created_at": "2026-01-18T17:51:53.308Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#679",
              "status": "open",
              "type": "issue",
              "number": 679,
              "title": "Add Json data type",
              "source": {
                "data": {
                  "id": "source-ZIO#679",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add Json data type",
                  "body": "The following is a sketch of what a proper `Json` data type should look like, including constructors, methods, and related types. Note that `DynamicPatch`, `JsonPatch`, and `JsonSchema` are all out-of-scope for this ticket.\n\n## Sketch\n\n```scala\npackage zio.blocks.schema.json\n\nimport zio.blocks.chunk.Chunk\nimport zio.blocks.schema.{DynamicOptic, DynamicValue, PrimitiveValue, Schema, SchemaError}\n\nimport java.io.{Reader, Writer}\nimport java.nio.ByteBuffer\nimport scala.util.control.NoStackTrace\n\n// =============================================================================\n// JSON ERROR\n// =============================================================================\n\n/**\n * Represents an error that occurred during JSON parsing, encoding, or processing.\n *\n * NOTE: This should replace JsonBinaryCodecError and be moved to `zio.block.schema.json`.\n *\n * @param message A human-readable description of the error\n * @param path The location in the JSON structure where the error occurred,\n *             represented as a [[DynamicOptic]]\n * @param offset Optional byte offset in the input where the error occurred\n * @param line Optional 1-indexed line number where the error occurred\n * @param column Optional 1-indexed column number where the error occurred\n */\nfinal case class JsonError(\n  message: String,\n  path: DynamicOptic,\n  offset: Option[Long],\n  line: Option[Int],\n  column: Option[Int]\n) extends Exception with NoStackTrace {\n\n  override def getMessage: String = {\n    val posInfo = (line, column) match {\n      case (Some(l), Some(c)) => s\" at line $l, column $c\"\n      case _                  => offset.map(o => s\" at offset $o\").getOrElse(\"\")\n    }\n    val pathInfo = if (path.nodes.isEmpty) \"\" else s\" at path $path\"\n    s\"$message$pathInfo$posInfo\"\n  }\n\n  /**\n   * Combines this error with another, preserving both error messages.\n   */\n  def ++(other: JsonError): JsonError =\n    JsonError(s\"${this.message}; ${other.message}\", this.path, this.offset, this.line, this.column)\n}\n\nobject JsonError {\n\n  /**\n   * Creates a JsonError with only a message, using root path and no position info.\n   */\n  def apply(message: String): JsonError =\n    JsonError(message, DynamicOptic.root, None, None, None)\n\n  /**\n   * Creates a JsonError with a message and path, no position info.\n   */\n  def apply(message: String, path: DynamicOptic): JsonError =\n    JsonError(message, path, None, None, None)\n\n  /**\n   * Converts a [[SchemaError]] to a [[JsonError]].\n   */\n  def fromSchemaError(error: SchemaError): JsonError =\n    JsonError(error.message, DynamicOptic.root, None, None, None)\n}\n\n// =============================================================================\n// JSON DECODER / ENCODER (implicit priority resolution)\n// =============================================================================\n\n/**\n * Type class for decoding [[Json]] values into Scala types.\n *\n * Implicit resolution prefers explicitly provided [[JsonBinaryCodec]] instances\n * over schema-derived instances, allowing users to override derived behavior.\n */\nsealed trait JsonDecoder[A] {\n\n  /**\n   * Decodes a [[Json]] value into type `A`.\n   *\n   * @param json The JSON value to decode\n   * @return Either a [[JsonError]] on failure, or the decoded value\n   */\n  def decode(json: Json): Either[JsonError, A]\n}\n\nobject JsonDecoder extends JsonDecoderLowPriority {\n\n  def apply[A](implicit decoder: JsonDecoder[A]): JsonDecoder[A] = decoder\n\n  /**\n   * Higher priority: use an explicitly provided [[JsonBinaryCodec]].\n   */\n  implicit def fromCodec[A](implicit codec: JsonBinaryCodec[A]): JsonDecoder[A] =\n    new JsonDecoder[A] {\n      def decode(json: Json): Either[JsonError, A] = json.decodeWith(codec)\n    }\n}\n\n/**\n * Lower priority implicits for [[JsonDecoder]].\n */\ntrait JsonDecoderLowPriority {\n\n  /**\n   * Lower priority: derive a codec from an implicit [[Schema]].\n   */\n  implicit def fromSchema[A](implicit schema: Schema[A]): JsonDecoder[A] =\n    new JsonDecoder[A] {\n      private lazy val codec: JsonBinaryCodec[A] = schema.derive(JsonBinaryCodecDeriver)\n      def decode(json: Json): Either[JsonError, A] = json.decodeWith(codec)\n    }\n}\n\n/**\n * Type class for encoding Scala types into [[Json]] values.\n *\n * Implicit resolution prefers explicitly provided [[JsonBinaryCodec]] instances\n * over schema-derived instances, allowing users to override derived behavior.\n */\nsealed trait JsonEncoder[A] {\n\n  /**\n   * Encodes a value of type `A` into [[Json]].\n   *\n   * @param value The value to encode\n   * @return The encoded JSON value\n   */\n  def encode(value: A): Json\n}\n\nobject JsonEncoder extends JsonEncoderLowPriority {\n\n  def apply[A](implicit encoder: JsonEncoder[A]): JsonEncoder[A] = encoder\n\n  /**\n   * Higher priority: use an explicitly provided [[JsonBinaryCodec]].\n   */\n  implicit def fromCodec[A](implicit codec: JsonBinaryCodec[A]): JsonEncoder[A] =\n    new JsonEncoder[A] {\n      def encode(value: A): Json = Json.encodeWith(value, codec)\n    }\n}\n\n/**\n * Lower priority implicits for [[JsonEncoder]].\n */\ntrait JsonEncoderLowPriority {\n\n  /**\n   * Lower priority: derive a codec from an implicit [[Schema]].\n   */\n  implicit def fromSchema[A](implicit schema: Schema[A]): JsonEncoder[A] =\n    new JsonEncoder[A] {\n      private lazy val codec: JsonBinaryCodec[A] = schema.derive(JsonBinaryCodecDeriver)\n      def encode(value: A): Json = Json.encodeWith(value, codec)\n    }\n}\n\n// =============================================================================\n// JSON SELECTION\n// =============================================================================\n\n/**\n * Represents a selection of zero or more JSON values, with accumulated errors.\n *\n * `JsonSelection` enables fluent chaining of operations that may fail without\n * requiring immediate error handling. Operations are applied to all values in\n * the selection, and errors are accumulated.\n *\n * {{{\n * val selection: JsonSelection = json.get(p\"users[*].name\")\n * val result: Either[SchemaError, Vector[Json]] = selection.toEither\n * }}}\n */\nfinal case class JsonSelection(toEither: Either[SchemaError, Vector[Json]]) { self =>\n\n  /**\n   * Returns true if this selection contains no values (either empty or errored).\n   */\n  def isEmpty: Boolean = toEither.fold(_ => true, _.isEmpty)\n\n  /**\n   * Returns true if this selection contains at least one value.\n   */\n  def nonEmpty: Boolean = toEither.fold(_ => false, _.nonEmpty)\n\n  /**\n   * Returns the number of values in this selection, or 0 if errored.\n   */\n  def size: Int = toEither.fold(_ => 0, _.size)\n\n  // ---------------------------------------------------------------------------\n  // Transformations\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Applies a function to each JSON value in this selection.\n   *\n   * @param f The transformation function\n   * @return A new selection with transformed values\n   */\n  def map(f: Json => Json): JsonSelection =\n    JsonSelection(toEither.map(_.map(f)))\n\n  /**\n   * Applies a function returning a selection to each value, flattening results.\n   *\n   * @param f The function producing selections\n   * @return A new selection with all results combined\n   */\n  def flatMap(f: Json => JsonSelection): JsonSelection =\n    JsonSelection(toEither.flatMap { jsons =>\n      jsons.foldLeft[Either[SchemaError, Vector[Json]]](Right(Vector.empty)) { (acc, json) =>\n        for {\n          existing <- acc\n          next     <- f(json).toEither\n        } yield existing ++ next\n      }\n    })\n\n  /**\n   * Filters values in this selection by a predicate.\n   *\n   * @param p The predicate to test values\n   * @return A new selection containing only values satisfying the predicate\n   */\n  def filter(p: Json => Boolean): JsonSelection =\n    JsonSelection(toEither.map(_.filter(p)))\n\n  /**\n   * Collects values for which the partial function is defined.\n   *\n   * @param pf A partial function to apply\n   * @return A new selection with collected results\n   */\n  def collect(pf: PartialFunction[Json, Json]): JsonSelection =\n    JsonSelection(toEither.map(_.collect(pf)))\n\n  // ---------------------------------------------------------------------------\n  // Navigation\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Navigates to values at the given path within each selected value.\n   *\n   * @param path The path to navigate\n   * @return A new selection with values at the path\n   */\n  def get(path: DynamicOptic): JsonSelection =\n    flatMap(json => json.get(path))\n\n  /**\n   * Alias for [[get]].\n   */\n  def apply(path: DynamicOptic): JsonSelection = get(path)\n\n  /**\n   * Navigates to array element at given index within each selected value.\n   *\n   * @param index The array index\n   * @return A new selection with elements at the index\n   */\n  def apply(index: Int): JsonSelection =\n    flatMap(json => json.apply(index))\n\n  /**\n   * Navigates to object field with given key within each selected value.\n   *\n   * @param key The object key\n   * @return A new selection with values at the key\n   */\n  def apply(key: String): JsonSelection =\n    flatMap(json => json.apply(key))\n\n  // ---------------------------------------------------------------------------\n  // Type Filtering\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Filters to only JSON objects.\n   */\n  def objects: JsonSelection = filter(_.isObject)\n\n  /**\n   * Filters to only JSON arrays.\n   */\n  def arrays: JsonSelection = filter(_.isArray)\n\n  /**\n   * Filters to only JSON strings.\n   */\n  def strings: JsonSelection = filter(_.isString)\n\n  /**\n   * Filters to only JSON numbers.\n   */\n  def numbers: JsonSelection = filter(_.isNumber)\n\n  /**\n   * Filters to only JSON booleans.\n   */\n  def booleans: JsonSelection = filter(_.isBoolean)\n\n  /**\n   * Filters to only JSON nulls.\n   */\n  def nulls: JsonSelection = filter(_.isNull)\n\n  // ---------------------------------------------------------------------------\n  // Combination\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Combines this selection with another, concatenating values or errors.\n   *\n   * @param other The other selection\n   * @return A combined selection\n   */\n  def ++(other: JsonSelection): JsonSelection =\n    (toEither, other.toEither) match {\n      case (Right(a), Right(b)) => JsonSelection(Right(a ++ b))\n      case (Left(a), Left(b))   => JsonSelection(Left(a ++ b))\n      case (Left(a), _)         => JsonSelection(Left(a))\n      case (_, Left(b))         => JsonSelection(Left(b))\n    }\n\n  // ---------------------------------------------------------------------------\n  // Terminal Operations\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Returns the single value if exactly one, an array of values if there are many, or \n   * otherwise an error.\n   */\n  def one: Either[SchemaError, Json] =\n    toEither.flatMap { jsons =>\n      if (jsons.size == 1) Right(jsons.head)\n      else if (jsons.size > 1) toArray\n      else Left(SchemaError.expectationMismatch(Nil, s\"expected exactly one value, got ${jsons.size}\"))\n    }\n\n  /**\n   * Returns the first value if any, otherwise an error.\n   */\n  def first: Either[SchemaError, Json] =\n    toEither.flatMap { jsons =>\n      jsons.headOption.toRight(SchemaError.expectationMismatch(Nil, \"expected at least one value, got none\"))\n    }\n\n  /**\n   * Returns all values as a [[Json.Array]], or an error.\n   */\n  def toArray: Either[SchemaError, Json] =\n    toEither.map(jsons => Json.Array(jsons))\n\n  /**\n   * Unsafe version of [[one]], throws on error or wrong count.\n   */\n  def oneUnsafe: Json = one.fold(e => throw JsonError.fromSchemaError(e), identity)\n\n  /**\n   * Unsafe version of [[first]], throws on error or empty.\n   */\n  def firstUnsafe: Json = first.fold(e => throw JsonError.fromSchemaError(e), identity)\n}\n\nobject JsonSelection {\n\n  /**\n   * Creates a selection containing a single value.\n   */\n  def apply(json: Json): JsonSelection = JsonSelection(Right(Vector(json)))\n\n  /**\n   * Creates a selection containing multiple values.\n   */\n  def fromVector(jsons: Vector[Json]): JsonSelection = JsonSelection(Right(jsons))\n\n  /**\n   * Creates an empty selection (no values, no error).\n   */\n  val empty: JsonSelection = JsonSelection(Right(Vector.empty))\n\n  /**\n   * Creates a failed selection with the given error.\n   */\n  def fail(error: SchemaError): JsonSelection = JsonSelection(Left(error))\n\n  /**\n   * Creates a failed selection with the given message.\n   */\n  def fail(message: String): JsonSelection =\n    JsonSelection(Left(SchemaError.expectationMismatch(Nil, message)))\n}\n\n// =============================================================================\n// JSON ADT\n// =============================================================================\n\n/**\n * Represents a JSON value.\n *\n * The JSON data model consists of:\n *  - '''Objects''': Unordered collections of key-value pairs\n *  - '''Arrays''': Ordered sequences of values\n *  - '''Strings''': Unicode text\n *  - '''Numbers''': Numeric values (stored as strings for precision)\n *  - '''Booleans''': `true` or `false`\n *  - '''Null''': The null value\n *\n * ==Construction==\n * {{{\n * val obj = Json.Object(\"name\" -> Json.String(\"Alice\"), \"age\" -> Json.number(30))\n * val arr = Json.Array(Json.String(\"a\"), Json.String(\"b\"))\n * val str = Json.String(\"hello\")\n * val num = Json.number(42)\n * val bool = Json.Boolean(true)\n * val nul = Json.Null\n * }}}\n *\n * ==Navigation==\n * {{{\n * json.get(p\"users[0].name\")   // JsonSelection\n * json(\"users\")(0)(\"name\")     // JsonSelection\n * json.fields                  // for objects\n * json.elements                // for arrays\n * }}}\n *\n * ==Pattern Matching==\n * {{{\n * json match {\n *   case Json.Object(fields) => ...\n *   case Json.Array(elements) => ...\n *   case Json.String(value) => ...\n *   case Json.Number(value) => ...\n *   case Json.Boolean(value) => ...\n *   case Json.Null => ...\n * }\n * }}}\n */\nsealed trait Json { self =>\n\n  // ===========================================================================\n  // Type Testing\n  // ===========================================================================\n\n  /**\n   * Returns `true` if this is a JSON object.\n   */\n  def isObject: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON array.\n   */\n  def isArray: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON string.\n   */\n  def isString: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON number.\n   */\n  def isNumber: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON boolean.\n   */\n  def isBoolean: Boolean = false\n\n  /**\n   * Returns `true` if this is JSON null.\n   */\n  def isNull: Boolean = false\n\n  // ===========================================================================\n  // Type Filtering (returns JsonSelection)\n  // ===========================================================================\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is an object,\n   * otherwise an empty selection.\n   */\n  def asObject: JsonSelection = if (isObject) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is an array,\n   * otherwise an empty selection.\n   */\n  def asArray: JsonSelection = if (isArray) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is a string,\n   * otherwise an empty selection.\n   */\n  def asString: JsonSelection = if (isString) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is a number,\n   * otherwise an empty selection.\n   */\n  def asNumber: JsonSelection = if (isNumber) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is a boolean,\n   * otherwise an empty selection.\n   */\n  def asBoolean: JsonSelection = if (isBoolean) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is null,\n   * otherwise an empty selection.\n   */\n  def asNull: JsonSelection = if (isNull) JsonSelection(self) else JsonSelection.empty\n\n  // ===========================================================================\n  // Direct Accessors\n  // ===========================================================================\n\n  /**\n   * If this is an object, returns its fields as key-value pairs.\n   * Otherwise returns an empty sequence.\n   */\n  def fields: Seq[(String, Json)] = Seq.empty\n\n  /**\n   * If this is an array, returns its elements.\n   * Otherwise returns an empty sequence.\n   */\n  def elements: Seq[Json] = Seq.empty\n\n  /**\n   * If this is a string, returns its value.\n   * Otherwise returns `None`.\n   */\n  def stringValue: Option[String] = None\n\n  /**\n   * If this is a number, returns its string representation.\n   * Otherwise returns `None`.\n   */\n  def numberValue: Option[String] = None\n\n  /**\n   * If this is a boolean, returns its value.\n   * Otherwise returns `None`.\n   */\n  def booleanValue: Option[scala.Boolean] = None\n\n  // ===========================================================================\n  // Navigation\n  // ===========================================================================\n\n  /**\n   * Navigates to values at the given path.\n   *\n   * {{{\n   * json.get(p\"users[0].name\")\n   * json.get(DynamicOptic.root.field(\"users\").at(0).field(\"name\"))\n   * }}}\n   *\n   * @param path The path to navigate\n   * @return A [[JsonSelection]] containing values at the path\n   */\n  def get(path: DynamicOptic): JsonSelection = ???\n\n  /**\n   * Alias for [[get]].\n   */\n  def apply(path: DynamicOptic): JsonSelection = get(path)\n\n  /**\n   * If this is an array, returns a selection containing the element at the given index.\n   * Returns an empty selection if not an array or index is out of bounds.\n   *\n   * @param index The array index (0-based)\n   */\n  def apply(index: Int): JsonSelection = self match {\n    case Json.Array(elems) if index >= 0 && index < elems.size =>\n      JsonSelection(elems(index))\n    case _ =>\n      JsonSelection.empty\n  }\n\n  /**\n   * If this is an object, returns a selection containing the value at the given key.\n   * Returns an empty selection if not an object or key is not present.\n   *\n   * @param key The object key\n   */\n  def apply(key: String): JsonSelection = self match {\n    case Json.Object(flds) =>\n      flds.collectFirst { case (k, v) if k == key => v } match {\n        case Some(v) => JsonSelection(v)\n        case None    => JsonSelection.empty\n      }\n    case _ =>\n      JsonSelection.empty\n  }\n\n  // ===========================================================================\n  // Modification (Json => Json)\n  // ===========================================================================\n\n  /**\n   * Modifies values at the given path using the provided function.\n   *\n   * If the path does not exist, returns this JSON unchanged.\n   *\n   * {{{\n   * json.modify(p\"users[*].age\", {\n   *   case Json.Number(n) => Json.number(n.toInt + 1)\n   *   case other => other\n   * })\n   * }}}\n   *\n   * @param path The path to values to modify\n   * @param f The modification function\n   * @return The modified JSON\n   */\n  def modify(path: DynamicOptic, f: Json => Json): Json = ???\n\n  /**\n   * Modifies values at the given path using a partial function.\n   *\n   * Values for which the partial function is not defined are left unchanged.\n   *\n   * @param path The path to values to modify\n   * @param pf The partial modification function\n   * @return Either an error if the path is invalid, or the modified JSON\n   */\n  def modifyOrFail(path: DynamicOptic, pf: PartialFunction[Json, Json]): Either[JsonError, Json] = ???\n\n  /**\n   * Sets the value at the given path.\n   *\n   * If the path does not exist, attempts to create intermediate structure.\n   * For array indices, the array must already exist and have sufficient length.\n   *\n   * {{{\n   * json.set(p\"user.name\", Json.String(\"Bob\"))\n   * }}}\n   *\n   * @param path The path to set\n   * @param value The value to set\n   * @return The modified JSON\n   */\n  def set(path: DynamicOptic, value: Json): Json = ???\n\n  /**\n   * Sets the value at the given path, returning an error if the path is invalid.\n   *\n   * @param path The path to set\n   * @param value The value to set\n   * @return Either an error or the modified JSON\n   */\n  def setOrFail(path: DynamicOptic, value: Json): Either[JsonError, Json] = ???\n\n  /**\n   * Deletes values at the given path.\n   *\n   * For object fields, removes the key-value pair.\n   * For array elements, removes the element and shifts subsequent elements.\n   *\n   * @param path The path to delete\n   * @return The modified JSON\n   */\n  def delete(path: DynamicOptic): Json = ???\n\n  /**\n   * Deletes values at the given path, returning an error if the path is invalid.\n   *\n   * @param path The path to delete\n   * @return Either an error or the modified JSON\n   */\n  def deleteOrFail(path: DynamicOptic): Either[JsonError, Json] = ???\n\n  /**\n   * Inserts a value at the given path.\n   *\n   * For arrays, inserts at the specified index, shifting subsequent elements.\n   * For objects, adds or replaces the key.\n   *\n   * @param path The path where to insert\n   * @param value The value to insert\n   * @return The modified JSON\n   */\n  def insert(path: DynamicOptic, value: Json): Json = ???\n\n  /**\n   * Inserts a value at the given path, returning an error if invalid.\n   *\n   * @param path The path where to insert\n   * @param value The value to insert\n   * @return Either an error or the modified JSON\n   */\n  def insertOrFail(path: DynamicOptic, value: Json): Either[JsonError, Json] = ???\n\n  // ===========================================================================\n  // Merging\n  // ===========================================================================\n\n  /**\n   * Merges this JSON with another using the specified strategy.\n   *\n   * {{{\n   * val merged = json1.merge(json2, MergeStrategy.Deep)\n   * }}}\n   *\n   * @param other The JSON to merge with\n   * @param strategy The merge strategy (default: [[MergeStrategy.Auto]])\n   * @return The merged JSON\n   */\n  def merge(other: Json, strategy: MergeStrategy = MergeStrategy.Auto): Json = ???\n\n  // ===========================================================================\n  // Patching\n  // ===========================================================================\n\n  /**\n   * Applies a [[JsonPatch]] to this JSON.\n   *\n   * @param patch The patch to apply\n   * @return Either an error if the patch cannot be applied, or the patched JSON\n   */\n  def patch(patch: JsonPatch): Either[JsonError, Json] = ???\n\n  /**\n   * Applies a [[JsonPatch]], throwing on failure.\n   *\n   * @param patch The patch to apply\n   * @return The patched JSON\n   * @throws JsonError if the patch cannot be applied\n   */\n  def patchUnsafe(patch: JsonPatch): Json = this.patch(patch).fold(throw _, identity)\n\n  // ===========================================================================\n  // Transformation\n  // ===========================================================================\n\n  /**\n   * Transforms all values in this JSON bottom-up (children before parents).\n   *\n   * @param f The transformation function receiving path and value\n   * @return The transformed JSON\n   */\n  def transformUp(f: (DynamicOptic, Json) => Json): Json = ???\n\n  /**\n   * Transforms all values in this JSON top-down (parents before children).\n   *\n   * @param f The transformation function receiving path and value\n   * @return The transformed JSON\n   */\n  def transformDown(f: (DynamicOptic, Json) => Json): Json = ???\n\n  /**\n   * Transforms all object keys in this JSON.\n   *\n   * @param f The key transformation function receiving path and key\n   * @return The transformed JSON\n   */\n  def transformKeys(f: (DynamicOptic, String) => String): Json = ???\n\n  // ===========================================================================\n  // Filtering\n  // ===========================================================================\n\n  /**\n   * Removes entries matching the predicate.\n   *\n   * For objects, removes matching key-value pairs.\n   * For arrays, removes matching elements.\n   *\n   * @param p The predicate receiving path and value\n   * @return The filtered JSON\n   */\n  def filterNot(p: (DynamicOptic, Json) => scala.Boolean): Json = ???\n\n  /**\n   * Keeps only entries matching the predicate.\n   *\n   * @param p The predicate receiving path and value\n   * @return The filtered JSON\n   */\n  def filter(p: (DynamicOptic, Json) => scala.Boolean): Json =\n    filterNot((path, json) => !p(path, json))\n\n  // ===========================================================================\n  // Projection\n  // ===========================================================================\n\n  /**\n   * Projects this JSON to include only the specified paths.\n   *\n   * Paths that don't exist are ignored. Structure is preserved.\n   *\n   * {{{\n   * json.project(p\"user.name\", p\"user.email\", p\"meta.created\")\n   * }}}\n   *\n   * @param paths The paths to include\n   * @return A new JSON containing only the specified paths\n   */\n  def project(paths: DynamicOptic*): Json = ???\n\n  // ===========================================================================\n  // Splitting / Partitioning\n  // ===========================================================================\n\n  /**\n   * Partitions this JSON into two based on a predicate.\n   *\n   * Returns a tuple where the first element contains entries satisfying\n   * the predicate, and the second contains entries that don't.\n   *\n   * @param p The predicate receiving path and value\n   * @return A tuple of (matching, non-matching) JSON values\n   */\n  def partition(p: (DynamicOptic, Json) => scala.Boolean): (Json, Json) = ???\n\n  // ===========================================================================\n  // Normalization\n  // ===========================================================================\n\n  /**\n   * Returns a normalized version of this JSON.\n   *\n   * Normalization includes:\n   *  - Sorting object keys alphabetically\n   *  - Normalizing number representations\n   *\n   * Useful for comparison and hashing.\n   */\n  def normalize: Json = ???\n\n  /**\n   * Returns this JSON with all object keys sorted alphabetically (recursive).\n   */\n  def sortKeys: Json = self match {\n    case Json.Object(flds) =>\n      Json.Object(flds.map { case (k, v) => (k, v.sortKeys) }.sortBy(_._1))\n    case Json.Array(elems) =>\n      Json.Array(elems.map(_.sortKeys))\n    case other =>\n      other\n  }\n\n  /**\n   * Returns this JSON with all null values removed from objects.\n   */\n  def dropNulls: Json = self match {\n    case Json.Object(flds) =>\n      Json.Object(flds.collect { case (k, v) if !v.isNull => (k, v.dropNulls) })\n    case Json.Array(elems) =>\n      Json.Array(elems.map(_.dropNulls))\n    case other =>\n      other\n  }\n\n  /**\n   * Returns this JSON with empty objects and arrays removed.\n   */\n  def dropEmpty: Json = self match {\n    case Json.Object(flds) =>\n      val filtered = flds.collect {\n        case (k, v) =>\n          val dropped = v.dropEmpty\n          dropped match {\n            case Json.Object(f) if f.isEmpty => None\n            case Json.Array(e) if e.isEmpty  => None\n            case other                       => Some((k, other))\n          }\n      }.flatten\n      Json.Object(filtered)\n    case Json.Array(elems) =>\n      val filtered = elems.map(_.dropEmpty).filter {\n        case Json.Object(f) if f.isEmpty => false\n        case Json.Array(e) if e.isEmpty  => false\n        case _                           => true\n      }\n      Json.Array(filtered)\n    case other =>\n      other\n  }\n\n  // ===========================================================================\n  // Diffing\n  // ===========================================================================\n\n  /**\n   * Computes a [[JsonPatch]] that transforms this JSON into the target.\n   *\n   * {{{\n   * val patch = source.diff(target)\n   * source.patch(patch) == Right(target) // true\n   * }}}\n   *\n   * @param target The target JSON\n   * @return A patch that transforms this into target\n   */\n  def diff(target: Json): JsonPatch = ???\n\n  // ===========================================================================\n  // Folding\n  // ===========================================================================\n\n  /**\n   * Folds over this JSON top-down (parents before children).\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function receiving path, value, and accumulator\n   * @tparam B The accumulator type\n   * @return The final accumulated value\n   */\n  def foldDown[B](z: B)(f: (DynamicOptic, Json, B) => B): B = ???\n\n  /**\n   * Folds over this JSON bottom-up (children before parents).\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function receiving path, value, and accumulator\n   * @tparam B The accumulator type\n   * @return The final accumulated value\n   */\n  def foldUp[B](z: B)(f: (DynamicOptic, Json, B) => B): B = ???\n\n  /**\n   * Folds over this JSON top-down, allowing the fold function to fail.\n   *\n   * Short-circuits on first failure.\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function that may fail\n   * @tparam B The accumulator type\n   * @return Either an error or the final accumulated value\n   */\n  def foldDownOrFail[B](z: B)(f: (DynamicOptic, Json, B) => Either[JsonError, B]): Either[JsonError, B] = ???\n\n  /**\n   * Folds over this JSON bottom-up, allowing the fold function to fail.\n   *\n   * Short-circuits on first failure.\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function that may fail\n   * @tparam B The accumulator type\n   * @return Either an error or the final accumulated value\n   */\n  def foldUpOrFail[B](z: B)(f: (DynamicOptic, Json, B) => Either[JsonError, B]): Either[JsonError, B] = ???\n\n  // ===========================================================================\n  // Querying\n  // ===========================================================================\n\n  /**\n   * Selects all values matching the predicate.\n   *\n   * @param p The predicate receiving path and value\n   * @return A [[JsonSelection]] containing matching values\n   */\n  def query(p: (DynamicOptic, Json) => scala.Boolean): JsonSelection = ???\n\n  // ===========================================================================\n  // Validation\n  // ===========================================================================\n\n  /**\n   * Validates this JSON against a [[JsonSchema]].\n   *\n   * @param schema The schema to validate against\n   * @return `None` if valid, `Some(error)` if invalid\n   */\n  def check(schema: JsonSchema): Option[SchemaError] = ???\n\n  /**\n   * Returns `true` if this JSON conforms to the given [[JsonSchema]].\n   */\n  def conforms(schema: JsonSchema): scala.Boolean = check(schema).isEmpty\n\n  // ===========================================================================\n  // KV Representation\n  // ===========================================================================\n\n  /**\n   * Flattens this JSON to a sequence of path-value pairs.\n   *\n   * Only leaf values (primitives, empty arrays, empty objects) are included.\n   *\n   * {{{\n   * Json.parse(\"\"\"{\"a\": {\"b\": 1}, \"c\": [2, 3]}\"\"\").toKV\n   * // Seq(\n   * //   (p\"a.b\", Json.Number(\"1\")),\n   * //   (p\"c[0]\", Json.Number(\"2\")),\n   * //   (p\"c[1]\", Json.Number(\"3\"))\n   * // )\n   * }}}\n   */\n  def toKV: Seq[(DynamicOptic, Json)] = ???\n\n  // ===========================================================================\n  // Comparison\n  // ===========================================================================\n\n  /**\n   * Compares this JSON to another for ordering.\n   *\n   * Ordering is defined as:\n   *  1. Null < Boolean < Number < String < Array < Object\n   *  2. Within types, natural ordering applies\n   */\n  def compare(that: Json): Int = (self, that) match {\n    case (Json.Null, Json.Null)               => 0\n    case (Json.Null, _)                       => -1\n    case (_, Json.Null)                       => 1\n    case (Json.Boolean(a), Json.Boolean(b))   => a.compare(b)\n    case (Json.Boolean(_), _)                 => -1\n    case (_, Json.Boolean(_))                 => 1\n    case (Json.Number(a), Json.Number(b))     => BigDecimal(a).compare(BigDecimal(b))\n    case (Json.Number(_), _)                  => -1\n    case (_, Json.Number(_))                  => 1\n    case (Json.String(a), Json.String(b))     => a.compare(b)\n    case (Json.String(_), _)                  => -1\n    case (_, Json.String(_))                  => 1\n    case (Json.Array(a), Json.Array(b))       => compareArrays(a, b)\n    case (Json.Array(_), _)                   => -1\n    case (_, Json.Array(_))                   => 1\n    case (Json.Object(a), Json.Object(b))     => compareObjects(a, b)\n  }\n\n  private def compareArrays(a: Vector[Json], b: Vector[Json]): Int = {\n    val len = math.min(a.size, b.size)\n    var i   = 0\n    while (i < len) {\n      val cmp = a(i).compare(b(i))\n      if (cmp != 0) return cmp\n      i += 1\n    }\n    a.size.compare(b.size)\n  }\n\n  private def compareObjects(a: Vector[(String, Json)], b: Vector[(String, Json)]): Int = {\n    val aSorted = a.sortBy(_._1)\n    val bSorted = b.sortBy(_._1)\n    val len     = math.min(aSorted.size, bSorted.size)\n    var i       = 0\n    while (i < len) {\n      val (ak, av) = aSorted(i)\n      val (bk, bv) = bSorted(i)\n      val keyCmp   = ak.compare(bk)\n      if (keyCmp != 0) return keyCmp\n      val valCmp = av.compare(bv)\n      if (valCmp != 0) return valCmp\n      i += 1\n    }\n    aSorted.size.compare(bSorted.size)\n  }\n\n  // ===========================================================================\n  // DynamicValue Interop\n  // ===========================================================================\n\n  /**\n   * Converts this JSON to a [[DynamicValue]].\n   *\n   * This conversion is lossless; all JSON values can be represented as DynamicValue.\n   */\n  def toDynamicValue: DynamicValue = self match {\n    case Json.Null =>\n      DynamicValue.Primitive(PrimitiveValue.Unit)\n    case Json.Boolean(v) =>\n      DynamicValue.Primitive(PrimitiveValue.Boolean(v))\n    case Json.Number(v) =>\n      // Preserve as BigDecimal for maximum precision\n      DynamicValue.Primitive(PrimitiveValue.BigDecimal(BigDecimal(v)))\n    case Json.String(v) =>\n      DynamicValue.Primitive(PrimitiveValue.String(v))\n    case Json.Array(elems) =>\n      DynamicValue.Sequence(elems.map(_.toDynamicValue))\n    case Json.Object(flds) =>\n      DynamicValue.Record(flds.map { case (k, v) => (k, v.toDynamicValue) })\n  }\n\n  // ===========================================================================\n  // Typed Decoding (Json => A)\n  // ===========================================================================\n\n  /**\n   * Decodes this JSON to a typed value.\n   *\n   * Uses implicit [[JsonDecoder]] which prefers explicit codecs over schema derivation.\n   *\n   * {{{\n   * val person: Either[JsonError, Person] = json.as[Person]\n   * }}}\n   *\n   * @tparam A The target type\n   * @return Either an error or the decoded value\n   */\n  def as[A](implicit decoder: JsonDecoder[A]): Either[JsonError, A] = decoder.decode(self)\n\n  /**\n   * Decodes this JSON to a typed value, throwing on failure.\n   *\n   * @tparam A The target type\n   * @return The decoded value\n   * @throws JsonError if decoding fails\n   */\n  def asUnsafe[A](implicit decoder: JsonDecoder[A]): A = as[A].fold(throw _, identity)\n\n  /**\n   * Internal: decode using an explicit codec.\n   */\n  private[json] def decodeWith[A](codec: JsonBinaryCodec[A]): Either[JsonError, A] = ???\n\n  // ===========================================================================\n  // Encoding (Json => String/Bytes)\n  // ===========================================================================\n\n  /**\n   * Encodes this JSON to a compact string (no extra whitespace).\n   */\n  def print: String = encode(WriterConfig)\n\n  /**\n   * Encodes this JSON to a string using the specified configuration.\n   *\n   * @param config Writer configuration (indentation, unicode escaping, etc.)\n   */\n  def print(config: WriterConfig): String = encode(config)\n\n  /**\n   * Alias for [[print]].\n   */\n  def encode: String = encode(WriterConfig)\n\n  /**\n   * Encodes this JSON to a string using the specified configuration.\n   *\n   * @param config Writer configuration\n   */\n  def encode(config: WriterConfig): String = ???\n\n  /**\n   * Encodes this JSON and writes to the provided [[Writer]].\n   *\n   * @param writer The writer to write to\n   */\n  def printTo(writer: Writer): Unit = printTo(writer, WriterConfig)\n\n  /**\n   * Encodes this JSON and writes to the provided [[Writer]] with configuration.\n   *\n   * @param writer The writer to write to\n   * @param config Writer configuration\n   */\n  def printTo(writer: Writer, config: WriterConfig): Unit = ???\n\n  /**\n   * Encodes this JSON to a byte array (UTF-8).\n   */\n  def encodeToBytes: Array[Byte] = encodeToBytes(WriterConfig)\n\n  /**\n   * Encodes this JSON to a byte array (UTF-8) with configuration.\n   *\n   * @param config Writer configuration\n   */\n  def encodeToBytes(config: WriterConfig): Array[Byte] = ???\n\n  /**\n   * Encodes this JSON to a [[Chunk]] of bytes (UTF-8).\n   */\n  def encodeToChunk: Chunk[Byte] = encodeToChunk(WriterConfig)\n\n  /**\n   * Encodes this JSON to a [[Chunk]] of bytes (UTF-8) with configuration.\n   *\n   * @param config Writer configuration\n   */\n  def encodeToChunk(config: WriterConfig): Chunk[Byte] = ???\n\n  /**\n   * Encodes this JSON into the provided [[ByteBuffer]].\n   *\n   * @param buffer The buffer to write to\n   */\n  def encodeTo(buffer: ByteBuffer): Unit = encodeTo(buffer, WriterConfig)\n\n  /**\n   * Encodes this JSON into the provided [[ByteBuffer]] with configuration.\n   *\n   * @param buffer The buffer to write to\n   * @param config Writer configuration\n   */\n  def encodeTo(buffer: ByteBuffer, config: WriterConfig): Unit = ???\n\n  // ===========================================================================\n  // Standard Methods\n  // ===========================================================================\n\n  override def hashCode(): Int = self match {\n    case Json.Null           => 0\n    case Json.Boolean(v)     => v.hashCode()\n    case Json.Number(v)      => BigDecimal(v).hashCode()\n    case Json.String(v)      => v.hashCode()\n    case Json.Array(elems)   => elems.hashCode()\n    case Json.Object(flds)   => flds.sortBy(_._1).hashCode()\n  }\n\n  override def equals(that: Any): Boolean = that match {\n    case other: Json => compare(other) == 0\n    case _           => false\n  }\n\n  override def toString: String = print\n}\n\nobject Json {\n\n  // ===========================================================================\n  // ADT Cases\n  // ===========================================================================\n\n  /**\n   * A JSON object: an unordered collection of key-value pairs.\n   *\n   * @param fields The key-value pairs. Keys should be unique; if duplicates\n   *               are present, behavior of accessors is undefined.\n   */\n  final case class Object(fields: Vector[(String, Json)]) extends Json {\n    override def isObject: scala.Boolean                = true\n    override def fields: Seq[(String, Json)]            = fields\n  }\n\n  object Object {\n\n    /**\n     * Creates an empty JSON object.\n     */\n    val empty: Object = Object(Vector.empty)\n\n    /**\n     * Creates a JSON object from key-value pairs.\n     */\n    def apply(fields: (String, Json)*): Object = Object(fields.toVector)\n  }\n\n  /**\n   * A JSON array: an ordered sequence of values.\n   *\n   * @param elements The array elements\n   */\n  final case class Array(elements: Vector[Json]) extends Json {\n    override def isArray: scala.Boolean  = true\n    override def elements: Seq[Json]     = elements\n  }\n\n  object Array {\n\n    /**\n     * Creates an empty JSON array.\n     */\n    val empty: Array = Array(Vector.empty)\n\n    /**\n     * Creates a JSON array from elements.\n     */\n    def apply(elements: Json*): Array = Array(elements.toVector)\n  }\n\n  /**\n   * A JSON string.\n   *\n   * @param value The string value (unescaped)\n   */\n  final case class String(value: java.lang.String) extends Json {\n    override def isString: scala.Boolean              = true\n    override def stringValue: Option[java.lang.String] = Some(value)\n  }\n\n  /**\n   * A JSON number.\n   *\n   * Stored as a string to preserve exact representation (precision, trailing zeros, etc.).\n   * Provides lazy conversion to numeric types.\n   *\n   * @param value The number as a string (should be valid JSON number syntax)\n   */\n  final case class Number(value: java.lang.String) extends Json {\n    override def isNumber: scala.Boolean                = true\n    override def numberValue: Option[java.lang.String]  = Some(value)\n\n    /**\n     * Converts to `Int`, truncating if necessary.\n     */\n    lazy val toInt: Int = toBigDecimal.toInt\n\n    /**\n     * Converts to `Long`, truncating if necessary.\n     */\n    lazy val toLong: Long = toBigDecimal.toLong\n\n    /**\n     * Converts to `Float`.\n     */\n    lazy val toFloat: Float = value.toFloat\n\n    /**\n     * Converts to `Double`.\n     */\n    lazy val toDouble: Double = value.toDouble\n\n    /**\n     * Converts to `BigInt`, truncating fractional part.\n     */\n    lazy val toBigInt: BigInt = toBigDecimal.toBigInt\n\n    /**\n     * Converts to `BigDecimal` (lossless).\n     */\n    lazy val toBigDecimal: BigDecimal = BigDecimal(value)\n  }\n\n  /**\n   * A JSON boolean.\n   *\n   * @param value The boolean value\n   */\n  final case class Boolean(value: scala.Boolean) extends Json {\n    override def isBoolean: scala.Boolean              = true\n    override def booleanValue: Option[scala.Boolean]   = Some(value)\n  }\n\n  object Boolean {\n    val True: Boolean  = Boolean(true)\n    val False: Boolean = Boolean(false)\n  }\n\n  /**\n   * The JSON null value.\n   */\n  case object Null extends Json {\n    override def isNull: scala.Boolean = true\n  }\n\n  // ===========================================================================\n  // Convenience Constructors\n  // ===========================================================================\n\n  /**\n   * Creates a JSON number from an `Int`.\n   */\n  def number(n: Int): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Long`.\n   */\n  def number(n: Long): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Float`.\n   */\n  def number(n: Float): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Double`.\n   */\n  def number(n: Double): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `BigInt`.\n   */\n  def number(n: BigInt): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `BigDecimal`.\n   */\n  def number(n: BigDecimal): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Short`.\n   */\n  def number(n: Short): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Byte`.\n   */\n  def number(n: Byte): Number = Number(n.toString)\n\n  // ===========================================================================\n  // Parsing / Decoding (String/Bytes => Json)\n  // ===========================================================================\n\n  /**\n   * Parses a JSON value from a string.\n   *\n   * @param s The JSON string\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(s: java.lang.String): Either[JsonError, Json] = decode(s)\n\n  /**\n   * Parses a JSON value from a `CharSequence`.\n   *\n   * @param s The JSON character sequence\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(s: CharSequence): Either[JsonError, Json] = decode(s)\n\n  /**\n   * Parses a JSON value from a byte array (UTF-8).\n   *\n   * @param bytes The JSON bytes\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(bytes: scala.Array[Byte]): Either[JsonError, Json] = decode(bytes)\n\n  /**\n   * Parses a JSON value from a [[Chunk]] of bytes (UTF-8).\n   *\n   * @param chunk The JSON bytes\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(chunk: Chunk[Byte]): Either[JsonError, Json] = decode(chunk)\n\n  /**\n   * Parses a JSON value from a [[ByteBuffer]] (UTF-8).\n   *\n   * @param buffer The JSON bytes\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(buffer: ByteBuffer): Either[JsonError, Json] = decode(buffer)\n\n  /**\n   * Parses a JSON value from a [[Reader]].\n   *\n   * @param reader The reader to read from\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(reader: Reader): Either[JsonError, Json] = decode(reader)\n\n  /**\n   * Decodes a JSON value from a string.\n   */\n  def decode(s: java.lang.String): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a `CharSequence`.\n   */\n  def decode(s: CharSequence): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a byte array (UTF-8).\n   */\n  def decode(bytes: scala.Array[Byte]): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a [[Chunk]] of bytes (UTF-8).\n   */\n  def decode(chunk: Chunk[Byte]): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a [[ByteBuffer]] (UTF-8).\n   */\n  def decode(buffer: ByteBuffer): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a [[Reader]].\n   */\n  def decode(reader: Reader): Either[JsonError, Json] = ???\n\n  /**\n   * Parses a JSON value from a string, throwing on failure.\n   *\n   * @param s The JSON string\n   * @return The parsed JSON\n   * @throws JsonError if parsing fails\n   */\n  def parseUnsafe(s: java.lang.String): Json = decode(s).fold(throw _, identity)\n\n  /**\n   * Alias for [[parseUnsafe]].\n   */\n  def decodeUnsafe(s: java.lang.String): Json = parseUnsafe(s)\n\n  // ===========================================================================\n  // Typed Encoding (A => Json)\n  // ===========================================================================\n\n  /**\n   * Encodes a typed value to JSON.\n   *\n   * Uses implicit [[JsonEncoder]] which prefers explicit codecs over schema derivation.\n   *\n   * {{{\n   * val json = Json.from(Person(\"Alice\", 30))\n   * }}}\n   *\n   * @param value The value to encode\n   * @return The encoded JSON\n   */\n  def from[A](value: A)(implicit encoder: JsonEncoder[A]): Json = encoder.encode(value)\n\n  /**\n   * Internal: encode using an explicit codec.\n   */\n  private[json] def encodeWith[A](value: A, codec: JsonBinaryCodec[A]): Json = ???\n\n  // ===========================================================================\n  // DynamicValue Interop\n  // ===========================================================================\n\n  /**\n   * Converts a [[DynamicValue]] to JSON.\n   *\n   * This conversion is lossy for `DynamicValue` types that have no JSON equivalent:\n   *  - `PrimitiveValue` types like `java.time.*` are converted to strings\n   *  - `DynamicValue.Variant` uses a discriminator field\n   *\n   * @param value The dynamic value to convert\n   * @return The JSON representation\n   */\n  def fromDynamicValue(value: DynamicValue): Json = value match {\n    case DynamicValue.Primitive(pv) => fromPrimitiveValue(pv)\n    case DynamicValue.Record(flds) =>\n      Object(flds.map { case (k, v) => (k, fromDynamicValue(v)) })\n    case DynamicValue.Variant(caseName, v) =>\n      Object(Vector(\"_type\" -> String(caseName), \"_value\" -> fromDynamicValue(v)))\n    case DynamicValue.Sequence(elems) =>\n      Array(elems.map(fromDynamicValue))\n    case DynamicValue.Map(entries) =>\n      Array(entries.map { case (k, v) =>\n        Object(Vector(\"key\" -> fromDynamicValue(k), \"value\" -> fromDynamicValue(v)))\n      })\n  }\n\n  private def fromPrimitiveValue(pv: PrimitiveValue): Json = pv match {\n    case PrimitiveValue.Unit              => Null\n    case PrimitiveValue.Boolean(v)        => Boolean(v)\n    case PrimitiveValue.Byte(v)           => number(v)\n    case PrimitiveValue.Short(v)          => number(v)\n    case PrimitiveValue.Int(v)            => number(v)\n    case PrimitiveValue.Long(v)           => number(v)\n    case PrimitiveValue.Float(v)          => number(v)\n    case PrimitiveValue.Double(v)         => number(v)\n    case PrimitiveValue.Char(v)           => String(v.toString)\n    case PrimitiveValue.String(v)         => String(v)\n    case PrimitiveValue.BigInt(v)         => number(v)\n    case PrimitiveValue.BigDecimal(v)     => number(v)\n    case PrimitiveValue.DayOfWeek(v)      => String(v.toString)\n    case PrimitiveValue.Duration(v)       => String(v.toString)\n    case PrimitiveValue.Instant(v)        => String(v.toString)\n    case PrimitiveValue.LocalDate(v)      => String(v.toString)\n    case PrimitiveValue.LocalDateTime(v)  => String(v.toString)\n    case PrimitiveValue.LocalTime(v)      => String(v.toString)\n    case PrimitiveValue.Month(v)          => String(v.toString)\n    case PrimitiveValue.MonthDay(v)       => String(v.toString)\n    case PrimitiveValue.OffsetDateTime(v) => String(v.toString)\n    case PrimitiveValue.OffsetTime(v)     => String(v.toString)\n    case PrimitiveValue.Period(v)         => String(v.toString)\n    case PrimitiveValue.Year(v)           => String(v.toString)\n    case PrimitiveValue.YearMonth(v)      => String(v.toString)\n    case PrimitiveValue.ZoneId(v)         => String(v.getId)\n    case PrimitiveValue.ZoneOffset(v)     => String(v.toString)\n    case PrimitiveValue.ZonedDateTime(v)  => String(v.toString)\n    case PrimitiveValue.Currency(v)       => String(v.getCurrencyCode)\n    case PrimitiveValue.UUID(v)           => String(v.toString)\n  }\n\n  // ===========================================================================\n  // KV Interop\n  // ===========================================================================\n\n  /**\n   * Assembles JSON from a sequence of path-value pairs.\n   *\n   * {{{\n   * Json.fromKV(Seq(\n   *   p\"a.b\" -> Json.number(1),\n   *   p\"a.c\" -> Json.String(\"x\"),\n   *   p\"d[0]\" -> Json.Boolean(true)\n   * ))\n   * // {\"a\": {\"b\": 1, \"c\": \"x\"}, \"d\": [true]}\n   * }}}\n   *\n   * @param kvs The path-value pairs\n   * @return Either an error (for conflicting paths) or the assembled JSON\n   */\n  def fromKV(kvs: Seq[(DynamicOptic, Json)]): Either[JsonError, Json] = ???\n\n  /**\n   * Assembles JSON from path-value pairs, throwing on conflict.\n   */\n  def fromKVUnsafe(kvs: Seq[(DynamicOptic, Json)]): Json = fromKV(kvs).fold(throw _, identity)\n\n  // ===========================================================================\n  // Patch Interop\n  // ===========================================================================\n\n  /**\n   * Serializes a [[JsonPatch]] to its JSON representation.\n   *\n   * The format follows RFC 6902 (JSON Patch) for standard operations,\n   * with extensions for LCS-based sequence diffs.\n   *\n   * @param patch The patch to serialize\n   * @return The JSON representation of the patch\n   */\n  def fromJsonPatch(patch: JsonPatch): Json = ???\n\n  /**\n   * Deserializes a JSON representation into a [[JsonPatch]].\n   *\n   * @param json The JSON patch representation\n   * @return Either an error or the parsed patch\n   */\n  def toJsonPatch(json: Json): Either[JsonError, JsonPatch] = ???\n\n  // ===========================================================================\n  // Ordering\n  // ===========================================================================\n\n  /**\n   * Ordering for JSON values.\n   *\n   * Order: Null < Boolean < Number < String < Array < Object\n   */\n  implicit val ordering: Ordering[Json] = (x: Json, y: Json) => x.compare(y)\n}\n\n// =============================================================================\n// MERGE STRATEGY\n// =============================================================================\n\n/**\n * Strategy for merging JSON values.\n */\nsealed trait MergeStrategy\n\nobject MergeStrategy {\n\n  /**\n   * Automatically determines merge behavior based on value types:\n   *  - Objects: deep merge (recurse into matching keys)\n   *  - Arrays: concatenate\n   *  - Primitives: right wins\n   */\n  case object Auto extends MergeStrategy\n\n  /**\n   * Deep merge for objects; concatenate arrays.\n   */\n  case object Deep extends MergeStrategy\n\n  /**\n   * Shallow merge: right value wins for any key conflict.\n   */\n  case object Shallow extends MergeStrategy\n\n  /**\n   * Concatenate arrays; for objects and primitives, right wins.\n   */\n  case object Concat extends MergeStrategy\n\n  /**\n   * Right value always wins (replacement).\n   */\n  case object Replace extends MergeStrategy\n\n  /**\n   * Custom merge function.\n   *\n   * @param f A function receiving path and both values, returning merged result\n   */\n  final case class Custom(f: (DynamicOptic, Json, Json) => Json) extends MergeStrategy\n}\n\n// =============================================================================\n// STRING INTERPOLATORS\n// =============================================================================\n\n/**\n * Provides string interpolators for JSON paths and literals.\n *\n * Import with:\n * {{{\n * import zio.blocks.schema.json.interpolators._\n * }}}\n *\n * ==Path Syntax==\n *\n * The `p` interpolator creates [[DynamicOptic]] paths using a JSONPath-compatible dialect:\n *\n * {{{\n * p\"foo.bar\"           // fields \"foo\" then \"bar\"\n * p\"users[0]\"          // field \"users\", then index 0\n * p\"users[0].name\"     // field \"users\", index 0, field \"name\"\n * p\"items[*]\"          // field \"items\", then all array elements\n * p\"config{*}\"         // field \"config\", then all object values\n * p\"config{*:}\"        // field \"config\", then all object keys\n * p\"[0,2,5]\"           // indices 0, 2, and 5\n * p\"[0:5]\"             // slice: indices 0 through 4\n * p\"[::2]\"             // slice: every other element\n * p\"`field.name`\"      // field with dots in name (backtick escaping)\n * p\"\"\"[\"field\"]\"\"\"     // alternate field syntax (bracket notation)\n * }}}\n *\n * ===JSONPath Compatibility===\n *\n * This syntax is a dialect of JSONPath (RFC 9535). Most JSONPath expressions work:\n *  - `$.foo.bar` - root prefix is optional and ignored\n *  - `.field`, `[\"field\"]` - field access\n *  - `[n]`, `[*]`, `[m,n]`, `[m:n]` - array access\n *\n * '''Not supported:'''\n *  - `..` (recursive descent)\n *  - `[?()]` (filter expressions)\n *\n * ===Extensions beyond JSONPath:===\n *  - `{*}` - all object values (explicit, vs `[*]` which is array-focused in JSONPath)\n *  - `{*:}` - all object keys (not expressible in standard JSONPath)\n *  - Backtick escaping for field names\n */\nobject interpolators {\n\n  implicit class JsonPathInterpolator(val sc: StringContext) extends AnyVal {\n\n    /**\n     * Creates a [[DynamicOptic]] from a path string at compile time.\n     *\n     * @return The parsed [[DynamicOptic]]\n     */\n    def p(args: Any*): DynamicOptic = macro PathMacros.pathInterpolator\n  }\n\n  implicit class JsonLiteralInterpolator(val sc: StringContext) extends AnyVal {\n\n    /**\n     * Creates a [[Json]] value from a JSON literal at compile time.\n     *\n     * {{{\n     * j\"\"\"{\"name\": \"Alice\", \"age\": 30}\"\"\"\n     * j\"[1, 2, 3]\"\n     * j\"null\"\n     * }}}\n     *\n     * Interpolated values are converted to JSON:\n     * {{{\n     * val name = \"Bob\"\n     * val age = 25\n     * j\"\"\"{\"name\": $name, \"age\": $age}\"\"\"\n     * }}}\n     *\n     * @return The parsed [[Json]] value\n     */\n    def j(args: Any*): Json = macro PathMacros.jsonInterpolator\n  }\n}\n\n/**\n * Macro implementations for string interpolators.\n * \n * Separate implementations would be needed for Scala 2 and Scala 3.\n */\nobject PathMacros {\n  import scala.reflect.macros.blackbox\n\n  def pathInterpolator(c: blackbox.Context)(args: c.Expr[Any]*): c.Expr[DynamicOptic] = ???\n\n  def jsonInterpolator(c: blackbox.Context)(args: c.Expr[Any]*): c.Expr[Json] = ???\n}\n\n// =============================================================================\n// PLACEHOLDER TYPES (assumed to exist)\n// =============================================================================\n\n/**\n * Represents a JSON Schema for validation.\n *\n * Placeholder - actual implementation TBD.\n */\nsealed trait JsonSchema\n\nobject JsonSchema {\n  // Placeholder\n}\n\n/**\n * Represents a patch that can be applied to JSON values.\n *\n * Supports RFC 6902 operations (add, remove, replace, move, copy, test)\n * plus extensions for LCS-based sequence diffs and string diffs.\n *\n * Placeholder - actual implementation TBD.\n */\nsealed trait JsonPatch {\n\n  /**\n   * Converts this JSON patch to a [[DynamicPatch]].\n   */\n  def toDynamicPatch: DynamicPatch\n}\n\nobject JsonPatch {\n\n  /**\n   * Creates an empty patch (no operations).\n   */\n  val empty: JsonPatch = ???\n\n  /**\n   * Creates a patch from a [[DynamicPatch]].\n   *\n   * May fail if the DynamicPatch contains operations not representable in JSON.\n   */\n  def fromDynamicPatch(patch: DynamicPatch): Either[JsonError, JsonPatch] = ???\n}\n\n/**\n * Represents a patch that can be applied to [[DynamicValue]].\n *\n * Placeholder - actual implementation TBD.\n */\nsealed trait DynamicPatch\n\nobject DynamicPatch {\n\n  /**\n   * Creates an empty patch (no operations).\n   */\n  val empty: DynamicPatch = ???\n}\n```",
                  "html_url": "https://github.com/zio/zio-blocks/issues/679"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#679",
              "body": "The following is a sketch of what a proper `Json` data type should look like, including constructors, methods, and related types. Note that `DynamicPatch`, `JsonPatch`, and `JsonSchema` are all out-of-scope for this ticket.\n\n## Sketch\n\n```scala\npackage zio.blocks.schema.json\n\nimport zio.blocks.chunk.Chunk\nimport zio.blocks.schema.{DynamicOptic, DynamicValue, PrimitiveValue, Schema, SchemaError}\n\nimport java.io.{Reader, Writer}\nimport java.nio.ByteBuffer\nimport scala.util.control.NoStackTrace\n\n// =============================================================================\n// JSON ERROR\n// =============================================================================\n\n/**\n * Represents an error that occurred during JSON parsing, encoding, or processing.\n *\n * NOTE: This should replace JsonBinaryCodecError and be moved to `zio.block.schema.json`.\n *\n * @param message A human-readable description of the error\n * @param path The location in the JSON structure where the error occurred,\n *             represented as a [[DynamicOptic]]\n * @param offset Optional byte offset in the input where the error occurred\n * @param line Optional 1-indexed line number where the error occurred\n * @param column Optional 1-indexed column number where the error occurred\n */\nfinal case class JsonError(\n  message: String,\n  path: DynamicOptic,\n  offset: Option[Long],\n  line: Option[Int],\n  column: Option[Int]\n) extends Exception with NoStackTrace {\n\n  override def getMessage: String = {\n    val posInfo = (line, column) match {\n      case (Some(l), Some(c)) => s\" at line $l, column $c\"\n      case _                  => offset.map(o => s\" at offset $o\").getOrElse(\"\")\n    }\n    val pathInfo = if (path.nodes.isEmpty) \"\" else s\" at path $path\"\n    s\"$message$pathInfo$posInfo\"\n  }\n\n  /**\n   * Combines this error with another, preserving both error messages.\n   */\n  def ++(other: JsonError): JsonError =\n    JsonError(s\"${this.message}; ${other.message}\", this.path, this.offset, this.line, this.column)\n}\n\nobject JsonError {\n\n  /**\n   * Creates a JsonError with only a message, using root path and no position info.\n   */\n  def apply(message: String): JsonError =\n    JsonError(message, DynamicOptic.root, None, None, None)\n\n  /**\n   * Creates a JsonError with a message and path, no position info.\n   */\n  def apply(message: String, path: DynamicOptic): JsonError =\n    JsonError(message, path, None, None, None)\n\n  /**\n   * Converts a [[SchemaError]] to a [[JsonError]].\n   */\n  def fromSchemaError(error: SchemaError): JsonError =\n    JsonError(error.message, DynamicOptic.root, None, None, None)\n}\n\n// =============================================================================\n// JSON DECODER / ENCODER (implicit priority resolution)\n// =============================================================================\n\n/**\n * Type class for decoding [[Json]] values into Scala types.\n *\n * Implicit resolution prefers explicitly provided [[JsonBinaryCodec]] instances\n * over schema-derived instances, allowing users to override derived behavior.\n */\nsealed trait JsonDecoder[A] {\n\n  /**\n   * Decodes a [[Json]] value into type `A`.\n   *\n   * @param json The JSON value to decode\n   * @return Either a [[JsonError]] on failure, or the decoded value\n   */\n  def decode(json: Json): Either[JsonError, A]\n}\n\nobject JsonDecoder extends JsonDecoderLowPriority {\n\n  def apply[A](implicit decoder: JsonDecoder[A]): JsonDecoder[A] = decoder\n\n  /**\n   * Higher priority: use an explicitly provided [[JsonBinaryCodec]].\n   */\n  implicit def fromCodec[A](implicit codec: JsonBinaryCodec[A]): JsonDecoder[A] =\n    new JsonDecoder[A] {\n      def decode(json: Json): Either[JsonError, A] = json.decodeWith(codec)\n    }\n}\n\n/**\n * Lower priority implicits for [[JsonDecoder]].\n */\ntrait JsonDecoderLowPriority {\n\n  /**\n   * Lower priority: derive a codec from an implicit [[Schema]].\n   */\n  implicit def fromSchema[A](implicit schema: Schema[A]): JsonDecoder[A] =\n    new JsonDecoder[A] {\n      private lazy val codec: JsonBinaryCodec[A] = schema.derive(JsonBinaryCodecDeriver)\n      def decode(json: Json): Either[JsonError, A] = json.decodeWith(codec)\n    }\n}\n\n/**\n * Type class for encoding Scala types into [[Json]] values.\n *\n * Implicit resolution prefers explicitly provided [[JsonBinaryCodec]] instances\n * over schema-derived instances, allowing users to override derived behavior.\n */\nsealed trait JsonEncoder[A] {\n\n  /**\n   * Encodes a value of type `A` into [[Json]].\n   *\n   * @param value The value to encode\n   * @return The encoded JSON value\n   */\n  def encode(value: A): Json\n}\n\nobject JsonEncoder extends JsonEncoderLowPriority {\n\n  def apply[A](implicit encoder: JsonEncoder[A]): JsonEncoder[A] = encoder\n\n  /**\n   * Higher priority: use an explicitly provided [[JsonBinaryCodec]].\n   */\n  implicit def fromCodec[A](implicit codec: JsonBinaryCodec[A]): JsonEncoder[A] =\n    new JsonEncoder[A] {\n      def encode(value: A): Json = Json.encodeWith(value, codec)\n    }\n}\n\n/**\n * Lower priority implicits for [[JsonEncoder]].\n */\ntrait JsonEncoderLowPriority {\n\n  /**\n   * Lower priority: derive a codec from an implicit [[Schema]].\n   */\n  implicit def fromSchema[A](implicit schema: Schema[A]): JsonEncoder[A] =\n    new JsonEncoder[A] {\n      private lazy val codec: JsonBinaryCodec[A] = schema.derive(JsonBinaryCodecDeriver)\n      def encode(value: A): Json = Json.encodeWith(value, codec)\n    }\n}\n\n// =============================================================================\n// JSON SELECTION\n// =============================================================================\n\n/**\n * Represents a selection of zero or more JSON values, with accumulated errors.\n *\n * `JsonSelection` enables fluent chaining of operations that may fail without\n * requiring immediate error handling. Operations are applied to all values in\n * the selection, and errors are accumulated.\n *\n * {{{\n * val selection: JsonSelection = json.get(p\"users[*].name\")\n * val result: Either[SchemaError, Vector[Json]] = selection.toEither\n * }}}\n */\nfinal case class JsonSelection(toEither: Either[SchemaError, Vector[Json]]) { self =>\n\n  /**\n   * Returns true if this selection contains no values (either empty or errored).\n   */\n  def isEmpty: Boolean = toEither.fold(_ => true, _.isEmpty)\n\n  /**\n   * Returns true if this selection contains at least one value.\n   */\n  def nonEmpty: Boolean = toEither.fold(_ => false, _.nonEmpty)\n\n  /**\n   * Returns the number of values in this selection, or 0 if errored.\n   */\n  def size: Int = toEither.fold(_ => 0, _.size)\n\n  // ---------------------------------------------------------------------------\n  // Transformations\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Applies a function to each JSON value in this selection.\n   *\n   * @param f The transformation function\n   * @return A new selection with transformed values\n   */\n  def map(f: Json => Json): JsonSelection =\n    JsonSelection(toEither.map(_.map(f)))\n\n  /**\n   * Applies a function returning a selection to each value, flattening results.\n   *\n   * @param f The function producing selections\n   * @return A new selection with all results combined\n   */\n  def flatMap(f: Json => JsonSelection): JsonSelection =\n    JsonSelection(toEither.flatMap { jsons =>\n      jsons.foldLeft[Either[SchemaError, Vector[Json]]](Right(Vector.empty)) { (acc, json) =>\n        for {\n          existing <- acc\n          next     <- f(json).toEither\n        } yield existing ++ next\n      }\n    })\n\n  /**\n   * Filters values in this selection by a predicate.\n   *\n   * @param p The predicate to test values\n   * @return A new selection containing only values satisfying the predicate\n   */\n  def filter(p: Json => Boolean): JsonSelection =\n    JsonSelection(toEither.map(_.filter(p)))\n\n  /**\n   * Collects values for which the partial function is defined.\n   *\n   * @param pf A partial function to apply\n   * @return A new selection with collected results\n   */\n  def collect(pf: PartialFunction[Json, Json]): JsonSelection =\n    JsonSelection(toEither.map(_.collect(pf)))\n\n  // ---------------------------------------------------------------------------\n  // Navigation\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Navigates to values at the given path within each selected value.\n   *\n   * @param path The path to navigate\n   * @return A new selection with values at the path\n   */\n  def get(path: DynamicOptic): JsonSelection =\n    flatMap(json => json.get(path))\n\n  /**\n   * Alias for [[get]].\n   */\n  def apply(path: DynamicOptic): JsonSelection = get(path)\n\n  /**\n   * Navigates to array element at given index within each selected value.\n   *\n   * @param index The array index\n   * @return A new selection with elements at the index\n   */\n  def apply(index: Int): JsonSelection =\n    flatMap(json => json.apply(index))\n\n  /**\n   * Navigates to object field with given key within each selected value.\n   *\n   * @param key The object key\n   * @return A new selection with values at the key\n   */\n  def apply(key: String): JsonSelection =\n    flatMap(json => json.apply(key))\n\n  // ---------------------------------------------------------------------------\n  // Type Filtering\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Filters to only JSON objects.\n   */\n  def objects: JsonSelection = filter(_.isObject)\n\n  /**\n   * Filters to only JSON arrays.\n   */\n  def arrays: JsonSelection = filter(_.isArray)\n\n  /**\n   * Filters to only JSON strings.\n   */\n  def strings: JsonSelection = filter(_.isString)\n\n  /**\n   * Filters to only JSON numbers.\n   */\n  def numbers: JsonSelection = filter(_.isNumber)\n\n  /**\n   * Filters to only JSON booleans.\n   */\n  def booleans: JsonSelection = filter(_.isBoolean)\n\n  /**\n   * Filters to only JSON nulls.\n   */\n  def nulls: JsonSelection = filter(_.isNull)\n\n  // ---------------------------------------------------------------------------\n  // Combination\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Combines this selection with another, concatenating values or errors.\n   *\n   * @param other The other selection\n   * @return A combined selection\n   */\n  def ++(other: JsonSelection): JsonSelection =\n    (toEither, other.toEither) match {\n      case (Right(a), Right(b)) => JsonSelection(Right(a ++ b))\n      case (Left(a), Left(b))   => JsonSelection(Left(a ++ b))\n      case (Left(a), _)         => JsonSelection(Left(a))\n      case (_, Left(b))         => JsonSelection(Left(b))\n    }\n\n  // ---------------------------------------------------------------------------\n  // Terminal Operations\n  // ---------------------------------------------------------------------------\n\n  /**\n   * Returns the single value if exactly one, an array of values if there are many, or \n   * otherwise an error.\n   */\n  def one: Either[SchemaError, Json] =\n    toEither.flatMap { jsons =>\n      if (jsons.size == 1) Right(jsons.head)\n      else if (jsons.size > 1) toArray\n      else Left(SchemaError.expectationMismatch(Nil, s\"expected exactly one value, got ${jsons.size}\"))\n    }\n\n  /**\n   * Returns the first value if any, otherwise an error.\n   */\n  def first: Either[SchemaError, Json] =\n    toEither.flatMap { jsons =>\n      jsons.headOption.toRight(SchemaError.expectationMismatch(Nil, \"expected at least one value, got none\"))\n    }\n\n  /**\n   * Returns all values as a [[Json.Array]], or an error.\n   */\n  def toArray: Either[SchemaError, Json] =\n    toEither.map(jsons => Json.Array(jsons))\n\n  /**\n   * Unsafe version of [[one]], throws on error or wrong count.\n   */\n  def oneUnsafe: Json = one.fold(e => throw JsonError.fromSchemaError(e), identity)\n\n  /**\n   * Unsafe version of [[first]], throws on error or empty.\n   */\n  def firstUnsafe: Json = first.fold(e => throw JsonError.fromSchemaError(e), identity)\n}\n\nobject JsonSelection {\n\n  /**\n   * Creates a selection containing a single value.\n   */\n  def apply(json: Json): JsonSelection = JsonSelection(Right(Vector(json)))\n\n  /**\n   * Creates a selection containing multiple values.\n   */\n  def fromVector(jsons: Vector[Json]): JsonSelection = JsonSelection(Right(jsons))\n\n  /**\n   * Creates an empty selection (no values, no error).\n   */\n  val empty: JsonSelection = JsonSelection(Right(Vector.empty))\n\n  /**\n   * Creates a failed selection with the given error.\n   */\n  def fail(error: SchemaError): JsonSelection = JsonSelection(Left(error))\n\n  /**\n   * Creates a failed selection with the given message.\n   */\n  def fail(message: String): JsonSelection =\n    JsonSelection(Left(SchemaError.expectationMismatch(Nil, message)))\n}\n\n// =============================================================================\n// JSON ADT\n// =============================================================================\n\n/**\n * Represents a JSON value.\n *\n * The JSON data model consists of:\n *  - '''Objects''': Unordered collections of key-value pairs\n *  - '''Arrays''': Ordered sequences of values\n *  - '''Strings''': Unicode text\n *  - '''Numbers''': Numeric values (stored as strings for precision)\n *  - '''Booleans''': `true` or `false`\n *  - '''Null''': The null value\n *\n * ==Construction==\n * {{{\n * val obj = Json.Object(\"name\" -> Json.String(\"Alice\"), \"age\" -> Json.number(30))\n * val arr = Json.Array(Json.String(\"a\"), Json.String(\"b\"))\n * val str = Json.String(\"hello\")\n * val num = Json.number(42)\n * val bool = Json.Boolean(true)\n * val nul = Json.Null\n * }}}\n *\n * ==Navigation==\n * {{{\n * json.get(p\"users[0].name\")   // JsonSelection\n * json(\"users\")(0)(\"name\")     // JsonSelection\n * json.fields                  // for objects\n * json.elements                // for arrays\n * }}}\n *\n * ==Pattern Matching==\n * {{{\n * json match {\n *   case Json.Object(fields) => ...\n *   case Json.Array(elements) => ...\n *   case Json.String(value) => ...\n *   case Json.Number(value) => ...\n *   case Json.Boolean(value) => ...\n *   case Json.Null => ...\n * }\n * }}}\n */\nsealed trait Json { self =>\n\n  // ===========================================================================\n  // Type Testing\n  // ===========================================================================\n\n  /**\n   * Returns `true` if this is a JSON object.\n   */\n  def isObject: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON array.\n   */\n  def isArray: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON string.\n   */\n  def isString: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON number.\n   */\n  def isNumber: Boolean = false\n\n  /**\n   * Returns `true` if this is a JSON boolean.\n   */\n  def isBoolean: Boolean = false\n\n  /**\n   * Returns `true` if this is JSON null.\n   */\n  def isNull: Boolean = false\n\n  // ===========================================================================\n  // Type Filtering (returns JsonSelection)\n  // ===========================================================================\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is an object,\n   * otherwise an empty selection.\n   */\n  def asObject: JsonSelection = if (isObject) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is an array,\n   * otherwise an empty selection.\n   */\n  def asArray: JsonSelection = if (isArray) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is a string,\n   * otherwise an empty selection.\n   */\n  def asString: JsonSelection = if (isString) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is a number,\n   * otherwise an empty selection.\n   */\n  def asNumber: JsonSelection = if (isNumber) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is a boolean,\n   * otherwise an empty selection.\n   */\n  def asBoolean: JsonSelection = if (isBoolean) JsonSelection(self) else JsonSelection.empty\n\n  /**\n   * Returns a [[JsonSelection]] containing this value if it is null,\n   * otherwise an empty selection.\n   */\n  def asNull: JsonSelection = if (isNull) JsonSelection(self) else JsonSelection.empty\n\n  // ===========================================================================\n  // Direct Accessors\n  // ===========================================================================\n\n  /**\n   * If this is an object, returns its fields as key-value pairs.\n   * Otherwise returns an empty sequence.\n   */\n  def fields: Seq[(String, Json)] = Seq.empty\n\n  /**\n   * If this is an array, returns its elements.\n   * Otherwise returns an empty sequence.\n   */\n  def elements: Seq[Json] = Seq.empty\n\n  /**\n   * If this is a string, returns its value.\n   * Otherwise returns `None`.\n   */\n  def stringValue: Option[String] = None\n\n  /**\n   * If this is a number, returns its string representation.\n   * Otherwise returns `None`.\n   */\n  def numberValue: Option[String] = None\n\n  /**\n   * If this is a boolean, returns its value.\n   * Otherwise returns `None`.\n   */\n  def booleanValue: Option[scala.Boolean] = None\n\n  // ===========================================================================\n  // Navigation\n  // ===========================================================================\n\n  /**\n   * Navigates to values at the given path.\n   *\n   * {{{\n   * json.get(p\"users[0].name\")\n   * json.get(DynamicOptic.root.field(\"users\").at(0).field(\"name\"))\n   * }}}\n   *\n   * @param path The path to navigate\n   * @return A [[JsonSelection]] containing values at the path\n   */\n  def get(path: DynamicOptic): JsonSelection = ???\n\n  /**\n   * Alias for [[get]].\n   */\n  def apply(path: DynamicOptic): JsonSelection = get(path)\n\n  /**\n   * If this is an array, returns a selection containing the element at the given index.\n   * Returns an empty selection if not an array or index is out of bounds.\n   *\n   * @param index The array index (0-based)\n   */\n  def apply(index: Int): JsonSelection = self match {\n    case Json.Array(elems) if index >= 0 && index < elems.size =>\n      JsonSelection(elems(index))\n    case _ =>\n      JsonSelection.empty\n  }\n\n  /**\n   * If this is an object, returns a selection containing the value at the given key.\n   * Returns an empty selection if not an object or key is not present.\n   *\n   * @param key The object key\n   */\n  def apply(key: String): JsonSelection = self match {\n    case Json.Object(flds) =>\n      flds.collectFirst { case (k, v) if k == key => v } match {\n        case Some(v) => JsonSelection(v)\n        case None    => JsonSelection.empty\n      }\n    case _ =>\n      JsonSelection.empty\n  }\n\n  // ===========================================================================\n  // Modification (Json => Json)\n  // ===========================================================================\n\n  /**\n   * Modifies values at the given path using the provided function.\n   *\n   * If the path does not exist, returns this JSON unchanged.\n   *\n   * {{{\n   * json.modify(p\"users[*].age\", {\n   *   case Json.Number(n) => Json.number(n.toInt + 1)\n   *   case other => other\n   * })\n   * }}}\n   *\n   * @param path The path to values to modify\n   * @param f The modification function\n   * @return The modified JSON\n   */\n  def modify(path: DynamicOptic, f: Json => Json): Json = ???\n\n  /**\n   * Modifies values at the given path using a partial function.\n   *\n   * Values for which the partial function is not defined are left unchanged.\n   *\n   * @param path The path to values to modify\n   * @param pf The partial modification function\n   * @return Either an error if the path is invalid, or the modified JSON\n   */\n  def modifyOrFail(path: DynamicOptic, pf: PartialFunction[Json, Json]): Either[JsonError, Json] = ???\n\n  /**\n   * Sets the value at the given path.\n   *\n   * If the path does not exist, attempts to create intermediate structure.\n   * For array indices, the array must already exist and have sufficient length.\n   *\n   * {{{\n   * json.set(p\"user.name\", Json.String(\"Bob\"))\n   * }}}\n   *\n   * @param path The path to set\n   * @param value The value to set\n   * @return The modified JSON\n   */\n  def set(path: DynamicOptic, value: Json): Json = ???\n\n  /**\n   * Sets the value at the given path, returning an error if the path is invalid.\n   *\n   * @param path The path to set\n   * @param value The value to set\n   * @return Either an error or the modified JSON\n   */\n  def setOrFail(path: DynamicOptic, value: Json): Either[JsonError, Json] = ???\n\n  /**\n   * Deletes values at the given path.\n   *\n   * For object fields, removes the key-value pair.\n   * For array elements, removes the element and shifts subsequent elements.\n   *\n   * @param path The path to delete\n   * @return The modified JSON\n   */\n  def delete(path: DynamicOptic): Json = ???\n\n  /**\n   * Deletes values at the given path, returning an error if the path is invalid.\n   *\n   * @param path The path to delete\n   * @return Either an error or the modified JSON\n   */\n  def deleteOrFail(path: DynamicOptic): Either[JsonError, Json] = ???\n\n  /**\n   * Inserts a value at the given path.\n   *\n   * For arrays, inserts at the specified index, shifting subsequent elements.\n   * For objects, adds or replaces the key.\n   *\n   * @param path The path where to insert\n   * @param value The value to insert\n   * @return The modified JSON\n   */\n  def insert(path: DynamicOptic, value: Json): Json = ???\n\n  /**\n   * Inserts a value at the given path, returning an error if invalid.\n   *\n   * @param path The path where to insert\n   * @param value The value to insert\n   * @return Either an error or the modified JSON\n   */\n  def insertOrFail(path: DynamicOptic, value: Json): Either[JsonError, Json] = ???\n\n  // ===========================================================================\n  // Merging\n  // ===========================================================================\n\n  /**\n   * Merges this JSON with another using the specified strategy.\n   *\n   * {{{\n   * val merged = json1.merge(json2, MergeStrategy.Deep)\n   * }}}\n   *\n   * @param other The JSON to merge with\n   * @param strategy The merge strategy (default: [[MergeStrategy.Auto]])\n   * @return The merged JSON\n   */\n  def merge(other: Json, strategy: MergeStrategy = MergeStrategy.Auto): Json = ???\n\n  // ===========================================================================\n  // Patching\n  // ===========================================================================\n\n  /**\n   * Applies a [[JsonPatch]] to this JSON.\n   *\n   * @param patch The patch to apply\n   * @return Either an error if the patch cannot be applied, or the patched JSON\n   */\n  def patch(patch: JsonPatch): Either[JsonError, Json] = ???\n\n  /**\n   * Applies a [[JsonPatch]], throwing on failure.\n   *\n   * @param patch The patch to apply\n   * @return The patched JSON\n   * @throws JsonError if the patch cannot be applied\n   */\n  def patchUnsafe(patch: JsonPatch): Json = this.patch(patch).fold(throw _, identity)\n\n  // ===========================================================================\n  // Transformation\n  // ===========================================================================\n\n  /**\n   * Transforms all values in this JSON bottom-up (children before parents).\n   *\n   * @param f The transformation function receiving path and value\n   * @return The transformed JSON\n   */\n  def transformUp(f: (DynamicOptic, Json) => Json): Json = ???\n\n  /**\n   * Transforms all values in this JSON top-down (parents before children).\n   *\n   * @param f The transformation function receiving path and value\n   * @return The transformed JSON\n   */\n  def transformDown(f: (DynamicOptic, Json) => Json): Json = ???\n\n  /**\n   * Transforms all object keys in this JSON.\n   *\n   * @param f The key transformation function receiving path and key\n   * @return The transformed JSON\n   */\n  def transformKeys(f: (DynamicOptic, String) => String): Json = ???\n\n  // ===========================================================================\n  // Filtering\n  // ===========================================================================\n\n  /**\n   * Removes entries matching the predicate.\n   *\n   * For objects, removes matching key-value pairs.\n   * For arrays, removes matching elements.\n   *\n   * @param p The predicate receiving path and value\n   * @return The filtered JSON\n   */\n  def filterNot(p: (DynamicOptic, Json) => scala.Boolean): Json = ???\n\n  /**\n   * Keeps only entries matching the predicate.\n   *\n   * @param p The predicate receiving path and value\n   * @return The filtered JSON\n   */\n  def filter(p: (DynamicOptic, Json) => scala.Boolean): Json =\n    filterNot((path, json) => !p(path, json))\n\n  // ===========================================================================\n  // Projection\n  // ===========================================================================\n\n  /**\n   * Projects this JSON to include only the specified paths.\n   *\n   * Paths that don't exist are ignored. Structure is preserved.\n   *\n   * {{{\n   * json.project(p\"user.name\", p\"user.email\", p\"meta.created\")\n   * }}}\n   *\n   * @param paths The paths to include\n   * @return A new JSON containing only the specified paths\n   */\n  def project(paths: DynamicOptic*): Json = ???\n\n  // ===========================================================================\n  // Splitting / Partitioning\n  // ===========================================================================\n\n  /**\n   * Partitions this JSON into two based on a predicate.\n   *\n   * Returns a tuple where the first element contains entries satisfying\n   * the predicate, and the second contains entries that don't.\n   *\n   * @param p The predicate receiving path and value\n   * @return A tuple of (matching, non-matching) JSON values\n   */\n  def partition(p: (DynamicOptic, Json) => scala.Boolean): (Json, Json) = ???\n\n  // ===========================================================================\n  // Normalization\n  // ===========================================================================\n\n  /**\n   * Returns a normalized version of this JSON.\n   *\n   * Normalization includes:\n   *  - Sorting object keys alphabetically\n   *  - Normalizing number representations\n   *\n   * Useful for comparison and hashing.\n   */\n  def normalize: Json = ???\n\n  /**\n   * Returns this JSON with all object keys sorted alphabetically (recursive).\n   */\n  def sortKeys: Json = self match {\n    case Json.Object(flds) =>\n      Json.Object(flds.map { case (k, v) => (k, v.sortKeys) }.sortBy(_._1))\n    case Json.Array(elems) =>\n      Json.Array(elems.map(_.sortKeys))\n    case other =>\n      other\n  }\n\n  /**\n   * Returns this JSON with all null values removed from objects.\n   */\n  def dropNulls: Json = self match {\n    case Json.Object(flds) =>\n      Json.Object(flds.collect { case (k, v) if !v.isNull => (k, v.dropNulls) })\n    case Json.Array(elems) =>\n      Json.Array(elems.map(_.dropNulls))\n    case other =>\n      other\n  }\n\n  /**\n   * Returns this JSON with empty objects and arrays removed.\n   */\n  def dropEmpty: Json = self match {\n    case Json.Object(flds) =>\n      val filtered = flds.collect {\n        case (k, v) =>\n          val dropped = v.dropEmpty\n          dropped match {\n            case Json.Object(f) if f.isEmpty => None\n            case Json.Array(e) if e.isEmpty  => None\n            case other                       => Some((k, other))\n          }\n      }.flatten\n      Json.Object(filtered)\n    case Json.Array(elems) =>\n      val filtered = elems.map(_.dropEmpty).filter {\n        case Json.Object(f) if f.isEmpty => false\n        case Json.Array(e) if e.isEmpty  => false\n        case _                           => true\n      }\n      Json.Array(filtered)\n    case other =>\n      other\n  }\n\n  // ===========================================================================\n  // Diffing\n  // ===========================================================================\n\n  /**\n   * Computes a [[JsonPatch]] that transforms this JSON into the target.\n   *\n   * {{{\n   * val patch = source.diff(target)\n   * source.patch(patch) == Right(target) // true\n   * }}}\n   *\n   * @param target The target JSON\n   * @return A patch that transforms this into target\n   */\n  def diff(target: Json): JsonPatch = ???\n\n  // ===========================================================================\n  // Folding\n  // ===========================================================================\n\n  /**\n   * Folds over this JSON top-down (parents before children).\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function receiving path, value, and accumulator\n   * @tparam B The accumulator type\n   * @return The final accumulated value\n   */\n  def foldDown[B](z: B)(f: (DynamicOptic, Json, B) => B): B = ???\n\n  /**\n   * Folds over this JSON bottom-up (children before parents).\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function receiving path, value, and accumulator\n   * @tparam B The accumulator type\n   * @return The final accumulated value\n   */\n  def foldUp[B](z: B)(f: (DynamicOptic, Json, B) => B): B = ???\n\n  /**\n   * Folds over this JSON top-down, allowing the fold function to fail.\n   *\n   * Short-circuits on first failure.\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function that may fail\n   * @tparam B The accumulator type\n   * @return Either an error or the final accumulated value\n   */\n  def foldDownOrFail[B](z: B)(f: (DynamicOptic, Json, B) => Either[JsonError, B]): Either[JsonError, B] = ???\n\n  /**\n   * Folds over this JSON bottom-up, allowing the fold function to fail.\n   *\n   * Short-circuits on first failure.\n   *\n   * @param z The initial accumulator value\n   * @param f The fold function that may fail\n   * @tparam B The accumulator type\n   * @return Either an error or the final accumulated value\n   */\n  def foldUpOrFail[B](z: B)(f: (DynamicOptic, Json, B) => Either[JsonError, B]): Either[JsonError, B] = ???\n\n  // ===========================================================================\n  // Querying\n  // ===========================================================================\n\n  /**\n   * Selects all values matching the predicate.\n   *\n   * @param p The predicate receiving path and value\n   * @return A [[JsonSelection]] containing matching values\n   */\n  def query(p: (DynamicOptic, Json) => scala.Boolean): JsonSelection = ???\n\n  // ===========================================================================\n  // Validation\n  // ===========================================================================\n\n  /**\n   * Validates this JSON against a [[JsonSchema]].\n   *\n   * @param schema The schema to validate against\n   * @return `None` if valid, `Some(error)` if invalid\n   */\n  def check(schema: JsonSchema): Option[SchemaError] = ???\n\n  /**\n   * Returns `true` if this JSON conforms to the given [[JsonSchema]].\n   */\n  def conforms(schema: JsonSchema): scala.Boolean = check(schema).isEmpty\n\n  // ===========================================================================\n  // KV Representation\n  // ===========================================================================\n\n  /**\n   * Flattens this JSON to a sequence of path-value pairs.\n   *\n   * Only leaf values (primitives, empty arrays, empty objects) are included.\n   *\n   * {{{\n   * Json.parse(\"\"\"{\"a\": {\"b\": 1}, \"c\": [2, 3]}\"\"\").toKV\n   * // Seq(\n   * //   (p\"a.b\", Json.Number(\"1\")),\n   * //   (p\"c[0]\", Json.Number(\"2\")),\n   * //   (p\"c[1]\", Json.Number(\"3\"))\n   * // )\n   * }}}\n   */\n  def toKV: Seq[(DynamicOptic, Json)] = ???\n\n  // ===========================================================================\n  // Comparison\n  // ===========================================================================\n\n  /**\n   * Compares this JSON to another for ordering.\n   *\n   * Ordering is defined as:\n   *  1. Null < Boolean < Number < String < Array < Object\n   *  2. Within types, natural ordering applies\n   */\n  def compare(that: Json): Int = (self, that) match {\n    case (Json.Null, Json.Null)               => 0\n    case (Json.Null, _)                       => -1\n    case (_, Json.Null)                       => 1\n    case (Json.Boolean(a), Json.Boolean(b))   => a.compare(b)\n    case (Json.Boolean(_), _)                 => -1\n    case (_, Json.Boolean(_))                 => 1\n    case (Json.Number(a), Json.Number(b))     => BigDecimal(a).compare(BigDecimal(b))\n    case (Json.Number(_), _)                  => -1\n    case (_, Json.Number(_))                  => 1\n    case (Json.String(a), Json.String(b))     => a.compare(b)\n    case (Json.String(_), _)                  => -1\n    case (_, Json.String(_))                  => 1\n    case (Json.Array(a), Json.Array(b))       => compareArrays(a, b)\n    case (Json.Array(_), _)                   => -1\n    case (_, Json.Array(_))                   => 1\n    case (Json.Object(a), Json.Object(b))     => compareObjects(a, b)\n  }\n\n  private def compareArrays(a: Vector[Json], b: Vector[Json]): Int = {\n    val len = math.min(a.size, b.size)\n    var i   = 0\n    while (i < len) {\n      val cmp = a(i).compare(b(i))\n      if (cmp != 0) return cmp\n      i += 1\n    }\n    a.size.compare(b.size)\n  }\n\n  private def compareObjects(a: Vector[(String, Json)], b: Vector[(String, Json)]): Int = {\n    val aSorted = a.sortBy(_._1)\n    val bSorted = b.sortBy(_._1)\n    val len     = math.min(aSorted.size, bSorted.size)\n    var i       = 0\n    while (i < len) {\n      val (ak, av) = aSorted(i)\n      val (bk, bv) = bSorted(i)\n      val keyCmp   = ak.compare(bk)\n      if (keyCmp != 0) return keyCmp\n      val valCmp = av.compare(bv)\n      if (valCmp != 0) return valCmp\n      i += 1\n    }\n    aSorted.size.compare(bSorted.size)\n  }\n\n  // ===========================================================================\n  // DynamicValue Interop\n  // ===========================================================================\n\n  /**\n   * Converts this JSON to a [[DynamicValue]].\n   *\n   * This conversion is lossless; all JSON values can be represented as DynamicValue.\n   */\n  def toDynamicValue: DynamicValue = self match {\n    case Json.Null =>\n      DynamicValue.Primitive(PrimitiveValue.Unit)\n    case Json.Boolean(v) =>\n      DynamicValue.Primitive(PrimitiveValue.Boolean(v))\n    case Json.Number(v) =>\n      // Preserve as BigDecimal for maximum precision\n      DynamicValue.Primitive(PrimitiveValue.BigDecimal(BigDecimal(v)))\n    case Json.String(v) =>\n      DynamicValue.Primitive(PrimitiveValue.String(v))\n    case Json.Array(elems) =>\n      DynamicValue.Sequence(elems.map(_.toDynamicValue))\n    case Json.Object(flds) =>\n      DynamicValue.Record(flds.map { case (k, v) => (k, v.toDynamicValue) })\n  }\n\n  // ===========================================================================\n  // Typed Decoding (Json => A)\n  // ===========================================================================\n\n  /**\n   * Decodes this JSON to a typed value.\n   *\n   * Uses implicit [[JsonDecoder]] which prefers explicit codecs over schema derivation.\n   *\n   * {{{\n   * val person: Either[JsonError, Person] = json.as[Person]\n   * }}}\n   *\n   * @tparam A The target type\n   * @return Either an error or the decoded value\n   */\n  def as[A](implicit decoder: JsonDecoder[A]): Either[JsonError, A] = decoder.decode(self)\n\n  /**\n   * Decodes this JSON to a typed value, throwing on failure.\n   *\n   * @tparam A The target type\n   * @return The decoded value\n   * @throws JsonError if decoding fails\n   */\n  def asUnsafe[A](implicit decoder: JsonDecoder[A]): A = as[A].fold(throw _, identity)\n\n  /**\n   * Internal: decode using an explicit codec.\n   */\n  private[json] def decodeWith[A](codec: JsonBinaryCodec[A]): Either[JsonError, A] = ???\n\n  // ===========================================================================\n  // Encoding (Json => String/Bytes)\n  // ===========================================================================\n\n  /**\n   * Encodes this JSON to a compact string (no extra whitespace).\n   */\n  def print: String = encode(WriterConfig)\n\n  /**\n   * Encodes this JSON to a string using the specified configuration.\n   *\n   * @param config Writer configuration (indentation, unicode escaping, etc.)\n   */\n  def print(config: WriterConfig): String = encode(config)\n\n  /**\n   * Alias for [[print]].\n   */\n  def encode: String = encode(WriterConfig)\n\n  /**\n   * Encodes this JSON to a string using the specified configuration.\n   *\n   * @param config Writer configuration\n   */\n  def encode(config: WriterConfig): String = ???\n\n  /**\n   * Encodes this JSON and writes to the provided [[Writer]].\n   *\n   * @param writer The writer to write to\n   */\n  def printTo(writer: Writer): Unit = printTo(writer, WriterConfig)\n\n  /**\n   * Encodes this JSON and writes to the provided [[Writer]] with configuration.\n   *\n   * @param writer The writer to write to\n   * @param config Writer configuration\n   */\n  def printTo(writer: Writer, config: WriterConfig): Unit = ???\n\n  /**\n   * Encodes this JSON to a byte array (UTF-8).\n   */\n  def encodeToBytes: Array[Byte] = encodeToBytes(WriterConfig)\n\n  /**\n   * Encodes this JSON to a byte array (UTF-8) with configuration.\n   *\n   * @param config Writer configuration\n   */\n  def encodeToBytes(config: WriterConfig): Array[Byte] = ???\n\n  /**\n   * Encodes this JSON to a [[Chunk]] of bytes (UTF-8).\n   */\n  def encodeToChunk: Chunk[Byte] = encodeToChunk(WriterConfig)\n\n  /**\n   * Encodes this JSON to a [[Chunk]] of bytes (UTF-8) with configuration.\n   *\n   * @param config Writer configuration\n   */\n  def encodeToChunk(config: WriterConfig): Chunk[Byte] = ???\n\n  /**\n   * Encodes this JSON into the provided [[ByteBuffer]].\n   *\n   * @param buffer The buffer to write to\n   */\n  def encodeTo(buffer: ByteBuffer): Unit = encodeTo(buffer, WriterConfig)\n\n  /**\n   * Encodes this JSON into the provided [[ByteBuffer]] with configuration.\n   *\n   * @param buffer The buffer to write to\n   * @param config Writer configuration\n   */\n  def encodeTo(buffer: ByteBuffer, config: WriterConfig): Unit = ???\n\n  // ===========================================================================\n  // Standard Methods\n  // ===========================================================================\n\n  override def hashCode(): Int = self match {\n    case Json.Null           => 0\n    case Json.Boolean(v)     => v.hashCode()\n    case Json.Number(v)      => BigDecimal(v).hashCode()\n    case Json.String(v)      => v.hashCode()\n    case Json.Array(elems)   => elems.hashCode()\n    case Json.Object(flds)   => flds.sortBy(_._1).hashCode()\n  }\n\n  override def equals(that: Any): Boolean = that match {\n    case other: Json => compare(other) == 0\n    case _           => false\n  }\n\n  override def toString: String = print\n}\n\nobject Json {\n\n  // ===========================================================================\n  // ADT Cases\n  // ===========================================================================\n\n  /**\n   * A JSON object: an unordered collection of key-value pairs.\n   *\n   * @param fields The key-value pairs. Keys should be unique; if duplicates\n   *               are present, behavior of accessors is undefined.\n   */\n  final case class Object(fields: Vector[(String, Json)]) extends Json {\n    override def isObject: scala.Boolean                = true\n    override def fields: Seq[(String, Json)]            = fields\n  }\n\n  object Object {\n\n    /**\n     * Creates an empty JSON object.\n     */\n    val empty: Object = Object(Vector.empty)\n\n    /**\n     * Creates a JSON object from key-value pairs.\n     */\n    def apply(fields: (String, Json)*): Object = Object(fields.toVector)\n  }\n\n  /**\n   * A JSON array: an ordered sequence of values.\n   *\n   * @param elements The array elements\n   */\n  final case class Array(elements: Vector[Json]) extends Json {\n    override def isArray: scala.Boolean  = true\n    override def elements: Seq[Json]     = elements\n  }\n\n  object Array {\n\n    /**\n     * Creates an empty JSON array.\n     */\n    val empty: Array = Array(Vector.empty)\n\n    /**\n     * Creates a JSON array from elements.\n     */\n    def apply(elements: Json*): Array = Array(elements.toVector)\n  }\n\n  /**\n   * A JSON string.\n   *\n   * @param value The string value (unescaped)\n   */\n  final case class String(value: java.lang.String) extends Json {\n    override def isString: scala.Boolean              = true\n    override def stringValue: Option[java.lang.String] = Some(value)\n  }\n\n  /**\n   * A JSON number.\n   *\n   * Stored as a string to preserve exact representation (precision, trailing zeros, etc.).\n   * Provides lazy conversion to numeric types.\n   *\n   * @param value The number as a string (should be valid JSON number syntax)\n   */\n  final case class Number(value: java.lang.String) extends Json {\n    override def isNumber: scala.Boolean                = true\n    override def numberValue: Option[java.lang.String]  = Some(value)\n\n    /**\n     * Converts to `Int`, truncating if necessary.\n     */\n    lazy val toInt: Int = toBigDecimal.toInt\n\n    /**\n     * Converts to `Long`, truncating if necessary.\n     */\n    lazy val toLong: Long = toBigDecimal.toLong\n\n    /**\n     * Converts to `Float`.\n     */\n    lazy val toFloat: Float = value.toFloat\n\n    /**\n     * Converts to `Double`.\n     */\n    lazy val toDouble: Double = value.toDouble\n\n    /**\n     * Converts to `BigInt`, truncating fractional part.\n     */\n    lazy val toBigInt: BigInt = toBigDecimal.toBigInt\n\n    /**\n     * Converts to `BigDecimal` (lossless).\n     */\n    lazy val toBigDecimal: BigDecimal = BigDecimal(value)\n  }\n\n  /**\n   * A JSON boolean.\n   *\n   * @param value The boolean value\n   */\n  final case class Boolean(value: scala.Boolean) extends Json {\n    override def isBoolean: scala.Boolean              = true\n    override def booleanValue: Option[scala.Boolean]   = Some(value)\n  }\n\n  object Boolean {\n    val True: Boolean  = Boolean(true)\n    val False: Boolean = Boolean(false)\n  }\n\n  /**\n   * The JSON null value.\n   */\n  case object Null extends Json {\n    override def isNull: scala.Boolean = true\n  }\n\n  // ===========================================================================\n  // Convenience Constructors\n  // ===========================================================================\n\n  /**\n   * Creates a JSON number from an `Int`.\n   */\n  def number(n: Int): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Long`.\n   */\n  def number(n: Long): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Float`.\n   */\n  def number(n: Float): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Double`.\n   */\n  def number(n: Double): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `BigInt`.\n   */\n  def number(n: BigInt): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `BigDecimal`.\n   */\n  def number(n: BigDecimal): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Short`.\n   */\n  def number(n: Short): Number = Number(n.toString)\n\n  /**\n   * Creates a JSON number from a `Byte`.\n   */\n  def number(n: Byte): Number = Number(n.toString)\n\n  // ===========================================================================\n  // Parsing / Decoding (String/Bytes => Json)\n  // ===========================================================================\n\n  /**\n   * Parses a JSON value from a string.\n   *\n   * @param s The JSON string\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(s: java.lang.String): Either[JsonError, Json] = decode(s)\n\n  /**\n   * Parses a JSON value from a `CharSequence`.\n   *\n   * @param s The JSON character sequence\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(s: CharSequence): Either[JsonError, Json] = decode(s)\n\n  /**\n   * Parses a JSON value from a byte array (UTF-8).\n   *\n   * @param bytes The JSON bytes\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(bytes: scala.Array[Byte]): Either[JsonError, Json] = decode(bytes)\n\n  /**\n   * Parses a JSON value from a [[Chunk]] of bytes (UTF-8).\n   *\n   * @param chunk The JSON bytes\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(chunk: Chunk[Byte]): Either[JsonError, Json] = decode(chunk)\n\n  /**\n   * Parses a JSON value from a [[ByteBuffer]] (UTF-8).\n   *\n   * @param buffer The JSON bytes\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(buffer: ByteBuffer): Either[JsonError, Json] = decode(buffer)\n\n  /**\n   * Parses a JSON value from a [[Reader]].\n   *\n   * @param reader The reader to read from\n   * @return Either a [[JsonError]] or the parsed JSON\n   */\n  def parse(reader: Reader): Either[JsonError, Json] = decode(reader)\n\n  /**\n   * Decodes a JSON value from a string.\n   */\n  def decode(s: java.lang.String): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a `CharSequence`.\n   */\n  def decode(s: CharSequence): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a byte array (UTF-8).\n   */\n  def decode(bytes: scala.Array[Byte]): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a [[Chunk]] of bytes (UTF-8).\n   */\n  def decode(chunk: Chunk[Byte]): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a [[ByteBuffer]] (UTF-8).\n   */\n  def decode(buffer: ByteBuffer): Either[JsonError, Json] = ???\n\n  /**\n   * Decodes a JSON value from a [[Reader]].\n   */\n  def decode(reader: Reader): Either[JsonError, Json] = ???\n\n  /**\n   * Parses a JSON value from a string, throwing on failure.\n   *\n   * @param s The JSON string\n   * @return The parsed JSON\n   * @throws JsonError if parsing fails\n   */\n  def parseUnsafe(s: java.lang.String): Json = decode(s).fold(throw _, identity)\n\n  /**\n   * Alias for [[parseUnsafe]].\n   */\n  def decodeUnsafe(s: java.lang.String): Json = parseUnsafe(s)\n\n  // ===========================================================================\n  // Typed Encoding (A => Json)\n  // ===========================================================================\n\n  /**\n   * Encodes a typed value to JSON.\n   *\n   * Uses implicit [[JsonEncoder]] which prefers explicit codecs over schema derivation.\n   *\n   * {{{\n   * val json = Json.from(Person(\"Alice\", 30))\n   * }}}\n   *\n   * @param value The value to encode\n   * @return The encoded JSON\n   */\n  def from[A](value: A)(implicit encoder: JsonEncoder[A]): Json = encoder.encode(value)\n\n  /**\n   * Internal: encode using an explicit codec.\n   */\n  private[json] def encodeWith[A](value: A, codec: JsonBinaryCodec[A]): Json = ???\n\n  // ===========================================================================\n  // DynamicValue Interop\n  // ===========================================================================\n\n  /**\n   * Converts a [[DynamicValue]] to JSON.\n   *\n   * This conversion is lossy for `DynamicValue` types that have no JSON equivalent:\n   *  - `PrimitiveValue` types like `java.time.*` are converted to strings\n   *  - `DynamicValue.Variant` uses a discriminator field\n   *\n   * @param value The dynamic value to convert\n   * @return The JSON representation\n   */\n  def fromDynamicValue(value: DynamicValue): Json = value match {\n    case DynamicValue.Primitive(pv) => fromPrimitiveValue(pv)\n    case DynamicValue.Record(flds) =>\n      Object(flds.map { case (k, v) => (k, fromDynamicValue(v)) })\n    case DynamicValue.Variant(caseName, v) =>\n      Object(Vector(\"_type\" -> String(caseName), \"_value\" -> fromDynamicValue(v)))\n    case DynamicValue.Sequence(elems) =>\n      Array(elems.map(fromDynamicValue))\n    case DynamicValue.Map(entries) =>\n      Array(entries.map { case (k, v) =>\n        Object(Vector(\"key\" -> fromDynamicValue(k), \"value\" -> fromDynamicValue(v)))\n      })\n  }\n\n  private def fromPrimitiveValue(pv: PrimitiveValue): Json = pv match {\n    case PrimitiveValue.Unit              => Null\n    case PrimitiveValue.Boolean(v)        => Boolean(v)\n    case PrimitiveValue.Byte(v)           => number(v)\n    case PrimitiveValue.Short(v)          => number(v)\n    case PrimitiveValue.Int(v)            => number(v)\n    case PrimitiveValue.Long(v)           => number(v)\n    case PrimitiveValue.Float(v)          => number(v)\n    case PrimitiveValue.Double(v)         => number(v)\n    case PrimitiveValue.Char(v)           => String(v.toString)\n    case PrimitiveValue.String(v)         => String(v)\n    case PrimitiveValue.BigInt(v)         => number(v)\n    case PrimitiveValue.BigDecimal(v)     => number(v)\n    case PrimitiveValue.DayOfWeek(v)      => String(v.toString)\n    case PrimitiveValue.Duration(v)       => String(v.toString)\n    case PrimitiveValue.Instant(v)        => String(v.toString)\n    case PrimitiveValue.LocalDate(v)      => String(v.toString)\n    case PrimitiveValue.LocalDateTime(v)  => String(v.toString)\n    case PrimitiveValue.LocalTime(v)      => String(v.toString)\n    case PrimitiveValue.Month(v)          => String(v.toString)\n    case PrimitiveValue.MonthDay(v)       => String(v.toString)\n    case PrimitiveValue.OffsetDateTime(v) => String(v.toString)\n    case PrimitiveValue.OffsetTime(v)     => String(v.toString)\n    case PrimitiveValue.Period(v)         => String(v.toString)\n    case PrimitiveValue.Year(v)           => String(v.toString)\n    case PrimitiveValue.YearMonth(v)      => String(v.toString)\n    case PrimitiveValue.ZoneId(v)         => String(v.getId)\n    case PrimitiveValue.ZoneOffset(v)     => String(v.toString)\n    case PrimitiveValue.ZonedDateTime(v)  => String(v.toString)\n    case PrimitiveValue.Currency(v)       => String(v.getCurrencyCode)\n    case PrimitiveValue.UUID(v)           => String(v.toString)\n  }\n\n  // ===========================================================================\n  // KV Interop\n  // ===========================================================================\n\n  /**\n   * Assembles JSON from a sequence of path-value pairs.\n   *\n   * {{{\n   * Json.fromKV(Seq(\n   *   p\"a.b\" -> Json.number(1),\n   *   p\"a.c\" -> Json.String(\"x\"),\n   *   p\"d[0]\" -> Json.Boolean(true)\n   * ))\n   * // {\"a\": {\"b\": 1, \"c\": \"x\"}, \"d\": [true]}\n   * }}}\n   *\n   * @param kvs The path-value pairs\n   * @return Either an error (for conflicting paths) or the assembled JSON\n   */\n  def fromKV(kvs: Seq[(DynamicOptic, Json)]): Either[JsonError, Json] = ???\n\n  /**\n   * Assembles JSON from path-value pairs, throwing on conflict.\n   */\n  def fromKVUnsafe(kvs: Seq[(DynamicOptic, Json)]): Json = fromKV(kvs).fold(throw _, identity)\n\n  // ===========================================================================\n  // Patch Interop\n  // ===========================================================================\n\n  /**\n   * Serializes a [[JsonPatch]] to its JSON representation.\n   *\n   * The format follows RFC 6902 (JSON Patch) for standard operations,\n   * with extensions for LCS-based sequence diffs.\n   *\n   * @param patch The patch to serialize\n   * @return The JSON representation of the patch\n   */\n  def fromJsonPatch(patch: JsonPatch): Json = ???\n\n  /**\n   * Deserializes a JSON representation into a [[JsonPatch]].\n   *\n   * @param json The JSON patch representation\n   * @return Either an error or the parsed patch\n   */\n  def toJsonPatch(json: Json): Either[JsonError, JsonPatch] = ???\n\n  // ===========================================================================\n  // Ordering\n  // ===========================================================================\n\n  /**\n   * Ordering for JSON values.\n   *\n   * Order: Null < Boolean < Number < String < Array < Object\n   */\n  implicit val ordering: Ordering[Json] = (x: Json, y: Json) => x.compare(y)\n}\n\n// =============================================================================\n// MERGE STRATEGY\n// =============================================================================\n\n/**\n * Strategy for merging JSON values.\n */\nsealed trait MergeStrategy\n\nobject MergeStrategy {\n\n  /**\n   * Automatically determines merge behavior based on value types:\n   *  - Objects: deep merge (recurse into matching keys)\n   *  - Arrays: concatenate\n   *  - Primitives: right wins\n   */\n  case object Auto extends MergeStrategy\n\n  /**\n   * Deep merge for objects; concatenate arrays.\n   */\n  case object Deep extends MergeStrategy\n\n  /**\n   * Shallow merge: right value wins for any key conflict.\n   */\n  case object Shallow extends MergeStrategy\n\n  /**\n   * Concatenate arrays; for objects and primitives, right wins.\n   */\n  case object Concat extends MergeStrategy\n\n  /**\n   * Right value always wins (replacement).\n   */\n  case object Replace extends MergeStrategy\n\n  /**\n   * Custom merge function.\n   *\n   * @param f A function receiving path and both values, returning merged result\n   */\n  final case class Custom(f: (DynamicOptic, Json, Json) => Json) extends MergeStrategy\n}\n\n// =============================================================================\n// STRING INTERPOLATORS\n// =============================================================================\n\n/**\n * Provides string interpolators for JSON paths and literals.\n *\n * Import with:\n * {{{\n * import zio.blocks.schema.json.interpolators._\n * }}}\n *\n * ==Path Syntax==\n *\n * The `p` interpolator creates [[DynamicOptic]] paths using a JSONPath-compatible dialect:\n *\n * {{{\n * p\"foo.bar\"           // fields \"foo\" then \"bar\"\n * p\"users[0]\"          // field \"users\", then index 0\n * p\"users[0].name\"     // field \"users\", index 0, field \"name\"\n * p\"items[*]\"          // field \"items\", then all array elements\n * p\"config{*}\"         // field \"config\", then all object values\n * p\"config{*:}\"        // field \"config\", then all object keys\n * p\"[0,2,5]\"           // indices 0, 2, and 5\n * p\"[0:5]\"             // slice: indices 0 through 4\n * p\"[::2]\"             // slice: every other element\n * p\"`field.name`\"      // field with dots in name (backtick escaping)\n * p\"\"\"[\"field\"]\"\"\"     // alternate field syntax (bracket notation)\n * }}}\n *\n * ===JSONPath Compatibility===\n *\n * This syntax is a dialect of JSONPath (RFC 9535). Most JSONPath expressions work:\n *  - `$.foo.bar` - root prefix is optional and ignored\n *  - `.field`, `[\"field\"]` - field access\n *  - `[n]`, `[*]`, `[m,n]`, `[m:n]` - array access\n *\n * '''Not supported:'''\n *  - `..` (recursive descent)\n *  - `[?()]` (filter expressions)\n *\n * ===Extensions beyond JSONPath:===\n *  - `{*}` - all object values (explicit, vs `[*]` which is array-focused in JSONPath)\n *  - `{*:}` - all object keys (not expressible in standard JSONPath)\n *  - Backtick escaping for field names\n */\nobject interpolators {\n\n  implicit class JsonPathInterpolator(val sc: StringContext) extends AnyVal {\n\n    /**\n     * Creates a [[DynamicOptic]] from a path string at compile time.\n     *\n     * @return The parsed [[DynamicOptic]]\n     */\n    def p(args: Any*): DynamicOptic = macro PathMacros.pathInterpolator\n  }\n\n  implicit class JsonLiteralInterpolator(val sc: StringContext) extends AnyVal {\n\n    /**\n     * Creates a [[Json]] value from a JSON literal at compile time.\n     *\n     * {{{\n     * j\"\"\"{\"name\": \"Alice\", \"age\": 30}\"\"\"\n     * j\"[1, 2, 3]\"\n     * j\"null\"\n     * }}}\n     *\n     * Interpolated values are converted to JSON:\n     * {{{\n     * val name = \"Bob\"\n     * val age = 25\n     * j\"\"\"{\"name\": $name, \"age\": $age}\"\"\"\n     * }}}\n     *\n     * @return The parsed [[Json]] value\n     */\n    def j(args: Any*): Json = macro PathMacros.jsonInterpolator\n  }\n}\n\n/**\n * Macro implementations for string interpolators.\n * \n * Separate implementations would be needed for Scala 2 and Scala 3.\n */\nobject PathMacros {\n  import scala.reflect.macros.blackbox\n\n  def pathInterpolator(c: blackbox.Context)(args: c.Expr[Any]*): c.Expr[DynamicOptic] = ???\n\n  def jsonInterpolator(c: blackbox.Context)(args: c.Expr[Any]*): c.Expr[Json] = ???\n}\n\n// =============================================================================\n// PLACEHOLDER TYPES (assumed to exist)\n// =============================================================================\n\n/**\n * Represents a JSON Schema for validation.\n *\n * Placeholder - actual implementation TBD.\n */\nsealed trait JsonSchema\n\nobject JsonSchema {\n  // Placeholder\n}\n\n/**\n * Represents a patch that can be applied to JSON values.\n *\n * Supports RFC 6902 operations (add, remove, replace, move, copy, test)\n * plus extensions for LCS-based sequence diffs and string diffs.\n *\n * Placeholder - actual implementation TBD.\n */\nsealed trait JsonPatch {\n\n  /**\n   * Converts this JSON patch to a [[DynamicPatch]].\n   */\n  def toDynamicPatch: DynamicPatch\n}\n\nobject JsonPatch {\n\n  /**\n   * Creates an empty patch (no operations).\n   */\n  val empty: JsonPatch = ???\n\n  /**\n   * Creates a patch from a [[DynamicPatch]].\n   *\n   * May fail if the DynamicPatch contains operations not representable in JSON.\n   */\n  def fromDynamicPatch(patch: DynamicPatch): Either[JsonError, JsonPatch] = ???\n}\n\n/**\n * Represents a patch that can be applied to [[DynamicValue]].\n *\n * Placeholder - actual implementation TBD.\n */\nsealed trait DynamicPatch\n\nobject DynamicPatch {\n\n  /**\n   * Creates an empty patch (no operations).\n   */\n  val empty: DynamicPatch = ???\n}\n```",
              "url": "https://github.com/zio/zio-blocks/issues/679",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#519",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-18T17:51:53.429Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:53.429Z",
            "created_at": "2026-01-18T17:51:53.429Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#519",
              "status": "open",
              "type": "issue",
              "number": 519,
              "title": "Schema Migration System for ZIO Schema 2",
              "source": {
                "data": {
                  "id": "source-ZIO#519",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Schema Migration System for ZIO Schema 2",
                  "body": "## Overview\n\nImplement a **pure, algebraic migration system** for ZIO Schema 2 that represents **structural transformations between schema versions** as first-class, serializable data.\n\nA migration describes how to transform data from one schema version to another, enabling:\n\n* schema evolution\n* backward / forward compatibility\n* data versioning\n* offline migrations (JSON, SQL, data lakes, registries, etc.)\n\nThe system provides a **typed, macro-validated user API** (`Migration[A, B]`) built on a **pure, serializable core** (`DynamicMigration`) that operates on `DynamicValue`. \n\nThe ADT is fully introspectable and can be used to generate DDL, etc.\n\n## Motivation & Big Picture\n\n### Why structural types?\n\nWhen evolving schemas over time, **older versions of data types should not require runtime representations**.\n\nIn this design:\n\n* **Current versions** are represented by real case classes / enums\n* **Past versions** are represented using:\n\n  * **structural types** for records\n  * **abstract types + intersection types** for sum types\n\nThese types:\n\n* exist **only at compile time**\n* have **no runtime representation**\n* introduce **zero runtime overhead**\n* do **not require optics or instances to be kept around**\n\nThis allows you to describe arbitrarily old versions of data *without polluting your runtime or codebase*.\n\n#### Typical Workflow\n\nA typical workflow looks like:\n\n1. You have a current type:\n\n   ```scala\n   @schema\n   case class Person(name: String, age: Int)\n   ```\n\n2. You derive and copy its structural shape:\n\n   ```scala\n   type PersonV1 = { def name: String; def age: Int }\n   ```\n\n3. You evolve the real type:\n\n   ```scala\n   @schema\n   case class Person(fullName: String, age: Int, country: String)\n   ```\n\n4. You keep only:\n\n   * the **current** runtime type\n   * the **structural type** for the old version\n   * a **pure migration** between them\n\nNo old case classes. No old optics. No runtime baggage.\n\nNote there is no requirement that the \"current\" type actually be a real case class, enum, etc.--so you can work purely with structural types, allowing you to define migrations for data types that are never materialized as runtime structures.\n\n---\n\n### Why pure data migrations?\n\nMigrations are represented entirely as **pure data**:\n\n* no user functions\n* no closures\n* no reflection\n* no runtime code generation\n\nAs a result:\n\n* migrations can be **serialized**\n* stored in **registries**\n* applied **dynamically**\n* inspected and transformed\n* used to generate:\n\n  * upgraders\n  * downgraders\n  * SQL DDL / DML\n  * offline data transforms\n\nWhile code generation is **out of scope for this ticket**, this explains many design decisions (invertibility, path-based actions, no functions).\n\n---\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed migration (user-facing API)\ncase class Migration[A, B](\n  dynamicMigration: DynamicMigration,\n  sourceSchema: Schema[A], // These are structural schemas!!!\n  targetSchema: Schema[B] // These are structural schemas!!!\n) {\n  /** Apply migration to transform A to B */\n  def apply(value: A): Either[MigrationError, B]\n\n  /** Compose migrations sequentially */\n  def ++[C](that: Migration[B, C]): Migration[A, C]\n\n  /** Alias for ++ */\n  def andThen[C](that: Migration[B, C]): Migration[A, C] = this ++ that\n\n  /** Reverse migration (structural inverse; runtime is best-effort) */\n  def reverse: Migration[B, A]\n}\n```\n\n```scala\n// Untyped migration (pure data, fully serializable)\ncase class DynamicMigration(\n  actions: Vector[MigrationAction]\n) {\n  def apply(value: DynamicValue): Either[MigrationError, DynamicValue]\n  def ++(that: DynamicMigration): DynamicMigration\n  def reverse: DynamicMigration\n}\n```\n\n* `Migration[A, B]` is introspectable, but not pure data due to bindings inside schemas\n* `DynamicMigration` is **fully serializable**\n\n---\n\n## User-Facing API: Selector Expressions\n\n### Selectors, not optics\n\nThe user-facing API **does not expose optics**.\n\nInstead, all locations are specified using **selector expressions**:\n\n```scala\nS => A\n```\n\nExamples:\n\n```scala\n_.name\n_.address.street\n_.addresses.each.streetNumber\n_.country.when[UK]\n```\n\nTo see the syntax, one can look at the `optic` macro, which utilizes the same selector syntax for optic creation (e.g. `optic(_.address.street)`, etc.).\n\n### Macro extraction\n\nAll builder methods that accept selectors are **implemented via macros** (or via a macro-generated type class such as `ToDynamicOptic`).\n\nThe macro:\n\n1. Inspects the selector expression\n2. Validates it is a supported projection\n3. Converts it into a `DynamicOptic`\n4. Stores that optic in the migration action\n\nSupported projections include:\n\n* field access (`_.foo.bar`)\n* case selection (`_.country.when[UK]`)\n* collection traversal (`_.items.each`)\n* (future) key access, wrappers, etc.\n\n`DynamicOptic` is **never exposed publicly**.\n\n---\n\n## Migration Builder\n\nAll selector-accepting methods are implemented via macros. For simplicity, these are shown as functions (e.g. `A => Any`), but this is NOT the way to implement them. Either all these functions need to be macros, or a macro needs to be used to generate an implicit / given at each call site. Macros may do additional validation to constrain the validity of these different types of transformations.\n\n```scala\nclass MigrationBuilder[A, B](\n  sourceSchema: Schema[A],\n  targetSchema: Schema[B],\n  actions: Vector[MigrationAction]\n) {\n\n  // ----- Record operations -----\n\n  def addField(\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def dropField(\n    source: A => Any,\n    defaultForReverse: SchemaExpr[B, ?] = SchemaExpr.DefaultValue\n  ): MigrationBuilder[A, B]\n\n  def renameField(\n    from: A => Any,\n    to: B => Any\n  ): MigrationBuilder[A, B]\n\n  def transformField(\n    from: A => Any,\n    to: B => Any,\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def mandateField(\n    source: A => Option[?],\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def optionalizeField(\n    source: A => Any,\n    target: B => Option[?]\n  ): MigrationBuilder[A, B]\n\n  def changeFieldType(\n    source: A => Any,\n    target: B => Any,\n    converter: SchemaExpr[A, ?]  // primitive-to-primitive only\n  ): MigrationBuilder[A, B]\n\n  // ----- Enum operations (limited) -----\n\n  def renameCase[SumA, SumB](\n    from: String,\n    to: String\n  ): MigrationBuilder[A, B]\n\n  def transformCase[SumA, CaseA, SumB, CaseB](\n    caseMigration: MigrationBuilder[CaseA, CaseB] => MigrationBuilder[CaseA, CaseB]\n  ): MigrationBuilder[A, B]\n\n  // ----- Collections -----\n\n  def transformElements(\n    at: A => Vector[?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  // ----- Maps -----\n\n  def transformKeys(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def transformValues(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  /** Build migration with full macro validation */\n  def build: Migration[A, B]\n\n  /** Build migration without full validation */\n  def buildPartial: Migration[A, B]\n}\n```\n\n---\n\n## Migration Actions (Untyped Core)\n\nAll actions operate at a **path**, represented by `DynamicOptic`.\n\n```scala\nsealed trait MigrationAction {\n  def at: DynamicOptic\n  def reverse: MigrationAction\n}\n```\n\n### Record Actions\n\n```scala\ncase class AddField(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class DropField(\n  at: DynamicOptic,\n  defaultForReverse: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Rename(\n  at: DynamicOptic,\n  to: String\n) extends MigrationAction\n\ncase class TransformValue(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Mandate(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Optionalize(\n  at: DynamicOptic\n) extends MigrationAction\n\ncase class Join(\n  at: DynamicOptic,\n  sourcePaths: Vector[DynamicOptic],\n  combiner: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Split(\n  at: DynamicOptic,\n  targetPaths: Vector[DynamicOptic],\n  splitter: SchemaExpr[?]\n) extends MigrationAction\n\ncase class ChangeType(\n  at: DynamicOptic,\n  converter: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n### Enum Actions (Supported)\n\n```scala\ncase class RenameCase(\n  at: DynamicOptic,\n  from: String,\n  to: String\n) extends MigrationAction\n\ncase class TransformCase(\n  at: DynamicOptic,\n  actions: Vector[MigrationAction]\n) extends MigrationAction\n```\n\n> Enum case addition / removal is **out of scope** for this ticket\n> (requires composite value construction).\n\n---\n\n### Collection / Map Actions\n\n```scala\ncase class TransformElements(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformKeys(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformValues(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n## SchemaExpr Integration\n\n* Used for all value-level transformations\n* **Constraints for this ticket**:\n\n  * primitive â†’ primitive only\n  * joins / splits must produce primitives\n  * no record / enum construction\n\n### `SchemaExpr.DefaultValue`\n\nA special expression that:\n\n1. uses the macro-captured field schema\n2. calls `schema.defaultValue`\n3. converts the value to `DynamicValue`\n4. is stored for reverse migrations\n\n---\n\n## Type Modeling\n\n### Records (Structural Types)\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\ntype PersonV1 = { val fullName: String; val age: Int }\n\nimplicit val v0Schema: Schema[PersonV0] = Schema.structural[PersonV0]\nimplicit val v1Schema: Schema[PersonV1] = Schema.structural[PersonV1]\n```\n\n---\n\n### Enums (Union of Structural Types with Tags)\n\nEnums are encoded into structural types by using union types, together with singleton types (string literals, which represent the name of the case of the enum).\n\nIn structural types, the names of the type aliases shown below are not relevant, nor are they used.\n\n```scala\ntype OldCreditCard =\n  { type Tag = \"CreditCard\"; def number: String; def exp: String }\ntype OldWireTransfer =\n  { type Tag = \"WireTransfer\"; def account: String; def routing: String }\ntype OldPaymentMethod = OldCreditCard | OldWireTransfer\n```\n\nMacros extract:\n\n* refinement type â†’ structure of the case\n* type `Tag` with singleton type â†’ case tag\n\n---\n\n## Laws\n\n### Identity\n\n```scala\nMigration.identity[A].apply(a) == Right(a)\n```\n\n### Associativity\n\n```scala\n(m1 ++ m2) ++ m3 == m1 ++ (m2 ++ m3)\n```\n\n### Structural Reverse\n\n```scala\nm.reverse.reverse == m\n```\n\n### Best-Effort Semantic Inverse\n\n```scala\nm.apply(a) == Right(b) â‡’ m.reverse.apply(b) == Right(a)\n```\n\n(when sufficient information exists)\n\n---\n\n## Error Handling\n\n* All runtime errors return `MigrationError`\n* Errors must capture **path information** (`DynamicOptic`)\n* Enables diagnostics such as:\n\n> â€œFailed to apply TransformValue at `.addresses.each.streetNumber`â€\n\n---\n\n## Example\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\n\n@schema\ncase class Person(fullName: String, age: Int)\n\nval migration =\n  Migration.newBuilder[PersonV0, Person]\n    .addField(_.age, 0)\n    .build\n\nval old =\n  new { val firstName = \"John\"; val lastName = \"Doe\" }\n\nmigration(old)\n// Right(Person(\"John Doe\", 0))\n```\n\n---\n\n## Success Criteria\n\n* [ ] `DynamicMigration` fully serializable\n* [ ] `Migration[A, B]` wraps schemas and actions\n* [ ] All actions path-based via `DynamicOptic`\n* [ ] User API uses selector functions (`S => A`) for \"optics\" on old and new types\n* [ ] Macro validation in `.build` to confirm \"old\" has been migrated to \"new\"\n* [ ] `.buildPartial` supported\n* [ ] Structural reverse implemented\n* [ ] Identity & associativity laws hold\n* [ ] Enum rename / transform supported\n* [ ] Errors include path information\n* [ ] Comprehensive tests\n* [ ] Scala 2.13 and Scala 3.5+ supported\n",
                  "html_url": "https://github.com/zio/zio-blocks/issues/519"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#519",
              "body": "## Overview\n\nImplement a **pure, algebraic migration system** for ZIO Schema 2 that represents **structural transformations between schema versions** as first-class, serializable data.\n\nA migration describes how to transform data from one schema version to another, enabling:\n\n* schema evolution\n* backward / forward compatibility\n* data versioning\n* offline migrations (JSON, SQL, data lakes, registries, etc.)\n\nThe system provides a **typed, macro-validated user API** (`Migration[A, B]`) built on a **pure, serializable core** (`DynamicMigration`) that operates on `DynamicValue`. \n\nThe ADT is fully introspectable and can be used to generate DDL, etc.\n\n## Motivation & Big Picture\n\n### Why structural types?\n\nWhen evolving schemas over time, **older versions of data types should not require runtime representations**.\n\nIn this design:\n\n* **Current versions** are represented by real case classes / enums\n* **Past versions** are represented using:\n\n  * **structural types** for records\n  * **abstract types + intersection types** for sum types\n\nThese types:\n\n* exist **only at compile time**\n* have **no runtime representation**\n* introduce **zero runtime overhead**\n* do **not require optics or instances to be kept around**\n\nThis allows you to describe arbitrarily old versions of data *without polluting your runtime or codebase*.\n\n#### Typical Workflow\n\nA typical workflow looks like:\n\n1. You have a current type:\n\n   ```scala\n   @schema\n   case class Person(name: String, age: Int)\n   ```\n\n2. You derive and copy its structural shape:\n\n   ```scala\n   type PersonV1 = { def name: String; def age: Int }\n   ```\n\n3. You evolve the real type:\n\n   ```scala\n   @schema\n   case class Person(fullName: String, age: Int, country: String)\n   ```\n\n4. You keep only:\n\n   * the **current** runtime type\n   * the **structural type** for the old version\n   * a **pure migration** between them\n\nNo old case classes. No old optics. No runtime baggage.\n\nNote there is no requirement that the \"current\" type actually be a real case class, enum, etc.--so you can work purely with structural types, allowing you to define migrations for data types that are never materialized as runtime structures.\n\n---\n\n### Why pure data migrations?\n\nMigrations are represented entirely as **pure data**:\n\n* no user functions\n* no closures\n* no reflection\n* no runtime code generation\n\nAs a result:\n\n* migrations can be **serialized**\n* stored in **registries**\n* applied **dynamically**\n* inspected and transformed\n* used to generate:\n\n  * upgraders\n  * downgraders\n  * SQL DDL / DML\n  * offline data transforms\n\nWhile code generation is **out of scope for this ticket**, this explains many design decisions (invertibility, path-based actions, no functions).\n\n---\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed migration (user-facing API)\ncase class Migration[A, B](\n  dynamicMigration: DynamicMigration,\n  sourceSchema: Schema[A], // These are structural schemas!!!\n  targetSchema: Schema[B] // These are structural schemas!!!\n) {\n  /** Apply migration to transform A to B */\n  def apply(value: A): Either[MigrationError, B]\n\n  /** Compose migrations sequentially */\n  def ++[C](that: Migration[B, C]): Migration[A, C]\n\n  /** Alias for ++ */\n  def andThen[C](that: Migration[B, C]): Migration[A, C] = this ++ that\n\n  /** Reverse migration (structural inverse; runtime is best-effort) */\n  def reverse: Migration[B, A]\n}\n```\n\n```scala\n// Untyped migration (pure data, fully serializable)\ncase class DynamicMigration(\n  actions: Vector[MigrationAction]\n) {\n  def apply(value: DynamicValue): Either[MigrationError, DynamicValue]\n  def ++(that: DynamicMigration): DynamicMigration\n  def reverse: DynamicMigration\n}\n```\n\n* `Migration[A, B]` is introspectable, but not pure data due to bindings inside schemas\n* `DynamicMigration` is **fully serializable**\n\n---\n\n## User-Facing API: Selector Expressions\n\n### Selectors, not optics\n\nThe user-facing API **does not expose optics**.\n\nInstead, all locations are specified using **selector expressions**:\n\n```scala\nS => A\n```\n\nExamples:\n\n```scala\n_.name\n_.address.street\n_.addresses.each.streetNumber\n_.country.when[UK]\n```\n\nTo see the syntax, one can look at the `optic` macro, which utilizes the same selector syntax for optic creation (e.g. `optic(_.address.street)`, etc.).\n\n### Macro extraction\n\nAll builder methods that accept selectors are **implemented via macros** (or via a macro-generated type class such as `ToDynamicOptic`).\n\nThe macro:\n\n1. Inspects the selector expression\n2. Validates it is a supported projection\n3. Converts it into a `DynamicOptic`\n4. Stores that optic in the migration action\n\nSupported projections include:\n\n* field access (`_.foo.bar`)\n* case selection (`_.country.when[UK]`)\n* collection traversal (`_.items.each`)\n* (future) key access, wrappers, etc.\n\n`DynamicOptic` is **never exposed publicly**.\n\n---\n\n## Migration Builder\n\nAll selector-accepting methods are implemented via macros. For simplicity, these are shown as functions (e.g. `A => Any`), but this is NOT the way to implement them. Either all these functions need to be macros, or a macro needs to be used to generate an implicit / given at each call site. Macros may do additional validation to constrain the validity of these different types of transformations.\n\n```scala\nclass MigrationBuilder[A, B](\n  sourceSchema: Schema[A],\n  targetSchema: Schema[B],\n  actions: Vector[MigrationAction]\n) {\n\n  // ----- Record operations -----\n\n  def addField(\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def dropField(\n    source: A => Any,\n    defaultForReverse: SchemaExpr[B, ?] = SchemaExpr.DefaultValue\n  ): MigrationBuilder[A, B]\n\n  def renameField(\n    from: A => Any,\n    to: B => Any\n  ): MigrationBuilder[A, B]\n\n  def transformField(\n    from: A => Any,\n    to: B => Any,\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def mandateField(\n    source: A => Option[?],\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def optionalizeField(\n    source: A => Any,\n    target: B => Option[?]\n  ): MigrationBuilder[A, B]\n\n  def changeFieldType(\n    source: A => Any,\n    target: B => Any,\n    converter: SchemaExpr[A, ?]  // primitive-to-primitive only\n  ): MigrationBuilder[A, B]\n\n  // ----- Enum operations (limited) -----\n\n  def renameCase[SumA, SumB](\n    from: String,\n    to: String\n  ): MigrationBuilder[A, B]\n\n  def transformCase[SumA, CaseA, SumB, CaseB](\n    caseMigration: MigrationBuilder[CaseA, CaseB] => MigrationBuilder[CaseA, CaseB]\n  ): MigrationBuilder[A, B]\n\n  // ----- Collections -----\n\n  def transformElements(\n    at: A => Vector[?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  // ----- Maps -----\n\n  def transformKeys(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def transformValues(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  /** Build migration with full macro validation */\n  def build: Migration[A, B]\n\n  /** Build migration without full validation */\n  def buildPartial: Migration[A, B]\n}\n```\n\n---\n\n## Migration Actions (Untyped Core)\n\nAll actions operate at a **path**, represented by `DynamicOptic`.\n\n```scala\nsealed trait MigrationAction {\n  def at: DynamicOptic\n  def reverse: MigrationAction\n}\n```\n\n### Record Actions\n\n```scala\ncase class AddField(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class DropField(\n  at: DynamicOptic,\n  defaultForReverse: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Rename(\n  at: DynamicOptic,\n  to: String\n) extends MigrationAction\n\ncase class TransformValue(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Mandate(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Optionalize(\n  at: DynamicOptic\n) extends MigrationAction\n\ncase class Join(\n  at: DynamicOptic,\n  sourcePaths: Vector[DynamicOptic],\n  combiner: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Split(\n  at: DynamicOptic,\n  targetPaths: Vector[DynamicOptic],\n  splitter: SchemaExpr[?]\n) extends MigrationAction\n\ncase class ChangeType(\n  at: DynamicOptic,\n  converter: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n### Enum Actions (Supported)\n\n```scala\ncase class RenameCase(\n  at: DynamicOptic,\n  from: String,\n  to: String\n) extends MigrationAction\n\ncase class TransformCase(\n  at: DynamicOptic,\n  actions: Vector[MigrationAction]\n) extends MigrationAction\n```\n\n> Enum case addition / removal is **out of scope** for this ticket\n> (requires composite value construction).\n\n---\n\n### Collection / Map Actions\n\n```scala\ncase class TransformElements(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformKeys(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformValues(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n## SchemaExpr Integration\n\n* Used for all value-level transformations\n* **Constraints for this ticket**:\n\n  * primitive â†’ primitive only\n  * joins / splits must produce primitives\n  * no record / enum construction\n\n### `SchemaExpr.DefaultValue`\n\nA special expression that:\n\n1. uses the macro-captured field schema\n2. calls `schema.defaultValue`\n3. converts the value to `DynamicValue`\n4. is stored for reverse migrations\n\n---\n\n## Type Modeling\n\n### Records (Structural Types)\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\ntype PersonV1 = { val fullName: String; val age: Int }\n\nimplicit val v0Schema: Schema[PersonV0] = Schema.structural[PersonV0]\nimplicit val v1Schema: Schema[PersonV1] = Schema.structural[PersonV1]\n```\n\n---\n\n### Enums (Union of Structural Types with Tags)\n\nEnums are encoded into structural types by using union types, together with singleton types (string literals, which represent the name of the case of the enum).\n\nIn structural types, the names of the type aliases shown below are not relevant, nor are they used.\n\n```scala\ntype OldCreditCard =\n  { type Tag = \"CreditCard\"; def number: String; def exp: String }\ntype OldWireTransfer =\n  { type Tag = \"WireTransfer\"; def account: String; def routing: String }\ntype OldPaymentMethod = OldCreditCard | OldWireTransfer\n```\n\nMacros extract:\n\n* refinement type â†’ structure of the case\n* type `Tag` with singleton type â†’ case tag\n\n---\n\n## Laws\n\n### Identity\n\n```scala\nMigration.identity[A].apply(a) == Right(a)\n```\n\n### Associativity\n\n```scala\n(m1 ++ m2) ++ m3 == m1 ++ (m2 ++ m3)\n```\n\n### Structural Reverse\n\n```scala\nm.reverse.reverse == m\n```\n\n### Best-Effort Semantic Inverse\n\n```scala\nm.apply(a) == Right(b) â‡’ m.reverse.apply(b) == Right(a)\n```\n\n(when sufficient information exists)\n\n---\n\n## Error Handling\n\n* All runtime errors return `MigrationError`\n* Errors must capture **path information** (`DynamicOptic`)\n* Enables diagnostics such as:\n\n> â€œFailed to apply TransformValue at `.addresses.each.streetNumber`â€\n\n---\n\n## Example\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\n\n@schema\ncase class Person(fullName: String, age: Int)\n\nval migration =\n  Migration.newBuilder[PersonV0, Person]\n    .addField(_.age, 0)\n    .build\n\nval old =\n  new { val firstName = \"John\"; val lastName = \"Doe\" }\n\nmigration(old)\n// Right(Person(\"John Doe\", 0))\n```\n\n---\n\n## Success Criteria\n\n* [ ] `DynamicMigration` fully serializable\n* [ ] `Migration[A, B]` wraps schemas and actions\n* [ ] All actions path-based via `DynamicOptic`\n* [ ] User API uses selector functions (`S => A`) for \"optics\" on old and new types\n* [ ] Macro validation in `.build` to confirm \"old\" has been migrated to \"new\"\n* [ ] `.buildPartial` supported\n* [ ] Structural reverse implemented\n* [ ] Identity & associativity laws hold\n* [ ] Enum rename / transform supported\n* [ ] Errors include path information\n* [ ] Comprehensive tests\n* [ ] Scala 2.13 and Scala 3.5+ supported\n",
              "url": "https://github.com/zio/zio-blocks/issues/519",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#518",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-18T17:51:53.545Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:53.545Z",
            "created_at": "2026-01-18T17:51:53.545Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#518",
              "status": "open",
              "type": "issue",
              "number": 518,
              "title": "Add `Into[A, B]` and `As[A, B]` Type Classes with Macro Derivation",
              "source": {
                "data": {
                  "id": "source-ZIO#518",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add `Into[A, B]` and `As[A, B]` Type Classes with Macro Derivation",
                  "body": "## Overview\n\nAdd two related type classes for type-safe schema evolution:\n\n1. **`Into[A, B]`**: One-way conversion from `A` to `B` with runtime validation\n2. **`As[A, B]`**: Bidirectional conversion establishing a partial equivalence between `A` and `B`\n\nBoth type classes are automatically derived via macros that intelligently map fields using names, positions, and types, with support for validation, coercion, and schema evolution patterns.\n\n---\n\n## Type Class Definitions\n\n### Into[A, B] - One-Way Conversion\n\n```scala\ntrait Into[-A, +B] {\n  def into(input: A): Either[SchemaError, B]\n}\n```\n\n**Purpose**: Convert from source type `A` to target type `B`, potentially failing at runtime when validation constraints cannot be satisfied.\n\n**Use Cases**:\n- Migrating between schema versions\n- Converting between equivalent representations\n- Validating conversions with opaque types\n- Transforming external data into internal models\n\n### As[A, B] - Bidirectional Conversion\n\n```scala\ntrait As[A, B] {\n  def into(input: A): Either[SchemaError, B]\n  def from(input: B): Either[SchemaError, A]\n}\n```\n\n**Purpose**: Establish a partial equivalence between types `A` and `B` where conversion can fail in either direction due to runtime validation.\n\n**Use Cases**:\n- Isomorphic schema versions\n- Equivalent representations (e.g., case class â†” tuple)\n- Reversible transformations with runtime validation\n- Round-trip serialization/deserialization\n\n**Relationship**: `As[A, B]` implies both `Into[A, B]` and `Into[B, A]` exist, but with the additional guarantee that both conversions use compatible mapping logic and can round-trip (subject to runtime validation).\n\n**Note**: `SchemaError` is composable, allowing multiple validation failures to be combined into a single error.\n\n---\n\n## Core Conversion Rules\n\n### Field Mapping Algorithm\n\nThe macro establishes field mappings using three attributes:\n1. **Field name** (identifier in source code)\n2. **Field position** (ordinal position in declaration)\n3. **Field type** (including coercible types)\n\n**Priority for disambiguation:**\n1. **Exact match**: Same name + same type\n2. **Name match with coercion**: Same name + coercible type\n3. **Unique type match**: Type appears only once in both source and target\n4. **Position + unique type**: Positional correspondence with unambiguous type\n5. **Fallback**: If no unambiguous mapping exists, derivation fails at compile-time\n\n### Mapping Examples\n\n#### Unambiguous by Unique Types\n```scala\ncase class Person(name: String, age: Int, active: Boolean)\ncase class User(username: String, yearsOld: Int, enabled: Boolean)\n\n// Success: Each type appears exactly once\n// Mapping: Stringâ†’String, Intâ†’Int, Booleanâ†’Boolean\n```\n\n#### Unambiguous by Names\n```scala\ncase class Point(x: Int, y: Int)\ncase class Coord(y: Int, x: Int)\n\n// Success: Names uniquely identify despite reordering\n// Mapping: xâ†’x, yâ†’y\n```\n\n#### Ambiguous - Compile Failure\n```scala\ncase class Dimensions(width: Int, height: Int)\ncase class Measurements(first: Int, second: Int)\n\n// COMPILE ERROR: Cannot determine mapping\n// Both Int types, different names, ambiguous positional match\n```\n\n#### Disambiguation by Position (Tuples)\n```scala\ncase class RGB(r: Int, g: Int, b: Int)\ntype ColorTuple = (Int, Int, Int)\n\n// Success: Position disambiguates\n// Mapping: râ†’_1, gâ†’_2, bâ†’_3\n```\n\n---\n\n## Supported Conversions\n\n### 1. Product Types (Records)\n\n#### Case Class to Case Class\n```scala\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(fullName: String, age: Int)\n\n// Success if 'name' is unique String in V1 and 'fullName' is unique String in V2\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30))\n// => Right(PersonV2(\"Alice\", 30))\n```\n\n#### Case Class to Tuple\n```scala\ncase class Point(x: Double, y: Double)\n\nInto[Point, (Double, Double)].into(Point(1.0, 2.0))\n// => Right((1.0, 2.0))\n```\n\n#### Tuple to Case Class\n```scala\ncase class RGB(red: Int, green: Int, blue: Int)\n\nInto[(Int, Int, Int), RGB].into((255, 128, 64))\n// => Right(RGB(255, 128, 64))\n```\n\n#### Tuple to Tuple\n```scala\nInto[(Int, String), (Long, String)].into((42, \"hello\"))\n// => Right((42L, \"hello\"))\n```\n\n### 2. Coproduct Types (Sum Types)\n\n#### Sealed Trait to Sealed Trait (by name)\n```scala\nsealed trait Color\ncase object Red extends Color\ncase object Blue extends Color\n\nsealed trait Hue\ncase object Red extends Hue\ncase object Blue extends Hue\n\nInto[Color, Hue].into(Red)\n// => Right(Red)\n```\n\n#### Sealed Trait to Sealed Trait (by signature)\n```scala\nsealed trait EventV1\ncase class Created(id: String, ts: Long) extends EventV1\ncase class Deleted(id: String) extends EventV1\n\nsealed trait EventV2\ncase class Spawned(id: String, ts: Long) extends EventV2\ncase class Removed(id: String) extends EventV2\n\nInto[EventV1, EventV2].into(Created(\"abc\", 123L))\n// => Right(Spawned(\"abc\", 123L))\n// Matched by constructor signature (String, Long)\n```\n\n#### Enum to Enum (Scala 3)\n```scala\nenum Status:\n  case Active, Inactive, Suspended\n\nenum State:\n  case Active, Inactive, Suspended\n\nInto[Status, State].into(Status.Active)\n// => Right(State.Active)\n```\n\n#### ADT with Payload Conversion\n```scala\nsealed trait ResultV1\ncase class Success(value: Int) extends ResultV1\ncase class Failure(msg: String) extends ResultV1\n\nsealed trait ResultV2\ncase class Success(value: Long) extends ResultV2\ncase class Failure(msg: String) extends ResultV2\n\nInto[ResultV1, ResultV2].into(Success(42))\n// => Right(Success(42L))\n// Field type coercion within matched case\n```\n\n### 3. Primitive Type Coercions\n\n#### Numeric Widening (Lossless)\n```scala\nInto[Byte, Short].into(42.toByte)    // => Right(42.toShort)\nInto[Short, Int].into(1000.toShort)  // => Right(1000)\nInto[Int, Long].into(100000)         // => Right(100000L)\nInto[Float, Double].into(3.14f)      // => Right(3.14)\n```\n\n#### Numeric Narrowing (with Runtime Validation)\n```scala\nInto[Long, Int].into(42L)\n// => Right(42)\n\nInto[Long, Int].into(3000000000L)\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n\nInto[Double, Float].into(3.14)\n// => Right(3.14f)\n\nInto[Double, Float].into(1e100)\n// => Left(SchemaError(\"Value 1.0E100 exceeds Float.MaxValue\"))\n```\n\n#### Collection Element Coercion\n```scala\nInto[List[Int], List[Long]].into(List(1, 2, 3))\n// => Right(List(1L, 2L, 3L))\n\nInto[Vector[Float], Vector[Double]].into(Vector(1.5f, 2.5f))\n// => Right(Vector(1.5, 2.5))\n\nInto[Set[Short], Set[Int]].into(Set(10.toShort, 20.toShort))\n// => Right(Set(10, 20))\n\nInto[List[Long], List[Int]].into(List(42L, 3000000000L))\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n```\n\n#### Nested Collection Coercion\n```scala\nInto[List[List[Int]], List[List[Long]]].into(List(List(1, 2), List(3, 4)))\n// => Right(List(List(1L, 2L), List(3L, 4L)))\n```\n\n#### Map Key/Value Coercion\n```scala\nInto[Map[Int, Float], Map[Long, Double]].into(Map(1 -> 1.5f, 2 -> 2.5f))\n// => Right(Map(1L -> 1.5, 2L -> 2.5))\n\nInto[Map[Long, String], Map[Int, String]].into(Map(42L -> \"a\", 3000000000L -> \"b\"))\n// => Left(SchemaError(\"Key 3000000000 exceeds Int.MaxValue\"))\n```\n\n#### Option Type Coercion\n```scala\nInto[Option[Int], Option[Long]].into(Some(42))\n// => Right(Some(42L))\n\nInto[Option[Int], Option[Long]].into(None)\n// => Right(None)\n\nInto[Option[Long], Option[Int]].into(Some(3000000000L))\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n```\n\n#### Either Type Coercion\n```scala\nInto[Either[String, Int], Either[String, Long]].into(Right(42))\n// => Right(Right(42L))\n\nInto[Either[Int, String], Either[Long, String]].into(Left(100))\n// => Right(Left(100L))\n```\n\n### 4. Collection Type Conversions\n\n#### Between Standard Collection Types\n```scala\nInto[List[Int], Vector[Int]].into(List(1, 2, 3))\n// => Right(Vector(1, 2, 3))\n\nInto[Vector[String], List[String]].into(Vector(\"a\", \"b\", \"c\"))\n// => Right(List(\"a\", \"b\", \"c\"))\n\nInto[Array[Int], List[Int]].into(Array(1, 2, 3))\n// => Right(List(1, 2, 3))\n\nInto[List[Int], Array[Int]].into(List(1, 2, 3))\n// => Right(Array(1, 2, 3))\n\nInto[Seq[Int], List[Int]].into(Seq(1, 2, 3))\n// => Right(List(1, 2, 3))\n\nInto[List[Int], Seq[Int]].into(List(1, 2, 3))\n// => Right(Seq(1, 2, 3))\n```\n\n#### Set Conversions (Order-Preserving Collections to Set)\n```scala\nInto[List[Int], Set[Int]].into(List(1, 2, 2, 3))\n// => Right(Set(1, 2, 3))\n// Note: Duplicates are removed\n\nInto[Vector[String], Set[String]].into(Vector(\"a\", \"b\", \"a\"))\n// => Right(Set(\"a\", \"b\"))\n```\n\n#### Set to Order-Preserving Collections\n```scala\nInto[Set[Int], List[Int]].into(Set(3, 1, 2))\n// => Right(List(1, 2, 3))\n// Note: Order is determined by Set's iteration order\n\nInto[Set[String], Vector[String]].into(Set(\"c\", \"a\", \"b\"))\n// => Right(Vector(\"a\", \"b\", \"c\"))\n```\n\n#### Combined Element and Collection Type Conversion\n```scala\nInto[List[Int], Vector[Long]].into(List(1, 2, 3))\n// => Right(Vector(1L, 2L, 3L))\n\nInto[Array[Short], List[Int]].into(Array(10.toShort, 20.toShort))\n// => Right(List(10, 20))\n\nInto[Set[Int], List[Long]].into(Set(1, 2, 3))\n// => Right(List(1L, 2L, 3L))\n```\n\n#### Nested Collection Type Conversions\n```scala\nInto[List[Vector[Int]], Vector[List[Long]]].into(List(Vector(1, 2), Vector(3, 4)))\n// => Right(Vector(List(1L, 2L), List(3L, 4L)))\n```\n\n### 5. Structural Types\n\n#### Structural Type Targets (Scala 3 with Selectable)\n```scala\ncase class Point(x: Int, y: Int)\ntype Coord = { def x: Int; def y: Int }\n\nInto[Point, Coord].into(Point(5, 10))\n// => Right(<structural instance with x=5, y=10>)\n```\n\n#### Structural Type Targets (Scala 2 with Dynamic)\n```scala\ncase class Person(name: String, age: Int)\ntype Record = { def name: String; def age: Int }\n\nInto[Person, Record].into(Person(\"Alice\", 30))\n// => Right(<dynamic instance with name=\"Alice\", age=30>)\n```\n\n#### Structural Type Sources\n```scala\ntype PersonLike = { def name: String; def age: Int }\ncase class User(name: String, age: Int)\n\nval personLike: PersonLike = ??? // some structural instance\nInto[PersonLike, User].into(personLike)\n// => Right(User(\"Alice\", 30))\n```\n\n### 6. Schema Evolution Patterns\n\n#### Adding Optional Fields\n```scala\ncase class UserV1(id: String, name: String)\ncase class UserV2(id: String, name: String, email: Option[String])\n\nInto[UserV1, UserV2].into(UserV1(\"123\", \"Alice\"))\n// => Right(UserV2(\"123\", \"Alice\", None))\n```\n\n#### Removing Optional Fields\n```scala\ncase class UserV2(id: String, name: String, email: Option[String])\ncase class UserV1(id: String, name: String)\n\nInto[UserV2, UserV1].into(UserV2(\"123\", \"Alice\", Some(\"alice@example.com\")))\n// => Right(UserV1(\"123\", \"Alice\"))\n// email field is dropped\n```\n\n#### Adding Required Fields with Defaults (Scala 3)\n```scala\ncase class ProductV1(name: String, price: Double)\ncase class ProductV2(name: String, price: Double, available: Boolean = true)\n\nInto[ProductV1, ProductV2].into(ProductV1(\"Widget\", 19.99))\n// => Right(ProductV2(\"Widget\", 19.99, true))\n```\n\n#### Field Reordering\n```scala\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(email: String, name: String, age: Int)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"alice@example.com\"))\n// => Right(PersonV2(\"alice@example.com\", \"Alice\", 30))\n```\n\n#### Field Renaming (with unique types)\n```scala\ncase class PersonV1(fullName: String, yearOfBirth: Int)\ncase class PersonV2(name: String, birthYear: Int)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice Smith\", 1990))\n// => Right(PersonV2(\"Alice Smith\", 1990))\n```\n\n#### Type Refinement\n```scala\ncase class ConfigV1(port: Int, timeout: Int)\ncase class ConfigV2(port: Int, timeout: Long)\n\nInto[ConfigV1, ConfigV2].into(ConfigV1(8080, 30))\n// => Right(ConfigV2(8080, 30L))\n```\n\n### 7. Nested Conversions\n\n#### Nested Products\n```scala\ncase class AddressV1(street: String, zip: Int)\ncase class PersonV1(name: String, address: AddressV1)\n\ncase class AddressV2(street: String, zip: Long)\ncase class PersonV2(name: String, address: AddressV2)\n\nInto[PersonV1, PersonV2].into(\n  PersonV1(\"Alice\", AddressV1(\"Main St\", 12345))\n)\n// => Right(PersonV2(\"Alice\", AddressV2(\"Main St\", 12345L)))\n```\n\n#### Nested Coproducts\n```scala\nsealed trait Inner\ncase class A(x: Int) extends Inner\ncase class B(y: String) extends Inner\n\nsealed trait Outer\ncase class Container(inner: Inner, label: String) extends Outer\n\n// Similar target types with Long instead of Int\nsealed trait InnerV2\ncase class A(x: Long) extends InnerV2\ncase class B(y: String) extends InnerV2\n\nsealed trait OuterV2\ncase class Container(inner: InnerV2, label: String) extends OuterV2\n\nInto[Outer, OuterV2].into(Container(A(42), \"test\"))\n// => Right(Container(A(42L), \"test\"))\n```\n\n#### Collections of Complex Types\n```scala\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(name: String, age: Long)\n\nInto[List[PersonV1], List[PersonV2]].into(\n  List(PersonV1(\"Alice\", 30), PersonV1(\"Bob\", 25))\n)\n// => Right(List(PersonV2(\"Alice\", 30L), PersonV2(\"Bob\", 25L)))\n```\n\n#### Nested Collections with Type Conversions\n```scala\ncase class DataV1(values: List[Vector[Int]])\ncase class DataV2(values: Vector[List[Long]])\n\nInto[DataV1, DataV2].into(\n  DataV1(List(Vector(1, 2), Vector(3, 4)))\n)\n// => Right(DataV2(Vector(List(1L, 2L), List(3L, 4L))))\n```\n\n---\n\n## Special Type Support\n\n### Opaque Types (Scala 3)\n\nOpaque types with validation are fully supported. The macro generates runtime validation calls.\n\n```scala\n// Definition with validation\nobject Domain:\n  opaque type Age = Int\n  object Age:\n    def apply(value: Int): Either[String, Age] =\n      if value >= 0 && value <= 150 then Right(value)\n      else Left(s\"Invalid age: $value\")\n    \n    def unsafe(value: Int): Age = value\n    \n    extension (age: Age)\n      def toInt: Int = age\n\n  opaque type Email = String\n  object Email:\n    def apply(value: String): Either[String, Email] =\n      if value.contains(\"@\") then Right(value)\n      else Left(s\"Invalid email: $value\")\n    \n    extension (email: Email)\n      def toString: String = email\n\nimport Domain._\n\n// Usage\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(name: String, age: Age, email: Email)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"alice@example.com\"))\n// => Right(PersonV2(\"Alice\", Age.unsafe(30), Email.unsafe(\"alice@example.com\")))\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", -5, \"alice@example.com\"))\n// => Left(SchemaError(\"Age validation failed: Invalid age: -5\"))\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"invalid\"))\n// => Left(SchemaError(\"Email validation failed: Invalid email: invalid\"))\n```\n\n**Macro Behavior**:\n- Detects opaque type companion objects with `apply(underlying): Either[_, OpaqueType]` method\n- Generates validation calls for each opaque type field\n- Accumulates all validation errors using `SchemaError` composition\n- Falls back to direct conversion if no validation method exists\n\n### Newtype Libraries (Scala 2)\n\n#### ZIO Prelude Newtypes (Built-in Support)\n\nThe macro includes hardcoded support for ZIO Prelude newtypes without requiring a compile-time dependency.\n\n```scala\nimport zio.prelude._\n\n// Definition with validation\nobject Domain {\n  object Age extends Subtype[Int] {\n    override def assertion = assert {\n      Assertion.between(0, 150)\n    }\n  }\n  type Age = Age.Type\n\n  object Email extends Newtype[String] {\n    override def assertion = assert {\n      Assertion.matches(\".*@.*\")\n    }\n  }\n  type Email = Email.Type\n}\n\nimport Domain._\n\n// Usage\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(name: String, age: Age, email: Email)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"alice@example.com\"))\n// => Right(PersonV2(\"Alice\", Age(30), Email(\"alice@example.com\")))\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 200, \"invalid\"))\n// => Left(SchemaError(\"Validation failed: age: 200 is not between 0 and 150, email: invalid does not match .*@.*\"))\n```\n\n**Macro Detection** (no ZIO Prelude dependency required):\n```scala\n// The macro detects ZIO Prelude newtypes by checking:\n// 1. Type extends Newtype[A] or Subtype[A]\n// 2. Companion object exists\n// 3. Has apply/wrap method with validation\n\n// Low-level AST matching in Scala 2 macro:\ndef isZIONewtype(tpe: Type): Boolean = {\n  tpe.typeSymbol.fullName.startsWith(\"zio.prelude.Newtype\") ||\n  tpe.typeSymbol.fullName.startsWith(\"zio.prelude.Subtype\")\n}\n```\n\n#### Other Newtype Libraries\n\nFor other newtype libraries, users can provide explicit `Into` instances. The macro will use these instances when available.\n\n```scala\n// User-provided instance for their newtype library\nimplicit val stringToMyNewtype: Into[String, MyNewtype] = \n  new Into[String, MyNewtype] {\n    def into(s: String): Either[SchemaError, MyNewtype] =\n      MyNewtype.make(s).left.map(e => SchemaError(e.toString))\n  }\n\n// The macro will automatically use this instance\ncase class PersonV1(email: String)\ncase class PersonV2(email: MyNewtype)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"test@example.com\"))\n// Uses the user-provided instance automatically\n```\n\n### Validation Error Accumulation\n\nWhen multiple validations fail, all errors are accumulated using `SchemaError` composition:\n\n```scala\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(name: String, age: Age, email: Email)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"\", -5, \"invalid\"))\n// => Left(SchemaError(...)) // Combined error containing all validation failures\n```\n\n---\n\n## As[A, B] Additional Requirements\n\nFor `As[A, B]` to be derivable, the bidirectional conversion must be **compatible**:\n\n### Compatibility Rules\n\n1. **Field mappings must be consistent**: The same field correspondence in both directions\n2. **Coercions must be invertible with runtime validation**: \n   - âœ… `Int` â†” `Long` is valid (narrowing validated at runtime)\n   - âœ… `Float` â†” `Double` is valid (narrowing validated at runtime)\n   - âœ… All numeric coercions are valid with runtime checks\n3. **Optional fields**: \n   - âœ… Can add optional fields in one direction (becomes `None` in reverse)\n   - âœ… Can remove optional fields in one direction (value is dropped)\n4. **Default values**:\n   - âŒ Cannot use default arguments (breaks round-trip guarantee)\n5. **Collection types**:\n   - âœ… Can convert between different collection types\n   - âš ï¸  Set â†’ List â†’ Set may not preserve original order\n   - âš ï¸  List â†’ Set â†’ List loses duplicates\n\n### Valid As[A, B] Examples\n\n```scala\n// Valid: Same structure, different names\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(fullName: String, yearsOld: Int)\n\nAs[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30))\n// => Right(PersonV2(\"Alice\", 30))\n\nAs[PersonV1, PersonV2].from(PersonV2(\"Bob\", 25))\n// => Right(PersonV1(\"Bob\", 25))\n```\n\n```scala\n// Valid: Case class â†” Tuple\ncase class Point(x: Double, y: Double)\n\nAs[Point, (Double, Double)].into(Point(1.0, 2.0))\n// => Right((1.0, 2.0))\n\nAs[Point, (Double, Double)].from((3.0, 4.0))\n// => Right(Point(3.0, 4.0))\n```\n\n```scala\n// Valid: Numeric coercion with runtime validation\ncase class ConfigV1(timeout: Int)\ncase class ConfigV2(timeout: Long)\n\nAs[ConfigV1, ConfigV2].into(ConfigV1(30))\n// => Right(ConfigV2(30L))\n\nAs[ConfigV1, ConfigV2].from(ConfigV2(30L))\n// => Right(ConfigV1(30))\n\nAs[ConfigV1, ConfigV2].from(ConfigV2(3000000000L))\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n```\n\n```scala\n// Valid: Opaque types (reversible via unwrap)\ncase class PersonRaw(name: String, age: Int)\ncase class PersonValidated(name: String, age: Age)\n\nAs[PersonRaw, PersonValidated].into(PersonRaw(\"Alice\", 30))\n// => Right(PersonValidated(\"Alice\", Age.unsafe(30)))\n\nAs[PersonRaw, PersonValidated].from(PersonValidated(\"Bob\", Age.unsafe(25)))\n// => Right(PersonRaw(\"Bob\", 25))\n\nAs[PersonRaw, PersonValidated].into(PersonRaw(\"Charlie\", -5))\n// => Left(SchemaError(\"Age validation failed: Invalid age: -5\"))\n```\n\n```scala\n// Valid: Collection type conversions\ncase class DataV1(items: List[Int])\ncase class DataV2(items: Vector[Int])\n\nAs[DataV1, DataV2].into(DataV1(List(1, 2, 3)))\n// => Right(DataV2(Vector(1, 2, 3)))\n\nAs[DataV1, DataV2].from(DataV2(Vector(4, 5, 6)))\n// => Right(DataV1(List(4, 5, 6)))\n```\n\n```scala\n// Valid: Optional field in one direction\ncase class UserV1(id: String, name: String)\ncase class UserV2(id: String, name: String, email: Option[String])\n\nAs[UserV1, UserV2].into(UserV1(\"123\", \"Alice\"))\n// => Right(UserV2(\"123\", \"Alice\", None))\n\nAs[UserV1, UserV2].from(UserV2(\"456\", \"Bob\", Some(\"bob@example.com\")))\n// => Right(UserV1(\"456\", \"Bob\"))\n// email is dropped in reverse direction\n```\n\n### Non-Ideal As[A, B] Examples (Valid but Lossy)\n\n```scala\n// Valid but lossy: List with duplicates â†’ Set â†’ List\ncase class DataV1(values: List[Int])\ncase class DataV2(values: Set[Int])\n\nAs[DataV1, DataV2].into(DataV1(List(1, 2, 2, 3)))\n// => Right(DataV2(Set(1, 2, 3)))\n\nAs[DataV1, DataV2].from(DataV2(Set(1, 2, 3)))\n// => Right(DataV1(List(1, 2, 3)))\n// Original duplicates are lost, but conversion is valid\n```\n\n```scala\n// Valid but lossy: Set â†’ List â†’ Set (order may change)\ncase class DataV1(values: Set[Int])\ncase class DataV2(values: List[Int])\n\nval original = DataV1(Set(3, 1, 2))\nval converted = As[DataV1, DataV2].into(original).right.get\n// converted.values might be List(1, 2, 3) depending on Set iteration order\n\nval roundTrip = As[DataV1, DataV2].from(converted).right.get\n// roundTrip.values == Set(1, 2, 3) - same elements, possibly different internal order\n```\n\n### Invalid As[A, B] Examples\n\n```scala\n// Invalid: Default values break round-trip guarantee\ncase class ProductV1(name: String, price: Double)\ncase class ProductV2(name: String, price: Double, taxable: Boolean = true)\n\n// COMPILE ERROR: Cannot derive As[ProductV1, ProductV2]\n// Reason: Default value for 'taxable' cannot be recovered in reverse direction\n// (We can't distinguish between explicitly set 'true' and default 'true')\n```\n\n---\n\n## Testing Requirements\n\n### Test Matrix Dimensions\n\n1. **Type Combinations** (both `Into` and `As`)\n   - Primitive â†’ Primitive (all coercion pairs, including narrowing)\n   - Product â†’ Product (case classes)\n   - Product â†’ Tuple\n   - Tuple â†’ Product\n   - Tuple â†’ Tuple\n   - Coproduct â†’ Coproduct (sealed traits, enums)\n   - Collection[A] â†’ Collection[B] (List, Vector, Set, Map, Option, Either, Array, Seq)\n   - Collection type conversions (List â†” Vector â†” Set â†” Array â†” Seq)\n   - Nested conversions\n   - Structural types\n\n2. **Disambiguation Scenarios**\n   - Unique types (names irrelevant)\n   - Matching names (types irrelevant with coercion)\n   - Duplicate types with name disambiguation\n   - Duplicate types with position disambiguation\n   - Ambiguous cases (must fail at compile-time)\n\n3. **Schema Evolution**\n   - Field reordering\n   - Field renaming (with unique types)\n   - Adding optional fields\n   - Removing optional fields\n   - Type refinement (Int â†’ Long, with narrowing validation)\n   - Adding default values (Scala 3)\n\n4. **Validation** (Scala 3 opaque types)\n   - Valid values pass through\n   - Invalid values produce SchemaError\n   - Multiple validation failures accumulate\n   - Nested validation in products\n   - Validation in coproduct cases\n   - Validation in collections\n   - Narrowing conversions (Long â†’ Int with overflow check)\n\n5. **Validation** (Scala 2 ZIO Prelude newtypes)\n   - Newtype validation success\n   - Newtype validation failure\n   - Subtype validation with assertions\n   - Multiple newtype fields\n\n6. **Collection Type Conversions**\n   - List â†” Vector\n   - List â†” Array\n   - List â†” Set (with duplicate handling)\n   - List â†” Seq\n   - Vector â†” Set\n   - Array â†” Vector\n   - All combinations with element type coercion\n   - Nested collection type conversions\n\n7. **Runtime Validation** (for `As[A, B]`)\n   - Numeric narrowing validation\n   - Round-trip with valid narrowing\n   - Round-trip failure with overflow\n   - Collection conversions with duplicates\n   - Optional field round-trips\n\n8. **Error Cases**\n   - Ambiguous field mapping (compile error)\n   - Ambiguous case mapping (compile error)\n   - Default value in `As` (compile error)\n   - Runtime validation failures\n   - Type mismatch (compile error)\n   - Overflow in narrowing conversions\n\n9. **Edge Cases**\n   - Empty case classes\n   - Single-field case classes\n   - Case objects\n   - Sealed traits with case objects only\n   - Deeply nested structures (5+ levels)\n   - Large products (20+ fields)\n   - Large coproducts (20+ cases)\n   - Recursive types (e.g., `case class Tree(value: Int, children: List[Tree])`)\n   - Mutually recursive types\n\n### Test Organization\n\n```\nsrc/test/scala/\n  into/\n    products/\n      CaseClassToCaseClassSpec.scala\n      CaseClassToTupleSpec.scala\n      TupleToCaseClassSpec.scala\n      TupleToTupleSpec.scala\n      FieldReorderingSpec.scala\n      FieldRenamingSpec.scala\n      NestedProductsSpec.scala\n    coproducts/\n      SealedTraitToSealedTraitSpec.scala\n      EnumToEnumSpec.scala (Scala 3 only)\n      CaseMatchingSpec.scala\n      SignatureMatchingSpec.scala\n      AmbiguousCaseSpec.scala\n      NestedCoproductsSpec.scala\n    primitives/\n      NumericWideningSpec.scala\n      NumericNarrowingSpec.scala\n      CollectionCoercionSpec.scala\n      OptionCoercionSpec.scala\n      EitherCoercionSpec.scala\n      NestedCollectionSpec.scala\n    collections/\n      ListToVectorSpec.scala\n      ListToSetSpec.scala\n      VectorToArraySpec.scala\n      CollectionTypeWithCoercionSpec.scala\n      NestedCollectionTypeSpec.scala\n      SetDuplicateHandlingSpec.scala\n    structural/\n      StructuralTypeTargetSpec.scala (Scala 3 Selectable)\n      DynamicTypeTargetSpec.scala (Scala 2 Dynamic)\n      StructuralTypeSourceSpec.scala\n    validation/\n      OpaqueTypeValidationSpec.scala (Scala 3 only)\n      ZIONewtypeValidationSpec.scala (Scala 2 only)\n      ValidationErrorAccumulationSpec.scala\n      NestedValidationSpec.scala\n      NarrowingValidationSpec.scala\n    evolution/\n      AddOptionalFieldSpec.scala\n      RemoveOptionalFieldSpec.scala\n      TypeRefinementSpec.scala\n      AddDefaultFieldSpec.scala (Scala 3 only)\n    disambiguation/\n      UniqueTypeDisambiguationSpec.scala\n      NameDisambiguationSpec.scala\n      PositionDisambiguationSpec.scala\n      AmbiguousCompileErrorSpec.scala\n    edge/\n      EmptyProductSpec.scala\n      SingleFieldSpec.scala\n      CaseObjectSpec.scala\n      DeepNestingSpec.scala\n      LargeProductSpec.scala\n      LargeCoproductSpec.scala\n      RecursiveTypeSpec.scala\n      MutuallyRecursiveTypeSpec.scala\n  \n  as/\n    reversibility/\n      RoundTripProductSpec.scala\n      RoundTripCoproductSpec.scala\n      RoundTripTupleSpec.scala\n      RoundTripCollectionTypeSpec.scala\n      OpaqueTypeRoundTripSpec.scala\n      NumericNarrowingRoundTripSpec.scala\n      OptionalFieldRoundTripSpec.scala\n    validation/\n      OverflowDetectionSpec.scala\n      NarrowingFailureSpec.scala\n      CollectionLossyConversionSpec.scala\n    compile_errors/\n      DefaultValueSpec.scala\n    (similar structure to into/ for applicable tests)\n```\n\n### Specific Test Cases\n\n#### Disambiguation Tests\n\n```scala\n// Test: Unique types make names irrelevant\ncase class A(x: String, y: Int, z: Boolean)\ncase class B(a: String, b: Int, c: Boolean)\nassert(Into[A, B].into(A(\"test\", 42, true)) == Right(B(\"test\", 42, true)))\n\n// Test: Names disambiguate duplicate types\ncase class Point(x: Int, y: Int)\ncase class Coord(y: Int, x: Int)\nassert(Into[Point, Coord].into(Point(1, 2)) == Right(Coord(2, 1)))\n\n// Test: Ambiguous mapping fails at compile-time\ncase class Dim(width: Int, height: Int)\ncase class Measure(first: Int, second: Int)\n// Must not compile: Into[Dim, Measure]\nassertDoesNotCompile(\"Into[Dim, Measure]\")\n```\n\n#### Numeric Narrowing Validation Tests\n\n```scala\n// Test: Valid narrowing conversion\ncase class V1(value: Long)\ncase class V2(value: Int)\nassert(Into[V1, V2].into(V1(42L)) == Right(V2(42)))\n\n// Test: Invalid narrowing (overflow)\nassert(Into[V1, V2].into(V1(3000000000L)).isLeft)\n\n// Test: Narrowing in collections\ncase class Data1(values: List[Long])\ncase class Data2(values: List[Int])\nassert(Into[Data1, Data2].into(Data1(List(1L, 2L, 3L))) == Right(Data2(List(1, 2, 3))))\nassert(Into[Data1, Data2].into(Data1(List(1L, 3000000000L))).isLeft)\n```\n\n#### Collection Type Conversion Tests\n\n```scala\n// Test: List to Vector\ncase class A(items: List[Int])\ncase class B(items: Vector[Int])\nassert(Into[A, B].into(A(List(1, 2, 3))) == Right(B(Vector(1, 2, 3))))\n\n// Test: List to Set (removes duplicates)\ncase class C(items: List[Int])\ncase class D(items: Set[Int])\nassert(Into[C, D].into(C(List(1, 2, 2, 3))) == Right(D(Set(1, 2, 3))))\n\n// Test: Vector to Array\ncase class E(items: Vector[String])\ncase class F(items: Array[String])\nval result = Into[E, F].into(E(Vector(\"a\", \"b\")))\nassert(result.isRight)\nassert(result.right.get.items.sameElements(Array(\"a\", \"b\")))\n\n// Test: Combined collection and element coercion\ncase class G(items: List[Int])\ncase class H(items: Vector[Long])\nassert(Into[G, H].into(G(List(1, 2, 3))) == Right(H(Vector(1L, 2L, 3L))))\n```\n\n#### Validation Tests (Scala 3)\n\n```scala\n// Test: Valid opaque type conversion\ncase class Raw(age: Int)\ncase class Validated(age: Age)\nassert(Into[Raw, Validated].into(Raw(30)).isRight)\n\n// Test: Invalid opaque type conversion\nassert(Into[Raw, Validated].into(Raw(-5)).isLeft)\n\n// Test: Multiple validation failures accumulate\ncase class RawPerson(age: Int, email: String)\ncase class ValidPerson(age: Age, email: Email)\nval result = Into[RawPerson, ValidPerson].into(RawPerson(-5, \"invalid\"))\nassert(result.isLeft)\n// SchemaError contains both validation failures\n```\n\n#### Round-Trip Tests (As)\n\n```scala\n// Test: Case class round-trip\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(fullName: String, yearsOld: Int)\n\nval v1 = PersonV1(\"Alice\", 30)\nval v2 = As[PersonV1, PersonV2].into(v1).right.get\nval roundTrip = As[PersonV1, PersonV2].from(v2).right.get\n\nassert(roundTrip == v1)\n\n// Test: Numeric narrowing round-trip (valid)\ncase class ConfigV1(timeout: Int)\ncase class ConfigV2(timeout: Long)\n\nval config1 = ConfigV1(30)\nval config2 = As[ConfigV1, ConfigV2].into(config1).right.get\nval back = As[ConfigV1, ConfigV2].from(config2).right.get\n\nassert(back == config1)\n\n// Test: Numeric narrowing round-trip (overflow failure)\nval config2Overflow = ConfigV2(3000000000L)\nassert(As[ConfigV1, ConfigV2].from(config2Overflow).isLeft)\n\n// Test: Collection type round-trip\ncase class Data1(items: List[Int])\ncase class Data2(items: Vector[Int])\n\nval data1 = Data1(List(1, 2, 3))\nval data2 = As[Data1, Data2].into(data1).right.get\nval backToData1 = As[Data1, Data2].from(data2).right.get\n\nassert(backToData1 == data1)\n\n// Test: Lossy collection round-trip (Set loses duplicates)\ncase class WithDuplicates(items: List[Int])\ncase class NoDuplicates(items: Set[Int])\n\nval original = WithDuplicates(List(1, 2, 2, 3))\nval asSet = As[WithDuplicates, NoDuplicates].into(original).right.get\nval backToList = As[WithDuplicates, NoDuplicates].from(asSet).right.get\n\nassert(asSet.items == Set(1, 2, 3))\nassert(backToList.items.toSet == Set(1, 2, 3)) // Order may differ, duplicates lost\n```\n\n#### Edge Case Tests\n\n```scala\n// Test: Empty case class\ncase class Empty()\nassert(Into[Empty, Empty].into(Empty()) == Right(Empty()))\n\n// Test: Large product (21 fields)\ncase class Large21(f1: Int, f2: Int, /* ... */, f21: Int)\ncase class Large21V2(f1: Long, f2: Long, /* ... */, f21: Long)\n// Must compile and work correctly\n\n// Test: Recursive type\ncase class Tree(value: Int, children: List[Tree])\ncase class TreeV2(value: Long, children: List[TreeV2])\nval tree = Tree(1, List(Tree(2, Nil), Tree(3, Nil)))\nval treeV2 = Into[Tree, TreeV2].into(tree).right.get\nassert(treeV2.value == 1L)\nassert(treeV2.children.head.value == 2L)\n\n// Test: Mutually recursive types\ncase class Node(id: Int, edges: List[Edge])\ncase class Edge(from: Int, to: Node)\ncase class NodeV2(id: Long, edges: List[EdgeV2])\ncase class EdgeV2(from: Long, to: NodeV2)\n// Must compile and handle mutual recursion\n```\n\n---\n\n## Implementation Signatures\n\n### Scala 3.5\n\n```scala\npackage zio.blocks.schema\n\nimport scala.quoted.*\n\n// One-way conversion\ntrait Into[-A, +B] {\n  def into(input: A): Either[SchemaError, B]\n}\n\nobject Into {\n  inline given [A, B]: Into[A, B] = ${intoMacro[A, B]}\n  \n  private def intoMacro[A: Type, B: Type](using Quotes): Expr[Into[A, B]] = {\n    import quotes.reflect.*\n    // Implementation:\n    // 1. Analyze types A and B\n    // 2. Build field mapping using disambiguation algorithm\n    // 3. Detect opaque types and generate validation calls\n    // 4. Generate narrowing validation for numeric coercions\n    // 5. Handle collection type conversions\n    // 6. Generate conversion code\n    // 7. Handle nested conversions recursively\n    ???\n  }\n}\n\n// Bidirectional conversion\ntrait As[A, B] {\n  def into(input: A): Either[SchemaError, B]\n  def from(input: B): Either[SchemaError, A]\n}\n\nobject As {\n  inline given [A, B]: As[A, B] = ${asMacro[A, B]}\n  \n  private def asMacro[A: Type, B: Type](using Quotes): Expr[As[A, B]] = {\n    import quotes.reflect.*\n    // Implementation:\n    // 1. Verify bidirectional compatibility\n    // 2. Check for default values (compile error if found)\n    // 3. Build bidirectional field mapping\n    // 4. Generate both conversion directions with validation\n    // 5. Ensure opaque type wrapping/unwrapping is symmetric\n    // 6. Handle numeric narrowing with runtime validation\n    // 7. Handle collection type conversions bidirectionally\n    ???\n  }\n}\n```\n\n### Scala 2.13\n\n```scala\npackage com.yourorg.schema\n\nimport scala.reflect.macros.blackbox.Context\nimport scala.language.experimental.macros\n\ncase class SchemaError(msg: String) {\n  // SchemaError is composable - can combine multiple errors\n}\n\n// One-way conversion\ntrait Into[-A, +B] {\n  def into(input: A): Either[SchemaError, B]\n}\n\nobject Into {\n  implicit def materializeInto[A, B]: Into[A, B] = macro materializeIntoImpl[A, B]\n  \n  def materializeIntoImpl[A: c.WeakTypeTag, B: c.WeakTypeTag](c: Context): c.Tree = {\n    import c.universe._\n    // Implementation:\n    // 1. Analyze types A and B using reflection\n    // 2. Build field mapping using disambiguation algorithm\n    // 3. Detect ZIO Prelude newtypes via AST pattern matching\n    // 4. Generate narrowing validation for numeric coercions\n    // 5. Handle collection type conversions\n    // 6. Generate conversion code using quasiquotes\n    // 7. Handle nested conversions recursively\n    ???\n  }\n}\n\n// Bidirectional conversion\ntrait As[A, B] {\n  def into(input: A): Either[SchemaError, B]\n  def from(input: B): Either[SchemaError, A]\n}\n\nobject As {\n  implicit def materializeAs[A, B]: As[A, B] = macro materializeAsImpl[A, B]\n  \n  def materializeAsImpl[A: c.WeakTypeTag, B: c.WeakTypeTag](c: Context): c.Tree = {\n    import c.universe._\n    // Implementation:\n    // 1. Verify bidirectional compatibility\n    // 2. Check for default values (compile error if found)\n    // 3. Build bidirectional field mapping\n    // 4. Generate both conversion directions with validation\n    // 5. Ensure newtype wrapping/unwrapping is symmetric\n    // 6. Handle numeric narrowing with runtime validation\n    // 7. Handle collection type conversions bidirectionally\n    ???\n  }\n}\n```\n\n---\n\n## Implementation Notes\n\n### Error Messages\n\nProvide helpful compile-time errors:\n\n```scala\n// Good error message example:\n\"\"\"\nCannot derive Into[PersonV1, PersonV2]: Ambiguous field mapping\n\n  PersonV1(width: Int, height: Int)\n  PersonV2(first: Int, second: Int)\n\nCannot determine unique mapping between fields of type Int.\nConsider:\n  - Using matching field names (width/height)\n  - Making field types unique\n  - Providing an explicit Into instance\n\"\"\"\n```\n\n### Cross-Version Compatibility\n\n- Share test cases between Scala 2 and Scala 3 where possible\n\n---\n\n## Deliverables\n\n1. âœ… `Into[A, B]` trait and macro for Scala 2.13\n2. âœ… `Into[A, B]` trait and macro for Scala 3.5\n3. âœ… `As[A, B]` trait and macro for Scala 2.13\n4. âœ… `As[A, B]` trait and macro for Scala 3.5\n5. âœ… Comprehensive test suite\n6. âœ… Documentation with examples\n",
                  "html_url": "https://github.com/zio/zio-blocks/issues/518"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#518",
              "body": "## Overview\n\nAdd two related type classes for type-safe schema evolution:\n\n1. **`Into[A, B]`**: One-way conversion from `A` to `B` with runtime validation\n2. **`As[A, B]`**: Bidirectional conversion establishing a partial equivalence between `A` and `B`\n\nBoth type classes are automatically derived via macros that intelligently map fields using names, positions, and types, with support for validation, coercion, and schema evolution patterns.\n\n---\n\n## Type Class Definitions\n\n### Into[A, B] - One-Way Conversion\n\n```scala\ntrait Into[-A, +B] {\n  def into(input: A): Either[SchemaError, B]\n}\n```\n\n**Purpose**: Convert from source type `A` to target type `B`, potentially failing at runtime when validation constraints cannot be satisfied.\n\n**Use Cases**:\n- Migrating between schema versions\n- Converting between equivalent representations\n- Validating conversions with opaque types\n- Transforming external data into internal models\n\n### As[A, B] - Bidirectional Conversion\n\n```scala\ntrait As[A, B] {\n  def into(input: A): Either[SchemaError, B]\n  def from(input: B): Either[SchemaError, A]\n}\n```\n\n**Purpose**: Establish a partial equivalence between types `A` and `B` where conversion can fail in either direction due to runtime validation.\n\n**Use Cases**:\n- Isomorphic schema versions\n- Equivalent representations (e.g., case class â†” tuple)\n- Reversible transformations with runtime validation\n- Round-trip serialization/deserialization\n\n**Relationship**: `As[A, B]` implies both `Into[A, B]` and `Into[B, A]` exist, but with the additional guarantee that both conversions use compatible mapping logic and can round-trip (subject to runtime validation).\n\n**Note**: `SchemaError` is composable, allowing multiple validation failures to be combined into a single error.\n\n---\n\n## Core Conversion Rules\n\n### Field Mapping Algorithm\n\nThe macro establishes field mappings using three attributes:\n1. **Field name** (identifier in source code)\n2. **Field position** (ordinal position in declaration)\n3. **Field type** (including coercible types)\n\n**Priority for disambiguation:**\n1. **Exact match**: Same name + same type\n2. **Name match with coercion**: Same name + coercible type\n3. **Unique type match**: Type appears only once in both source and target\n4. **Position + unique type**: Positional correspondence with unambiguous type\n5. **Fallback**: If no unambiguous mapping exists, derivation fails at compile-time\n\n### Mapping Examples\n\n#### Unambiguous by Unique Types\n```scala\ncase class Person(name: String, age: Int, active: Boolean)\ncase class User(username: String, yearsOld: Int, enabled: Boolean)\n\n// Success: Each type appears exactly once\n// Mapping: Stringâ†’String, Intâ†’Int, Booleanâ†’Boolean\n```\n\n#### Unambiguous by Names\n```scala\ncase class Point(x: Int, y: Int)\ncase class Coord(y: Int, x: Int)\n\n// Success: Names uniquely identify despite reordering\n// Mapping: xâ†’x, yâ†’y\n```\n\n#### Ambiguous - Compile Failure\n```scala\ncase class Dimensions(width: Int, height: Int)\ncase class Measurements(first: Int, second: Int)\n\n// COMPILE ERROR: Cannot determine mapping\n// Both Int types, different names, ambiguous positional match\n```\n\n#### Disambiguation by Position (Tuples)\n```scala\ncase class RGB(r: Int, g: Int, b: Int)\ntype ColorTuple = (Int, Int, Int)\n\n// Success: Position disambiguates\n// Mapping: râ†’_1, gâ†’_2, bâ†’_3\n```\n\n---\n\n## Supported Conversions\n\n### 1. Product Types (Records)\n\n#### Case Class to Case Class\n```scala\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(fullName: String, age: Int)\n\n// Success if 'name' is unique String in V1 and 'fullName' is unique String in V2\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30))\n// => Right(PersonV2(\"Alice\", 30))\n```\n\n#### Case Class to Tuple\n```scala\ncase class Point(x: Double, y: Double)\n\nInto[Point, (Double, Double)].into(Point(1.0, 2.0))\n// => Right((1.0, 2.0))\n```\n\n#### Tuple to Case Class\n```scala\ncase class RGB(red: Int, green: Int, blue: Int)\n\nInto[(Int, Int, Int), RGB].into((255, 128, 64))\n// => Right(RGB(255, 128, 64))\n```\n\n#### Tuple to Tuple\n```scala\nInto[(Int, String), (Long, String)].into((42, \"hello\"))\n// => Right((42L, \"hello\"))\n```\n\n### 2. Coproduct Types (Sum Types)\n\n#### Sealed Trait to Sealed Trait (by name)\n```scala\nsealed trait Color\ncase object Red extends Color\ncase object Blue extends Color\n\nsealed trait Hue\ncase object Red extends Hue\ncase object Blue extends Hue\n\nInto[Color, Hue].into(Red)\n// => Right(Red)\n```\n\n#### Sealed Trait to Sealed Trait (by signature)\n```scala\nsealed trait EventV1\ncase class Created(id: String, ts: Long) extends EventV1\ncase class Deleted(id: String) extends EventV1\n\nsealed trait EventV2\ncase class Spawned(id: String, ts: Long) extends EventV2\ncase class Removed(id: String) extends EventV2\n\nInto[EventV1, EventV2].into(Created(\"abc\", 123L))\n// => Right(Spawned(\"abc\", 123L))\n// Matched by constructor signature (String, Long)\n```\n\n#### Enum to Enum (Scala 3)\n```scala\nenum Status:\n  case Active, Inactive, Suspended\n\nenum State:\n  case Active, Inactive, Suspended\n\nInto[Status, State].into(Status.Active)\n// => Right(State.Active)\n```\n\n#### ADT with Payload Conversion\n```scala\nsealed trait ResultV1\ncase class Success(value: Int) extends ResultV1\ncase class Failure(msg: String) extends ResultV1\n\nsealed trait ResultV2\ncase class Success(value: Long) extends ResultV2\ncase class Failure(msg: String) extends ResultV2\n\nInto[ResultV1, ResultV2].into(Success(42))\n// => Right(Success(42L))\n// Field type coercion within matched case\n```\n\n### 3. Primitive Type Coercions\n\n#### Numeric Widening (Lossless)\n```scala\nInto[Byte, Short].into(42.toByte)    // => Right(42.toShort)\nInto[Short, Int].into(1000.toShort)  // => Right(1000)\nInto[Int, Long].into(100000)         // => Right(100000L)\nInto[Float, Double].into(3.14f)      // => Right(3.14)\n```\n\n#### Numeric Narrowing (with Runtime Validation)\n```scala\nInto[Long, Int].into(42L)\n// => Right(42)\n\nInto[Long, Int].into(3000000000L)\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n\nInto[Double, Float].into(3.14)\n// => Right(3.14f)\n\nInto[Double, Float].into(1e100)\n// => Left(SchemaError(\"Value 1.0E100 exceeds Float.MaxValue\"))\n```\n\n#### Collection Element Coercion\n```scala\nInto[List[Int], List[Long]].into(List(1, 2, 3))\n// => Right(List(1L, 2L, 3L))\n\nInto[Vector[Float], Vector[Double]].into(Vector(1.5f, 2.5f))\n// => Right(Vector(1.5, 2.5))\n\nInto[Set[Short], Set[Int]].into(Set(10.toShort, 20.toShort))\n// => Right(Set(10, 20))\n\nInto[List[Long], List[Int]].into(List(42L, 3000000000L))\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n```\n\n#### Nested Collection Coercion\n```scala\nInto[List[List[Int]], List[List[Long]]].into(List(List(1, 2), List(3, 4)))\n// => Right(List(List(1L, 2L), List(3L, 4L)))\n```\n\n#### Map Key/Value Coercion\n```scala\nInto[Map[Int, Float], Map[Long, Double]].into(Map(1 -> 1.5f, 2 -> 2.5f))\n// => Right(Map(1L -> 1.5, 2L -> 2.5))\n\nInto[Map[Long, String], Map[Int, String]].into(Map(42L -> \"a\", 3000000000L -> \"b\"))\n// => Left(SchemaError(\"Key 3000000000 exceeds Int.MaxValue\"))\n```\n\n#### Option Type Coercion\n```scala\nInto[Option[Int], Option[Long]].into(Some(42))\n// => Right(Some(42L))\n\nInto[Option[Int], Option[Long]].into(None)\n// => Right(None)\n\nInto[Option[Long], Option[Int]].into(Some(3000000000L))\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n```\n\n#### Either Type Coercion\n```scala\nInto[Either[String, Int], Either[String, Long]].into(Right(42))\n// => Right(Right(42L))\n\nInto[Either[Int, String], Either[Long, String]].into(Left(100))\n// => Right(Left(100L))\n```\n\n### 4. Collection Type Conversions\n\n#### Between Standard Collection Types\n```scala\nInto[List[Int], Vector[Int]].into(List(1, 2, 3))\n// => Right(Vector(1, 2, 3))\n\nInto[Vector[String], List[String]].into(Vector(\"a\", \"b\", \"c\"))\n// => Right(List(\"a\", \"b\", \"c\"))\n\nInto[Array[Int], List[Int]].into(Array(1, 2, 3))\n// => Right(List(1, 2, 3))\n\nInto[List[Int], Array[Int]].into(List(1, 2, 3))\n// => Right(Array(1, 2, 3))\n\nInto[Seq[Int], List[Int]].into(Seq(1, 2, 3))\n// => Right(List(1, 2, 3))\n\nInto[List[Int], Seq[Int]].into(List(1, 2, 3))\n// => Right(Seq(1, 2, 3))\n```\n\n#### Set Conversions (Order-Preserving Collections to Set)\n```scala\nInto[List[Int], Set[Int]].into(List(1, 2, 2, 3))\n// => Right(Set(1, 2, 3))\n// Note: Duplicates are removed\n\nInto[Vector[String], Set[String]].into(Vector(\"a\", \"b\", \"a\"))\n// => Right(Set(\"a\", \"b\"))\n```\n\n#### Set to Order-Preserving Collections\n```scala\nInto[Set[Int], List[Int]].into(Set(3, 1, 2))\n// => Right(List(1, 2, 3))\n// Note: Order is determined by Set's iteration order\n\nInto[Set[String], Vector[String]].into(Set(\"c\", \"a\", \"b\"))\n// => Right(Vector(\"a\", \"b\", \"c\"))\n```\n\n#### Combined Element and Collection Type Conversion\n```scala\nInto[List[Int], Vector[Long]].into(List(1, 2, 3))\n// => Right(Vector(1L, 2L, 3L))\n\nInto[Array[Short], List[Int]].into(Array(10.toShort, 20.toShort))\n// => Right(List(10, 20))\n\nInto[Set[Int], List[Long]].into(Set(1, 2, 3))\n// => Right(List(1L, 2L, 3L))\n```\n\n#### Nested Collection Type Conversions\n```scala\nInto[List[Vector[Int]], Vector[List[Long]]].into(List(Vector(1, 2), Vector(3, 4)))\n// => Right(Vector(List(1L, 2L), List(3L, 4L)))\n```\n\n### 5. Structural Types\n\n#### Structural Type Targets (Scala 3 with Selectable)\n```scala\ncase class Point(x: Int, y: Int)\ntype Coord = { def x: Int; def y: Int }\n\nInto[Point, Coord].into(Point(5, 10))\n// => Right(<structural instance with x=5, y=10>)\n```\n\n#### Structural Type Targets (Scala 2 with Dynamic)\n```scala\ncase class Person(name: String, age: Int)\ntype Record = { def name: String; def age: Int }\n\nInto[Person, Record].into(Person(\"Alice\", 30))\n// => Right(<dynamic instance with name=\"Alice\", age=30>)\n```\n\n#### Structural Type Sources\n```scala\ntype PersonLike = { def name: String; def age: Int }\ncase class User(name: String, age: Int)\n\nval personLike: PersonLike = ??? // some structural instance\nInto[PersonLike, User].into(personLike)\n// => Right(User(\"Alice\", 30))\n```\n\n### 6. Schema Evolution Patterns\n\n#### Adding Optional Fields\n```scala\ncase class UserV1(id: String, name: String)\ncase class UserV2(id: String, name: String, email: Option[String])\n\nInto[UserV1, UserV2].into(UserV1(\"123\", \"Alice\"))\n// => Right(UserV2(\"123\", \"Alice\", None))\n```\n\n#### Removing Optional Fields\n```scala\ncase class UserV2(id: String, name: String, email: Option[String])\ncase class UserV1(id: String, name: String)\n\nInto[UserV2, UserV1].into(UserV2(\"123\", \"Alice\", Some(\"alice@example.com\")))\n// => Right(UserV1(\"123\", \"Alice\"))\n// email field is dropped\n```\n\n#### Adding Required Fields with Defaults (Scala 3)\n```scala\ncase class ProductV1(name: String, price: Double)\ncase class ProductV2(name: String, price: Double, available: Boolean = true)\n\nInto[ProductV1, ProductV2].into(ProductV1(\"Widget\", 19.99))\n// => Right(ProductV2(\"Widget\", 19.99, true))\n```\n\n#### Field Reordering\n```scala\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(email: String, name: String, age: Int)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"alice@example.com\"))\n// => Right(PersonV2(\"alice@example.com\", \"Alice\", 30))\n```\n\n#### Field Renaming (with unique types)\n```scala\ncase class PersonV1(fullName: String, yearOfBirth: Int)\ncase class PersonV2(name: String, birthYear: Int)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice Smith\", 1990))\n// => Right(PersonV2(\"Alice Smith\", 1990))\n```\n\n#### Type Refinement\n```scala\ncase class ConfigV1(port: Int, timeout: Int)\ncase class ConfigV2(port: Int, timeout: Long)\n\nInto[ConfigV1, ConfigV2].into(ConfigV1(8080, 30))\n// => Right(ConfigV2(8080, 30L))\n```\n\n### 7. Nested Conversions\n\n#### Nested Products\n```scala\ncase class AddressV1(street: String, zip: Int)\ncase class PersonV1(name: String, address: AddressV1)\n\ncase class AddressV2(street: String, zip: Long)\ncase class PersonV2(name: String, address: AddressV2)\n\nInto[PersonV1, PersonV2].into(\n  PersonV1(\"Alice\", AddressV1(\"Main St\", 12345))\n)\n// => Right(PersonV2(\"Alice\", AddressV2(\"Main St\", 12345L)))\n```\n\n#### Nested Coproducts\n```scala\nsealed trait Inner\ncase class A(x: Int) extends Inner\ncase class B(y: String) extends Inner\n\nsealed trait Outer\ncase class Container(inner: Inner, label: String) extends Outer\n\n// Similar target types with Long instead of Int\nsealed trait InnerV2\ncase class A(x: Long) extends InnerV2\ncase class B(y: String) extends InnerV2\n\nsealed trait OuterV2\ncase class Container(inner: InnerV2, label: String) extends OuterV2\n\nInto[Outer, OuterV2].into(Container(A(42), \"test\"))\n// => Right(Container(A(42L), \"test\"))\n```\n\n#### Collections of Complex Types\n```scala\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(name: String, age: Long)\n\nInto[List[PersonV1], List[PersonV2]].into(\n  List(PersonV1(\"Alice\", 30), PersonV1(\"Bob\", 25))\n)\n// => Right(List(PersonV2(\"Alice\", 30L), PersonV2(\"Bob\", 25L)))\n```\n\n#### Nested Collections with Type Conversions\n```scala\ncase class DataV1(values: List[Vector[Int]])\ncase class DataV2(values: Vector[List[Long]])\n\nInto[DataV1, DataV2].into(\n  DataV1(List(Vector(1, 2), Vector(3, 4)))\n)\n// => Right(DataV2(Vector(List(1L, 2L), List(3L, 4L))))\n```\n\n---\n\n## Special Type Support\n\n### Opaque Types (Scala 3)\n\nOpaque types with validation are fully supported. The macro generates runtime validation calls.\n\n```scala\n// Definition with validation\nobject Domain:\n  opaque type Age = Int\n  object Age:\n    def apply(value: Int): Either[String, Age] =\n      if value >= 0 && value <= 150 then Right(value)\n      else Left(s\"Invalid age: $value\")\n    \n    def unsafe(value: Int): Age = value\n    \n    extension (age: Age)\n      def toInt: Int = age\n\n  opaque type Email = String\n  object Email:\n    def apply(value: String): Either[String, Email] =\n      if value.contains(\"@\") then Right(value)\n      else Left(s\"Invalid email: $value\")\n    \n    extension (email: Email)\n      def toString: String = email\n\nimport Domain._\n\n// Usage\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(name: String, age: Age, email: Email)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"alice@example.com\"))\n// => Right(PersonV2(\"Alice\", Age.unsafe(30), Email.unsafe(\"alice@example.com\")))\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", -5, \"alice@example.com\"))\n// => Left(SchemaError(\"Age validation failed: Invalid age: -5\"))\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"invalid\"))\n// => Left(SchemaError(\"Email validation failed: Invalid email: invalid\"))\n```\n\n**Macro Behavior**:\n- Detects opaque type companion objects with `apply(underlying): Either[_, OpaqueType]` method\n- Generates validation calls for each opaque type field\n- Accumulates all validation errors using `SchemaError` composition\n- Falls back to direct conversion if no validation method exists\n\n### Newtype Libraries (Scala 2)\n\n#### ZIO Prelude Newtypes (Built-in Support)\n\nThe macro includes hardcoded support for ZIO Prelude newtypes without requiring a compile-time dependency.\n\n```scala\nimport zio.prelude._\n\n// Definition with validation\nobject Domain {\n  object Age extends Subtype[Int] {\n    override def assertion = assert {\n      Assertion.between(0, 150)\n    }\n  }\n  type Age = Age.Type\n\n  object Email extends Newtype[String] {\n    override def assertion = assert {\n      Assertion.matches(\".*@.*\")\n    }\n  }\n  type Email = Email.Type\n}\n\nimport Domain._\n\n// Usage\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(name: String, age: Age, email: Email)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"alice@example.com\"))\n// => Right(PersonV2(\"Alice\", Age(30), Email(\"alice@example.com\")))\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 200, \"invalid\"))\n// => Left(SchemaError(\"Validation failed: age: 200 is not between 0 and 150, email: invalid does not match .*@.*\"))\n```\n\n**Macro Detection** (no ZIO Prelude dependency required):\n```scala\n// The macro detects ZIO Prelude newtypes by checking:\n// 1. Type extends Newtype[A] or Subtype[A]\n// 2. Companion object exists\n// 3. Has apply/wrap method with validation\n\n// Low-level AST matching in Scala 2 macro:\ndef isZIONewtype(tpe: Type): Boolean = {\n  tpe.typeSymbol.fullName.startsWith(\"zio.prelude.Newtype\") ||\n  tpe.typeSymbol.fullName.startsWith(\"zio.prelude.Subtype\")\n}\n```\n\n#### Other Newtype Libraries\n\nFor other newtype libraries, users can provide explicit `Into` instances. The macro will use these instances when available.\n\n```scala\n// User-provided instance for their newtype library\nimplicit val stringToMyNewtype: Into[String, MyNewtype] = \n  new Into[String, MyNewtype] {\n    def into(s: String): Either[SchemaError, MyNewtype] =\n      MyNewtype.make(s).left.map(e => SchemaError(e.toString))\n  }\n\n// The macro will automatically use this instance\ncase class PersonV1(email: String)\ncase class PersonV2(email: MyNewtype)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"test@example.com\"))\n// Uses the user-provided instance automatically\n```\n\n### Validation Error Accumulation\n\nWhen multiple validations fail, all errors are accumulated using `SchemaError` composition:\n\n```scala\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(name: String, age: Age, email: Email)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"\", -5, \"invalid\"))\n// => Left(SchemaError(...)) // Combined error containing all validation failures\n```\n\n---\n\n## As[A, B] Additional Requirements\n\nFor `As[A, B]` to be derivable, the bidirectional conversion must be **compatible**:\n\n### Compatibility Rules\n\n1. **Field mappings must be consistent**: The same field correspondence in both directions\n2. **Coercions must be invertible with runtime validation**: \n   - âœ… `Int` â†” `Long` is valid (narrowing validated at runtime)\n   - âœ… `Float` â†” `Double` is valid (narrowing validated at runtime)\n   - âœ… All numeric coercions are valid with runtime checks\n3. **Optional fields**: \n   - âœ… Can add optional fields in one direction (becomes `None` in reverse)\n   - âœ… Can remove optional fields in one direction (value is dropped)\n4. **Default values**:\n   - âŒ Cannot use default arguments (breaks round-trip guarantee)\n5. **Collection types**:\n   - âœ… Can convert between different collection types\n   - âš ï¸  Set â†’ List â†’ Set may not preserve original order\n   - âš ï¸  List â†’ Set â†’ List loses duplicates\n\n### Valid As[A, B] Examples\n\n```scala\n// Valid: Same structure, different names\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(fullName: String, yearsOld: Int)\n\nAs[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30))\n// => Right(PersonV2(\"Alice\", 30))\n\nAs[PersonV1, PersonV2].from(PersonV2(\"Bob\", 25))\n// => Right(PersonV1(\"Bob\", 25))\n```\n\n```scala\n// Valid: Case class â†” Tuple\ncase class Point(x: Double, y: Double)\n\nAs[Point, (Double, Double)].into(Point(1.0, 2.0))\n// => Right((1.0, 2.0))\n\nAs[Point, (Double, Double)].from((3.0, 4.0))\n// => Right(Point(3.0, 4.0))\n```\n\n```scala\n// Valid: Numeric coercion with runtime validation\ncase class ConfigV1(timeout: Int)\ncase class ConfigV2(timeout: Long)\n\nAs[ConfigV1, ConfigV2].into(ConfigV1(30))\n// => Right(ConfigV2(30L))\n\nAs[ConfigV1, ConfigV2].from(ConfigV2(30L))\n// => Right(ConfigV1(30))\n\nAs[ConfigV1, ConfigV2].from(ConfigV2(3000000000L))\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n```\n\n```scala\n// Valid: Opaque types (reversible via unwrap)\ncase class PersonRaw(name: String, age: Int)\ncase class PersonValidated(name: String, age: Age)\n\nAs[PersonRaw, PersonValidated].into(PersonRaw(\"Alice\", 30))\n// => Right(PersonValidated(\"Alice\", Age.unsafe(30)))\n\nAs[PersonRaw, PersonValidated].from(PersonValidated(\"Bob\", Age.unsafe(25)))\n// => Right(PersonRaw(\"Bob\", 25))\n\nAs[PersonRaw, PersonValidated].into(PersonRaw(\"Charlie\", -5))\n// => Left(SchemaError(\"Age validation failed: Invalid age: -5\"))\n```\n\n```scala\n// Valid: Collection type conversions\ncase class DataV1(items: List[Int])\ncase class DataV2(items: Vector[Int])\n\nAs[DataV1, DataV2].into(DataV1(List(1, 2, 3)))\n// => Right(DataV2(Vector(1, 2, 3)))\n\nAs[DataV1, DataV2].from(DataV2(Vector(4, 5, 6)))\n// => Right(DataV1(List(4, 5, 6)))\n```\n\n```scala\n// Valid: Optional field in one direction\ncase class UserV1(id: String, name: String)\ncase class UserV2(id: String, name: String, email: Option[String])\n\nAs[UserV1, UserV2].into(UserV1(\"123\", \"Alice\"))\n// => Right(UserV2(\"123\", \"Alice\", None))\n\nAs[UserV1, UserV2].from(UserV2(\"456\", \"Bob\", Some(\"bob@example.com\")))\n// => Right(UserV1(\"456\", \"Bob\"))\n// email is dropped in reverse direction\n```\n\n### Non-Ideal As[A, B] Examples (Valid but Lossy)\n\n```scala\n// Valid but lossy: List with duplicates â†’ Set â†’ List\ncase class DataV1(values: List[Int])\ncase class DataV2(values: Set[Int])\n\nAs[DataV1, DataV2].into(DataV1(List(1, 2, 2, 3)))\n// => Right(DataV2(Set(1, 2, 3)))\n\nAs[DataV1, DataV2].from(DataV2(Set(1, 2, 3)))\n// => Right(DataV1(List(1, 2, 3)))\n// Original duplicates are lost, but conversion is valid\n```\n\n```scala\n// Valid but lossy: Set â†’ List â†’ Set (order may change)\ncase class DataV1(values: Set[Int])\ncase class DataV2(values: List[Int])\n\nval original = DataV1(Set(3, 1, 2))\nval converted = As[DataV1, DataV2].into(original).right.get\n// converted.values might be List(1, 2, 3) depending on Set iteration order\n\nval roundTrip = As[DataV1, DataV2].from(converted).right.get\n// roundTrip.values == Set(1, 2, 3) - same elements, possibly different internal order\n```\n\n### Invalid As[A, B] Examples\n\n```scala\n// Invalid: Default values break round-trip guarantee\ncase class ProductV1(name: String, price: Double)\ncase class ProductV2(name: String, price: Double, taxable: Boolean = true)\n\n// COMPILE ERROR: Cannot derive As[ProductV1, ProductV2]\n// Reason: Default value for 'taxable' cannot be recovered in reverse direction\n// (We can't distinguish between explicitly set 'true' and default 'true')\n```\n\n---\n\n## Testing Requirements\n\n### Test Matrix Dimensions\n\n1. **Type Combinations** (both `Into` and `As`)\n   - Primitive â†’ Primitive (all coercion pairs, including narrowing)\n   - Product â†’ Product (case classes)\n   - Product â†’ Tuple\n   - Tuple â†’ Product\n   - Tuple â†’ Tuple\n   - Coproduct â†’ Coproduct (sealed traits, enums)\n   - Collection[A] â†’ Collection[B] (List, Vector, Set, Map, Option, Either, Array, Seq)\n   - Collection type conversions (List â†” Vector â†” Set â†” Array â†” Seq)\n   - Nested conversions\n   - Structural types\n\n2. **Disambiguation Scenarios**\n   - Unique types (names irrelevant)\n   - Matching names (types irrelevant with coercion)\n   - Duplicate types with name disambiguation\n   - Duplicate types with position disambiguation\n   - Ambiguous cases (must fail at compile-time)\n\n3. **Schema Evolution**\n   - Field reordering\n   - Field renaming (with unique types)\n   - Adding optional fields\n   - Removing optional fields\n   - Type refinement (Int â†’ Long, with narrowing validation)\n   - Adding default values (Scala 3)\n\n4. **Validation** (Scala 3 opaque types)\n   - Valid values pass through\n   - Invalid values produce SchemaError\n   - Multiple validation failures accumulate\n   - Nested validation in products\n   - Validation in coproduct cases\n   - Validation in collections\n   - Narrowing conversions (Long â†’ Int with overflow check)\n\n5. **Validation** (Scala 2 ZIO Prelude newtypes)\n   - Newtype validation success\n   - Newtype validation failure\n   - Subtype validation with assertions\n   - Multiple newtype fields\n\n6. **Collection Type Conversions**\n   - List â†” Vector\n   - List â†” Array\n   - List â†” Set (with duplicate handling)\n   - List â†” Seq\n   - Vector â†” Set\n   - Array â†” Vector\n   - All combinations with element type coercion\n   - Nested collection type conversions\n\n7. **Runtime Validation** (for `As[A, B]`)\n   - Numeric narrowing validation\n   - Round-trip with valid narrowing\n   - Round-trip failure with overflow\n   - Collection conversions with duplicates\n   - Optional field round-trips\n\n8. **Error Cases**\n   - Ambiguous field mapping (compile error)\n   - Ambiguous case mapping (compile error)\n   - Default value in `As` (compile error)\n   - Runtime validation failures\n   - Type mismatch (compile error)\n   - Overflow in narrowing conversions\n\n9. **Edge Cases**\n   - Empty case classes\n   - Single-field case classes\n   - Case objects\n   - Sealed traits with case objects only\n   - Deeply nested structures (5+ levels)\n   - Large products (20+ fields)\n   - Large coproducts (20+ cases)\n   - Recursive types (e.g., `case class Tree(value: Int, children: List[Tree])`)\n   - Mutually recursive types\n\n### Test Organization\n\n```\nsrc/test/scala/\n  into/\n    products/\n      CaseClassToCaseClassSpec.scala\n      CaseClassToTupleSpec.scala\n      TupleToCaseClassSpec.scala\n      TupleToTupleSpec.scala\n      FieldReorderingSpec.scala\n      FieldRenamingSpec.scala\n      NestedProductsSpec.scala\n    coproducts/\n      SealedTraitToSealedTraitSpec.scala\n      EnumToEnumSpec.scala (Scala 3 only)\n      CaseMatchingSpec.scala\n      SignatureMatchingSpec.scala\n      AmbiguousCaseSpec.scala\n      NestedCoproductsSpec.scala\n    primitives/\n      NumericWideningSpec.scala\n      NumericNarrowingSpec.scala\n      CollectionCoercionSpec.scala\n      OptionCoercionSpec.scala\n      EitherCoercionSpec.scala\n      NestedCollectionSpec.scala\n    collections/\n      ListToVectorSpec.scala\n      ListToSetSpec.scala\n      VectorToArraySpec.scala\n      CollectionTypeWithCoercionSpec.scala\n      NestedCollectionTypeSpec.scala\n      SetDuplicateHandlingSpec.scala\n    structural/\n      StructuralTypeTargetSpec.scala (Scala 3 Selectable)\n      DynamicTypeTargetSpec.scala (Scala 2 Dynamic)\n      StructuralTypeSourceSpec.scala\n    validation/\n      OpaqueTypeValidationSpec.scala (Scala 3 only)\n      ZIONewtypeValidationSpec.scala (Scala 2 only)\n      ValidationErrorAccumulationSpec.scala\n      NestedValidationSpec.scala\n      NarrowingValidationSpec.scala\n    evolution/\n      AddOptionalFieldSpec.scala\n      RemoveOptionalFieldSpec.scala\n      TypeRefinementSpec.scala\n      AddDefaultFieldSpec.scala (Scala 3 only)\n    disambiguation/\n      UniqueTypeDisambiguationSpec.scala\n      NameDisambiguationSpec.scala\n      PositionDisambiguationSpec.scala\n      AmbiguousCompileErrorSpec.scala\n    edge/\n      EmptyProductSpec.scala\n      SingleFieldSpec.scala\n      CaseObjectSpec.scala\n      DeepNestingSpec.scala\n      LargeProductSpec.scala\n      LargeCoproductSpec.scala\n      RecursiveTypeSpec.scala\n      MutuallyRecursiveTypeSpec.scala\n  \n  as/\n    reversibility/\n      RoundTripProductSpec.scala\n      RoundTripCoproductSpec.scala\n      RoundTripTupleSpec.scala\n      RoundTripCollectionTypeSpec.scala\n      OpaqueTypeRoundTripSpec.scala\n      NumericNarrowingRoundTripSpec.scala\n      OptionalFieldRoundTripSpec.scala\n    validation/\n      OverflowDetectionSpec.scala\n      NarrowingFailureSpec.scala\n      CollectionLossyConversionSpec.scala\n    compile_errors/\n      DefaultValueSpec.scala\n    (similar structure to into/ for applicable tests)\n```\n\n### Specific Test Cases\n\n#### Disambiguation Tests\n\n```scala\n// Test: Unique types make names irrelevant\ncase class A(x: String, y: Int, z: Boolean)\ncase class B(a: String, b: Int, c: Boolean)\nassert(Into[A, B].into(A(\"test\", 42, true)) == Right(B(\"test\", 42, true)))\n\n// Test: Names disambiguate duplicate types\ncase class Point(x: Int, y: Int)\ncase class Coord(y: Int, x: Int)\nassert(Into[Point, Coord].into(Point(1, 2)) == Right(Coord(2, 1)))\n\n// Test: Ambiguous mapping fails at compile-time\ncase class Dim(width: Int, height: Int)\ncase class Measure(first: Int, second: Int)\n// Must not compile: Into[Dim, Measure]\nassertDoesNotCompile(\"Into[Dim, Measure]\")\n```\n\n#### Numeric Narrowing Validation Tests\n\n```scala\n// Test: Valid narrowing conversion\ncase class V1(value: Long)\ncase class V2(value: Int)\nassert(Into[V1, V2].into(V1(42L)) == Right(V2(42)))\n\n// Test: Invalid narrowing (overflow)\nassert(Into[V1, V2].into(V1(3000000000L)).isLeft)\n\n// Test: Narrowing in collections\ncase class Data1(values: List[Long])\ncase class Data2(values: List[Int])\nassert(Into[Data1, Data2].into(Data1(List(1L, 2L, 3L))) == Right(Data2(List(1, 2, 3))))\nassert(Into[Data1, Data2].into(Data1(List(1L, 3000000000L))).isLeft)\n```\n\n#### Collection Type Conversion Tests\n\n```scala\n// Test: List to Vector\ncase class A(items: List[Int])\ncase class B(items: Vector[Int])\nassert(Into[A, B].into(A(List(1, 2, 3))) == Right(B(Vector(1, 2, 3))))\n\n// Test: List to Set (removes duplicates)\ncase class C(items: List[Int])\ncase class D(items: Set[Int])\nassert(Into[C, D].into(C(List(1, 2, 2, 3))) == Right(D(Set(1, 2, 3))))\n\n// Test: Vector to Array\ncase class E(items: Vector[String])\ncase class F(items: Array[String])\nval result = Into[E, F].into(E(Vector(\"a\", \"b\")))\nassert(result.isRight)\nassert(result.right.get.items.sameElements(Array(\"a\", \"b\")))\n\n// Test: Combined collection and element coercion\ncase class G(items: List[Int])\ncase class H(items: Vector[Long])\nassert(Into[G, H].into(G(List(1, 2, 3))) == Right(H(Vector(1L, 2L, 3L))))\n```\n\n#### Validation Tests (Scala 3)\n\n```scala\n// Test: Valid opaque type conversion\ncase class Raw(age: Int)\ncase class Validated(age: Age)\nassert(Into[Raw, Validated].into(Raw(30)).isRight)\n\n// Test: Invalid opaque type conversion\nassert(Into[Raw, Validated].into(Raw(-5)).isLeft)\n\n// Test: Multiple validation failures accumulate\ncase class RawPerson(age: Int, email: String)\ncase class ValidPerson(age: Age, email: Email)\nval result = Into[RawPerson, ValidPerson].into(RawPerson(-5, \"invalid\"))\nassert(result.isLeft)\n// SchemaError contains both validation failures\n```\n\n#### Round-Trip Tests (As)\n\n```scala\n// Test: Case class round-trip\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(fullName: String, yearsOld: Int)\n\nval v1 = PersonV1(\"Alice\", 30)\nval v2 = As[PersonV1, PersonV2].into(v1).right.get\nval roundTrip = As[PersonV1, PersonV2].from(v2).right.get\n\nassert(roundTrip == v1)\n\n// Test: Numeric narrowing round-trip (valid)\ncase class ConfigV1(timeout: Int)\ncase class ConfigV2(timeout: Long)\n\nval config1 = ConfigV1(30)\nval config2 = As[ConfigV1, ConfigV2].into(config1).right.get\nval back = As[ConfigV1, ConfigV2].from(config2).right.get\n\nassert(back == config1)\n\n// Test: Numeric narrowing round-trip (overflow failure)\nval config2Overflow = ConfigV2(3000000000L)\nassert(As[ConfigV1, ConfigV2].from(config2Overflow).isLeft)\n\n// Test: Collection type round-trip\ncase class Data1(items: List[Int])\ncase class Data2(items: Vector[Int])\n\nval data1 = Data1(List(1, 2, 3))\nval data2 = As[Data1, Data2].into(data1).right.get\nval backToData1 = As[Data1, Data2].from(data2).right.get\n\nassert(backToData1 == data1)\n\n// Test: Lossy collection round-trip (Set loses duplicates)\ncase class WithDuplicates(items: List[Int])\ncase class NoDuplicates(items: Set[Int])\n\nval original = WithDuplicates(List(1, 2, 2, 3))\nval asSet = As[WithDuplicates, NoDuplicates].into(original).right.get\nval backToList = As[WithDuplicates, NoDuplicates].from(asSet).right.get\n\nassert(asSet.items == Set(1, 2, 3))\nassert(backToList.items.toSet == Set(1, 2, 3)) // Order may differ, duplicates lost\n```\n\n#### Edge Case Tests\n\n```scala\n// Test: Empty case class\ncase class Empty()\nassert(Into[Empty, Empty].into(Empty()) == Right(Empty()))\n\n// Test: Large product (21 fields)\ncase class Large21(f1: Int, f2: Int, /* ... */, f21: Int)\ncase class Large21V2(f1: Long, f2: Long, /* ... */, f21: Long)\n// Must compile and work correctly\n\n// Test: Recursive type\ncase class Tree(value: Int, children: List[Tree])\ncase class TreeV2(value: Long, children: List[TreeV2])\nval tree = Tree(1, List(Tree(2, Nil), Tree(3, Nil)))\nval treeV2 = Into[Tree, TreeV2].into(tree).right.get\nassert(treeV2.value == 1L)\nassert(treeV2.children.head.value == 2L)\n\n// Test: Mutually recursive types\ncase class Node(id: Int, edges: List[Edge])\ncase class Edge(from: Int, to: Node)\ncase class NodeV2(id: Long, edges: List[EdgeV2])\ncase class EdgeV2(from: Long, to: NodeV2)\n// Must compile and handle mutual recursion\n```\n\n---\n\n## Implementation Signatures\n\n### Scala 3.5\n\n```scala\npackage zio.blocks.schema\n\nimport scala.quoted.*\n\n// One-way conversion\ntrait Into[-A, +B] {\n  def into(input: A): Either[SchemaError, B]\n}\n\nobject Into {\n  inline given [A, B]: Into[A, B] = ${intoMacro[A, B]}\n  \n  private def intoMacro[A: Type, B: Type](using Quotes): Expr[Into[A, B]] = {\n    import quotes.reflect.*\n    // Implementation:\n    // 1. Analyze types A and B\n    // 2. Build field mapping using disambiguation algorithm\n    // 3. Detect opaque types and generate validation calls\n    // 4. Generate narrowing validation for numeric coercions\n    // 5. Handle collection type conversions\n    // 6. Generate conversion code\n    // 7. Handle nested conversions recursively\n    ???\n  }\n}\n\n// Bidirectional conversion\ntrait As[A, B] {\n  def into(input: A): Either[SchemaError, B]\n  def from(input: B): Either[SchemaError, A]\n}\n\nobject As {\n  inline given [A, B]: As[A, B] = ${asMacro[A, B]}\n  \n  private def asMacro[A: Type, B: Type](using Quotes): Expr[As[A, B]] = {\n    import quotes.reflect.*\n    // Implementation:\n    // 1. Verify bidirectional compatibility\n    // 2. Check for default values (compile error if found)\n    // 3. Build bidirectional field mapping\n    // 4. Generate both conversion directions with validation\n    // 5. Ensure opaque type wrapping/unwrapping is symmetric\n    // 6. Handle numeric narrowing with runtime validation\n    // 7. Handle collection type conversions bidirectionally\n    ???\n  }\n}\n```\n\n### Scala 2.13\n\n```scala\npackage com.yourorg.schema\n\nimport scala.reflect.macros.blackbox.Context\nimport scala.language.experimental.macros\n\ncase class SchemaError(msg: String) {\n  // SchemaError is composable - can combine multiple errors\n}\n\n// One-way conversion\ntrait Into[-A, +B] {\n  def into(input: A): Either[SchemaError, B]\n}\n\nobject Into {\n  implicit def materializeInto[A, B]: Into[A, B] = macro materializeIntoImpl[A, B]\n  \n  def materializeIntoImpl[A: c.WeakTypeTag, B: c.WeakTypeTag](c: Context): c.Tree = {\n    import c.universe._\n    // Implementation:\n    // 1. Analyze types A and B using reflection\n    // 2. Build field mapping using disambiguation algorithm\n    // 3. Detect ZIO Prelude newtypes via AST pattern matching\n    // 4. Generate narrowing validation for numeric coercions\n    // 5. Handle collection type conversions\n    // 6. Generate conversion code using quasiquotes\n    // 7. Handle nested conversions recursively\n    ???\n  }\n}\n\n// Bidirectional conversion\ntrait As[A, B] {\n  def into(input: A): Either[SchemaError, B]\n  def from(input: B): Either[SchemaError, A]\n}\n\nobject As {\n  implicit def materializeAs[A, B]: As[A, B] = macro materializeAsImpl[A, B]\n  \n  def materializeAsImpl[A: c.WeakTypeTag, B: c.WeakTypeTag](c: Context): c.Tree = {\n    import c.universe._\n    // Implementation:\n    // 1. Verify bidirectional compatibility\n    // 2. Check for default values (compile error if found)\n    // 3. Build bidirectional field mapping\n    // 4. Generate both conversion directions with validation\n    // 5. Ensure newtype wrapping/unwrapping is symmetric\n    // 6. Handle numeric narrowing with runtime validation\n    // 7. Handle collection type conversions bidirectionally\n    ???\n  }\n}\n```\n\n---\n\n## Implementation Notes\n\n### Error Messages\n\nProvide helpful compile-time errors:\n\n```scala\n// Good error message example:\n\"\"\"\nCannot derive Into[PersonV1, PersonV2]: Ambiguous field mapping\n\n  PersonV1(width: Int, height: Int)\n  PersonV2(first: Int, second: Int)\n\nCannot determine unique mapping between fields of type Int.\nConsider:\n  - Using matching field names (width/height)\n  - Making field types unique\n  - Providing an explicit Into instance\n\"\"\"\n```\n\n### Cross-Version Compatibility\n\n- Share test cases between Scala 2 and Scala 3 where possible\n\n---\n\n## Deliverables\n\n1. âœ… `Into[A, B]` trait and macro for Scala 2.13\n2. âœ… `Into[A, B]` trait and macro for Scala 3.5\n3. âœ… `As[A, B]` trait and macro for Scala 2.13\n4. âœ… `As[A, B]` trait and macro for Scala 3.5\n5. âœ… Comprehensive test suite\n6. âœ… Documentation with examples\n",
              "url": "https://github.com/zio/zio-blocks/issues/518",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "Mudlet#8030",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "Mudlet",
              "id": "generated-Mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2026-01-18T17:51:56.892Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/Mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:56.892Z",
            "created_at": "2026-01-18T17:51:56.892Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-Mudlet#8030",
              "status": "open",
              "type": "issue",
              "number": 8030,
              "title": "Split Mudlet up into `libmudlet` and a Qt front-end",
              "source": {
                "data": {
                  "id": "source-Mudlet#8030",
                  "user": {
                    "login": "vadi2",
                    "id": 110988,
                    "node_id": "MDQ6VXNlcjExMDk4OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/110988?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vadi2",
                    "html_url": "https://github.com/vadi2",
                    "followers_url": "https://api.github.com/users/vadi2/followers",
                    "following_url": "https://api.github.com/users/vadi2/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vadi2/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vadi2/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vadi2/subscriptions",
                    "organizations_url": "https://api.github.com/users/vadi2/orgs",
                    "repos_url": "https://api.github.com/users/vadi2/repos",
                    "events_url": "https://api.github.com/users/vadi2/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vadi2/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Split Mudlet up into `libmudlet` and a Qt front-end",
                  "body": "#### Description of requested feature:\nMudlet is a Qt Widgets based application, which works great for Linux/macOS/Windows, but not so great for running natively on Android or iPhone, which are popular feature requests.\n\nAkin to how VLC is split into libVLC and various front-ends, split Mudlet out into libmudlet (providing all of core functionality) and a Qt Widget frontend that makes use of all of the core functionality.\n\n**Prior to taking this issue up**, open a new github issue here and in there, provide (1) plan for how the library/frontend split will work on an architectural level, and (2) a plan for the migration strategy, since once mega PR will not work for this.\n\n#### Reasons for adding feature:\n\n1. allowing Mudlet to eventually have a mobile-native version\n\n#### Expected result of feature\nlibmudlet may use Qt Core classes (QObject, QTimer, QThread, QSettings, etc.) but must not depend on Qt Widgets, Qt GUI, or any UI-related Qt modules.\n\n Mudlet's functionality pre and post-split should be 100% the same, nothing should be lost in the transition:\n -  All existing automated tests must pass, plus:\n  - All menu items and dialogs function identically\n  - All Lua API functions return identical results\n  - All protocol features work (GMCP, MXP, etc.)\n  - All file formats (profiles, packages) remain compatible\n\nPerformance of the network/text display stack as well as the trigger engine should be comparable as well (no more than 10% lost). Measured in:\n\n  - Text display: X lines/second in main console (can be measured using [stressinator](https://packages.mudlet.org/packages#pkg-Stressinator))\n  - Network: Y MB/s processing throughput (needs to be measured)\n  - Memory: no more than 10% increase in base memory usage\n\n####\n\n",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/8030"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#8030",
              "body": "#### Description of requested feature:\nMudlet is a Qt Widgets based application, which works great for Linux/macOS/Windows, but not so great for running natively on Android or iPhone, which are popular feature requests.\n\nAkin to how VLC is split into libVLC and various front-ends, split Mudlet out into libmudlet (providing all of core functionality) and a Qt Widget frontend that makes use of all of the core functionality.\n\n**Prior to taking this issue up**, open a new github issue here and in there, provide (1) plan for how the library/frontend split will work on an architectural level, and (2) a plan for the migration strategy, since once mega PR will not work for this.\n\n#### Reasons for adding feature:\n\n1. allowing Mudlet to eventually have a mobile-native version\n\n#### Expected result of feature\nlibmudlet may use Qt Core classes (QObject, QTimer, QThread, QSettings, etc.) but must not depend on Qt Widgets, Qt GUI, or any UI-related Qt modules.\n\n Mudlet's functionality pre and post-split should be 100% the same, nothing should be lost in the transition:\n -  All existing automated tests must pass, plus:\n  - All menu items and dialogs function identically\n  - All Lua API functions return identical results\n  - All protocol features work (GMCP, MXP, etc.)\n  - All file formats (profiles, packages) remain compatible\n\nPerformance of the network/text display stack as well as the trigger engine should be comparable as well (no more than 10% lost). Measured in:\n\n  - Text display: X lines/second in main console (can be measured using [stressinator](https://packages.mudlet.org/packages#pkg-Stressinator))\n  - Network: Y MB/s processing throughput (needs to be measured)\n  - Memory: no more than 10% increase in base memory usage\n\n####\n\n",
              "url": "https://github.com/Mudlet/Mudlet/issues/8030",
              "tech": [],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "Mudlet#3172",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "Mudlet",
              "id": "generated-Mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2026-01-18T17:51:57.021Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/Mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:57.021Z",
            "created_at": "2026-01-18T17:51:57.021Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-Mudlet#3172",
              "status": "open",
              "type": "issue",
              "number": 3172,
              "title": "generic mapper: add video walkthrough on how to set it up",
              "source": {
                "data": {
                  "id": "source-Mudlet#3172",
                  "user": {
                    "login": "vadi2",
                    "id": 110988,
                    "node_id": "MDQ6VXNlcjExMDk4OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/110988?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vadi2",
                    "html_url": "https://github.com/vadi2",
                    "followers_url": "https://api.github.com/users/vadi2/followers",
                    "following_url": "https://api.github.com/users/vadi2/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vadi2/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vadi2/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vadi2/subscriptions",
                    "organizations_url": "https://api.github.com/users/vadi2/orgs",
                    "repos_url": "https://api.github.com/users/vadi2/repos",
                    "events_url": "https://api.github.com/users/vadi2/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vadi2/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "generic mapper: add video walkthrough on how to set it up",
                  "body": "#### Brief summary of issue / Description of requested feature:\r\nIt's been requested a few times, and it would be really handy to link people to a video explanation of how the generic mapper script should be setup.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1. \r\n2. \r\n3. \r\n\r\n#### Error output / Expected result of feature\r\n\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/3172"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#3172",
              "body": "#### Brief summary of issue / Description of requested feature:\r\nIt's been requested a few times, and it would be really handy to link people to a video explanation of how the generic mapper script should be setup.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1. \r\n2. \r\n3. \r\n\r\n#### Error output / Expected result of feature\r\n\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n",
              "url": "https://github.com/Mudlet/Mudlet/issues/3172",
              "tech": [],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "Mudlet#689",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "Mudlet",
              "id": "generated-Mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2026-01-18T17:51:57.145Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/Mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:57.146Z",
            "created_at": "2026-01-18T17:51:57.146Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-Mudlet#689",
              "status": "open",
              "type": "issue",
              "number": 689,
              "title": "Support telnet:// links",
              "source": {
                "data": {
                  "id": "source-Mudlet#689",
                  "user": {
                    "login": "vadi2",
                    "id": 110988,
                    "node_id": "MDQ6VXNlcjExMDk4OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/110988?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vadi2",
                    "html_url": "https://github.com/vadi2",
                    "followers_url": "https://api.github.com/users/vadi2/followers",
                    "following_url": "https://api.github.com/users/vadi2/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vadi2/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vadi2/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vadi2/subscriptions",
                    "organizations_url": "https://api.github.com/users/vadi2/orgs",
                    "repos_url": "https://api.github.com/users/vadi2/repos",
                    "events_url": "https://api.github.com/users/vadi2/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vadi2/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Support telnet:// links",
                  "body": "Idea: MUDs should be able to provide an easy to use link with their connection info to spawn Mudlet and get it to connect to their game. Similar to apt://, steam:// and so forth links.\r\n\r\nI think Mudlet should support those types of links - it'd be a lot more convenient for players to try out new MUDs if they only have to click on a link, instead of copying the server and port, going to Mudlet, making a new profile and so on.\r\n\r\nAs for the naming of the link, we could either go with a custom one: mudlet:// or - use an already standard one (telnet://), which would be much better as some websites use it already (http://dmud.thebbs.org/lotflink.htm) and it would be compatible with other MUDs clients.\r\n\r\nI believe the latter option is better.\r\n\r\nTelnet links seem to work in the format of: telnet://<server>[:<optional port #>], see https://tools.ietf.org/html/rfc4248 for the actual spec.\r\n\r\nThe logic for this could be the following:\r\n\r\nWhen Mudlet is spawned via the telnet link, check to see if any profile(s) server matches server field of the link. If multiple profiles do, auto-load the latest profile used. If one matches, load that profile. If not profiles match...\r\n\r\nCreate a new profile with the given server and port data, and the profiles name will be the servers name as well. Auto-load this newly created profile.\r\n\r\n\r\nI think these cases sound plausible. There'll an issue with peoples already made profile using the server name vs IP address directly as webmasters might, but that's not something that could be easily avoided.\r\n\r\nLaunchpad Details: [#LP1187243](https://bugs.launchpad.net/bugs/1187243) Vadim Peretokin - 2013-06-04 04:47:05 +0000",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/689"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#689",
              "body": "Idea: MUDs should be able to provide an easy to use link with their connection info to spawn Mudlet and get it to connect to their game. Similar to apt://, steam:// and so forth links.\r\n\r\nI think Mudlet should support those types of links - it'd be a lot more convenient for players to try out new MUDs if they only have to click on a link, instead of copying the server and port, going to Mudlet, making a new profile and so on.\r\n\r\nAs for the naming of the link, we could either go with a custom one: mudlet:// or - use an already standard one (telnet://), which would be much better as some websites use it already (http://dmud.thebbs.org/lotflink.htm) and it would be compatible with other MUDs clients.\r\n\r\nI believe the latter option is better.\r\n\r\nTelnet links seem to work in the format of: telnet://<server>[:<optional port #>], see https://tools.ietf.org/html/rfc4248 for the actual spec.\r\n\r\nThe logic for this could be the following:\r\n\r\nWhen Mudlet is spawned via the telnet link, check to see if any profile(s) server matches server field of the link. If multiple profiles do, auto-load the latest profile used. If one matches, load that profile. If not profiles match...\r\n\r\nCreate a new profile with the given server and port data, and the profiles name will be the servers name as well. Auto-load this newly created profile.\r\n\r\n\r\nI think these cases sound plausible. There'll an issue with peoples already made profile using the server name vs IP address directly as webmasters might, but that's not something that could be easily avoided.\r\n\r\nLaunchpad Details: [#LP1187243](https://bugs.launchpad.net/bugs/1187243) Vadim Peretokin - 2013-06-04 04:47:05 +0000",
              "url": "https://github.com/Mudlet/Mudlet/issues/689",
              "tech": [],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "Mudlet#5310",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "Mudlet",
              "id": "generated-Mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2026-01-18T17:51:57.267Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/Mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:51:57.267Z",
            "created_at": "2026-01-18T17:51:57.267Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-Mudlet#5310",
              "status": "open",
              "type": "issue",
              "number": 5310,
              "title": "Autocomplete steals window focus, prevents further typing",
              "source": {
                "data": {
                  "id": "source-Mudlet#5310",
                  "user": {
                    "login": "Matthew-Marsh",
                    "id": 79426017,
                    "node_id": "MDQ6VXNlcjc5NDI2MDE3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/79426017?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Matthew-Marsh",
                    "html_url": "https://github.com/Matthew-Marsh",
                    "followers_url": "https://api.github.com/users/Matthew-Marsh/followers",
                    "following_url": "https://api.github.com/users/Matthew-Marsh/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Matthew-Marsh/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Matthew-Marsh/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Matthew-Marsh/subscriptions",
                    "organizations_url": "https://api.github.com/users/Matthew-Marsh/orgs",
                    "repos_url": "https://api.github.com/users/Matthew-Marsh/repos",
                    "events_url": "https://api.github.com/users/Matthew-Marsh/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Matthew-Marsh/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Autocomplete steals window focus, prevents further typing",
                  "body": "#### Brief summary of issue / Description of requested feature:\r\n\r\nOccasionally encountering an issue where autocomplete pops up and prevents typing. Need to esc to remove the autocomplete, but will pop up again with another relevant letter.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1.  Unknown to why it begins.\r\n2.  Typing a letter that has a corresponding lua command in the autocomplete. \r\n\r\n#### Error output / Expected result of feature\r\n\r\nExpected result: Being able to continue typing outside of autocomplete.\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n\r\nMudlet version: 4.11.2\r\nWindows 10 Home\r\nVideo recording: https://youtu.be/qJF0h2MDWzg\r\n",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/5310"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#5310",
              "body": "#### Brief summary of issue / Description of requested feature:\r\n\r\nOccasionally encountering an issue where autocomplete pops up and prevents typing. Need to esc to remove the autocomplete, but will pop up again with another relevant letter.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1.  Unknown to why it begins.\r\n2.  Typing a letter that has a corresponding lua command in the autocomplete. \r\n\r\n#### Error output / Expected result of feature\r\n\r\nExpected result: Being able to continue typing outside of autocomplete.\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n\r\nMudlet version: 4.11.2\r\nWindows 10 Home\r\nVideo recording: https://youtu.be/qJF0h2MDWzg\r\n",
              "url": "https://github.com/Mudlet/Mudlet/issues/5310",
              "tech": [],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#1693",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-01-18T17:52:14.612Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:52:14.612Z",
            "created_at": "2026-01-18T17:52:14.612Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#1693",
              "status": "open",
              "type": "issue",
              "number": 1693,
              "title": "test - pls ignore",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#1693",
                  "user": {
                    "login": "dogancanbakir",
                    "id": 65292895,
                    "node_id": "MDQ6VXNlcjY1MjkyODk1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/65292895?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/dogancanbakir",
                    "html_url": "https://github.com/dogancanbakir",
                    "followers_url": "https://api.github.com/users/dogancanbakir/followers",
                    "following_url": "https://api.github.com/users/dogancanbakir/following{/other_user}",
                    "gists_url": "https://api.github.com/users/dogancanbakir/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/dogancanbakir/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/dogancanbakir/subscriptions",
                    "organizations_url": "https://api.github.com/users/dogancanbakir/orgs",
                    "repos_url": "https://api.github.com/users/dogancanbakir/repos",
                    "events_url": "https://api.github.com/users/dogancanbakir/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/dogancanbakir/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "test - pls ignore",
                  "body": "test",
                  "html_url": "https://github.com/projectdiscovery/subfinder/issues/1693"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/subfinder#1693",
              "body": "test",
              "url": "https://github.com/projectdiscovery/subfinder/issues/1693",
              "tech": [],
              "repo_name": "subfinder",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14576",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-01-18T17:52:14.753Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:52:14.753Z",
            "created_at": "2026-01-18T17:52:14.753Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14576",
              "status": "open",
              "type": "issue",
              "number": 14576,
              "title": "CVE-2018-8581 - Microsoft Exchange Server - Elevation of Privilege ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14576",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2018-8581 - Microsoft Exchange Server - Elevation of Privilege ðŸ’°",
                  "body": "\n### Description: \n> Microsoft Exchange Server contains an elevation of privilege caused by a vulnerability in the system, letting attackers escalate their privileges, exploit requires specific conditions not specified.\n\n#### Severity: `High`\n\n#### POC: \n- https://vulncheck.com/xdb/276c34c7f74f\n- https///gitee.com:mirrors_WyAtu/CVE-2018-8581.git\n- https://vulncheck.com/xdb/7730cd30a582\n- https://github.com/Ridter/Exchange2domain\n- https///github.com:Ridter/Exchange2domain.git\n- https://vulncheck.com/xdb/d7f23b749ff9\n- https://github.com/qiantu88/CVE-2018-8581\n- https///github.com:qiantu88/CVE-2018-8581.git\n- https://vulncheck.com/xdb/dba145cf3cba\n- https://github.com/WyAtu/CVE-2018-8581\n- https///github.com:WyAtu/CVE-2018-8581.git\n- https://vulncheck.com/xdb/3d3434d62f82\n- https///github.com:thezdi/PoC.git\n\n### KEV: True\n\n### Shodan Query: `cpe:\"cpe:2.3:a:microsoft:exchange_server\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14576"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14576",
              "body": "\n### Description: \n> Microsoft Exchange Server contains an elevation of privilege caused by a vulnerability in the system, letting attackers escalate their privileges, exploit requires specific conditions not specified.\n\n#### Severity: `High`\n\n#### POC: \n- https://vulncheck.com/xdb/276c34c7f74f\n- https///gitee.com:mirrors_WyAtu/CVE-2018-8581.git\n- https://vulncheck.com/xdb/7730cd30a582\n- https://github.com/Ridter/Exchange2domain\n- https///github.com:Ridter/Exchange2domain.git\n- https://vulncheck.com/xdb/d7f23b749ff9\n- https://github.com/qiantu88/CVE-2018-8581\n- https///github.com:qiantu88/CVE-2018-8581.git\n- https://vulncheck.com/xdb/dba145cf3cba\n- https://github.com/WyAtu/CVE-2018-8581\n- https///github.com:WyAtu/CVE-2018-8581.git\n- https://vulncheck.com/xdb/3d3434d62f82\n- https///github.com:thezdi/PoC.git\n\n### KEV: True\n\n### Shodan Query: `cpe:\"cpe:2.3:a:microsoft:exchange_server\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14576",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14535",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-01-18T17:52:14.856Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:52:14.856Z",
            "created_at": "2026-01-18T17:52:14.856Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14535",
              "status": "open",
              "type": "issue",
              "number": 14535,
              "title": "CVE-2018-20753 - Kaseya VSA - Command Injection ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14535",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2018-20753 - Kaseya VSA - Command Injection ðŸ’°",
                  "body": "\n### Description: \n> Kaseya VSA RMM before R9.3 9.3.0.35, R9.4 before 9.4.0.36, and R9.5 before 9.5.0.5 contain a command injection caused by insufficient input validation in PowerShell execution, letting unprivileged remote attackers execute arbitrary PowerShell payloads on all managed devices, exploit requires network access to the system.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://blog.huntresslabs.com/deep-dive-kaseya-vsa-mining-payload-c0ac839a0e88\n\n### KEV: True\n\n### Shodan Query: `http.favicon.hash:-1445519482`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14535"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14535",
              "body": "\n### Description: \n> Kaseya VSA RMM before R9.3 9.3.0.35, R9.4 before 9.4.0.36, and R9.5 before 9.5.0.5 contain a command injection caused by insufficient input validation in PowerShell execution, letting unprivileged remote attackers execute arbitrary PowerShell payloads on all managed devices, exploit requires network access to the system.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://blog.huntresslabs.com/deep-dive-kaseya-vsa-mining-payload-c0ac839a0e88\n\n### KEV: True\n\n### Shodan Query: `http.favicon.hash:-1445519482`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14535",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14488",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-01-18T17:52:14.969Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:52:14.969Z",
            "created_at": "2026-01-18T17:52:14.969Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14488",
              "status": "open",
              "type": "issue",
              "number": 14488,
              "title": "CVE-2024-3408 - man-group/dtale - Authentication Bypass & Remote Code Execution ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14488",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2024-3408 - man-group/dtale - Authentication Bypass & Remote Code Execution ðŸ’°",
                  "body": "\n### Description: \n> man-group/dtale 3.10.0 contains an authentication bypass and remote code execution caused by improper input validation and a hardcoded SECRET_KEY in Flask configuration, letting attackers forge session cookies and execute arbitrary code, exploit requires attacker to access the application.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://huntr.com/bounties/57a06666-ff85-4577-af19-f3dfb7b02f91\n- https://github.com/rapid7/metasploit-framework/blob/master/modules/exploits/linux/http/dtale_rce_cve_2025_0655.rb\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14488"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14488",
              "body": "\n### Description: \n> man-group/dtale 3.10.0 contains an authentication bypass and remote code execution caused by improper input validation and a hardcoded SECRET_KEY in Flask configuration, letting attackers forge session cookies and execute arbitrary code, exploit requires attacker to access the application.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://huntr.com/bounties/57a06666-ff85-4577-af19-f3dfb7b02f91\n- https://github.com/rapid7/metasploit-framework/blob/master/modules/exploits/linux/http/dtale_rce_cve_2025_0655.rb\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14488",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14488",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-01-18T17:52:14.986Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:52:14.986Z",
            "created_at": "2026-01-18T17:52:14.986Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14488",
              "status": "open",
              "type": "issue",
              "number": 14488,
              "title": "CVE-2024-3408 - man-group/dtale - Authentication Bypass & Remote Code Execution ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14488",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2024-3408 - man-group/dtale - Authentication Bypass & Remote Code Execution ðŸ’°",
                  "body": "\n### Description: \n> man-group/dtale 3.10.0 contains an authentication bypass and remote code execution caused by improper input validation and a hardcoded SECRET_KEY in Flask configuration, letting attackers forge session cookies and execute arbitrary code, exploit requires attacker to access the application.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://huntr.com/bounties/57a06666-ff85-4577-af19-f3dfb7b02f91\n- https://github.com/rapid7/metasploit-framework/blob/master/modules/exploits/linux/http/dtale_rce_cve_2025_0655.rb\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14488"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14488",
              "body": "\n### Description: \n> man-group/dtale 3.10.0 contains an authentication bypass and remote code execution caused by improper input validation and a hardcoded SECRET_KEY in Flask configuration, letting attackers forge session cookies and execute arbitrary code, exploit requires attacker to access the application.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://huntr.com/bounties/57a06666-ff85-4577-af19-f3dfb7b02f91\n- https://github.com/rapid7/metasploit-framework/blob/master/modules/exploits/linux/http/dtale_rce_cve_2025_0655.rb\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14488",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14451",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-01-18T17:52:15.082Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:52:15.082Z",
            "created_at": "2026-01-18T17:52:15.082Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14451",
              "status": "open",
              "type": "issue",
              "number": 14451,
              "title": "CVE-2017-18365 - GitHub Enterprise - Insecure Deserialization ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14451",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2017-18365 - GitHub Enterprise - Insecure Deserialization ðŸ’°",
                  "body": "\n### Description: \n> GitHub Enterprise 2.8.x before 2.8.7 contains a deserialization caused by a static enterprise session secret in the Management Console, letting unauthenticated attackers execute arbitrary code, exploit requires crafting a signed cookie with the secret.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://www.exablue.de/blog/2017-03-15-github-enterprise-remote-code-execution.html\n- https://github.com/rapid7/metasploit-framework/blob/master/modules/exploits/linux/http/github_enterprise_secret.rb\n\n### KEV: True\n\n### Shodan Query: `http.title:\"github debug\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14451"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14451",
              "body": "\n### Description: \n> GitHub Enterprise 2.8.x before 2.8.7 contains a deserialization caused by a static enterprise session secret in the Management Console, letting unauthenticated attackers execute arbitrary code, exploit requires crafting a signed cookie with the secret.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://www.exablue.de/blog/2017-03-15-github-enterprise-remote-code-execution.html\n- https://github.com/rapid7/metasploit-framework/blob/master/modules/exploits/linux/http/github_enterprise_secret.rb\n\n### KEV: True\n\n### Shodan Query: `http.title:\"github debug\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14451",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14436",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-01-18T17:52:15.180Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:52:15.180Z",
            "created_at": "2026-01-18T17:52:15.180Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14436",
              "status": "open",
              "type": "issue",
              "number": 14436,
              "title": "CVE-2019-8978 - Ellucian Banner - Broken Authentication ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14436",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2019-8978 - Ellucian Banner - Broken Authentication ðŸ’°",
                  "body": "\n### Description: \n> Ellucian Banner Web Tailor 8.8.3, 8.8.4, 8.9 and Banner Enterprise Identity Services 8.3, 8.3.1, 8.3.2, 8.4 contain an improper authentication caused by a race condition in conjunction with SSO Manager, letting remote attackers steal sessions and cause denial of service, exploit requires repeated requests with victimâ€™s IDMSESSID cookie.\n\n#### Severity: `High`\n\n#### POC: \n- https://github.com/SecKatie/CVE-2019-8978\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14436"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14436",
              "body": "\n### Description: \n> Ellucian Banner Web Tailor 8.8.3, 8.8.4, 8.9 and Banner Enterprise Identity Services 8.3, 8.3.1, 8.3.2, 8.4 contain an improper authentication caused by a race condition in conjunction with SSO Manager, letting remote attackers steal sessions and cause denial of service, exploit requires repeated requests with victimâ€™s IDMSESSID cookie.\n\n#### Severity: `High`\n\n#### POC: \n- https://github.com/SecKatie/CVE-2019-8978\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14436",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14382",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-01-18T17:52:15.287Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:52:15.287Z",
            "created_at": "2026-01-18T17:52:15.287Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14382",
              "status": "open",
              "type": "issue",
              "number": 14382,
              "title": "CVE-2018-19629 - Hyland Perceptive Content Server - Denial of Service ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14382",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2018-19629 - Hyland Perceptive Content Server - Denial of Service ðŸ’°",
                  "body": "\n### Description: \n> Hyland Perceptive Content Server before 7.1.5 contains a denial of service caused by crashing the ImageNow Server service via a TCP connection, letting attackers disrupt service, exploit requires sending crafted TCP packets.\n\n#### Severity: `High`\n\n#### POC: \n- https://www.oppositionsecurity.com/imagenow-7-1-4-dos/\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14382"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14382",
              "body": "\n### Description: \n> Hyland Perceptive Content Server before 7.1.5 contains a denial of service caused by crashing the ImageNow Server service via a TCP connection, letting attackers disrupt service, exploit requires sending crafted TCP packets.\n\n#### Severity: `High`\n\n#### POC: \n- https://www.oppositionsecurity.com/imagenow-7-1-4-dos/\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14382",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14297",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-01-18T17:52:15.414Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:52:15.414Z",
            "created_at": "2026-01-18T17:52:15.414Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14297",
              "status": "open",
              "type": "issue",
              "number": 14297,
              "title": "CVE-2019-3980 - Solarwinds Dameware Mini Remote Client - Remote Code Execution ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14297",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2019-3980 - Solarwinds Dameware Mini Remote Client - Remote Code Execution ðŸ’°",
                  "body": "\n### Description: \n> Solarwinds Dameware Mini Remote Client agent v12.1.0.89 contains a remote code execution caused by support for smart card authentication allowing upload and execution of arbitrary executables on the host, letting unauthenticated attackers execute code under the Local System account, exploit requires requesting smart card login.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://www.tenable.com/security/research/tra-227-43\n- https://github.com/CyberQuestor-infosec/CVE-2019-3980-Open_Net_Admin_v18.1.1_RCE\n- https///github.com:CyberQuestor-infosec/CVE-2019-3980-Open_Net_Admin_v18.1.1_RCE.git\n- https://github.com/Barbarisch/CVE-2019-3980\n- https://vulncheck.com/xdb/b2d525559d87\n- https///github.com:Barbarisch/CVE-2019-3980.git\n- https://github.com/warferik/CVE-2019-3980\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14297"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14297",
              "body": "\n### Description: \n> Solarwinds Dameware Mini Remote Client agent v12.1.0.89 contains a remote code execution caused by support for smart card authentication allowing upload and execution of arbitrary executables on the host, letting unauthenticated attackers execute code under the Local System account, exploit requires requesting smart card login.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://www.tenable.com/security/research/tra-227-43\n- https://github.com/CyberQuestor-infosec/CVE-2019-3980-Open_Net_Admin_v18.1.1_RCE\n- https///github.com:CyberQuestor-infosec/CVE-2019-3980-Open_Net_Admin_v18.1.1_RCE.git\n- https://github.com/Barbarisch/CVE-2019-3980\n- https://vulncheck.com/xdb/b2d525559d87\n- https///github.com:Barbarisch/CVE-2019-3980.git\n- https://github.com/warferik/CVE-2019-3980\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14297",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14278",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-01-18T17:52:15.544Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-18T17:52:15.544Z",
            "created_at": "2026-01-18T17:52:15.544Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14278",
              "status": "open",
              "type": "issue",
              "number": 14278,
              "title": "CVE-2019-18935 - Progress Telerik UI for ASP.NET AJAX - Insecure Deserialization ðŸ’°",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14278",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2019-18935 - Progress Telerik UI for ASP.NET AJAX - Insecure Deserialization ðŸ’°",
                  "body": "\n### Description: \n> Progress Telerik UI for ASP.NET AJAX <= 2019.3.1023 contains a .NET deserialization caused by insecure RadAsyncUpload function, letting attackers with known encryption keys execute remote code, exploit requires known encryption keys or specific settings.\n\n#### Severity: `Critical`\n\n#### POC: \n- http://packetstormsecurity.com/files/159653/Telerik-UI-ASP.NET-AJAX-RadAsyncUpload-Deserialization.html\n- https://github.com/bao7uo/RAU_crypto\n- https://github.com/noperator/CVE-2019-18935\n- https://know.bishopfox.com/research/cve-2019-18935-remote-code-execution-in-telerik-ui\n- https://github.com/rapid7/metasploit-framework/blob/master/modules/exploits/windows/http/telerik_rau_deserialization.rb\n- https://github.com/menashe12346/CVE-2019-18935\n- https///github.com:menashe12346/CVE-2019-18935.git\n- https://github.com/quyt0/CVE-2019-18935-exploit-study\n- https///github.com:quyt0/CVE-2019-18935-exploit-study.git\n- https///github.com:hnytgl/TelerikUI-RCE.git\n- https://github.com/0xsharz/telerik-scanner-CVE-2019-18935\n- https://github.com/ekkoo-z/CVE-2019-18935-bypasswaf\n- https///github.com:ekkoo-z/CVE-2019-18935-bypasswaf.git\n- https://vulncheck.com/xdb/c621c71a9bf3\n- https://github.com/clarkvoss/telerik\n- https///github.com:clarkvoss/telerik.git\n- https://github.com/dust-life/CVE-2019-18935-memShell\n- https://github.com/KasunPriyashan/Telerik-UI-ASP.NET-AJAX-Exploitation\n- https://vulncheck.com/xdb/dffdf06b5f8a\n- https://github.com/0xAgun/CVE-2019-18935-checker\n- https///github.com:0xAgun/CVE-2019-18935-checker.git\n- https://github.com/random-robbie/CVE-2019-18935\n- https://vulncheck.com/xdb/dd4d5145d7fd\n- https://github.com/appliedi/Telerik_CVE-2019-18935\n- https///github.com:appliedi/Telerik_CVE-2019-18935.git\n- https://vulncheck.com/xdb/8dc793fec147\n- https://github.com/murataydemir/CVE-2019-18935\n- https///github.com:murataydemir/CVE-2019-18935.git\n- https://vulncheck.com/xdb/569e3fec38c8\n- https://github.com/ThanHuuTuan/CVE_2019_18935\n- https///github.com:ThanHuuTuan/CVE_2019_18935.git\n- https://vulncheck.com/xdb/48d2eb3dee46\n- https://github.com/ThanHuuTuan/Telerik_CVE-2019-18935\n- https///github.com:ThanHuuTuan/Telerik_CVE-2019-18935.git\n- https://vulncheck.com/xdb/6733f1b67fb2\n- https://github.com/becrevex/Telerik_CVE-2019-18935\n- https///github.com:becrevex/Telerik_CVE-2019-18935.git\n- https://vulncheck.com/xdb/de3ebe4e8ea8\n- https///github.com:noperator/CVE-2019-18935.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14278"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14278",
              "body": "\n### Description: \n> Progress Telerik UI for ASP.NET AJAX <= 2019.3.1023 contains a .NET deserialization caused by insecure RadAsyncUpload function, letting attackers with known encryption keys execute remote code, exploit requires known encryption keys or specific settings.\n\n#### Severity: `Critical`\n\n#### POC: \n- http://packetstormsecurity.com/files/159653/Telerik-UI-ASP.NET-AJAX-RadAsyncUpload-Deserialization.html\n- https://github.com/bao7uo/RAU_crypto\n- https://github.com/noperator/CVE-2019-18935\n- https://know.bishopfox.com/research/cve-2019-18935-remote-code-execution-in-telerik-ui\n- https://github.com/rapid7/metasploit-framework/blob/master/modules/exploits/windows/http/telerik_rau_deserialization.rb\n- https://github.com/menashe12346/CVE-2019-18935\n- https///github.com:menashe12346/CVE-2019-18935.git\n- https://github.com/quyt0/CVE-2019-18935-exploit-study\n- https///github.com:quyt0/CVE-2019-18935-exploit-study.git\n- https///github.com:hnytgl/TelerikUI-RCE.git\n- https://github.com/0xsharz/telerik-scanner-CVE-2019-18935\n- https://github.com/ekkoo-z/CVE-2019-18935-bypasswaf\n- https///github.com:ekkoo-z/CVE-2019-18935-bypasswaf.git\n- https://vulncheck.com/xdb/c621c71a9bf3\n- https://github.com/clarkvoss/telerik\n- https///github.com:clarkvoss/telerik.git\n- https://github.com/dust-life/CVE-2019-18935-memShell\n- https://github.com/KasunPriyashan/Telerik-UI-ASP.NET-AJAX-Exploitation\n- https://vulncheck.com/xdb/dffdf06b5f8a\n- https://github.com/0xAgun/CVE-2019-18935-checker\n- https///github.com:0xAgun/CVE-2019-18935-checker.git\n- https://github.com/random-robbie/CVE-2019-18935\n- https://vulncheck.com/xdb/dd4d5145d7fd\n- https://github.com/appliedi/Telerik_CVE-2019-18935\n- https///github.com:appliedi/Telerik_CVE-2019-18935.git\n- https://vulncheck.com/xdb/8dc793fec147\n- https://github.com/murataydemir/CVE-2019-18935\n- https///github.com:murataydemir/CVE-2019-18935.git\n- https://vulncheck.com/xdb/569e3fec38c8\n- https://github.com/ThanHuuTuan/CVE_2019_18935\n- https///github.com:ThanHuuTuan/CVE_2019_18935.git\n- https://vulncheck.com/xdb/48d2eb3dee46\n- https://github.com/ThanHuuTuan/Telerik_CVE-2019-18935\n- https///github.com:ThanHuuTuan/Telerik_CVE-2019-18935.git\n- https://vulncheck.com/xdb/6733f1b67fb2\n- https://github.com/becrevex/Telerik_CVE-2019-18935\n- https///github.com:becrevex/Telerik_CVE-2019-18935.git\n- https://vulncheck.com/xdb/de3ebe4e8ea8\n- https///github.com:noperator/CVE-2019-18935.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wonâ€™t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14278",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          }
        ],
        "next_cursor": null
      }
    }
  }
}