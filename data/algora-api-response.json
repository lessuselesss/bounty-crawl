{
  "result": {
    "data": {
      "json": {
        "items": [
          {
            "id": "golemcloud#275",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "golemcloud",
              "id": "generated-golemcloud",
              "name": "Golemcloud",
              "description": "",
              "members": [],
              "display_name": "Golemcloud",
              "created_at": "2026-01-12T11:35:28.607Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/golemcloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:28.607Z",
            "created_at": "2026-01-12T11:35:28.607Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-golemcloud#275",
              "status": "open",
              "type": "issue",
              "number": 275,
              "title": "Incorporate MCP Server into Golem CLI",
              "source": {
                "data": {
                  "id": "source-golemcloud#275",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Incorporate MCP Server into Golem CLI",
                  "body": "With a new command, Golem CLI enters serve mode:\n\n```bash\n%> golem-cli --serve --serve-port 1232\n%> golem-cli running MCP Server at port 1232\n```\n\nIn this mode, Golem CLI creates an MCP Server that exposes different commands as different tools, and exposes relevant resources (the manifest file in the current, ancestor, and children directories) as resources.\n\nWhen this ticket is completed, it should be possible to use an agent such as Claude Code to perform anything that Golem CLI can do. Moreover, all individual tools and resources must be end-to-end tested with an MCP Client that interacts with the MCP Server.\n\n[This library](https://github.com/rust-mcp-stack/rust-mcp-sdk) looks like the one to use for Rust, but perhaps there are better options available.",
                  "html_url": "https://github.com/golemcloud/golem/issues/1926"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem-cli#275",
              "body": "With a new command, Golem CLI enters serve mode:\n\n```bash\n%> golem-cli --serve --serve-port 1232\n%> golem-cli running MCP Server at port 1232\n```\n\nIn this mode, Golem CLI creates an MCP Server that exposes different commands as different tools, and exposes relevant resources (the manifest file in the current, ancestor, and children directories) as resources.\n\nWhen this ticket is completed, it should be possible to use an agent such as Claude Code to perform anything that Golem CLI can do. Moreover, all individual tools and resources must be end-to-end tested with an MCP Client that interacts with the MCP Server.\n\n[This library](https://github.com/rust-mcp-stack/rust-mcp-sdk) looks like the one to use for Rust, but perhaps there are better options available.",
              "url": "https://github.com/golemcloud/golem/issues/1926",
              "tech": [
                "go"
              ],
              "repo_name": "golem-cli",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "golemcloud#23",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "golemcloud",
              "id": "generated-golemcloud",
              "name": "Golemcloud",
              "description": "",
              "members": [],
              "display_name": "Golemcloud",
              "created_at": "2026-01-12T11:35:28.871Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/golemcloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:28.871Z",
            "created_at": "2026-01-12T11:35:28.871Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-golemcloud#23",
              "status": "open",
              "type": "issue",
              "number": 23,
              "title": "Implement Durable Text-to-Speech Provider Components for golem:tts WIT Interface",
              "source": {
                "data": {
                  "id": "source-golemcloud#23",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Implement Durable Text-to-Speech Provider Components for golem:tts WIT Interface",
                  "body": "I have attached to this ticket a WIT file that describes a generic interface for text-to-speech operations. This interface can be implemented by various providers, either by emulating features not present in a given provider, utilizing the provider's native support for a feature, or indicating an error if a particular combination is not natively supported by a provider.\n\nThe intent of this WIT specification is to allow developers of WASM components (on wasmCloud, Spin, or Golem) to leverage text-to-speech capabilities to build voice-powered applications, accessibility services, and audio content generation systems in a portable and provider-agnostic fashion.\n\nThis ticket involves constructing implementations of this WIT interface for the following providers:\n\n- **ElevenLabs**: The leading AI voice synthesis platform with comprehensive voice cloning, real-time streaming, voice conversion, and sound effects generation capabilities.\n- **AWS Polly**: Amazon's enterprise text-to-speech service with extensive language support, custom lexicons, speech marks, and asynchronous synthesis for long-form content.\n- **Google Cloud Text-to-Speech**: Google's neural voice synthesis service with WaveNet and Neural2 voices, device optimization profiles, and streaming synthesis capabilities.\n- **Deepgram Aura**: High-performance real-time TTS with session-based streaming, low-latency neural voices, and conversational AI optimization.\n\nThese implementations must be written in Rust and compilable to WASM Components (WASI 0.23 only, since Golem does not yet support WASI 0.3). The standard Rust toolchain for WASM component development can be employed (see cargo component and the Rust examples of components in this and other Golem repositories).\n\nAdditionally, these implementations should incorporate custom durability semantics using the Golem durability API and the Golem host API. This approach ensures that durability is managed at the level of individual TTS operations (voice synthesis, streaming session creation, voice cloning, batch processing), providing a higher-level and clearer operation log, which aids in debugging and monitoring. See golem:llm and golem:embed for more details and durable implementations in this same repository.\n\nThe final deliverables associated with this ticket are:\n\n- **ElevenLabs implementation**: A WASM Component (WASI 0.23), named `tts-elevenlabs.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **AWS Polly implementation**: A WASM Component (WASI 0.23), named `tts-polly.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Google Cloud TTS implementation**: A WASM Component (WASI 0.23), named `tts-google.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Deepgram Aura implementation**: A WASM Component (WASI 0.23), named `tts-deepgram.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n\n**Note**: If you have a strong recommendation to swap out one or two of these with other popular / common TTS providers (such as Azure Cognitive Services Speech, IBM Watson Text to Speech, or OpenAI TTS), then as long as you get permission beforehand, that's okay with me. However, we definitely need ElevenLabs and AWS Polly.\n\nThese components will require runtime configuration, notably API keys, endpoint URLs, authentication credentials, and provider-specific settings. For configuring this information, the components can use environment variables for now (in the future, they will use wasi-runtime-config, but Golem does not support this yet, whereas Golem has good support for environment variables).\n\nMoreover, the Rust components need to be tested within Golem to ensure compatibility with Golem 1.2.x.\n\nThis WIT has been designed by examining and comparing the APIs of ElevenLabs, AWS Polly, Google Cloud TTS, Azure Speech Services, OpenAI TTS, and Deepgram Aura. However, given there are no implementations, it is possible the provided WIT is not the optimal abstraction across all these providers. Therefore, deviations from the proposed design can be made. However, to be accepted, any deviation must be fully justified and deemed by Golem core contributors to be an improvement from the original specification.\n\n## Implementation Guidelines\n\nEach provider implementation should handle the following key mapping considerations:\n\n- **Voice Management**: Map the unified voice resource to provider-specific voice identifiers, handle voice discovery and metadata appropriately for each provider's voice catalog structure\n- **Audio Format Conversion**: Implement native audio format support where available, or provide format conversion for unsupported output formats using audio processing libraries\n- **Streaming Implementation**: Utilize native streaming APIs where supported (ElevenLabs, Deepgram), or implement chunk-based synthesis for providers without native streaming support\n- **Authentication Handling**: Implement appropriate authentication mechanisms (API keys, OAuth, service accounts) per provider requirements\n- **Feature Availability**: Route advanced features (voice cloning, sound effects, speech marks) through provider-native APIs where supported, or return `unsupported-operation` errors for unavailable features\n- **Error Mapping**: Map provider-specific HTTP errors and API responses to the unified `tts-error` enumeration with appropriate context preservation\n- **Rate Limiting**: Handle provider-specific rate limits and quota management, implementing appropriate retry logic and error reporting\n- **Long-form Content**: Implement efficient handling of long-form synthesis using provider-native async operations (AWS Polly) or intelligent chunking strategies\n\n## Testing Requirements\n\nEach implementation must include comprehensive test suites covering:\n- Basic synthesis operations (text-to-speech with various voices and configurations)\n- Voice discovery and metadata retrieval\n- Streaming synthesis lifecycle (session creation, chunk processing, cleanup)\n- Advanced feature testing (voice cloning, sound effects, custom pronunciations where supported)\n- Audio format validation and quality verification\n- Authentication and authorization scenarios\n- Error handling for unsupported operations and malformed inputs\n- Rate limiting and quota management behavior\n- Connection management and retry logic\n- Long-form content synthesis (>5000 characters)\n- Durability semantics verification across operation boundaries\n- Provider-specific feature utilization (lexicons for Polly, voice settings for ElevenLabs, etc.)\n\n## Configuration Requirements\n\nEach implementation should support the following environment variables:\n\n### Common Configuration\n- `TTS_PROVIDER_ENDPOINT`: Custom endpoint URL (for enterprise/regional deployments)\n- `TTS_PROVIDER_TIMEOUT`: Request timeout in seconds (default: 30)\n- `TTS_PROVIDER_MAX_RETRIES`: Maximum retry attempts (default: 3)\n- `TTS_PROVIDER_LOG_LEVEL`: Logging verbosity (debug, info, warn, error)\n\n### Provider-Specific Configuration\n- **ElevenLabs**: `ELEVENLABS_API_KEY`, `ELEVENLABS_MODEL_VERSION`\n- **AWS Polly**: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `AWS_SESSION_TOKEN`\n- **Google Cloud**: `GOOGLE_APPLICATION_CREDENTIALS`, `GOOGLE_CLOUD_PROJECT`\n- **Deepgram**: `DEEPGRAM_API_KEY`, `DEEPGRAM_API_VERSION`\n\n```wit\npackage golem:tts@1.0.0;\n\n/// Core types and error handling for universal text-to-speech\ninterface types {\n    /// Comprehensive error types covering all TTS operations\n    variant tts-error {\n        /// Input validation errors\n        invalid-text(string),\n        text-too-long(u32),\n        invalid-ssml(string),\n        unsupported-language(string),\n        \n        /// Voice and model errors\n        voice-not-found(string),\n        model-not-found(string),\n        voice-unavailable(string),\n        \n        /// Authentication and authorization\n        unauthorized(string),\n        access-denied(string),\n        \n        /// Resource and quota limits\n        quota-exceeded(quota-info),\n        rate-limited(u32),\n        insufficient-credits,\n        \n        /// Operation errors\n        synthesis-failed(string),\n        unsupported-operation(string),\n        invalid-configuration(string),\n        \n        /// Service errors\n        service-unavailable(string),\n        network-error(string),\n        internal-error(string),\n        \n        /// Storage errors (for async operations)\n        invalid-storage-location(string),\n        storage-access-denied(string),\n    }\n\n    record quota-info {\n        used: u32,\n        limit: u32,\n        reset-time: u64,\n        unit: quota-unit,\n    }\n\n    enum quota-unit {\n        characters,\n        requests,\n        seconds,\n        credits,\n    }\n\n    /// Language identification using BCP 47 codes\n    type language-code = string;\n\n    /// Voice gender classification\n    enum voice-gender {\n        male,\n        female,\n        neutral,\n    }\n\n    /// Voice quality tiers\n    enum voice-quality {\n        standard,\n        premium,\n        neural,\n        studio,\n    }\n\n    /// Text input types\n    enum text-type {\n        plain,\n        ssml,\n    }\n\n    /// Audio output formats\n    enum audio-format {\n        mp3,\n        wav,\n        pcm,\n        ogg-opus,\n        aac,\n        flac,\n        mulaw,\n        alaw,\n    }\n\n    /// Audio quality settings\n    record audio-config {\n        format: audio-format,\n        sample-rate: option<u32>,\n        bit-rate: option<u32>,\n        channels: option<u8>,\n    }\n\n    /// Voice synthesis parameters\n    record voice-settings {\n        /// Speaking rate (0.25 to 4.0, default 1.0)\n        speed: option<f32>,\n        /// Pitch adjustment in semitones (-20.0 to 20.0, default 0.0)\n        pitch: option<f32>,\n        /// Volume gain in dB (-96.0 to 16.0, default 0.0)\n        volume: option<f32>,\n        /// Voice stability (0.0 to 1.0, provider-specific)\n        stability: option<f32>,\n        /// Similarity to original (0.0 to 1.0, provider-specific)\n        similarity: option<f32>,\n        /// Style exaggeration (0.0 to 1.0, provider-specific)\n        style: option<f32>,\n    }\n\n    /// Audio effects and device optimization\n    flags audio-effects {\n        telephone-quality,\n        headphone-optimized,\n        speaker-optimized,\n        car-audio-optimized,\n        noise-reduction,\n        bass-boost,\n        treble-boost,\n    }\n\n    /// Input text with metadata\n    record text-input {\n        content: string,\n        text-type: text-type,\n        language: option<language-code>,\n    }\n\n    /// Complete synthesis result\n    record synthesis-result {\n        audio-data: list<u8>,\n        metadata: synthesis-metadata,\n    }\n\n    /// Metadata about synthesized audio\n    record synthesis-metadata {\n        duration-seconds: f32,\n        character-count: u32,\n        word-count: u32,\n        audio-size-bytes: u32,\n        request-id: string,\n        provider-info: option<string>,\n    }\n\n    /// Streaming audio chunk\n    record audio-chunk {\n        data: list<u8>,\n        sequence-number: u32,\n        is-final: bool,\n        timing-info: option<timing-info>,\n    }\n\n    /// Timing and synchronization information\n    record timing-info {\n        start-time-seconds: f32,\n        end-time-seconds: option<f32>,\n        text-offset: option<u32>,\n        mark-type: option<timing-mark-type>,\n    }\n\n    enum timing-mark-type {\n        word,\n        sentence,\n        paragraph,\n        ssml-mark,\n        viseme,\n    }\n\n\n}\n\n/// Voice discovery and management\ninterface voices {\n    use types.{tts-error, language-code, voice-gender, voice-quality};\n\n    /// Represents a voice that can be used for speech synthesis\n    resource voice {\n        /// Get voice identification\n        get-id: func() -> string;\n        get-name: func() -> string;\n        get-provider-id: func() -> option<string>;\n        \n        /// Get voice characteristics\n        get-language: func() -> language-code;\n        get-additional-languages: func() -> list<language-code>;\n        get-gender: func() -> voice-gender;\n        get-quality: func() -> voice-quality;\n        get-description: func() -> option<string>;\n        \n        /// Voice capabilities\n        supports-ssml: func() -> bool;\n        get-sample-rates: func() -> list<u32>;\n        get-supported-formats: func() -> list<types.audio-format>;\n        \n        /// Voice management (may return unsupported-operation)\n        update-settings: func(settings: types.voice-settings) -> result<_, tts-error>;\n        delete: func() -> result<_, tts-error>;\n        clone: func() -> result<voice, tts-error>;\n        \n        /// Preview voice with sample text\n        preview: func(text: string) -> result<list<u8>, tts-error>;\n    }\n\n    /// Voice search and filtering\n    record voice-filter {\n        language: option<language-code>,\n        gender: option<voice-gender>,\n        quality: option<voice-quality>,\n        supports-ssml: option<bool>,\n        provider: option<string>,\n        search-query: option<string>,\n    }\n\n    /// Detailed voice information\n    record voice-info {\n        id: string,\n        name: string,\n        language: language-code,\n        additional-languages: list<language-code>,\n        gender: voice-gender,\n        quality: voice-quality,\n        description: option<string>,\n        provider: string,\n        sample-rate: u32,\n        is-custom: bool,\n        is-cloned: bool,\n        preview-url: option<string>,\n        use-cases: list<string>,\n    }\n\n    /// Resource-based iterator for voice results\n    resource voice-results {\n        /// Check if more voices are available\n        has-more: func() -> bool;\n        \n        /// Get next batch of voices\n        get-next: func() -> result<list<voice-info>, tts-error>;\n        \n        /// Get total count if available\n        get-total-count: func() -> option<u32>;\n    }\n\n    /// List available voices with filtering and pagination\n    list-voices: func(\n        filter: option<voice-filter>\n    ) -> result<voice-results, tts-error>;\n\n    /// Get specific voice by ID\n    get-voice: func(voice-id: string) -> result<voice, tts-error>;\n\n    /// Search voices by characteristics\n    search-voices: func(\n        query: string,\n        filter: option<voice-filter>\n    ) -> result<list<voice-info>, tts-error>;\n\n    /// Get supported languages\n    list-languages: func() -> result<list<language-info>, tts-error>;\n\n    record language-info {\n        code: language-code,\n        name: string,\n        native-name: string,\n        voice-count: u32,\n    }\n}\n\n/// Core text-to-speech synthesis operations\ninterface synthesis {\n    use types.{\n        text-input, audio-config, voice-settings, audio-effects,\n        synthesis-result, tts-error, timing-info\n    };\n    use voices.{voice};\n\n    /// Synthesis configuration options\n    record synthesis-options {\n        audio-config: option<audio-config>,\n        voice-settings: option<voice-settings>,\n        audio-effects: option<audio-effects>,\n        enable-timing: option<bool>,\n        enable-word-timing: option<bool>,\n        seed: option<u32>,\n        model-version: option<string>,\n        context: option<synthesis-context>,\n    }\n\n    /// Context for better synthesis quality\n    record synthesis-context {\n        previous-text: option<string>,\n        next-text: option<string>,\n        topic: option<string>,\n        emotion: option<string>,\n        speaking-style: option<string>,\n    }\n\n    /// Convert text to speech (removed async)\n    synthesize: func(\n        input: text-input,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-result, tts-error>;\n\n    /// Batch synthesis for multiple inputs (removed async)\n    synthesize-batch: func(\n        inputs: list<text-input>,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<list<synthesis-result>, tts-error>;\n\n    /// Get timing information without audio synthesis\n    get-timing-marks: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<list<timing-info>, tts-error>;\n\n    /// Validate text before synthesis\n    validate-input: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<validation-result, tts-error>;\n\n    record validation-result {\n        is-valid: bool,\n        character-count: u32,\n        estimated-duration: option<f32>,\n        warnings: list<string>,\n        errors: list<string>,\n    }\n}\n\n/// Real-time streaming synthesis\ninterface streaming {\n    use types.{\n        text-input, audio-config, voice-settings, audio-chunk,\n        tts-error, timing-info\n    };\n    use voices.{voice};\n    use synthesis.{synthesis-options};\n\n    /// Streaming synthesis session\n    resource synthesis-stream {\n        /// Send text for synthesis (can be called multiple times)\n        send-text: func(input: text-input) -> result<_, tts-error>;\n        \n        /// Signal end of input and flush remaining audio\n        finish: func() -> result<_, tts-error>;\n        \n        /// Receive next audio chunk (non-blocking)\n        receive-chunk: func() -> result<option<audio-chunk>, tts-error>;\n        \n        /// Check if more chunks are available\n        has-pending-audio: func() -> bool;\n        \n        /// Get current stream status\n        get-status: func() -> stream-status;\n        \n        /// Close stream and clean up resources\n        close: func();\n    }\n\n    enum stream-status {\n        ready,\n        processing,\n        finished,\n        error,\n        closed,\n    }\n\n    /// Create streaming synthesis session\n    create-stream: func(\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-stream, tts-error>;\n\n    /// Real-time voice conversion streaming\n    create-voice-conversion-stream: func(\n        target-voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<voice-conversion-stream, tts-error>;\n\n    resource voice-conversion-stream {\n        /// Send input audio chunks\n        send-audio: func(audio-data: list<u8>) -> result<_, tts-error>;\n        \n        /// Receive converted audio chunks\n        receive-converted: func() -> result<option<audio-chunk>, tts-error>;\n        \n        finish: func() -> result<_, tts-error>;\n        close: func();\n    }\n}\n\n/// Advanced TTS features and voice manipulation\ninterface advanced {\n    use types.{tts-error, audio-config, language-code};\n    use voices.{voice};\n\n    /// Voice cloning and creation (removed async)\n    create-voice-clone: func(\n        name: string,\n        audio-samples: list<audio-sample>,\n        description: option<string>\n    ) -> result<voice, tts-error>;\n\n    record audio-sample {\n        data: list<u8>,\n        transcript: option<string>,\n        quality-rating: option<u8>,\n    }\n\n    /// Design synthetic voice (removed async)\n    design-voice: func(\n        name: string,\n        characteristics: voice-design-params\n    ) -> result<voice, tts-error>;\n\n    record voice-design-params {\n        gender: types.voice-gender,\n        age-category: age-category,\n        accent: string,\n        personality-traits: list<string>,\n        reference-voice: option<string>,\n    }\n\n    enum age-category {\n        child,\n        young-adult,\n        middle-aged,\n        elderly,\n    }\n\n    /// Voice-to-voice conversion (removed async)\n    convert-voice: func(\n        input-audio: list<u8>,\n        target-voice: borrow<voice>,\n        preserve-timing: option<bool>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Generate sound effects from text description (removed async)\n    generate-sound-effect: func(\n        description: string,\n        duration-seconds: option<f32>,\n        style-influence: option<f32>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Custom pronunciation management\n    resource pronunciation-lexicon {\n        get-name: func() -> string;\n        get-language: func() -> language-code;\n        get-entry-count: func() -> u32;\n        \n        /// Add pronunciation rule\n        add-entry: func(word: string, pronunciation: string) -> result<_, tts-error>;\n        \n        /// Remove pronunciation rule\n        remove-entry: func(word: string) -> result<_, tts-error>;\n        \n        /// Export lexicon content\n        export-content: func() -> result<string, tts-error>;\n    }\n\n    /// Create custom pronunciation lexicon\n    create-lexicon: func(\n        name: string,\n        language: language-code,\n        entries: option<list<pronunciation-entry>>\n    ) -> result<pronunciation-lexicon, tts-error>;\n\n    record pronunciation-entry {\n        word: string,\n        pronunciation: string,\n        part-of-speech: option<string>,\n    }\n\n    /// Long-form content synthesis with optimization (removed async)\n    synthesize-long-form: func(\n        content: string,\n        voice: borrow<voice>,\n        output-location: string,\n        chapter-breaks: option<list<u32>>\n    ) -> result<long-form-operation, tts-error>;\n\n    resource long-form-operation {\n        get-status: func() -> operation-status;\n        get-progress: func() -> f32;\n        cancel: func() -> result<_, tts-error>;\n        get-result: func() -> result<long-form-result, tts-error>;\n    }\n\n    enum operation-status {\n        pending,\n        processing,\n        completed,\n        failed,\n        cancelled,\n    }\n\n    record long-form-result {\n        output-location: string,\n        total-duration: f32,\n        chapter-durations: option<list<f32>>,\n        metadata: types.synthesis-metadata,\n    }\n}\n```",
                  "html_url": "https://github.com/golemcloud/golem-ai/issues/23"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem-ai#23",
              "body": "I have attached to this ticket a WIT file that describes a generic interface for text-to-speech operations. This interface can be implemented by various providers, either by emulating features not present in a given provider, utilizing the provider's native support for a feature, or indicating an error if a particular combination is not natively supported by a provider.\n\nThe intent of this WIT specification is to allow developers of WASM components (on wasmCloud, Spin, or Golem) to leverage text-to-speech capabilities to build voice-powered applications, accessibility services, and audio content generation systems in a portable and provider-agnostic fashion.\n\nThis ticket involves constructing implementations of this WIT interface for the following providers:\n\n- **ElevenLabs**: The leading AI voice synthesis platform with comprehensive voice cloning, real-time streaming, voice conversion, and sound effects generation capabilities.\n- **AWS Polly**: Amazon's enterprise text-to-speech service with extensive language support, custom lexicons, speech marks, and asynchronous synthesis for long-form content.\n- **Google Cloud Text-to-Speech**: Google's neural voice synthesis service with WaveNet and Neural2 voices, device optimization profiles, and streaming synthesis capabilities.\n- **Deepgram Aura**: High-performance real-time TTS with session-based streaming, low-latency neural voices, and conversational AI optimization.\n\nThese implementations must be written in Rust and compilable to WASM Components (WASI 0.23 only, since Golem does not yet support WASI 0.3). The standard Rust toolchain for WASM component development can be employed (see cargo component and the Rust examples of components in this and other Golem repositories).\n\nAdditionally, these implementations should incorporate custom durability semantics using the Golem durability API and the Golem host API. This approach ensures that durability is managed at the level of individual TTS operations (voice synthesis, streaming session creation, voice cloning, batch processing), providing a higher-level and clearer operation log, which aids in debugging and monitoring. See golem:llm and golem:embed for more details and durable implementations in this same repository.\n\nThe final deliverables associated with this ticket are:\n\n- **ElevenLabs implementation**: A WASM Component (WASI 0.23), named `tts-elevenlabs.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **AWS Polly implementation**: A WASM Component (WASI 0.23), named `tts-polly.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Google Cloud TTS implementation**: A WASM Component (WASI 0.23), named `tts-google.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Deepgram Aura implementation**: A WASM Component (WASI 0.23), named `tts-deepgram.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n\n**Note**: If you have a strong recommendation to swap out one or two of these with other popular / common TTS providers (such as Azure Cognitive Services Speech, IBM Watson Text to Speech, or OpenAI TTS), then as long as you get permission beforehand, that's okay with me. However, we definitely need ElevenLabs and AWS Polly.\n\nThese components will require runtime configuration, notably API keys, endpoint URLs, authentication credentials, and provider-specific settings. For configuring this information, the components can use environment variables for now (in the future, they will use wasi-runtime-config, but Golem does not support this yet, whereas Golem has good support for environment variables).\n\nMoreover, the Rust components need to be tested within Golem to ensure compatibility with Golem 1.2.x.\n\nThis WIT has been designed by examining and comparing the APIs of ElevenLabs, AWS Polly, Google Cloud TTS, Azure Speech Services, OpenAI TTS, and Deepgram Aura. However, given there are no implementations, it is possible the provided WIT is not the optimal abstraction across all these providers. Therefore, deviations from the proposed design can be made. However, to be accepted, any deviation must be fully justified and deemed by Golem core contributors to be an improvement from the original specification.\n\n## Implementation Guidelines\n\nEach provider implementation should handle the following key mapping considerations:\n\n- **Voice Management**: Map the unified voice resource to provider-specific voice identifiers, handle voice discovery and metadata appropriately for each provider's voice catalog structure\n- **Audio Format Conversion**: Implement native audio format support where available, or provide format conversion for unsupported output formats using audio processing libraries\n- **Streaming Implementation**: Utilize native streaming APIs where supported (ElevenLabs, Deepgram), or implement chunk-based synthesis for providers without native streaming support\n- **Authentication Handling**: Implement appropriate authentication mechanisms (API keys, OAuth, service accounts) per provider requirements\n- **Feature Availability**: Route advanced features (voice cloning, sound effects, speech marks) through provider-native APIs where supported, or return `unsupported-operation` errors for unavailable features\n- **Error Mapping**: Map provider-specific HTTP errors and API responses to the unified `tts-error` enumeration with appropriate context preservation\n- **Rate Limiting**: Handle provider-specific rate limits and quota management, implementing appropriate retry logic and error reporting\n- **Long-form Content**: Implement efficient handling of long-form synthesis using provider-native async operations (AWS Polly) or intelligent chunking strategies\n\n## Testing Requirements\n\nEach implementation must include comprehensive test suites covering:\n- Basic synthesis operations (text-to-speech with various voices and configurations)\n- Voice discovery and metadata retrieval\n- Streaming synthesis lifecycle (session creation, chunk processing, cleanup)\n- Advanced feature testing (voice cloning, sound effects, custom pronunciations where supported)\n- Audio format validation and quality verification\n- Authentication and authorization scenarios\n- Error handling for unsupported operations and malformed inputs\n- Rate limiting and quota management behavior\n- Connection management and retry logic\n- Long-form content synthesis (>5000 characters)\n- Durability semantics verification across operation boundaries\n- Provider-specific feature utilization (lexicons for Polly, voice settings for ElevenLabs, etc.)\n\n## Configuration Requirements\n\nEach implementation should support the following environment variables:\n\n### Common Configuration\n- `TTS_PROVIDER_ENDPOINT`: Custom endpoint URL (for enterprise/regional deployments)\n- `TTS_PROVIDER_TIMEOUT`: Request timeout in seconds (default: 30)\n- `TTS_PROVIDER_MAX_RETRIES`: Maximum retry attempts (default: 3)\n- `TTS_PROVIDER_LOG_LEVEL`: Logging verbosity (debug, info, warn, error)\n\n### Provider-Specific Configuration\n- **ElevenLabs**: `ELEVENLABS_API_KEY`, `ELEVENLABS_MODEL_VERSION`\n- **AWS Polly**: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `AWS_SESSION_TOKEN`\n- **Google Cloud**: `GOOGLE_APPLICATION_CREDENTIALS`, `GOOGLE_CLOUD_PROJECT`\n- **Deepgram**: `DEEPGRAM_API_KEY`, `DEEPGRAM_API_VERSION`\n\n```wit\npackage golem:tts@1.0.0;\n\n/// Core types and error handling for universal text-to-speech\ninterface types {\n    /// Comprehensive error types covering all TTS operations\n    variant tts-error {\n        /// Input validation errors\n        invalid-text(string),\n        text-too-long(u32),\n        invalid-ssml(string),\n        unsupported-language(string),\n        \n        /// Voice and model errors\n        voice-not-found(string),\n        model-not-found(string),\n        voice-unavailable(string),\n        \n        /// Authentication and authorization\n        unauthorized(string),\n        access-denied(string),\n        \n        /// Resource and quota limits\n        quota-exceeded(quota-info),\n        rate-limited(u32),\n        insufficient-credits,\n        \n        /// Operation errors\n        synthesis-failed(string),\n        unsupported-operation(string),\n        invalid-configuration(string),\n        \n        /// Service errors\n        service-unavailable(string),\n        network-error(string),\n        internal-error(string),\n        \n        /// Storage errors (for async operations)\n        invalid-storage-location(string),\n        storage-access-denied(string),\n    }\n\n    record quota-info {\n        used: u32,\n        limit: u32,\n        reset-time: u64,\n        unit: quota-unit,\n    }\n\n    enum quota-unit {\n        characters,\n        requests,\n        seconds,\n        credits,\n    }\n\n    /// Language identification using BCP 47 codes\n    type language-code = string;\n\n    /// Voice gender classification\n    enum voice-gender {\n        male,\n        female,\n        neutral,\n    }\n\n    /// Voice quality tiers\n    enum voice-quality {\n        standard,\n        premium,\n        neural,\n        studio,\n    }\n\n    /// Text input types\n    enum text-type {\n        plain,\n        ssml,\n    }\n\n    /// Audio output formats\n    enum audio-format {\n        mp3,\n        wav,\n        pcm,\n        ogg-opus,\n        aac,\n        flac,\n        mulaw,\n        alaw,\n    }\n\n    /// Audio quality settings\n    record audio-config {\n        format: audio-format,\n        sample-rate: option<u32>,\n        bit-rate: option<u32>,\n        channels: option<u8>,\n    }\n\n    /// Voice synthesis parameters\n    record voice-settings {\n        /// Speaking rate (0.25 to 4.0, default 1.0)\n        speed: option<f32>,\n        /// Pitch adjustment in semitones (-20.0 to 20.0, default 0.0)\n        pitch: option<f32>,\n        /// Volume gain in dB (-96.0 to 16.0, default 0.0)\n        volume: option<f32>,\n        /// Voice stability (0.0 to 1.0, provider-specific)\n        stability: option<f32>,\n        /// Similarity to original (0.0 to 1.0, provider-specific)\n        similarity: option<f32>,\n        /// Style exaggeration (0.0 to 1.0, provider-specific)\n        style: option<f32>,\n    }\n\n    /// Audio effects and device optimization\n    flags audio-effects {\n        telephone-quality,\n        headphone-optimized,\n        speaker-optimized,\n        car-audio-optimized,\n        noise-reduction,\n        bass-boost,\n        treble-boost,\n    }\n\n    /// Input text with metadata\n    record text-input {\n        content: string,\n        text-type: text-type,\n        language: option<language-code>,\n    }\n\n    /// Complete synthesis result\n    record synthesis-result {\n        audio-data: list<u8>,\n        metadata: synthesis-metadata,\n    }\n\n    /// Metadata about synthesized audio\n    record synthesis-metadata {\n        duration-seconds: f32,\n        character-count: u32,\n        word-count: u32,\n        audio-size-bytes: u32,\n        request-id: string,\n        provider-info: option<string>,\n    }\n\n    /// Streaming audio chunk\n    record audio-chunk {\n        data: list<u8>,\n        sequence-number: u32,\n        is-final: bool,\n        timing-info: option<timing-info>,\n    }\n\n    /// Timing and synchronization information\n    record timing-info {\n        start-time-seconds: f32,\n        end-time-seconds: option<f32>,\n        text-offset: option<u32>,\n        mark-type: option<timing-mark-type>,\n    }\n\n    enum timing-mark-type {\n        word,\n        sentence,\n        paragraph,\n        ssml-mark,\n        viseme,\n    }\n\n\n}\n\n/// Voice discovery and management\ninterface voices {\n    use types.{tts-error, language-code, voice-gender, voice-quality};\n\n    /// Represents a voice that can be used for speech synthesis\n    resource voice {\n        /// Get voice identification\n        get-id: func() -> string;\n        get-name: func() -> string;\n        get-provider-id: func() -> option<string>;\n        \n        /// Get voice characteristics\n        get-language: func() -> language-code;\n        get-additional-languages: func() -> list<language-code>;\n        get-gender: func() -> voice-gender;\n        get-quality: func() -> voice-quality;\n        get-description: func() -> option<string>;\n        \n        /// Voice capabilities\n        supports-ssml: func() -> bool;\n        get-sample-rates: func() -> list<u32>;\n        get-supported-formats: func() -> list<types.audio-format>;\n        \n        /// Voice management (may return unsupported-operation)\n        update-settings: func(settings: types.voice-settings) -> result<_, tts-error>;\n        delete: func() -> result<_, tts-error>;\n        clone: func() -> result<voice, tts-error>;\n        \n        /// Preview voice with sample text\n        preview: func(text: string) -> result<list<u8>, tts-error>;\n    }\n\n    /// Voice search and filtering\n    record voice-filter {\n        language: option<language-code>,\n        gender: option<voice-gender>,\n        quality: option<voice-quality>,\n        supports-ssml: option<bool>,\n        provider: option<string>,\n        search-query: option<string>,\n    }\n\n    /// Detailed voice information\n    record voice-info {\n        id: string,\n        name: string,\n        language: language-code,\n        additional-languages: list<language-code>,\n        gender: voice-gender,\n        quality: voice-quality,\n        description: option<string>,\n        provider: string,\n        sample-rate: u32,\n        is-custom: bool,\n        is-cloned: bool,\n        preview-url: option<string>,\n        use-cases: list<string>,\n    }\n\n    /// Resource-based iterator for voice results\n    resource voice-results {\n        /// Check if more voices are available\n        has-more: func() -> bool;\n        \n        /// Get next batch of voices\n        get-next: func() -> result<list<voice-info>, tts-error>;\n        \n        /// Get total count if available\n        get-total-count: func() -> option<u32>;\n    }\n\n    /// List available voices with filtering and pagination\n    list-voices: func(\n        filter: option<voice-filter>\n    ) -> result<voice-results, tts-error>;\n\n    /// Get specific voice by ID\n    get-voice: func(voice-id: string) -> result<voice, tts-error>;\n\n    /// Search voices by characteristics\n    search-voices: func(\n        query: string,\n        filter: option<voice-filter>\n    ) -> result<list<voice-info>, tts-error>;\n\n    /// Get supported languages\n    list-languages: func() -> result<list<language-info>, tts-error>;\n\n    record language-info {\n        code: language-code,\n        name: string,\n        native-name: string,\n        voice-count: u32,\n    }\n}\n\n/// Core text-to-speech synthesis operations\ninterface synthesis {\n    use types.{\n        text-input, audio-config, voice-settings, audio-effects,\n        synthesis-result, tts-error, timing-info\n    };\n    use voices.{voice};\n\n    /// Synthesis configuration options\n    record synthesis-options {\n        audio-config: option<audio-config>,\n        voice-settings: option<voice-settings>,\n        audio-effects: option<audio-effects>,\n        enable-timing: option<bool>,\n        enable-word-timing: option<bool>,\n        seed: option<u32>,\n        model-version: option<string>,\n        context: option<synthesis-context>,\n    }\n\n    /// Context for better synthesis quality\n    record synthesis-context {\n        previous-text: option<string>,\n        next-text: option<string>,\n        topic: option<string>,\n        emotion: option<string>,\n        speaking-style: option<string>,\n    }\n\n    /// Convert text to speech (removed async)\n    synthesize: func(\n        input: text-input,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-result, tts-error>;\n\n    /// Batch synthesis for multiple inputs (removed async)\n    synthesize-batch: func(\n        inputs: list<text-input>,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<list<synthesis-result>, tts-error>;\n\n    /// Get timing information without audio synthesis\n    get-timing-marks: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<list<timing-info>, tts-error>;\n\n    /// Validate text before synthesis\n    validate-input: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<validation-result, tts-error>;\n\n    record validation-result {\n        is-valid: bool,\n        character-count: u32,\n        estimated-duration: option<f32>,\n        warnings: list<string>,\n        errors: list<string>,\n    }\n}\n\n/// Real-time streaming synthesis\ninterface streaming {\n    use types.{\n        text-input, audio-config, voice-settings, audio-chunk,\n        tts-error, timing-info\n    };\n    use voices.{voice};\n    use synthesis.{synthesis-options};\n\n    /// Streaming synthesis session\n    resource synthesis-stream {\n        /// Send text for synthesis (can be called multiple times)\n        send-text: func(input: text-input) -> result<_, tts-error>;\n        \n        /// Signal end of input and flush remaining audio\n        finish: func() -> result<_, tts-error>;\n        \n        /// Receive next audio chunk (non-blocking)\n        receive-chunk: func() -> result<option<audio-chunk>, tts-error>;\n        \n        /// Check if more chunks are available\n        has-pending-audio: func() -> bool;\n        \n        /// Get current stream status\n        get-status: func() -> stream-status;\n        \n        /// Close stream and clean up resources\n        close: func();\n    }\n\n    enum stream-status {\n        ready,\n        processing,\n        finished,\n        error,\n        closed,\n    }\n\n    /// Create streaming synthesis session\n    create-stream: func(\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-stream, tts-error>;\n\n    /// Real-time voice conversion streaming\n    create-voice-conversion-stream: func(\n        target-voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<voice-conversion-stream, tts-error>;\n\n    resource voice-conversion-stream {\n        /// Send input audio chunks\n        send-audio: func(audio-data: list<u8>) -> result<_, tts-error>;\n        \n        /// Receive converted audio chunks\n        receive-converted: func() -> result<option<audio-chunk>, tts-error>;\n        \n        finish: func() -> result<_, tts-error>;\n        close: func();\n    }\n}\n\n/// Advanced TTS features and voice manipulation\ninterface advanced {\n    use types.{tts-error, audio-config, language-code};\n    use voices.{voice};\n\n    /// Voice cloning and creation (removed async)\n    create-voice-clone: func(\n        name: string,\n        audio-samples: list<audio-sample>,\n        description: option<string>\n    ) -> result<voice, tts-error>;\n\n    record audio-sample {\n        data: list<u8>,\n        transcript: option<string>,\n        quality-rating: option<u8>,\n    }\n\n    /// Design synthetic voice (removed async)\n    design-voice: func(\n        name: string,\n        characteristics: voice-design-params\n    ) -> result<voice, tts-error>;\n\n    record voice-design-params {\n        gender: types.voice-gender,\n        age-category: age-category,\n        accent: string,\n        personality-traits: list<string>,\n        reference-voice: option<string>,\n    }\n\n    enum age-category {\n        child,\n        young-adult,\n        middle-aged,\n        elderly,\n    }\n\n    /// Voice-to-voice conversion (removed async)\n    convert-voice: func(\n        input-audio: list<u8>,\n        target-voice: borrow<voice>,\n        preserve-timing: option<bool>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Generate sound effects from text description (removed async)\n    generate-sound-effect: func(\n        description: string,\n        duration-seconds: option<f32>,\n        style-influence: option<f32>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Custom pronunciation management\n    resource pronunciation-lexicon {\n        get-name: func() -> string;\n        get-language: func() -> language-code;\n        get-entry-count: func() -> u32;\n        \n        /// Add pronunciation rule\n        add-entry: func(word: string, pronunciation: string) -> result<_, tts-error>;\n        \n        /// Remove pronunciation rule\n        remove-entry: func(word: string) -> result<_, tts-error>;\n        \n        /// Export lexicon content\n        export-content: func() -> result<string, tts-error>;\n    }\n\n    /// Create custom pronunciation lexicon\n    create-lexicon: func(\n        name: string,\n        language: language-code,\n        entries: option<list<pronunciation-entry>>\n    ) -> result<pronunciation-lexicon, tts-error>;\n\n    record pronunciation-entry {\n        word: string,\n        pronunciation: string,\n        part-of-speech: option<string>,\n    }\n\n    /// Long-form content synthesis with optimization (removed async)\n    synthesize-long-form: func(\n        content: string,\n        voice: borrow<voice>,\n        output-location: string,\n        chapter-breaks: option<list<u32>>\n    ) -> result<long-form-operation, tts-error>;\n\n    resource long-form-operation {\n        get-status: func() -> operation-status;\n        get-progress: func() -> f32;\n        cancel: func() -> result<_, tts-error>;\n        get-result: func() -> result<long-form-result, tts-error>;\n    }\n\n    enum operation-status {\n        pending,\n        processing,\n        completed,\n        failed,\n        cancelled,\n    }\n\n    record long-form-result {\n        output-location: string,\n        total-duration: f32,\n        chapter-durations: option<list<f32>>,\n        metadata: types.synthesis-metadata,\n    }\n}\n```",
              "url": "https://github.com/golemcloud/golem-ai/issues/23",
              "tech": [
                "go"
              ],
              "repo_name": "golem-ai",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7743",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-12T11:35:21.707Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:21.707Z",
            "created_at": "2026-01-12T11:35:21.707Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7743",
              "status": "open",
              "type": "issue",
              "number": 7743,
              "title": "[Enhancement]: Don't timeout public database proxies after 10 min",
              "source": {
                "data": {
                  "id": "source-coollabsio#7743",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Don't timeout public database proxies after 10 min",
                  "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the TCP proxy in front of Postgres when you mark \"Expose publicly\" times out after about 10m. Switch this to have no timeout or to have a configurable timeout in the GUI.\n\nUse case: I sometimes have `SELECT *` statements that take a very long time (30m+) to download the results for. The connection timing out prevents that from being successful\n\nBounty: $100 USD once merged and live on Coolify Cloud.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com), a charity that supports teenagers who love coding and electronics! We previously funded database SSL support, backups API, and pgBackRest support for Postgres backups (in progress).",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7743"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7743",
              "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the TCP proxy in front of Postgres when you mark \"Expose publicly\" times out after about 10m. Switch this to have no timeout or to have a configurable timeout in the GUI.\n\nUse case: I sometimes have `SELECT *` statements that take a very long time (30m+) to download the results for. The connection timing out prevents that from being successful\n\nBounty: $100 USD once merged and live on Coolify Cloud.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com), a charity that supports teenagers who love coding and electronics! We previously funded database SSL support, backups API, and pgBackRest support for Postgres backups (in progress).",
              "url": "https://github.com/coollabsio/coolify/issues/7743",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7738",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-12T11:35:26.314Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:26.314Z",
            "created_at": "2026-01-12T11:35:26.314Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7738",
              "status": "open",
              "type": "issue",
              "number": 7738,
              "title": "[Enhancement]: Environment variables for each server that can be made available to each application deployed on it",
              "source": {
                "data": {
                  "id": "source-coollabsio#7738",
                  "user": {
                    "login": "pkpio",
                    "id": 816666,
                    "node_id": "MDQ6VXNlcjgxNjY2Ng==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/816666?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/pkpio",
                    "html_url": "https://github.com/pkpio",
                    "followers_url": "https://api.github.com/users/pkpio/followers",
                    "following_url": "https://api.github.com/users/pkpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/pkpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/pkpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/pkpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/pkpio/orgs",
                    "repos_url": "https://api.github.com/users/pkpio/repos",
                    "events_url": "https://api.github.com/users/pkpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/pkpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Environment variables for each server that can be made available to each application deployed on it",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\nWhen deploying a resource using the \"Multiple Servers\" option, currently there is no way to distinguish between the servers from within the application - because the container running on both servers get identical setup. \n\nThis makes debugging harder as application logs cannot identify which server deployment an issue happened - take for instance a failure due to network errors happening specifically on one server (randomly). \n\nA way to define Environment variables for each server and making them available for each application deployed on that server, will fix this limitation (and also generalised in a way for use cases beyond what I described here).",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7738"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7738",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\nWhen deploying a resource using the \"Multiple Servers\" option, currently there is no way to distinguish between the servers from within the application - because the container running on both servers get identical setup. \n\nThis makes debugging harder as application logs cannot identify which server deployment an issue happened - take for instance a failure due to network errors happening specifically on one server (randomly). \n\nA way to define Environment variables for each server and making them available for each application deployed on that server, will fix this limitation (and also generalised in a way for use cases beyond what I described here).",
              "url": "https://github.com/coollabsio/coolify/issues/7738",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7724",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-12T11:35:27.723Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:27.723Z",
            "created_at": "2026-01-12T11:35:27.723Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7724",
              "status": "open",
              "type": "issue",
              "number": 7724,
              "title": "[Bug]: Sporadic Permission denied (publickey,password).",
              "source": {
                "data": {
                  "id": "source-coollabsio#7724",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Sporadic Permission denied (publickey,password).",
                  "body": "### Error Message and Logs\n\n<img width=\"380\" height=\"129\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a615ea52-e26d-435d-8121-e01cd7d7f656\" />\n\nStarting maybe ~2 weeks ago we started getting this error constantly. Generating a new private SSH key and setting it up seems to stop it for a bit, then it starts happening again. I'm 99% sure something is causing Coolify to send the wrong SSH key. When I check server logs, it shows that logins are indeed failing. They are not being blocked by fail2ban or anything like that.\n\nI will pay $250 to anyone who can diagnose and fix this issue. It's causing major issues for us. Acceptance criteria: Fix is merged into Coolify Cloud.\n\n### Steps to Reproduce\n\nI'm sorry, I don't have good reproduction steps. It sporadically seems to happen.\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7724"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7724",
              "body": "### Error Message and Logs\n\n<img width=\"380\" height=\"129\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a615ea52-e26d-435d-8121-e01cd7d7f656\" />\n\nStarting maybe ~2 weeks ago we started getting this error constantly. Generating a new private SSH key and setting it up seems to stop it for a bit, then it starts happening again. I'm 99% sure something is causing Coolify to send the wrong SSH key. When I check server logs, it shows that logins are indeed failing. They are not being blocked by fail2ban or anything like that.\n\nI will pay $250 to anyone who can diagnose and fix this issue. It's causing major issues for us. Acceptance criteria: Fix is merged into Coolify Cloud.\n\n### Steps to Reproduce\n\nI'm sorry, I don't have good reproduction steps. It sporadically seems to happen.\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/7724",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7642",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-12T11:35:28.048Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:28.048Z",
            "created_at": "2026-01-12T11:35:28.048Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7642",
              "status": "open",
              "type": "issue",
              "number": 7642,
              "title": "[Enhancement]: Add surrealDB with and without TIKV",
              "source": {
                "data": {
                  "id": "source-coollabsio#7642",
                  "user": {
                    "login": "Jordan-Hall",
                    "id": 2092344,
                    "node_id": "MDQ6VXNlcjIwOTIzNDQ=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/2092344?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Jordan-Hall",
                    "html_url": "https://github.com/Jordan-Hall",
                    "followers_url": "https://api.github.com/users/Jordan-Hall/followers",
                    "following_url": "https://api.github.com/users/Jordan-Hall/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Jordan-Hall/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Jordan-Hall/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Jordan-Hall/subscriptions",
                    "organizations_url": "https://api.github.com/users/Jordan-Hall/orgs",
                    "repos_url": "https://api.github.com/users/Jordan-Hall/repos",
                    "events_url": "https://api.github.com/users/Jordan-Hall/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Jordan-Hall/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Add surrealDB with and without TIKV",
                  "body": "### Request Type\n\nNew Service\n\n### Description\n\nThey a couple of decussion around surrealdb as a database option but it be nice if it was bulit in with both TIKV and rockdb as an option\n\nhttps://github.com/coollabsio/coolify/discussions/3587\nhttps://github.com/coollabsio/coolify/discussions/4013 ",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7642"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7642",
              "body": "### Request Type\n\nNew Service\n\n### Description\n\nThey a couple of decussion around surrealdb as a database option but it be nice if it was bulit in with both TIKV and rockdb as an option\n\nhttps://github.com/coollabsio/coolify/discussions/3587\nhttps://github.com/coollabsio/coolify/discussions/4013 ",
              "url": "https://github.com/coollabsio/coolify/issues/7642",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7596",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-12T11:35:28.303Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:28.303Z",
            "created_at": "2026-01-12T11:35:28.303Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7596",
              "status": "open",
              "type": "issue",
              "number": 7596,
              "title": "[Enhancement]: new deployment page",
              "source": {
                "data": {
                  "id": "source-coollabsio#7596",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: new deployment page",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n- Add deployments to sidebar\n- Show past deployments (all of them)\n- Add a filter on the top:\n  - Filter by project\n  - Filter by server\n  - Filter by sources\n  - Filter by status (queued, pending, done)\n- Show live updates / refresh?\n- Hide filters if only 1 server / 1 source\n\n## Design inspiration\n\nVercel example:\n\n<img width=\"1362\" height=\"967\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e46d7470-fff1-46c5-8011-63ba82119db2\" />\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7596"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7596",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n- Add deployments to sidebar\n- Show past deployments (all of them)\n- Add a filter on the top:\n  - Filter by project\n  - Filter by server\n  - Filter by sources\n  - Filter by status (queued, pending, done)\n- Show live updates / refresh?\n- Hide filters if only 1 server / 1 source\n\n## Design inspiration\n\nVercel example:\n\n<img width=\"1362\" height=\"967\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e46d7470-fff1-46c5-8011-63ba82119db2\" />\n",
              "url": "https://github.com/coollabsio/coolify/issues/7596",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7528",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-12T11:35:28.514Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:28.514Z",
            "created_at": "2026-01-12T11:35:28.514Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7528",
              "status": "open",
              "type": "issue",
              "number": 7528,
              "title": "[Enhancement]: Enable database detection and backup support for Docker Compose deployments via GitHub App",
              "source": {
                "data": {
                  "id": "source-coollabsio#7528",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Enable database detection and backup support for Docker Compose deployments via GitHub App",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nWhen deploying a Docker Compose file via GitHub App (using the `dockercompose` buildpack), database services are not detected and `ServiceDatabase` records are not created. This means automated backups are not available for databases in these deployments.\n\nHowever, when using \"Empty Docker Compose\" or one-click services (like Supabase), database detection works correctly and backups are available.\n\n### Current Behavior\n\n| Deployment Method | Model | Creates ServiceDatabase | Backups Available |\n|---|---|---|---|\n| Empty Docker Compose | `Service` |  Yes |  Yes |\n| GitHub App (dockercompose buildpack) | `Application` |  No |  No |\n| One-click Services (e.g., Supabase) | `Service` |  Yes |  Yes |\n\n### Expected Behavior\n\nDatabase services in Docker Compose files deployed via GitHub App should be detected and have backup functionality available, similar to Empty Docker Compose deployments.\n\n### Technical Details\n\nThe issue is in `bootstrap/helpers/shared.php` in the `parseDockerComposeFile()` function:\n\n**Service model path (lines 1263-2025):**\n- Calls `isDatabaseImage()` to detect databases\n- Creates `ServiceDatabase` records for detected databases\n- These databases can have scheduled backups\n\n**Application model path (lines 2026-2767):**\n- Does NOT call `isDatabaseImage()`\n- Does NOT create `ServiceDatabase` records\n- All services are treated as application containers\n- No backup support\n\n### Proposed Solution\n\nAdd database detection logic to the Application model parsing path:\n\n1. In `parseDockerComposeFile()` for the Application model (around line 2066), add:\n   ```php\n   $isDatabase = isDatabaseImage($image, $service);\n   data_set($service, 'is_database', $isDatabase);\n   ```\n\n2. Create `ServiceDatabase` records for detected database services, similar to how it's done in the Service model path.\n\n3. Alternatively, consider refactoring to share the database detection logic between both paths.\n\n### Use Case\n\nUsers deploying full-stack applications via GitHub (e.g., Next.js app + PostgreSQL + pgbouncer in a single compose file) expect database backups to work the same way as standalone database deployments or one-click services.\n\n### Related Code\n\n- `bootstrap/helpers/shared.php` - `parseDockerComposeFile()` function\n- `bootstrap/helpers/docker.php` - `isDatabaseImage()` function\n- `app/Models/ServiceDatabase.php` - Database model with backup support\n- `app/Models/ScheduledDatabaseBackup.php` - Backup scheduling\n\n### Environment\n\n- Coolify version: latest\n- Deployment method: GitHub App with dockercompose buildpack\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7528"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7528",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nWhen deploying a Docker Compose file via GitHub App (using the `dockercompose` buildpack), database services are not detected and `ServiceDatabase` records are not created. This means automated backups are not available for databases in these deployments.\n\nHowever, when using \"Empty Docker Compose\" or one-click services (like Supabase), database detection works correctly and backups are available.\n\n### Current Behavior\n\n| Deployment Method | Model | Creates ServiceDatabase | Backups Available |\n|---|---|---|---|\n| Empty Docker Compose | `Service` |  Yes |  Yes |\n| GitHub App (dockercompose buildpack) | `Application` |  No |  No |\n| One-click Services (e.g., Supabase) | `Service` |  Yes |  Yes |\n\n### Expected Behavior\n\nDatabase services in Docker Compose files deployed via GitHub App should be detected and have backup functionality available, similar to Empty Docker Compose deployments.\n\n### Technical Details\n\nThe issue is in `bootstrap/helpers/shared.php` in the `parseDockerComposeFile()` function:\n\n**Service model path (lines 1263-2025):**\n- Calls `isDatabaseImage()` to detect databases\n- Creates `ServiceDatabase` records for detected databases\n- These databases can have scheduled backups\n\n**Application model path (lines 2026-2767):**\n- Does NOT call `isDatabaseImage()`\n- Does NOT create `ServiceDatabase` records\n- All services are treated as application containers\n- No backup support\n\n### Proposed Solution\n\nAdd database detection logic to the Application model parsing path:\n\n1. In `parseDockerComposeFile()` for the Application model (around line 2066), add:\n   ```php\n   $isDatabase = isDatabaseImage($image, $service);\n   data_set($service, 'is_database', $isDatabase);\n   ```\n\n2. Create `ServiceDatabase` records for detected database services, similar to how it's done in the Service model path.\n\n3. Alternatively, consider refactoring to share the database detection logic between both paths.\n\n### Use Case\n\nUsers deploying full-stack applications via GitHub (e.g., Next.js app + PostgreSQL + pgbouncer in a single compose file) expect database backups to work the same way as standalone database deployments or one-click services.\n\n### Related Code\n\n- `bootstrap/helpers/shared.php` - `parseDockerComposeFile()` function\n- `bootstrap/helpers/docker.php` - `isDatabaseImage()` function\n- `app/Models/ServiceDatabase.php` - Database model with backup support\n- `app/Models/ScheduledDatabaseBackup.php` - Backup scheduling\n\n### Environment\n\n- Coolify version: latest\n- Deployment method: GitHub App with dockercompose buildpack\n",
              "url": "https://github.com/coollabsio/coolify/issues/7528",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7473",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-12T11:35:28.684Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:28.684Z",
            "created_at": "2026-01-12T11:35:28.684Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7473",
              "status": "open",
              "type": "issue",
              "number": 7473,
              "title": "[Bug]: Database Backups won't use the custom timeout in ssh command (regression)",
              "source": {
                "data": {
                  "id": "source-coollabsio#7473",
                  "user": {
                    "login": "isokosan",
                    "id": 1430946,
                    "node_id": "MDQ6VXNlcjE0MzA5NDY=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1430946?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/isokosan",
                    "html_url": "https://github.com/isokosan",
                    "followers_url": "https://api.github.com/users/isokosan/followers",
                    "following_url": "https://api.github.com/users/isokosan/following{/other_user}",
                    "gists_url": "https://api.github.com/users/isokosan/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/isokosan/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/isokosan/subscriptions",
                    "organizations_url": "https://api.github.com/users/isokosan/orgs",
                    "repos_url": "https://api.github.com/users/isokosan/repos",
                    "events_url": "https://api.github.com/users/isokosan/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/isokosan/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Database Backups won't use the custom timeout in ssh command (regression)",
                  "body": "### Error Message and Logs\n\nWe had [this issue](https://github.com/coollabsio/coolify/issues/3325) with backups exceeding timeouts and we made a new feature where we can customize the timeout settings in the backups.\n\nThis was working but seems to have regressed as the timeout setting is not being passed to the backup ssh command, instead the default 3600 is being used I'm afraid:\n\nThe process \"timeout 3600 ssh -i /var/www/html/storage/app/ssh/keys/ssh_key@jgcwgggco80sc0occ88skg0s -o StrictHos... truncated ...FoM2ROejJRRmtjT1M0NXNt\" exceeded the timeout of 3600 seconds.\n\n@Cinzya commented that this is about the SSH command now and not the backup itself:\n> I believe this is actually the SSH process timing out and not the backup itself.\n> The SSH process has a hard timeout of 3600. The backup timeout is not really passed to the SSH process to increase that timeout as well. \n> This is either an oversight or there is a specific reason why a SSH process shouldn't linger more then 3600 seconds. \n> But yes, feel free to open a new issue about it. \n\n\n### Steps to Reproduce\n\n1. Configure a database and then backups.\n2. Use the Timeout option in the dashboard to set a custom timeout, eg 10800 (default 3600 seconds)\n3. Click on Backup Now\n4. Check the command that is run by coolify to see the timeout not being passed to the SSH command\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7473"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7473",
              "body": "### Error Message and Logs\n\nWe had [this issue](https://github.com/coollabsio/coolify/issues/3325) with backups exceeding timeouts and we made a new feature where we can customize the timeout settings in the backups.\n\nThis was working but seems to have regressed as the timeout setting is not being passed to the backup ssh command, instead the default 3600 is being used I'm afraid:\n\nThe process \"timeout 3600 ssh -i /var/www/html/storage/app/ssh/keys/ssh_key@jgcwgggco80sc0occ88skg0s -o StrictHos... truncated ...FoM2ROejJRRmtjT1M0NXNt\" exceeded the timeout of 3600 seconds.\n\n@Cinzya commented that this is about the SSH command now and not the backup itself:\n> I believe this is actually the SSH process timing out and not the backup itself.\n> The SSH process has a hard timeout of 3600. The backup timeout is not really passed to the SSH process to increase that timeout as well. \n> This is either an oversight or there is a specific reason why a SSH process shouldn't linger more then 3600 seconds. \n> But yes, feel free to open a new issue about it. \n\n\n### Steps to Reproduce\n\n1. Configure a database and then backups.\n2. Use the Timeout option in the dashboard to set a custom timeout, eg 10800 (default 3600 seconds)\n3. Click on Backup Now\n4. Check the command that is run by coolify to see the timeout not being passed to the SSH command\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/7473",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7458",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-12T11:35:28.947Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:28.947Z",
            "created_at": "2026-01-12T11:35:28.947Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7458",
              "status": "open",
              "type": "issue",
              "number": 7458,
              "title": "[Bug + Multiple Bounties]: Official Selfhosted Supabase MCP Setup hindered by Coolify AND Bounty List",
              "source": {
                "data": {
                  "id": "source-coollabsio#7458",
                  "user": {
                    "login": "rootacc3ss",
                    "id": 192549131,
                    "node_id": "U_kgDOC3oRCw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/192549131?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/rootacc3ss",
                    "html_url": "https://github.com/rootacc3ss",
                    "followers_url": "https://api.github.com/users/rootacc3ss/followers",
                    "following_url": "https://api.github.com/users/rootacc3ss/following{/other_user}",
                    "gists_url": "https://api.github.com/users/rootacc3ss/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/rootacc3ss/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/rootacc3ss/subscriptions",
                    "organizations_url": "https://api.github.com/users/rootacc3ss/orgs",
                    "repos_url": "https://api.github.com/users/rootacc3ss/repos",
                    "events_url": "https://api.github.com/users/rootacc3ss/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/rootacc3ss/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug + Multiple Bounties]: Official Selfhosted Supabase MCP Setup hindered by Coolify AND Bounty List",
                  "body": "### Error Message and Logs\n\n**Bounty! $15.00 on Algora.io; will add ASAP, need to figure out how to use it.**\n\nWhen following these documents from Supabase pertaining to the latest selfhosted Supabase docker setup:\nhttps://supabase.com/docs/guides/self-hosting/enable-mcp\n_you will notice the following..._\n\n1. There is no configuration to turn this on or off with ease, or even commented out docker-compose, nor any notes.\n2. With how we expose Kong via URL by default, the approach in the document could be messy or unsafe\n3. It looks like additional configuration may be required if there are multiple Supabase instances on the same server with individual /mcp exposures as Traefik is handling the routing and everything is using the same ports, etc...\n\n**I am looking for a \"work around\" as the resolution for this bounty.** That is acceptable, but I will require **at minimum a tutorial below** that figures out how to get around this bug/issue and properly documents the following:\n\n- How to configure the MCP and use it on local network\n- How to setup Wireguard to properly allow for usage of this MCP\n- How to configure Cursor/Claude Code/Windsurf to use this MCP\n- **MOST IMPORTANTLY, HOW TO CONNECT TO DIFFERENT SUPABASE INSTANCES ON THE SAME COOLIFY INSTANCE (assuming all of them are running the default Service template)**\n\nCreating a fix within the system we have to spin up and manage a Supabase instance may be difficult due to the template system's restraints, but if you want to work on that complaint of mine and **earn much more than $15**, you can see the bottom of this post. I list off the other bounties I will be offering and putting up cash for upon clearing some wires and hopefully seeing someone (or a few people) dedicate time to it.\n\n### Steps to Reproduce\n\n1. Follow docs linked above\n2. Attempt to edit the docker and piece it all together as tutorial says\n3. ???\n\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nUbuntu 24.04.03\n\n### Additional Information\n\nI am starting this bounty small as I have no clue how this system works and if I will be able to add crypto or not. I want to list these other bounties here firstly to see if there is any immediate response for \n\n**If you claim the small bounty for this, I have a few more I am willing to put in to place -- just let me know if you're interested and make sure to clear whichever one you wish to do with me to I can post the bounty for it:**\n\n- **[$35]** Better Cloudflared/Cloudflare management tools (easy exclusions and inclusions by project, IP, etc... manage domains and subdomains via Cloudflare Zero Trust or DNS settings automatically -- or at least though a portal of some sort)\n- **[$15]** Improved Supabase template (easily configure MCP properly using some sort of fix from this thread, configure mail server for automated mail and OTP with ease, set up external S3 with ease, etc -- I can contribute what I have learned from messing with the template)\n- **[$25]** Working MailCow OR Stalwart+Roundcube \"Service\" template... It's time...\n- **[$XXX]** CoolifyAI -- add API key, get AI assistant w/ knowledge-base similar to the Supabase assistant, ideally with GitHub issue lookup and basic research capability  \n- **[$XXX - $X,XXX]** More proper, fleshed out \"Services\" template system WITH ability to add remote repositories outside of the official Coolify templates; setup scripting w/ select-able options, easily modify docker template or automations/commands with checkboxes, dropdowns and input fields and the works. Ideally, a system in which \"addons\" in these same repositories as the whole \"Services\" themselves can be added on to each individual service; I.e. for Cloudflared, my request above. Or for Supabase, an easy tool to help you visualize the parts missing from Selfhosted that are in Supabase SaaS/Cloud and perhaps an API to interface with it. **This would make Coolify the single self-hosted PaaS with scripting for templates, but also an extension system allowing new functionality.**\n\nIf you are interested in discussing, claiming or collaborating on one of these bounties, see the little repo I made to track this here:\nhttps://github.com/rootacc3ss/coolify-bounties/tree/main",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7458"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7458",
              "body": "### Error Message and Logs\n\n**Bounty! $15.00 on Algora.io; will add ASAP, need to figure out how to use it.**\n\nWhen following these documents from Supabase pertaining to the latest selfhosted Supabase docker setup:\nhttps://supabase.com/docs/guides/self-hosting/enable-mcp\n_you will notice the following..._\n\n1. There is no configuration to turn this on or off with ease, or even commented out docker-compose, nor any notes.\n2. With how we expose Kong via URL by default, the approach in the document could be messy or unsafe\n3. It looks like additional configuration may be required if there are multiple Supabase instances on the same server with individual /mcp exposures as Traefik is handling the routing and everything is using the same ports, etc...\n\n**I am looking for a \"work around\" as the resolution for this bounty.** That is acceptable, but I will require **at minimum a tutorial below** that figures out how to get around this bug/issue and properly documents the following:\n\n- How to configure the MCP and use it on local network\n- How to setup Wireguard to properly allow for usage of this MCP\n- How to configure Cursor/Claude Code/Windsurf to use this MCP\n- **MOST IMPORTANTLY, HOW TO CONNECT TO DIFFERENT SUPABASE INSTANCES ON THE SAME COOLIFY INSTANCE (assuming all of them are running the default Service template)**\n\nCreating a fix within the system we have to spin up and manage a Supabase instance may be difficult due to the template system's restraints, but if you want to work on that complaint of mine and **earn much more than $15**, you can see the bottom of this post. I list off the other bounties I will be offering and putting up cash for upon clearing some wires and hopefully seeing someone (or a few people) dedicate time to it.\n\n### Steps to Reproduce\n\n1. Follow docs linked above\n2. Attempt to edit the docker and piece it all together as tutorial says\n3. ???\n\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nUbuntu 24.04.03\n\n### Additional Information\n\nI am starting this bounty small as I have no clue how this system works and if I will be able to add crypto or not. I want to list these other bounties here firstly to see if there is any immediate response for \n\n**If you claim the small bounty for this, I have a few more I am willing to put in to place -- just let me know if you're interested and make sure to clear whichever one you wish to do with me to I can post the bounty for it:**\n\n- **[$35]** Better Cloudflared/Cloudflare management tools (easy exclusions and inclusions by project, IP, etc... manage domains and subdomains via Cloudflare Zero Trust or DNS settings automatically -- or at least though a portal of some sort)\n- **[$15]** Improved Supabase template (easily configure MCP properly using some sort of fix from this thread, configure mail server for automated mail and OTP with ease, set up external S3 with ease, etc -- I can contribute what I have learned from messing with the template)\n- **[$25]** Working MailCow OR Stalwart+Roundcube \"Service\" template... It's time...\n- **[$XXX]** CoolifyAI -- add API key, get AI assistant w/ knowledge-base similar to the Supabase assistant, ideally with GitHub issue lookup and basic research capability  \n- **[$XXX - $X,XXX]** More proper, fleshed out \"Services\" template system WITH ability to add remote repositories outside of the official Coolify templates; setup scripting w/ select-able options, easily modify docker template or automations/commands with checkboxes, dropdowns and input fields and the works. Ideally, a system in which \"addons\" in these same repositories as the whole \"Services\" themselves can be added on to each individual service; I.e. for Cloudflared, my request above. Or for Supabase, an easy tool to help you visualize the parts missing from Selfhosted that are in Supabase SaaS/Cloud and perhaps an API to interface with it. **This would make Coolify the single self-hosted PaaS with scripting for templates, but also an extension system allowing new functionality.**\n\nIf you are interested in discussing, claiming or collaborating on one of these bounties, see the little repo I made to track this here:\nhttps://github.com/rootacc3ss/coolify-bounties/tree/main",
              "url": "https://github.com/coollabsio/coolify/issues/7458",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7423",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-12T11:35:29.086Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:29.086Z",
            "created_at": "2026-01-12T11:35:29.086Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7423",
              "status": "open",
              "type": "issue",
              "number": 7423,
              "title": "[Enhancement]: Use pgBackRest for Postgres backups",
              "source": {
                "data": {
                  "id": "source-coollabsio#7423",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Use pgBackRest for Postgres backups",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\nImplement support for using pgBackRest for Postgres backups, ideally as the new default for Postgres.\n\nThis will enable incremental backups and make the backup experience 100x better for large DBs using Postgres. The current backup system is good, but starts to have failures for larger DBs. The current backup system also causes huge S3 bills for larger DBs (ex. nightly backups of 100gb DBs start to add up).\n\nThis must also support the backups API.\n\n$1,000 USD bounty once this is merged into https://app.coolify.io's/ instance and I've verified it works on Postgres DBs with 100gb of data in them.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com/), a charity that supports teenagers who love computers and electronics! We previously funded database SSL support and the creation of the backups API.",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7423"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7423",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\nImplement support for using pgBackRest for Postgres backups, ideally as the new default for Postgres.\n\nThis will enable incremental backups and make the backup experience 100x better for large DBs using Postgres. The current backup system is good, but starts to have failures for larger DBs. The current backup system also causes huge S3 bills for larger DBs (ex. nightly backups of 100gb DBs start to add up).\n\nThis must also support the backups API.\n\n$1,000 USD bounty once this is merged into https://app.coolify.io's/ instance and I've verified it works on Postgres DBs with 100gb of data in them.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com/), a charity that supports teenagers who love computers and electronics! We previously funded database SSL support and the creation of the backups API.",
              "url": "https://github.com/coollabsio/coolify/issues/7423",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#6519",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-12T11:35:29.331Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:29.331Z",
            "created_at": "2026-01-12T11:35:29.331Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#6519",
              "status": "open",
              "type": "issue",
              "number": 6519,
              "title": "[Enhancement]: Filebrowser for Containerlevel",
              "source": {
                "data": {
                  "id": "source-coollabsio#6519",
                  "user": {
                    "login": "swissbyte",
                    "id": 33572050,
                    "node_id": "MDQ6VXNlcjMzNTcyMDUw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/33572050?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/swissbyte",
                    "html_url": "https://github.com/swissbyte",
                    "followers_url": "https://api.github.com/users/swissbyte/followers",
                    "following_url": "https://api.github.com/users/swissbyte/following{/other_user}",
                    "gists_url": "https://api.github.com/users/swissbyte/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/swissbyte/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/swissbyte/subscriptions",
                    "organizations_url": "https://api.github.com/users/swissbyte/orgs",
                    "repos_url": "https://api.github.com/users/swissbyte/repos",
                    "events_url": "https://api.github.com/users/swissbyte/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/swissbyte/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Filebrowser for Containerlevel",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\nI would like to get the ability to have a filebrowser on containerlevel. The idea is, that, for example, one can download or upload config file or images or any other type of files within the scope of the container. This includes mounts and also the overlay fs. Just a filebrowser for everything that you can see inside the container itself. \n\nPrio 1: mapped folders\nPrio 2: everything \"inside\" the container. \n\nIt should support: \n\n- Browsing like windows explorer or nautilus under linux\n- Upload and download single files\n- Upload and download folders\n- Create folders\n- Delete folders / files\n- Check Filesize\n- Check permissions (optional: set them)\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/6519"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#6519",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\nI would like to get the ability to have a filebrowser on containerlevel. The idea is, that, for example, one can download or upload config file or images or any other type of files within the scope of the container. This includes mounts and also the overlay fs. Just a filebrowser for everything that you can see inside the container itself. \n\nPrio 1: mapped folders\nPrio 2: everything \"inside\" the container. \n\nIt should support: \n\n- Browsing like windows explorer or nautilus under linux\n- Upload and download single files\n- Upload and download folders\n- Create folders\n- Delete folders / files\n- Check Filesize\n- Check permissions (optional: set them)\n",
              "url": "https://github.com/coollabsio/coolify/issues/6519",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#3531",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2026-01-12T11:35:37.016Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:37.016Z",
            "created_at": "2026-01-12T11:35:37.016Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3531",
              "status": "open",
              "type": "issue",
              "number": 3531,
              "title": "Better error response for wrong datetime format in REST filter",
              "source": {
                "data": {
                  "id": "source-qdrant#3531",
                  "user": {
                    "login": "timvisee",
                    "id": 856222,
                    "node_id": "MDQ6VXNlcjg1NjIyMg==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/856222?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/timvisee",
                    "html_url": "https://github.com/timvisee",
                    "followers_url": "https://api.github.com/users/timvisee/followers",
                    "following_url": "https://api.github.com/users/timvisee/following{/other_user}",
                    "gists_url": "https://api.github.com/users/timvisee/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/timvisee/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/timvisee/subscriptions",
                    "organizations_url": "https://api.github.com/users/timvisee/orgs",
                    "repos_url": "https://api.github.com/users/timvisee/repos",
                    "events_url": "https://api.github.com/users/timvisee/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/timvisee/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Better error response for wrong datetime format in REST filter",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\nWe recently merged <https://github.com/qdrant/qdrant/pull/3395> which adds a datetime payload index.\r\n\r\nCurrently, the datetime parser is very strict, only allowing [RFC 3339](https://www.rfc-editor.org/rfc/rfc3339) formats in our REST API. A common format such as `YYYY-MM-DD HH:MM:SS` is currently not accepted.\r\n\r\nIf you'd send the following request:\r\n\r\n```json\r\nPOST collections/test_collection/points/scroll\r\n{\r\n  \"limit\": 10,\r\n  \"filter\": {\r\n    \"must\": [\r\n      {\r\n        \"key\": \"updated\",\r\n        \"datetime_range\": {\r\n          \"gt\": \"2014-01-01T00:00:00\"\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nYou'd receive the following error:\r\n\r\n```\r\nFormat error in JSON body: data did not match any variant of untagged enum Condition at line 1 column 96\r\n```\r\n\r\nThis error is very confusing.\r\n\r\n**Describe the solution you'd like**\r\nWe'd strongly prefer a more descriptive error message instead.\r\n\r\nSomething like this would be a lot better:\r\n\r\n```\r\nFormat error in JSON body: '2014-01-01T00:00:00' does not match any accepted datetime format\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n_None_\r\n\r\n**Additional context**\r\nRelated issue: <https://github.com/qdrant/qdrant/issues/3529>",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3531"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3531",
              "body": "**Is your feature request related to a problem? Please describe.**\r\nWe recently merged <https://github.com/qdrant/qdrant/pull/3395> which adds a datetime payload index.\r\n\r\nCurrently, the datetime parser is very strict, only allowing [RFC 3339](https://www.rfc-editor.org/rfc/rfc3339) formats in our REST API. A common format such as `YYYY-MM-DD HH:MM:SS` is currently not accepted.\r\n\r\nIf you'd send the following request:\r\n\r\n```json\r\nPOST collections/test_collection/points/scroll\r\n{\r\n  \"limit\": 10,\r\n  \"filter\": {\r\n    \"must\": [\r\n      {\r\n        \"key\": \"updated\",\r\n        \"datetime_range\": {\r\n          \"gt\": \"2014-01-01T00:00:00\"\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nYou'd receive the following error:\r\n\r\n```\r\nFormat error in JSON body: data did not match any variant of untagged enum Condition at line 1 column 96\r\n```\r\n\r\nThis error is very confusing.\r\n\r\n**Describe the solution you'd like**\r\nWe'd strongly prefer a more descriptive error message instead.\r\n\r\nSomething like this would be a lot better:\r\n\r\n```\r\nFormat error in JSON body: '2014-01-01T00:00:00' does not match any accepted datetime format\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n_None_\r\n\r\n**Additional context**\r\nRelated issue: <https://github.com/qdrant/qdrant/issues/3529>",
              "url": "https://github.com/qdrant/qdrant/issues/3531",
              "tech": [],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#3322",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2026-01-12T11:35:37.258Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:37.258Z",
            "created_at": "2026-01-12T11:35:37.258Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3322",
              "status": "open",
              "type": "issue",
              "number": 3322,
              "title": "Per-collection metrics for Prometheus",
              "source": {
                "data": {
                  "id": "source-qdrant#3322",
                  "user": {
                    "login": "generall",
                    "id": 1935623,
                    "node_id": "MDQ6VXNlcjE5MzU2MjM=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1935623?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/generall",
                    "html_url": "https://github.com/generall",
                    "followers_url": "https://api.github.com/users/generall/followers",
                    "following_url": "https://api.github.com/users/generall/following{/other_user}",
                    "gists_url": "https://api.github.com/users/generall/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/generall/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/generall/subscriptions",
                    "organizations_url": "https://api.github.com/users/generall/orgs",
                    "repos_url": "https://api.github.com/users/generall/repos",
                    "events_url": "https://api.github.com/users/generall/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/generall/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Per-collection metrics for Prometheus",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, all metrics in `/metrics` are global, meaning that its impossible to see differences per collection.\r\n\r\nIn addition to that, all our metrics should have per-collection granularity to allow better aggregation in Prometheus, including:\r\n\r\n- point/vector counts\r\n- REST/gRPC requests\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample:\r\n```\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\"} 0.000046\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection\"} 0.000049\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection-2\"} 0.000046\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreate dedicated endpoint for each collection `/collections/my-collecton/metrics`\r\nbut feedback from DevOps on this idea was negative.\r\n\r\n**Additional context**\r\n\r\nIt might be beneficial to allow users to disable per-collection output. It is especially relevant if there are a lot of collections and metric response could become huge. But this is a nice-to-have requirement.\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently\r\n\r\n",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3322"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3322",
              "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, all metrics in `/metrics` are global, meaning that its impossible to see differences per collection.\r\n\r\nIn addition to that, all our metrics should have per-collection granularity to allow better aggregation in Prometheus, including:\r\n\r\n- point/vector counts\r\n- REST/gRPC requests\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample:\r\n```\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\"} 0.000046\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection\"} 0.000049\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection-2\"} 0.000046\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreate dedicated endpoint for each collection `/collections/my-collecton/metrics`\r\nbut feedback from DevOps on this idea was negative.\r\n\r\n**Additional context**\r\n\r\nIt might be beneficial to allow users to disable per-collection output. It is especially relevant if there are a lot of collections and metric response could become huge. But this is a nice-to-have requirement.\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently\r\n\r\n",
              "url": "https://github.com/qdrant/qdrant/issues/3322",
              "tech": [],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#1911",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2026-01-12T11:35:37.016Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:37.016Z",
            "created_at": "2026-01-12T11:35:37.016Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#1911",
              "status": "open",
              "type": "issue",
              "number": 1911,
              "title": "Warn on mismatch between global `prisma` and local `prisma` or `@prisma/client`",
              "source": {
                "data": {
                  "id": "source-prisma#1911",
                  "user": {
                    "login": "janpio",
                    "id": 183673,
                    "node_id": "MDQ6VXNlcjE4MzY3Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/183673?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/janpio",
                    "html_url": "https://github.com/janpio",
                    "followers_url": "https://api.github.com/users/janpio/followers",
                    "following_url": "https://api.github.com/users/janpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/janpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/janpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/janpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/janpio/orgs",
                    "repos_url": "https://api.github.com/users/janpio/repos",
                    "events_url": "https://api.github.com/users/janpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/janpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Warn on mismatch between global `prisma` and local `prisma` or `@prisma/client`",
                  "body": "Using a global `prisma generate` with a different local `prisma` or `@prisma/client` might lead to problems. It might be a good idea to warn users if they are doing that and ask for explicit confirmation.",
                  "html_url": "https://github.com/prisma/prisma/issues/1911"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#1911",
              "body": "Using a global `prisma generate` with a different local `prisma` or `@prisma/client` might lead to problems. It might be a good idea to warn users if they are doing that and ask for explicit confirmation.",
              "url": "https://github.com/prisma/prisma/issues/1911",
              "tech": [],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#8548",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2026-01-12T11:35:37.258Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:37.258Z",
            "created_at": "2026-01-12T11:35:37.258Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#8548",
              "status": "open",
              "type": "issue",
              "number": 8548,
              "title": "`prisma format` ends the file with a single CRLF on windows",
              "source": {
                "data": {
                  "id": "source-prisma#8548",
                  "user": {
                    "login": "binary64",
                    "id": 1680627,
                    "node_id": "MDQ6VXNlcjE2ODA2Mjc=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1680627?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/binary64",
                    "html_url": "https://github.com/binary64",
                    "followers_url": "https://api.github.com/users/binary64/followers",
                    "following_url": "https://api.github.com/users/binary64/following{/other_user}",
                    "gists_url": "https://api.github.com/users/binary64/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/binary64/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/binary64/subscriptions",
                    "organizations_url": "https://api.github.com/users/binary64/orgs",
                    "repos_url": "https://api.github.com/users/binary64/repos",
                    "events_url": "https://api.github.com/users/binary64/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/binary64/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "`prisma format` ends the file with a single CRLF on windows",
                  "body": "### Bug description\n\nOn windows, I run `prisma format` and note the unusual file ending. The lines are all LF, but the very last line is CRLF.\r\n\r\nThis causes issue on my Linux CI where it formats it ending in LF's only, causing a diff to occur and the build to fail.\n\n### How to reproduce\n\n1. On windows do prisma format\r\n2. Open in HxD or similar\r\n3. See attached:\r\n \r\n![image](https://user-images.githubusercontent.com/1680627/127931864-fcd66391-9b31-4914-8553-f6c71b3a6fad.png)\r\n\n\n### Expected behavior\n\nLF's only - no CR's to exist at all\n\n### Prisma information\n\n<!-- Do not include your database credentials when sharing your Prisma schema! -->\r\n\n\n### Environment & setup\n\nNode 16\r\nWindows/Linux\n\n### Prisma Version\n\n```\r\n$ C:\\p\\pab\\monorepo\\node_modules\\.bin\\prisma -v\r\nprisma               : 2.26.0\r\n@prisma/client       : 2.28.0\r\nCurrent platform     : windows\r\nQuery Engine         : query-engine 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\query-engine-windows.exe)\r\nMigration Engine     : migration-engine-cli 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\migration-engine-windows.exe)\r\nIntrospection Engine : introspection-core 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\introspection-engine-windows.exe)\r\nFormat Binary        : prisma-fmt 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\prisma-fmt-windows.exe)\r\nDefault Engines Hash : 9b816b3aa13cc270074f172f30d6eda8a8ce867d\r\nStudio               : 0.408.0\r\n```",
                  "html_url": "https://github.com/prisma/prisma/issues/8548"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#8548",
              "body": "### Bug description\n\nOn windows, I run `prisma format` and note the unusual file ending. The lines are all LF, but the very last line is CRLF.\r\n\r\nThis causes issue on my Linux CI where it formats it ending in LF's only, causing a diff to occur and the build to fail.\n\n### How to reproduce\n\n1. On windows do prisma format\r\n2. Open in HxD or similar\r\n3. See attached:\r\n \r\n![image](https://user-images.githubusercontent.com/1680627/127931864-fcd66391-9b31-4914-8553-f6c71b3a6fad.png)\r\n\n\n### Expected behavior\n\nLF's only - no CR's to exist at all\n\n### Prisma information\n\n<!-- Do not include your database credentials when sharing your Prisma schema! -->\r\n\n\n### Environment & setup\n\nNode 16\r\nWindows/Linux\n\n### Prisma Version\n\n```\r\n$ C:\\p\\pab\\monorepo\\node_modules\\.bin\\prisma -v\r\nprisma               : 2.26.0\r\n@prisma/client       : 2.28.0\r\nCurrent platform     : windows\r\nQuery Engine         : query-engine 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\query-engine-windows.exe)\r\nMigration Engine     : migration-engine-cli 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\migration-engine-windows.exe)\r\nIntrospection Engine : introspection-core 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\introspection-engine-windows.exe)\r\nFormat Binary        : prisma-fmt 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\prisma-fmt-windows.exe)\r\nDefault Engines Hash : 9b816b3aa13cc270074f172f30d6eda8a8ce867d\r\nStudio               : 0.408.0\r\n```",
              "url": "https://github.com/prisma/prisma/issues/8548",
              "tech": [],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#7771",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2026-01-12T11:35:37.434Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:35:37.434Z",
            "created_at": "2026-01-12T11:35:37.434Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#7771",
              "status": "open",
              "type": "issue",
              "number": 7771,
              "title": "Output path of current Prisma in `-v` ",
              "source": {
                "data": {
                  "id": "source-prisma#7771",
                  "user": {
                    "login": "janpio",
                    "id": 183673,
                    "node_id": "MDQ6VXNlcjE4MzY3Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/183673?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/janpio",
                    "html_url": "https://github.com/janpio",
                    "followers_url": "https://api.github.com/users/janpio/followers",
                    "following_url": "https://api.github.com/users/janpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/janpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/janpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/janpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/janpio/orgs",
                    "repos_url": "https://api.github.com/users/janpio/repos",
                    "events_url": "https://api.github.com/users/janpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/janpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Output path of current Prisma in `-v` ",
                  "body": "## Problem\r\n\r\nThis is a situation that can happen:\r\n```\r\n--- yarn prisma -v ---\r\nwarning package.json: No license field\r\nprisma               : 2.26.0-dev.7\r\n@prisma/client       : 2.26.0-dev.7\r\nCurrent platform     : debian-openssl-1.1.x\r\nQuery Engine         : query-engine c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/query-engine-debian-openssl-1.1.x)\r\nMigration Engine     : migration-engine-cli c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/migration-engine-debian-openssl-1.1.x)\r\nIntrospection Engine : introspection-core c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/introspection-engine-debian-openssl-1.1.x)\r\nFormat Binary        : prisma-fmt c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/prisma-fmt-debian-openssl-1.1.x)\r\nDefault Engines Hash : c838e79f39885bc8e1611849b1eb28b5bb5bc922\r\nStudio               : 0.402.0\r\n--- ls node_modules/@prisma/engines/ ---\r\nls: cannot access 'node_modules/@prisma/engines/': No such file or directory\r\n```\r\n\r\nAs you can see `yarn prisma -v` tells us the engines comes from `node_modules/@prisma/engines`, but when you try to list that directory, it is actually not present.\r\n\r\nWhat is happening here is that `yarn prisma` is actually from a few folders _above_ our project. This is kinda visible when you look to not run `yarn -s` but just `yarn`:\r\n```\r\ncodespace  /workspaces/e2e-tests/platforms-serverless/firebase-functions (janpio-patch-5 ) $ yarn prisma -v\r\nyarn run v1.22.10\r\nwarning package.json: No license field\r\n$ /workspaces/e2e-tests/node_modules/.bin/prisma -v\r\nprisma               : 2.25.0-dev.36\r\n@prisma/client       : 2.25.0-dev.36\r\n...\r\n```\r\n\r\n## Suggested solution\r\n\r\nOutput the directory of where the executed `prisma` is from, either similar to Yarn the absolute path to the binary in `node_modules`, or the folder where the `package.json` that is responsible for the installation of Prisma comes from.\r\n\r\n## Alternatives\r\n\r\nRely on `yarn` itself to give that information. Will not work with `npx` unfortunately for example.",
                  "html_url": "https://github.com/prisma/prisma/issues/7771"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#7771",
              "body": "## Problem\r\n\r\nThis is a situation that can happen:\r\n```\r\n--- yarn prisma -v ---\r\nwarning package.json: No license field\r\nprisma               : 2.26.0-dev.7\r\n@prisma/client       : 2.26.0-dev.7\r\nCurrent platform     : debian-openssl-1.1.x\r\nQuery Engine         : query-engine c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/query-engine-debian-openssl-1.1.x)\r\nMigration Engine     : migration-engine-cli c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/migration-engine-debian-openssl-1.1.x)\r\nIntrospection Engine : introspection-core c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/introspection-engine-debian-openssl-1.1.x)\r\nFormat Binary        : prisma-fmt c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/prisma-fmt-debian-openssl-1.1.x)\r\nDefault Engines Hash : c838e79f39885bc8e1611849b1eb28b5bb5bc922\r\nStudio               : 0.402.0\r\n--- ls node_modules/@prisma/engines/ ---\r\nls: cannot access 'node_modules/@prisma/engines/': No such file or directory\r\n```\r\n\r\nAs you can see `yarn prisma -v` tells us the engines comes from `node_modules/@prisma/engines`, but when you try to list that directory, it is actually not present.\r\n\r\nWhat is happening here is that `yarn prisma` is actually from a few folders _above_ our project. This is kinda visible when you look to not run `yarn -s` but just `yarn`:\r\n```\r\ncodespace  /workspaces/e2e-tests/platforms-serverless/firebase-functions (janpio-patch-5 ) $ yarn prisma -v\r\nyarn run v1.22.10\r\nwarning package.json: No license field\r\n$ /workspaces/e2e-tests/node_modules/.bin/prisma -v\r\nprisma               : 2.25.0-dev.36\r\n@prisma/client       : 2.25.0-dev.36\r\n...\r\n```\r\n\r\n## Suggested solution\r\n\r\nOutput the directory of where the executed `prisma` is from, either similar to Yarn the absolute path to the binary in `node_modules`, or the folder where the `package.json` that is responsible for the installation of Prisma comes from.\r\n\r\n## Alternatives\r\n\r\nRely on `yarn` itself to give that information. Will not work with `npx` unfortunately for example.",
              "url": "https://github.com/prisma/prisma/issues/7771",
              "tech": [],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#654",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-12T11:36:02.995Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:36:02.995Z",
            "created_at": "2026-01-12T11:36:02.995Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#654",
              "status": "open",
              "type": "issue",
              "number": 654,
              "title": "Add TOON support to ZIO Schema 2",
              "source": {
                "data": {
                  "id": "source-ZIO#654",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add TOON support to ZIO Schema 2",
                  "body": "This ticket is for adding TOON support for ZIO Schema 2, as a new Format, with associated codec, deriver, test, and documentation.\n\n**NOTE**: What follows is an AI-generated description of the problem and sketch of solution--it may be useful, but it certainly contains errors, and if you don't know enough to find and fix those errors, you shouldn't attempt to complete this ticket.\n\n------------------------\n\n<html><head></head><body><h1>TOON Format Implementation Guide for ZIO Schema 2</h1>\n<h2>Executive Summary</h2>\n<p>This guide provides a complete specification for implementing TOON (Token-Oriented Object Notation) codec support in ZIO Schema 2 (zio-blocks). TOON is a compact, human-readable serialization format designed to minimize token usage when passing structured data to Large Language Models, achieving 30-60% token reduction compared to JSON while maintaining lossless bidirectional conversion.</p>\n<p>The implementation will follow the established patterns in zio-blocks, mirroring the architecture of <code>JsonBinaryCodecDeriver</code> while adding TOON-specific capabilities for array format selection and indentation-based structure.</p>\n<hr>\n<h2>Part 1: TOON Format Specification</h2>\n<h3>1.1 Overview</h3>\n<p>TOON was created by Johann Schopplich in 2025 to address the inefficiency of JSON when used in LLM prompts. The format combines YAML-style indentation with CSV-style tabular data representation. The specification is maintained at <a href=\"https://github.com/toon-format/spec\">github.com/toon-format/spec</a>, currently at version 3.0.</p>\n<p><strong>Design goals:</strong></p>\n<ul>\n<li>Minimize token count for LLM context windows</li>\n<li>Maintain human readability</li>\n<li>Enable lossless JSONTOON conversion</li>\n<li>Schema-aware encoding for maximum compression</li>\n</ul>\n<h3>1.2 Data Types</h3>\n<p>TOON supports the complete JSON data model:</p>\n\nType | TOON Representation | Example\n-- | -- | --\nString | Unquoted (default) or quoted | hello or \"hello, world\"\nNumber | Decimal form only (no scientific notation) | 42, 3.14159\nBoolean | Lowercase keywords | true, false\nNull | Keyword | null\nArray | Three formats (see 1.4) | items[3]: a,b,c\nObject | Indentation-based nesting | See 1.3\n\n</body></html># TOON Format Implementation Guide for ZIO Schema 2\n\n## Executive Summary\n\nThis guide provides a complete specification for implementing TOON (Token-Oriented Object Notation) codec support in ZIO Schema 2 (zio-blocks). TOON is a compact, human-readable serialization format designed to minimize token usage when passing structured data to Large Language Models, achieving 30-60% token reduction compared to JSON while maintaining lossless bidirectional conversion.\n\nThe implementation will follow the established patterns in zio-blocks, mirroring the architecture of `JsonBinaryCodecDeriver` while adding TOON-specific capabilities for array format selection and indentation-based structure.\n\n---\n\n## Part 1: TOON Format Specification\n\n### 1.1 Overview\n\nTOON was created by Johann Schopplich in 2025 to address the inefficiency of JSON when used in LLM prompts. The format combines YAML-style indentation with CSV-style tabular data representation. The specification is maintained at [[github.com/toon-format/spec](https://github.com/toon-format/spec)](https://github.com/toon-format/spec), currently at version 3.0.\n\n**Design goals:**\n- Minimize token count for LLM context windows\n- Maintain human readability\n- Enable lossless JSONTOON conversion\n- Schema-aware encoding for maximum compression\n\n### 1.2 Data Types\n\nTOON supports the complete JSON data model:\n\n| Type | TOON Representation | Example |\n|------|---------------------|---------|\n| String | Unquoted (default) or quoted | `hello` or `\"hello, world\"` |\n| Number | Decimal form only (no scientific notation) | `42`, `3.14159` |\n| Boolean | Lowercase keywords | `true`, `false` |\n| Null | Keyword | `null` |\n| Array | Three formats (see 1.4) | `items[3]: a,b,c` |\n| Object | Indentation-based nesting | See 1.3 |\n\n### 1.3 Object Encoding\n\nObjects use indentation (2 spaces default) with colon-separated key-value pairs:\n\n```toon\nname: Alice\nage: 30\naddress:\n  street: 123 Main St\n  city: Springfield\n```\n\nEquivalent JSON:\n```json\n{\"name\":\"Alice\",\"age\":30,\"address\":{\"street\":\"123 Main St\",\"city\":\"Springfield\"}}\n```\n\n**Key rules:**\n- Keys are unquoted unless they contain special characters\n- Values on the same line as keys (primitives) or indented below (nested structures)\n- Empty objects: just the key with colon and nothing following\n\n### 1.4 Array Encoding Formats\n\nTOON's primary innovation is intelligent array encoding. The format supports three array representations:\n\n#### Tabular Format (Maximum Compression)\n\nFor arrays of uniform objects where all elements share identical keys with only primitive values:\n\n```toon\nusers[3]{id,name,email}:\n  1,Alice,alice@example.com\n  2,Bob,bob@example.com\n  3,Carol,carol@example.com\n```\n\nEquivalent JSON:\n```json\n{\"users\":[{\"id\":1,\"name\":\"Alice\",\"email\":\"alice@example.com\"},{\"id\":2,\"name\":\"Bob\",\"email\":\"bob@example.com\"},{\"id\":3,\"name\":\"Carol\",\"email\":\"carol@example.com\"}]}\n```\n\n**Tabular eligibility requirements:**\n1. All elements must be objects\n2. All objects must have identical keys in the same order\n3. All field values must be primitives (not nested objects or arrays)\n\n#### Inline Format (Primitive Arrays)\n\nFor arrays containing only primitive values:\n\n```toon\ntags[4]: javascript,react,typescript,node\nnumbers[5]: 1,2,3,4,5\n```\n\n#### List Format (Heterogeneous Data)\n\nFor arrays with mixed types, nested structures, or non-uniform objects:\n\n```toon\nitems[3]:\n  - name: Widget\n    price: 9.99\n  - name: Gadget\n    price: 19.99\n  - simple string value\n```\n\n### 1.5 String Quoting Rules\n\nStrings are **unquoted by default**. Quotes are required only when the string contains:\n- The active delimiter (comma by default)\n- A colon `:`\n- Leading or trailing whitespace\n- Control characters\n- The characters `{`, `}`, `[`, `]`\n\n**Escape sequences** (only these five are valid):\n- `\\\\`  backslash\n- `\\\"`  double quote\n- `\\n`  newline\n- `\\r`  carriage return\n- `\\t`  tab\n\n### 1.6 Number Formatting\n\nTOON requires decimal form without scientific notation:\n\n| Value | JSON | TOON |\n|-------|------|------|\n| 15 billion | `1.5e10` | `15000000000` |\n| Tiny | `1e-10` | `0.0000000001` |\n| NaN | N/A | `null` |\n| Infinity | N/A | `null` |\n| -0 | `-0` | `0` |\n\n### 1.7 Key Folding (Optional)\n\nChains of single-key wrapper objects can be collapsed:\n\n```toon\nuser.profile.settings.theme: dark\n```\n\nEquivalent to:\n```toon\nuser:\n  profile:\n    settings:\n      theme: dark\n```\n\n---\n\n## Part 2: ZIO Schema 2 Architecture\n\n### 2.1 Core Abstractions\n\nZIO Schema 2 uses a deriver-based architecture where format codecs are derived from `Schema[A]` definitions. The key components are:\n\n```scala\n// The schema definition\ncase class Person(name: String, age: Int)\nobject Person {\n  implicit val schema: Schema[Person] = Schema.derived\n}\n\n// Deriving a codec\nval jsonCodec: JsonBinaryCodec[Person] = Schema[Person].derive(JsonFormat.deriver)\n```\n\n### 2.2 Deriver Trait\n\nThe `Deriver[TC[_]]` trait defines how to derive type class instances for different schema shapes:\n\n```scala\ntrait Deriver[TC[_]] {\n  def derivePrimitive[F[_, _], A](\n    primitiveType: PrimitiveType[A],\n    typeName: TypeName[A],\n    binding: Binding[BindingType.Primitive, A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  ): Lazy[TC[A]]\n\n  def deriveRecord[F[_, _], A](\n    fields: IndexedSeq[Term[F, A, ?]],\n    typeName: TypeName[A],\n    binding: Binding[BindingType.Record, A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[TC[A]]\n\n  def deriveVariant[F[_, _], A](\n    cases: IndexedSeq[Term[F, A, ?]],\n    typeName: TypeName[A],\n    binding: Binding[BindingType.Variant, A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[TC[A]]\n\n  def deriveSequence[F[_, _], C[_], A](\n    element: Reflect[F, A],\n    typeName: TypeName[C[A]],\n    binding: Binding[BindingType.Seq[C], C[A]],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[TC[C[A]]]\n\n  def deriveMap[F[_, _], M[_, _], K, V](\n    key: Reflect[F, K],\n    value: Reflect[F, V],\n    typeName: TypeName[M[K, V]],\n    binding: Binding[BindingType.Map[M], M[K, V]],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[TC[M[K, V]]]\n\n  def deriveDynamic[F[_, _]](\n    binding: Binding[BindingType.Dynamic, DynamicValue],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[TC[DynamicValue]]\n\n  def deriveWrapper[F[_, _], A, B](\n    wrapped: Reflect[F, B],\n    typeName: TypeName[A],\n    wrapperPrimitiveType: Option[PrimitiveType[A]],\n    binding: Binding[BindingType.Wrapper[A, B], A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[TC[A]]\n}\n```\n\n### 2.3 BinaryCodec Pattern\n\nCodecs extend `BinaryCodec[A]` and work with streaming readers/writers:\n\n```scala\nabstract class JsonBinaryCodec[A](val valueType: Int = JsonBinaryCodec.objectType) \n    extends BinaryCodec[A] {\n  \n  // Core methods to implement\n  def decodeValue(in: JsonReader, default: A): A\n  def encodeValue(x: A, out: JsonWriter): Unit\n  \n  // Optional key encoding (for map keys)\n  def decodeKey(in: JsonReader): A\n  def encodeKey(x: A, out: JsonWriter): Unit\n  \n  // Null value for initialization\n  def nullValue: A = null.asInstanceOf[A]\n  \n  // Public API\n  def decode(input: ByteBuffer, config: ReaderConfig): Either[SchemaError, A]\n  def encode(value: A, output: ByteBuffer, config: WriterConfig): Unit\n}\n```\n\n### 2.4 Configuration Architecture\n\nConfiguration is split between two concerns:\n\n**Semantic configuration** lives on the deriver class itself:\n\n```scala\nclass JsonBinaryCodecDeriver(\n  fieldNameMapper: NameMapper,           // Field name transformation\n  caseNameMapper: NameMapper,            // Case/variant name transformation  \n  discriminatorKind: DiscriminatorKind,  // ADT encoding strategy\n  rejectExtraFields: Boolean,            // Fail on unknown fields\n  enumValuesAsStrings: Boolean,          // Enum encoding style\n  transientNone: Boolean,                // Omit None values\n  requireOptionFields: Boolean,          // Require Option fields\n  transientEmptyCollection: Boolean,     // Omit empty collections\n  requireCollectionFields: Boolean,      // Require collection fields\n  transientDefaultValue: Boolean,        // Omit default-valued fields\n  requireDefaultValueFields: Boolean     // Require fields with defaults\n) extends Deriver[JsonBinaryCodec]\n```\n\n**Runtime configuration** lives in separate config classes:\n\n```scala\n// ReaderConfig: buffer sizes and parsing behavior\nclass ReaderConfig(\n  val preferredBufSize: Int,      // Default: 32768\n  val preferredCharBufSize: Int,  // Default: 4096\n  val maxBufSize: Int,            // Default: 33554432\n  val maxCharBufSize: Int,        // Default: 4194304\n  val checkForEndOfInput: Boolean // Default: true\n)\n\n// WriterConfig: output formatting\nclass WriterConfig(\n  val indentionStep: Int,     // Default: 0 (compact)\n  val preferredBufSize: Int,  // Default: 32768\n  val escapeUnicode: Boolean  // Default: false\n)\n```\n\n### 2.5 DiscriminatorKind for ADTs\n\nSum types (sealed traits) support three encoding strategies:\n\n```scala\nsealed trait DiscriminatorKind\n\nobject DiscriminatorKind {\n  // Wrapper object: {\"Cat\": {\"name\": \"Whiskers\"}}\n  case object Key extends DiscriminatorKind  // DEFAULT\n  \n  // Embedded field: {\"type\": \"Cat\", \"name\": \"Whiskers\"}\n  case class Field(name: String) extends DiscriminatorKind\n  \n  // No discriminator: try each case sequentially\n  case object None extends DiscriminatorKind\n}\n```\n\n### 2.6 NameMapper for Field Transformation\n\n```scala\nsealed trait NameMapper extends (String => String)\n\nobject NameMapper {\n  case object Identity extends NameMapper   // No transformation (default)\n  case object SnakeCase extends NameMapper  // memberName  member_name\n  case object CamelCase extends NameMapper  // member_name  memberName\n  case object PascalCase extends NameMapper // member_name  MemberName\n  case object KebabCase extends NameMapper  // memberName  member-name\n  case class Custom(f: String => String) extends NameMapper\n}\n```\n\n### 2.7 Modifier System\n\nZIO Schema 2 uses `Modifier` classes (not Java annotations) for customization:\n\n```scala\n// Rename a field or case\n@Modifier.rename(\"new_name\")\ncase class Example(field: String)\n\n// Add decoding aliases\n@Modifier.alias(\"old_name\")\ncase object Blue extends Color\n\n// Mark field as transient (excluded from serialization)\n@Modifier.transient()\nval internalField: Int = 0\n```\n\nProgrammatic application:\n```scala\nval codec = Color.schema\n  .deriving(JsonBinaryCodecDeriver)\n  .modifier(Color.red, Modifier.rename(\"Rose\"))\n  .modifier(Color.red, Modifier.alias(\"Ruby\"))\n  .derive\n```\n\n---\n\n## Part 3: TOON Implementation Design\n\n### 3.1 Module Structure\n\n```\nzio-blocks/\n schema-toon/\n     src/main/scala/zio/blocks/schema/toon/\n         ToonFormat.scala           # Format definition object\n         ToonBinaryCodec.scala      # Abstract codec class\n         ToonBinaryCodecDeriver.scala # Deriver implementation\n         ToonReader.scala           # Streaming parser\n         ToonWriter.scala           # Streaming serializer\n         ReaderConfig.scala         # Parser configuration\n         WriterConfig.scala         # Serializer configuration\n         ArrayFormat.scala          # TOON-specific array encoding\n         DiscriminatorKind.scala    # Reuse or extend from JSON\n```\n\n### 3.2 ToonFormat Object\n\n```scala\npackage zio.blocks.schema.toon\n\nimport zio.blocks.schema.codec.BinaryFormat\n\n/**\n * The TOON format for ZIO Schema 2.\n * \n * TOON (Token-Oriented Object Notation) is a compact serialization format\n * optimized for LLM token efficiency, achieving 30-60% reduction vs JSON.\n */\nobject ToonFormat extends BinaryFormat(\"application/toon\", ToonBinaryCodecDeriver)\n```\n\n### 3.3 ArrayFormat Enum\n\n```scala\npackage zio.blocks.schema.toon\n\n/**\n * Specifies how arrays should be encoded in TOON format.\n */\nsealed trait ArrayFormat\n\nobject ArrayFormat {\n  /**\n   * Automatically select the most compact format based on array contents:\n   * - Tabular for uniform object arrays with primitive fields\n   * - Inline for primitive arrays\n   * - List for heterogeneous or nested data\n   */\n  case object Auto extends ArrayFormat\n  \n  /**\n   * Force tabular format: `items[N]{field1,field2}: val1,val2`\n   * Falls back to List if array is not tabular-eligible.\n   */\n  case object Tabular extends ArrayFormat\n  \n  /**\n   * Force inline format: `items[N]: val1,val2,val3`\n   * Only valid for primitive arrays.\n   */\n  case object Inline extends ArrayFormat\n  \n  /**\n   * Force list format with `- ` markers.\n   */\n  case object List extends ArrayFormat\n}\n```\n\n### 3.4 ToonBinaryCodecDeriver\n\n```scala\npackage zio.blocks.schema.toon\n\nimport zio.blocks.schema._\nimport zio.blocks.schema.binding._\nimport zio.blocks.schema.codec.BinaryFormat\nimport zio.blocks.schema.derive._\nimport zio.blocks.schema.json.{DiscriminatorKind, NameMapper}\n\n/**\n * Default TOON deriver with standard settings.\n */\nobject ToonBinaryCodecDeriver extends ToonBinaryCodecDeriver(\n  fieldNameMapper = NameMapper.Identity,\n  caseNameMapper = NameMapper.Identity,\n  discriminatorKind = DiscriminatorKind.Key,\n  arrayFormat = ArrayFormat.Auto,\n  delimiter = ',',\n  rejectExtraFields = false,\n  enumValuesAsStrings = true,\n  transientNone = true,\n  requireOptionFields = false,\n  transientEmptyCollection = true,\n  requireCollectionFields = false,\n  transientDefaultValue = true,\n  requireDefaultValueFields = false,\n  enableKeyFolding = false\n)\n\n/**\n * Deriver for TOON binary codecs with configurable behavior.\n *\n * @param fieldNameMapper       Transform strategy for field names\n * @param caseNameMapper        Transform strategy for variant case names  \n * @param discriminatorKind     ADT encoding strategy (Key, Field, None)\n * @param arrayFormat           Array encoding preference (Auto, Tabular, Inline, List)\n * @param delimiter             Value separator in tabular/inline arrays (comma default)\n * @param rejectExtraFields     Fail decoding on unrecognized fields\n * @param enumValuesAsStrings   Encode case object enums as strings\n * @param transientNone         Omit None-valued Option fields\n * @param requireOptionFields   Require Option fields to be present\n * @param transientEmptyCollection  Omit empty collection fields\n * @param requireCollectionFields   Require collection fields to be present\n * @param transientDefaultValue     Omit fields matching their default value\n * @param requireDefaultValueFields Require fields with defaults to be present\n * @param enableKeyFolding      Enable dotted key path expansion\n */\nclass ToonBinaryCodecDeriver private[toon] (\n  fieldNameMapper: NameMapper,\n  caseNameMapper: NameMapper,\n  discriminatorKind: DiscriminatorKind,\n  arrayFormat: ArrayFormat,\n  delimiter: Char,\n  rejectExtraFields: Boolean,\n  enumValuesAsStrings: Boolean,\n  transientNone: Boolean,\n  requireOptionFields: Boolean,\n  transientEmptyCollection: Boolean,\n  requireCollectionFields: Boolean,\n  transientDefaultValue: Boolean,\n  requireDefaultValueFields: Boolean,\n  enableKeyFolding: Boolean\n) extends Deriver[ToonBinaryCodec] {\n\n  // Builder methods\n  def withFieldNameMapper(mapper: NameMapper): ToonBinaryCodecDeriver =\n    copy(fieldNameMapper = mapper)\n    \n  def withCaseNameMapper(mapper: NameMapper): ToonBinaryCodecDeriver =\n    copy(caseNameMapper = mapper)\n    \n  def withDiscriminatorKind(kind: DiscriminatorKind): ToonBinaryCodecDeriver =\n    copy(discriminatorKind = kind)\n    \n  def withArrayFormat(format: ArrayFormat): ToonBinaryCodecDeriver =\n    copy(arrayFormat = format)\n    \n  def withDelimiter(delim: Char): ToonBinaryCodecDeriver =\n    copy(delimiter = delim)\n    \n  def withRejectExtraFields(reject: Boolean): ToonBinaryCodecDeriver =\n    copy(rejectExtraFields = reject)\n    \n  def withEnumValuesAsStrings(asStrings: Boolean): ToonBinaryCodecDeriver =\n    copy(enumValuesAsStrings = asStrings)\n    \n  def withTransientNone(transient: Boolean): ToonBinaryCodecDeriver =\n    copy(transientNone = transient)\n    \n  def withKeyFolding(enabled: Boolean): ToonBinaryCodecDeriver =\n    copy(enableKeyFolding = enabled)\n\n  // ... additional builder methods ...\n\n  private def copy(\n    fieldNameMapper: NameMapper = fieldNameMapper,\n    caseNameMapper: NameMapper = caseNameMapper,\n    discriminatorKind: DiscriminatorKind = discriminatorKind,\n    arrayFormat: ArrayFormat = arrayFormat,\n    delimiter: Char = delimiter,\n    rejectExtraFields: Boolean = rejectExtraFields,\n    enumValuesAsStrings: Boolean = enumValuesAsStrings,\n    transientNone: Boolean = transientNone,\n    requireOptionFields: Boolean = requireOptionFields,\n    transientEmptyCollection: Boolean = transientEmptyCollection,\n    requireCollectionFields: Boolean = requireCollectionFields,\n    transientDefaultValue: Boolean = transientDefaultValue,\n    requireDefaultValueFields: Boolean = requireDefaultValueFields,\n    enableKeyFolding: Boolean = enableKeyFolding\n  ): ToonBinaryCodecDeriver = new ToonBinaryCodecDeriver(\n    fieldNameMapper, caseNameMapper, discriminatorKind, arrayFormat,\n    delimiter, rejectExtraFields, enumValuesAsStrings, transientNone,\n    requireOptionFields, transientEmptyCollection, requireCollectionFields,\n    transientDefaultValue, requireDefaultValueFields, enableKeyFolding\n  )\n\n  // Deriver implementation\n  override def derivePrimitive[F[_, _], A](\n    primitiveType: PrimitiveType[A],\n    typeName: TypeName[A],\n    binding: Binding[BindingType.Primitive, A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  ): Lazy[ToonBinaryCodec[A]] = Lazy {\n    // Implementation: return appropriate codec for primitive type\n    ???\n  }\n\n  override def deriveRecord[F[_, _], A](\n    fields: IndexedSeq[Term[F, A, ?]],\n    typeName: TypeName[A],\n    binding: Binding[BindingType.Record, A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[ToonBinaryCodec[A]] = Lazy {\n    // Implementation: derive codec for case class / record\n    ???\n  }\n\n  override def deriveVariant[F[_, _], A](\n    cases: IndexedSeq[Term[F, A, ?]],\n    typeName: TypeName[A],\n    binding: Binding[BindingType.Variant, A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[ToonBinaryCodec[A]] = Lazy {\n    // Implementation: derive codec for sealed trait / enum\n    // Handle discriminatorKind, enumValuesAsStrings, caseNameMapper\n    ???\n  }\n\n  override def deriveSequence[F[_, _], C[_], A](\n    element: Reflect[F, A],\n    typeName: TypeName[C[A]],\n    binding: Binding[BindingType.Seq[C], C[A]],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[ToonBinaryCodec[C[A]]] = Lazy {\n    // Implementation: derive codec for sequences\n    // Key TOON logic: select array format based on arrayFormat setting\n    // and element uniformity analysis\n    ???\n  }\n\n  override def deriveMap[F[_, _], M[_, _], K, V](\n    key: Reflect[F, K],\n    value: Reflect[F, V],\n    typeName: TypeName[M[K, V]],\n    binding: Binding[BindingType.Map[M], M[K, V]],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[ToonBinaryCodec[M[K, V]]] = Lazy {\n    // Implementation: derive codec for maps\n    ???\n  }\n\n  override def deriveDynamic[F[_, _]](\n    binding: Binding[BindingType.Dynamic, DynamicValue],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[ToonBinaryCodec[DynamicValue]] = Lazy {\n    // Implementation: derive codec for dynamic values\n    ???\n  }\n\n  override def deriveWrapper[F[_, _], A, B](\n    wrapped: Reflect[F, B],\n    typeName: TypeName[A],\n    wrapperPrimitiveType: Option[PrimitiveType[A]],\n    binding: Binding[BindingType.Wrapper[A, B], A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[ToonBinaryCodec[A]] = Lazy {\n    // Implementation: derive codec for wrapper types (newtypes)\n    ???\n  }\n}\n```\n\n### 3.5 ToonBinaryCodec\n\n```scala\npackage zio.blocks.schema.toon\n\nimport zio.blocks.schema.SchemaError\nimport zio.blocks.schema.codec.BinaryCodec\nimport java.nio.ByteBuffer\n\n/**\n * Abstract codec for TOON encoding/decoding.\n *\n * @param valueType Optimization hint for primitive types\n */\nabstract class ToonBinaryCodec[A](val valueType: Int = ToonBinaryCodec.objectType) \n    extends BinaryCodec[A] {\n\n  /**\n   * Decode a value from a TOON reader.\n   *\n   * @param in      The TOON reader providing input\n   * @param default Default value for initialization\n   * @return The decoded value\n   */\n  def decodeValue(in: ToonReader, default: A): A\n\n  /**\n   * Encode a value to a TOON writer.\n   *\n   * @param x   The value to encode\n   * @param out The TOON writer for output\n   */\n  def encodeValue(x: A, out: ToonWriter): Unit\n\n  /**\n   * Decode a value used as a map key.\n   */\n  def decodeKey(in: ToonReader): A = \n    in.decodeError(\"decoding as TOON key is not supported\")\n\n  /**\n   * Encode a value as a map key.\n   */\n  def encodeKey(x: A, out: ToonWriter): Unit = \n    out.encodeError(\"encoding as TOON key is not supported\")\n\n  /**\n   * The null/default value for this type.\n   */\n  def nullValue: A = null.asInstanceOf[A]\n\n  // Public API\n  override def decode(input: ByteBuffer): Either[SchemaError, A] = \n    decode(input, ToonReaderConfig)\n\n  override def encode(value: A, output: ByteBuffer): Unit = \n    encode(value, output, ToonWriterConfig)\n\n  def decode(input: ByteBuffer, config: ToonReaderConfig): Either[SchemaError, A]\n  \n  def encode(value: A, output: ByteBuffer, config: ToonWriterConfig): Unit\n\n  // Convenience methods for byte arrays and strings\n  def decodeFromString(input: String): Either[SchemaError, A]\n  def encodeToString(value: A): String\n}\n\nobject ToonBinaryCodec {\n  val objectType  = 0\n  val intType     = 1\n  val longType    = 2\n  val floatType   = 3\n  val doubleType  = 4\n  val booleanType = 5\n  val byteType    = 6\n  val charType    = 7\n  val shortType   = 8\n  val unitType    = 9\n  \n  // Predefined primitive codecs\n  val unitCodec: ToonBinaryCodec[Unit] = ???\n  val booleanCodec: ToonBinaryCodec[Boolean] = ???\n  val byteCodec: ToonBinaryCodec[Byte] = ???\n  val shortCodec: ToonBinaryCodec[Short] = ???\n  val intCodec: ToonBinaryCodec[Int] = ???\n  val longCodec: ToonBinaryCodec[Long] = ???\n  val floatCodec: ToonBinaryCodec[Float] = ???\n  val doubleCodec: ToonBinaryCodec[Double] = ???\n  val charCodec: ToonBinaryCodec[Char] = ???\n  val stringCodec: ToonBinaryCodec[String] = ???\n  val bigIntCodec: ToonBinaryCodec[BigInt] = ???\n  val bigDecimalCodec: ToonBinaryCodec[BigDecimal] = ???\n  // ... java.time codecs, UUID, Currency, etc.\n}\n```\n\n### 3.6 Configuration Classes\n\n```scala\npackage zio.blocks.schema.toon\n\n/**\n * Configuration for ToonReader.\n *\n * @param preferredBufSize     Preferred byte buffer size\n * @param preferredCharBufSize Preferred char buffer size  \n * @param maxBufSize           Maximum byte buffer size\n * @param maxCharBufSize       Maximum char buffer size\n * @param checkForEndOfInput   Verify no trailing content after parsing\n * @param strictArrayLength    Validate array length markers match actual count\n */\nclass ToonReaderConfig private (\n  val preferredBufSize: Int,\n  val preferredCharBufSize: Int,\n  val maxBufSize: Int,\n  val maxCharBufSize: Int,\n  val checkForEndOfInput: Boolean,\n  val strictArrayLength: Boolean\n) extends Serializable {\n  def withStrictArrayLength(strict: Boolean): ToonReaderConfig =\n    copy(strictArrayLength = strict)\n  // ... other builder methods\n}\n\nobject ToonReaderConfig extends ToonReaderConfig(\n  preferredBufSize = 32768,\n  preferredCharBufSize = 4096,\n  maxBufSize = 33554432,\n  maxCharBufSize = 4194304,\n  checkForEndOfInput = true,\n  strictArrayLength = true\n)\n\n/**\n * Configuration for ToonWriter.\n *\n * @param indentSize       Spaces per indentation level (default: 2)\n * @param preferredBufSize Preferred output buffer size\n * @param lineEnding       Line ending style (LF recommended per spec)\n */\nclass ToonWriterConfig private (\n  val indentSize: Int,\n  val preferredBufSize: Int,\n  val lineEnding: String\n) extends Serializable {\n  def withIndentSize(size: Int): ToonWriterConfig =\n    copy(indentSize = size)\n  // ... other builder methods\n}\n\nobject ToonWriterConfig extends ToonWriterConfig(\n  indentSize = 2,\n  preferredBufSize = 32768,\n  lineEnding = \"\\n\"\n)\n```\n\n---\n\n## Part 4: Encoding Rules and Algorithms\n\n### 4.1 Array Format Selection Algorithm\n\nWhen `ArrayFormat.Auto` is configured, the encoder must analyze array contents:\n\n```scala\ndef selectArrayFormat[A](elements: Iterable[A], elementCodec: ToonBinaryCodec[A]): ArrayFormat = {\n  if (elements.isEmpty) {\n    ArrayFormat.Inline  // Empty arrays: items[0]:\n  } else if (isPrimitiveCodec(elementCodec)) {\n    ArrayFormat.Inline  // Primitive arrays: items[3]: a,b,c\n  } else if (isUniformObjectArray(elements)) {\n    ArrayFormat.Tabular // Uniform objects: items[N]{fields}: rows...\n  } else {\n    ArrayFormat.List    // Everything else: - item format\n  }\n}\n\ndef isUniformObjectArray[A](elements: Iterable[A]): Boolean = {\n  // Check that:\n  // 1. All elements are objects (case classes)\n  // 2. All have identical field names in same order\n  // 3. All field values are primitives (not nested objects/arrays)\n  ???\n}\n```\n\n### 4.2 String Encoding Rules\n\n```scala\ndef requiresQuoting(s: String, delimiter: Char): Boolean = {\n  s.isEmpty ||\n  s.charAt(0).isWhitespace ||\n  s.charAt(s.length - 1).isWhitespace ||\n  s.indexOf(delimiter) >= 0 ||\n  s.indexOf(':') >= 0 ||\n  s.indexOf('{') >= 0 ||\n  s.indexOf('}') >= 0 ||\n  s.indexOf('[') >= 0 ||\n  s.indexOf(']') >= 0 ||\n  containsControlCharacters(s)\n}\n\ndef encodeString(s: String, delimiter: Char, out: ToonWriter): Unit = {\n  if (requiresQuoting(s, delimiter)) {\n    out.writeQuotedString(s)  // Escape \\, \", \\n, \\r, \\t\n  } else {\n    out.writeRawString(s)\n  }\n}\n```\n\n### 4.3 Number Encoding Rules\n\n```scala\ndef encodeNumber(n: BigDecimal, out: ToonWriter): Unit = {\n  if (n.isNaN || n.isInfinity) {\n    out.writeNull()\n  } else if (n == BigDecimal(0) && n.signum < 0) {\n    out.writeRaw(\"0\")  // Normalize -0 to 0\n  } else {\n    // Convert to non-exponential decimal form\n    out.writeRaw(n.bigDecimal.toPlainString)\n  }\n}\n```\n\n### 4.4 ADT Encoding with Discriminators\n\n**DiscriminatorKind.Key (default):**\n```toon\nCat:\n  name: Whiskers\n  lives: 9\n```\n\n**DiscriminatorKind.Field(\"type\"):**\n```toon\ntype: Cat\nname: Whiskers\nlives: 9\n```\n\n**DiscriminatorKind.None:**\n```toon\nname: Whiskers\nlives: 9\n```\n(Decoder tries each case sequentially)\n\n### 4.5 Tabular Array Encoding\n\nFor uniform object arrays:\n\n```scala\ndef encodeTabularArray[A](\n  fieldName: String,\n  elements: IndexedSeq[A],\n  fieldNames: IndexedSeq[String],\n  fieldCodecs: IndexedSeq[ToonBinaryCodec[?]],\n  out: ToonWriter\n): Unit = {\n  // Header: fieldName[count]{field1,field2,...}:\n  out.writeRaw(fieldName)\n  out.writeRaw(\"[\")\n  out.writeRaw(elements.length.toString)\n  out.writeRaw(\"]{\")\n  out.writeRaw(fieldNames.mkString(\",\"))\n  out.writeRaw(\"}:\")\n  out.newLine()\n  \n  // Rows: value1,value2,...\n  elements.foreach { element =>\n    out.writeIndent()\n    fieldCodecs.zipWithIndex.foreach { case (codec, idx) =>\n      if (idx > 0) out.writeRaw(\",\")\n      codec.encodeValue(getField(element, idx), out)\n    }\n    out.newLine()\n  }\n}\n```\n\n---\n\n## Part 5: Acceptance Criteria\n\n### 5.1 Functional Requirements\n\n#### Primitive Types\n- [ ] All primitive types encode/decode correctly: Unit, Boolean, Byte, Short, Int, Long, Float, Double, Char, String, BigInt, BigDecimal\n- [ ] All java.time types: Instant, LocalDate, LocalTime, LocalDateTime, OffsetDateTime, ZonedDateTime, Duration, Period, Year, YearMonth, MonthDay, Month, DayOfWeek, ZoneId, ZoneOffset\n- [ ] UUID and Currency types\n- [ ] Numbers use decimal form (no scientific notation)\n- [ ] NaN and Infinity encode as `null`\n- [ ] -0 normalizes to 0\n\n#### Strings\n- [ ] Unquoted strings work for simple values\n- [ ] Quoted strings handle delimiters, colons, whitespace, control characters\n- [ ] Only valid escape sequences: `\\\\`, `\\\"`, `\\n`, `\\r`, `\\t`\n- [ ] UTF-8 encoding with LF line endings\n\n#### Arrays\n- [ ] ArrayFormat.Auto selects optimal format\n- [ ] Tabular format for uniform object arrays\n- [ ] Inline format for primitive arrays\n- [ ] List format for heterogeneous data\n- [ ] Array length markers `[N]` are accurate\n- [ ] Empty arrays encode correctly: `items[0]:`\n- [ ] Custom delimiter support (comma, tab, pipe)\n\n#### Objects/Records\n- [ ] Indentation-based nesting works correctly\n- [ ] Field name transformation via NameMapper\n- [ ] Transient field handling (None, empty collections, defaults)\n- [ ] Required field validation\n- [ ] Extra field rejection (configurable)\n- [ ] Modifier.rename and Modifier.alias support\n\n#### ADTs/Variants\n- [ ] DiscriminatorKind.Key (wrapper object) works\n- [ ] DiscriminatorKind.Field embeds discriminator\n- [ ] DiscriminatorKind.None tries cases sequentially\n- [ ] Case name transformation via NameMapper\n- [ ] enumValuesAsStrings for case object enums\n- [ ] Nested ADTs work correctly\n- [ ] Modifier.rename and Modifier.alias on cases\n\n#### Maps\n- [ ] String-keyed maps encode as objects\n- [ ] Non-string-keyed maps use array of pairs or error\n\n#### Wrappers/Newtypes\n- [ ] Wrapper types encode as their underlying type\n- [ ] Validation on decode (partial wrappers)\n\n#### DynamicValue\n- [ ] Full DynamicValue support for schema-less data\n\n### 5.2 Non-Functional Requirements\n\n#### Performance\n- [ ] Zero-allocation encoding for primitives (use value types)\n- [ ] Streaming encode/decode (no full materialization)\n- [ ] Buffer reuse via thread-local pools\n- [ ] Comparable performance to JSON codec\n\n#### Compatibility\n- [ ] Cross-platform: JVM, Scala.js, Scala Native\n- [ ] Scala 2.13 and Scala 3 support\n- [ ] No runtime reflection\n\n#### Specification Compliance\n- [ ] UTF-8 output with LF line endings\n- [ ] Consistent indentation (configurable, default 2 spaces)\n- [ ] No trailing whitespace\n- [ ] No trailing newline\n- [ ] Accurate array length markers\n- [ ] Preserve object key order\n\n### 5.3 Test Coverage\n\n#### Unit Tests\n- [ ] All primitive codecs round-trip correctly\n- [ ] All array formats encode/decode correctly\n- [ ] All discriminator kinds work\n- [ ] All NameMapper variants work\n- [ ] Error messages include path information\n- [ ] Edge cases: empty strings, empty arrays, empty objects, deeply nested structures\n\n#### Property-Based Tests\n- [ ] Arbitrary case classes round-trip\n- [ ] Arbitrary sealed traits round-trip\n- [ ] JSONTOON conversion is lossless\n\n#### Integration Tests\n- [ ] Large documents (>1MB)\n- [ ] Deeply nested structures (>100 levels)\n- [ ] Wide objects (>100 fields)\n- [ ] Unicode content\n\n### 5.4 Documentation\n\n- [ ] Scaladoc on all public APIs\n- [ ] Usage examples in tests\n- [ ] README with quick start guide\n- [ ] Configuration reference\n\n---\n\n## Part 6: Reference Implementation Notes\n\n### 6.1 Existing TOON Libraries\n\n**toon4s** (github.com/vim89/toon4s) provides a Scala TOON implementation with:\n- Sealed ADT for TOON values: `ToonValue = TNull | TBool | TNumber | TString | TArray | TObj`\n- JSONTOON bidirectional conversion\n- Does NOT provide automatic derivation for case classes\n\n**TypeScript SDK** (github.com/toon-format/toon) is the reference implementation with:\n- Complete parser and serializer\n- Schema-aware encoding\n- Comprehensive test suite\n\n### 6.2 JSON Codec Reference\n\nThe `JsonBinaryCodecDeriver` in zio-blocks serves as the primary reference for implementation patterns:\n- Thread-local caching for recursive types\n- Field info classes for optimized encoding\n- String map for O(1) field lookup during decoding\n- Specialized codecs for primitive arrays\n\n### 6.3 Test Data\n\nThe TOON specification repository includes a test suite at `github.com/toon-format/spec/tree/main/tests` with:\n- Valid TOON documents\n- Invalid TOON documents with expected errors\n- JSONTOON conversion pairs\n\n---\n\n## Appendix A: Example Encodings\n\n### Simple Record\n```scala\ncase class Person(name: String, age: Int)\nval person = Person(\"Alice\", 30)\n```\n\n**TOON:**\n```toon\nname: Alice\nage: 30\n```\n\n### Nested Record\n```scala\ncase class Address(street: String, city: String)\ncase class Person(name: String, address: Address)\nval person = Person(\"Alice\", Address(\"123 Main\", \"Springfield\"))\n```\n\n**TOON:**\n```toon\nname: Alice\naddress:\n  street: 123 Main\n  city: Springfield\n```\n\n### Uniform Array (Tabular)\n```scala\ncase class User(id: Int, name: String)\nval users = List(User(1, \"Alice\"), User(2, \"Bob\"))\n```\n\n**TOON:**\n```toon\n[2]{id,name}:\n  1,Alice\n  2,Bob\n```\n\n### Sealed Trait (Key Discriminator)\n```scala\nsealed trait Pet\ncase class Cat(name: String, lives: Int) extends Pet\ncase class Dog(name: String, breed: String) extends Pet\n\nval pet: Pet = Cat(\"Whiskers\", 9)\n```\n\n**TOON:**\n```toon\nCat:\n  name: Whiskers\n  lives: 9\n```\n\n### Sealed Trait (Field Discriminator)\n```scala\n// With: .withDiscriminatorKind(DiscriminatorKind.Field(\"type\"))\n```\n\n**TOON:**\n```toon\ntype: Cat\nname: Whiskers\nlives: 9\n```\n\n### Case Object Enum\n```scala\nsealed trait Color\ncase object Red extends Color\ncase object Green extends Color\ncase object Blue extends Color\n\nval color: Color = Green\n```\n\n**TOON (enumValuesAsStrings = true, default):**\n```toon\nGreen\n```\n\n**TOON (enumValuesAsStrings = false):**\n```toon\nGreen:\n```\n\n### Option Types\n```scala\ncase class Config(name: String, timeout: Option[Int])\nval config = Config(\"app\", Some(30))\n```\n\n**TOON (transientNone = true, default):**\n```toon\nname: app\ntimeout: 30\n```\n\n**TOON (None value, transientNone = true):**\n```toon\nname: app\n```\n\n---\n\n## Appendix B: Error Messages\n\nError messages should follow the JSON codec pattern with path information:\n\n```\nillegal number with leading zero at: .users[2].age\nmissing required field \"name\" at: .config\nillegal discriminator at: .event\nexpected '}' or ',' at: .response.data\nunexpected field \"extra\" at: .request  (when rejectExtraFields = true)\narray length mismatch: expected 3, got 2 at: .items  (when strictArrayLength = true)\n```\n\n---\n\n## Appendix C: Configuration Quick Reference\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `fieldNameMapper` | `NameMapper` | `Identity` | Field name transformation |\n| `caseNameMapper` | `NameMapper` | `Identity` | Case name transformation |\n| `discriminatorKind` | `DiscriminatorKind` | `Key` | ADT encoding strategy |\n| `arrayFormat` | `ArrayFormat` | `Auto` | Array encoding preference |\n| `delimiter` | `Char` | `,` | Array value separator |\n| `rejectExtraFields` | `Boolean` | `false` | Fail on unknown fields |\n| `enumValuesAsStrings` | `Boolean` | `true` | Case objects as strings |\n| `transientNone` | `Boolean` | `true` | Omit None values |\n| `requireOptionFields` | `Boolean` | `false` | Require Option fields |\n| `transientEmptyCollection` | `Boolean` | `true` | Omit empty collections |\n| `requireCollectionFields` | `Boolean` | `false` | Require collections |\n| `transientDefaultValue` | `Boolean` | `true` | Omit default values |\n| `requireDefaultValueFields` | `Boolean` | `false` | Require default fields |\n| `enableKeyFolding` | `Boolean` | `false` | Dotted key expansion |",
                  "html_url": "https://github.com/zio/zio-blocks/issues/654"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#654",
              "body": "This ticket is for adding TOON support for ZIO Schema 2, as a new Format, with associated codec, deriver, test, and documentation.\n\n**NOTE**: What follows is an AI-generated description of the problem and sketch of solution--it may be useful, but it certainly contains errors, and if you don't know enough to find and fix those errors, you shouldn't attempt to complete this ticket.\n\n------------------------\n\n<html><head></head><body><h1>TOON Format Implementation Guide for ZIO Schema 2</h1>\n<h2>Executive Summary</h2>\n<p>This guide provides a complete specification for implementing TOON (Token-Oriented Object Notation) codec support in ZIO Schema 2 (zio-blocks). TOON is a compact, human-readable serialization format designed to minimize token usage when passing structured data to Large Language Models, achieving 30-60% token reduction compared to JSON while maintaining lossless bidirectional conversion.</p>\n<p>The implementation will follow the established patterns in zio-blocks, mirroring the architecture of <code>JsonBinaryCodecDeriver</code> while adding TOON-specific capabilities for array format selection and indentation-based structure.</p>\n<hr>\n<h2>Part 1: TOON Format Specification</h2>\n<h3>1.1 Overview</h3>\n<p>TOON was created by Johann Schopplich in 2025 to address the inefficiency of JSON when used in LLM prompts. The format combines YAML-style indentation with CSV-style tabular data representation. The specification is maintained at <a href=\"https://github.com/toon-format/spec\">github.com/toon-format/spec</a>, currently at version 3.0.</p>\n<p><strong>Design goals:</strong></p>\n<ul>\n<li>Minimize token count for LLM context windows</li>\n<li>Maintain human readability</li>\n<li>Enable lossless JSONTOON conversion</li>\n<li>Schema-aware encoding for maximum compression</li>\n</ul>\n<h3>1.2 Data Types</h3>\n<p>TOON supports the complete JSON data model:</p>\n\nType | TOON Representation | Example\n-- | -- | --\nString | Unquoted (default) or quoted | hello or \"hello, world\"\nNumber | Decimal form only (no scientific notation) | 42, 3.14159\nBoolean | Lowercase keywords | true, false\nNull | Keyword | null\nArray | Three formats (see 1.4) | items[3]: a,b,c\nObject | Indentation-based nesting | See 1.3\n\n</body></html># TOON Format Implementation Guide for ZIO Schema 2\n\n## Executive Summary\n\nThis guide provides a complete specification for implementing TOON (Token-Oriented Object Notation) codec support in ZIO Schema 2 (zio-blocks). TOON is a compact, human-readable serialization format designed to minimize token usage when passing structured data to Large Language Models, achieving 30-60% token reduction compared to JSON while maintaining lossless bidirectional conversion.\n\nThe implementation will follow the established patterns in zio-blocks, mirroring the architecture of `JsonBinaryCodecDeriver` while adding TOON-specific capabilities for array format selection and indentation-based structure.\n\n---\n\n## Part 1: TOON Format Specification\n\n### 1.1 Overview\n\nTOON was created by Johann Schopplich in 2025 to address the inefficiency of JSON when used in LLM prompts. The format combines YAML-style indentation with CSV-style tabular data representation. The specification is maintained at [[github.com/toon-format/spec](https://github.com/toon-format/spec)](https://github.com/toon-format/spec), currently at version 3.0.\n\n**Design goals:**\n- Minimize token count for LLM context windows\n- Maintain human readability\n- Enable lossless JSONTOON conversion\n- Schema-aware encoding for maximum compression\n\n### 1.2 Data Types\n\nTOON supports the complete JSON data model:\n\n| Type | TOON Representation | Example |\n|------|---------------------|---------|\n| String | Unquoted (default) or quoted | `hello` or `\"hello, world\"` |\n| Number | Decimal form only (no scientific notation) | `42`, `3.14159` |\n| Boolean | Lowercase keywords | `true`, `false` |\n| Null | Keyword | `null` |\n| Array | Three formats (see 1.4) | `items[3]: a,b,c` |\n| Object | Indentation-based nesting | See 1.3 |\n\n### 1.3 Object Encoding\n\nObjects use indentation (2 spaces default) with colon-separated key-value pairs:\n\n```toon\nname: Alice\nage: 30\naddress:\n  street: 123 Main St\n  city: Springfield\n```\n\nEquivalent JSON:\n```json\n{\"name\":\"Alice\",\"age\":30,\"address\":{\"street\":\"123 Main St\",\"city\":\"Springfield\"}}\n```\n\n**Key rules:**\n- Keys are unquoted unless they contain special characters\n- Values on the same line as keys (primitives) or indented below (nested structures)\n- Empty objects: just the key with colon and nothing following\n\n### 1.4 Array Encoding Formats\n\nTOON's primary innovation is intelligent array encoding. The format supports three array representations:\n\n#### Tabular Format (Maximum Compression)\n\nFor arrays of uniform objects where all elements share identical keys with only primitive values:\n\n```toon\nusers[3]{id,name,email}:\n  1,Alice,alice@example.com\n  2,Bob,bob@example.com\n  3,Carol,carol@example.com\n```\n\nEquivalent JSON:\n```json\n{\"users\":[{\"id\":1,\"name\":\"Alice\",\"email\":\"alice@example.com\"},{\"id\":2,\"name\":\"Bob\",\"email\":\"bob@example.com\"},{\"id\":3,\"name\":\"Carol\",\"email\":\"carol@example.com\"}]}\n```\n\n**Tabular eligibility requirements:**\n1. All elements must be objects\n2. All objects must have identical keys in the same order\n3. All field values must be primitives (not nested objects or arrays)\n\n#### Inline Format (Primitive Arrays)\n\nFor arrays containing only primitive values:\n\n```toon\ntags[4]: javascript,react,typescript,node\nnumbers[5]: 1,2,3,4,5\n```\n\n#### List Format (Heterogeneous Data)\n\nFor arrays with mixed types, nested structures, or non-uniform objects:\n\n```toon\nitems[3]:\n  - name: Widget\n    price: 9.99\n  - name: Gadget\n    price: 19.99\n  - simple string value\n```\n\n### 1.5 String Quoting Rules\n\nStrings are **unquoted by default**. Quotes are required only when the string contains:\n- The active delimiter (comma by default)\n- A colon `:`\n- Leading or trailing whitespace\n- Control characters\n- The characters `{`, `}`, `[`, `]`\n\n**Escape sequences** (only these five are valid):\n- `\\\\`  backslash\n- `\\\"`  double quote\n- `\\n`  newline\n- `\\r`  carriage return\n- `\\t`  tab\n\n### 1.6 Number Formatting\n\nTOON requires decimal form without scientific notation:\n\n| Value | JSON | TOON |\n|-------|------|------|\n| 15 billion | `1.5e10` | `15000000000` |\n| Tiny | `1e-10` | `0.0000000001` |\n| NaN | N/A | `null` |\n| Infinity | N/A | `null` |\n| -0 | `-0` | `0` |\n\n### 1.7 Key Folding (Optional)\n\nChains of single-key wrapper objects can be collapsed:\n\n```toon\nuser.profile.settings.theme: dark\n```\n\nEquivalent to:\n```toon\nuser:\n  profile:\n    settings:\n      theme: dark\n```\n\n---\n\n## Part 2: ZIO Schema 2 Architecture\n\n### 2.1 Core Abstractions\n\nZIO Schema 2 uses a deriver-based architecture where format codecs are derived from `Schema[A]` definitions. The key components are:\n\n```scala\n// The schema definition\ncase class Person(name: String, age: Int)\nobject Person {\n  implicit val schema: Schema[Person] = Schema.derived\n}\n\n// Deriving a codec\nval jsonCodec: JsonBinaryCodec[Person] = Schema[Person].derive(JsonFormat.deriver)\n```\n\n### 2.2 Deriver Trait\n\nThe `Deriver[TC[_]]` trait defines how to derive type class instances for different schema shapes:\n\n```scala\ntrait Deriver[TC[_]] {\n  def derivePrimitive[F[_, _], A](\n    primitiveType: PrimitiveType[A],\n    typeName: TypeName[A],\n    binding: Binding[BindingType.Primitive, A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  ): Lazy[TC[A]]\n\n  def deriveRecord[F[_, _], A](\n    fields: IndexedSeq[Term[F, A, ?]],\n    typeName: TypeName[A],\n    binding: Binding[BindingType.Record, A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[TC[A]]\n\n  def deriveVariant[F[_, _], A](\n    cases: IndexedSeq[Term[F, A, ?]],\n    typeName: TypeName[A],\n    binding: Binding[BindingType.Variant, A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[TC[A]]\n\n  def deriveSequence[F[_, _], C[_], A](\n    element: Reflect[F, A],\n    typeName: TypeName[C[A]],\n    binding: Binding[BindingType.Seq[C], C[A]],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[TC[C[A]]]\n\n  def deriveMap[F[_, _], M[_, _], K, V](\n    key: Reflect[F, K],\n    value: Reflect[F, V],\n    typeName: TypeName[M[K, V]],\n    binding: Binding[BindingType.Map[M], M[K, V]],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[TC[M[K, V]]]\n\n  def deriveDynamic[F[_, _]](\n    binding: Binding[BindingType.Dynamic, DynamicValue],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[TC[DynamicValue]]\n\n  def deriveWrapper[F[_, _], A, B](\n    wrapped: Reflect[F, B],\n    typeName: TypeName[A],\n    wrapperPrimitiveType: Option[PrimitiveType[A]],\n    binding: Binding[BindingType.Wrapper[A, B], A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[TC[A]]\n}\n```\n\n### 2.3 BinaryCodec Pattern\n\nCodecs extend `BinaryCodec[A]` and work with streaming readers/writers:\n\n```scala\nabstract class JsonBinaryCodec[A](val valueType: Int = JsonBinaryCodec.objectType) \n    extends BinaryCodec[A] {\n  \n  // Core methods to implement\n  def decodeValue(in: JsonReader, default: A): A\n  def encodeValue(x: A, out: JsonWriter): Unit\n  \n  // Optional key encoding (for map keys)\n  def decodeKey(in: JsonReader): A\n  def encodeKey(x: A, out: JsonWriter): Unit\n  \n  // Null value for initialization\n  def nullValue: A = null.asInstanceOf[A]\n  \n  // Public API\n  def decode(input: ByteBuffer, config: ReaderConfig): Either[SchemaError, A]\n  def encode(value: A, output: ByteBuffer, config: WriterConfig): Unit\n}\n```\n\n### 2.4 Configuration Architecture\n\nConfiguration is split between two concerns:\n\n**Semantic configuration** lives on the deriver class itself:\n\n```scala\nclass JsonBinaryCodecDeriver(\n  fieldNameMapper: NameMapper,           // Field name transformation\n  caseNameMapper: NameMapper,            // Case/variant name transformation  \n  discriminatorKind: DiscriminatorKind,  // ADT encoding strategy\n  rejectExtraFields: Boolean,            // Fail on unknown fields\n  enumValuesAsStrings: Boolean,          // Enum encoding style\n  transientNone: Boolean,                // Omit None values\n  requireOptionFields: Boolean,          // Require Option fields\n  transientEmptyCollection: Boolean,     // Omit empty collections\n  requireCollectionFields: Boolean,      // Require collection fields\n  transientDefaultValue: Boolean,        // Omit default-valued fields\n  requireDefaultValueFields: Boolean     // Require fields with defaults\n) extends Deriver[JsonBinaryCodec]\n```\n\n**Runtime configuration** lives in separate config classes:\n\n```scala\n// ReaderConfig: buffer sizes and parsing behavior\nclass ReaderConfig(\n  val preferredBufSize: Int,      // Default: 32768\n  val preferredCharBufSize: Int,  // Default: 4096\n  val maxBufSize: Int,            // Default: 33554432\n  val maxCharBufSize: Int,        // Default: 4194304\n  val checkForEndOfInput: Boolean // Default: true\n)\n\n// WriterConfig: output formatting\nclass WriterConfig(\n  val indentionStep: Int,     // Default: 0 (compact)\n  val preferredBufSize: Int,  // Default: 32768\n  val escapeUnicode: Boolean  // Default: false\n)\n```\n\n### 2.5 DiscriminatorKind for ADTs\n\nSum types (sealed traits) support three encoding strategies:\n\n```scala\nsealed trait DiscriminatorKind\n\nobject DiscriminatorKind {\n  // Wrapper object: {\"Cat\": {\"name\": \"Whiskers\"}}\n  case object Key extends DiscriminatorKind  // DEFAULT\n  \n  // Embedded field: {\"type\": \"Cat\", \"name\": \"Whiskers\"}\n  case class Field(name: String) extends DiscriminatorKind\n  \n  // No discriminator: try each case sequentially\n  case object None extends DiscriminatorKind\n}\n```\n\n### 2.6 NameMapper for Field Transformation\n\n```scala\nsealed trait NameMapper extends (String => String)\n\nobject NameMapper {\n  case object Identity extends NameMapper   // No transformation (default)\n  case object SnakeCase extends NameMapper  // memberName  member_name\n  case object CamelCase extends NameMapper  // member_name  memberName\n  case object PascalCase extends NameMapper // member_name  MemberName\n  case object KebabCase extends NameMapper  // memberName  member-name\n  case class Custom(f: String => String) extends NameMapper\n}\n```\n\n### 2.7 Modifier System\n\nZIO Schema 2 uses `Modifier` classes (not Java annotations) for customization:\n\n```scala\n// Rename a field or case\n@Modifier.rename(\"new_name\")\ncase class Example(field: String)\n\n// Add decoding aliases\n@Modifier.alias(\"old_name\")\ncase object Blue extends Color\n\n// Mark field as transient (excluded from serialization)\n@Modifier.transient()\nval internalField: Int = 0\n```\n\nProgrammatic application:\n```scala\nval codec = Color.schema\n  .deriving(JsonBinaryCodecDeriver)\n  .modifier(Color.red, Modifier.rename(\"Rose\"))\n  .modifier(Color.red, Modifier.alias(\"Ruby\"))\n  .derive\n```\n\n---\n\n## Part 3: TOON Implementation Design\n\n### 3.1 Module Structure\n\n```\nzio-blocks/\n schema-toon/\n     src/main/scala/zio/blocks/schema/toon/\n         ToonFormat.scala           # Format definition object\n         ToonBinaryCodec.scala      # Abstract codec class\n         ToonBinaryCodecDeriver.scala # Deriver implementation\n         ToonReader.scala           # Streaming parser\n         ToonWriter.scala           # Streaming serializer\n         ReaderConfig.scala         # Parser configuration\n         WriterConfig.scala         # Serializer configuration\n         ArrayFormat.scala          # TOON-specific array encoding\n         DiscriminatorKind.scala    # Reuse or extend from JSON\n```\n\n### 3.2 ToonFormat Object\n\n```scala\npackage zio.blocks.schema.toon\n\nimport zio.blocks.schema.codec.BinaryFormat\n\n/**\n * The TOON format for ZIO Schema 2.\n * \n * TOON (Token-Oriented Object Notation) is a compact serialization format\n * optimized for LLM token efficiency, achieving 30-60% reduction vs JSON.\n */\nobject ToonFormat extends BinaryFormat(\"application/toon\", ToonBinaryCodecDeriver)\n```\n\n### 3.3 ArrayFormat Enum\n\n```scala\npackage zio.blocks.schema.toon\n\n/**\n * Specifies how arrays should be encoded in TOON format.\n */\nsealed trait ArrayFormat\n\nobject ArrayFormat {\n  /**\n   * Automatically select the most compact format based on array contents:\n   * - Tabular for uniform object arrays with primitive fields\n   * - Inline for primitive arrays\n   * - List for heterogeneous or nested data\n   */\n  case object Auto extends ArrayFormat\n  \n  /**\n   * Force tabular format: `items[N]{field1,field2}: val1,val2`\n   * Falls back to List if array is not tabular-eligible.\n   */\n  case object Tabular extends ArrayFormat\n  \n  /**\n   * Force inline format: `items[N]: val1,val2,val3`\n   * Only valid for primitive arrays.\n   */\n  case object Inline extends ArrayFormat\n  \n  /**\n   * Force list format with `- ` markers.\n   */\n  case object List extends ArrayFormat\n}\n```\n\n### 3.4 ToonBinaryCodecDeriver\n\n```scala\npackage zio.blocks.schema.toon\n\nimport zio.blocks.schema._\nimport zio.blocks.schema.binding._\nimport zio.blocks.schema.codec.BinaryFormat\nimport zio.blocks.schema.derive._\nimport zio.blocks.schema.json.{DiscriminatorKind, NameMapper}\n\n/**\n * Default TOON deriver with standard settings.\n */\nobject ToonBinaryCodecDeriver extends ToonBinaryCodecDeriver(\n  fieldNameMapper = NameMapper.Identity,\n  caseNameMapper = NameMapper.Identity,\n  discriminatorKind = DiscriminatorKind.Key,\n  arrayFormat = ArrayFormat.Auto,\n  delimiter = ',',\n  rejectExtraFields = false,\n  enumValuesAsStrings = true,\n  transientNone = true,\n  requireOptionFields = false,\n  transientEmptyCollection = true,\n  requireCollectionFields = false,\n  transientDefaultValue = true,\n  requireDefaultValueFields = false,\n  enableKeyFolding = false\n)\n\n/**\n * Deriver for TOON binary codecs with configurable behavior.\n *\n * @param fieldNameMapper       Transform strategy for field names\n * @param caseNameMapper        Transform strategy for variant case names  \n * @param discriminatorKind     ADT encoding strategy (Key, Field, None)\n * @param arrayFormat           Array encoding preference (Auto, Tabular, Inline, List)\n * @param delimiter             Value separator in tabular/inline arrays (comma default)\n * @param rejectExtraFields     Fail decoding on unrecognized fields\n * @param enumValuesAsStrings   Encode case object enums as strings\n * @param transientNone         Omit None-valued Option fields\n * @param requireOptionFields   Require Option fields to be present\n * @param transientEmptyCollection  Omit empty collection fields\n * @param requireCollectionFields   Require collection fields to be present\n * @param transientDefaultValue     Omit fields matching their default value\n * @param requireDefaultValueFields Require fields with defaults to be present\n * @param enableKeyFolding      Enable dotted key path expansion\n */\nclass ToonBinaryCodecDeriver private[toon] (\n  fieldNameMapper: NameMapper,\n  caseNameMapper: NameMapper,\n  discriminatorKind: DiscriminatorKind,\n  arrayFormat: ArrayFormat,\n  delimiter: Char,\n  rejectExtraFields: Boolean,\n  enumValuesAsStrings: Boolean,\n  transientNone: Boolean,\n  requireOptionFields: Boolean,\n  transientEmptyCollection: Boolean,\n  requireCollectionFields: Boolean,\n  transientDefaultValue: Boolean,\n  requireDefaultValueFields: Boolean,\n  enableKeyFolding: Boolean\n) extends Deriver[ToonBinaryCodec] {\n\n  // Builder methods\n  def withFieldNameMapper(mapper: NameMapper): ToonBinaryCodecDeriver =\n    copy(fieldNameMapper = mapper)\n    \n  def withCaseNameMapper(mapper: NameMapper): ToonBinaryCodecDeriver =\n    copy(caseNameMapper = mapper)\n    \n  def withDiscriminatorKind(kind: DiscriminatorKind): ToonBinaryCodecDeriver =\n    copy(discriminatorKind = kind)\n    \n  def withArrayFormat(format: ArrayFormat): ToonBinaryCodecDeriver =\n    copy(arrayFormat = format)\n    \n  def withDelimiter(delim: Char): ToonBinaryCodecDeriver =\n    copy(delimiter = delim)\n    \n  def withRejectExtraFields(reject: Boolean): ToonBinaryCodecDeriver =\n    copy(rejectExtraFields = reject)\n    \n  def withEnumValuesAsStrings(asStrings: Boolean): ToonBinaryCodecDeriver =\n    copy(enumValuesAsStrings = asStrings)\n    \n  def withTransientNone(transient: Boolean): ToonBinaryCodecDeriver =\n    copy(transientNone = transient)\n    \n  def withKeyFolding(enabled: Boolean): ToonBinaryCodecDeriver =\n    copy(enableKeyFolding = enabled)\n\n  // ... additional builder methods ...\n\n  private def copy(\n    fieldNameMapper: NameMapper = fieldNameMapper,\n    caseNameMapper: NameMapper = caseNameMapper,\n    discriminatorKind: DiscriminatorKind = discriminatorKind,\n    arrayFormat: ArrayFormat = arrayFormat,\n    delimiter: Char = delimiter,\n    rejectExtraFields: Boolean = rejectExtraFields,\n    enumValuesAsStrings: Boolean = enumValuesAsStrings,\n    transientNone: Boolean = transientNone,\n    requireOptionFields: Boolean = requireOptionFields,\n    transientEmptyCollection: Boolean = transientEmptyCollection,\n    requireCollectionFields: Boolean = requireCollectionFields,\n    transientDefaultValue: Boolean = transientDefaultValue,\n    requireDefaultValueFields: Boolean = requireDefaultValueFields,\n    enableKeyFolding: Boolean = enableKeyFolding\n  ): ToonBinaryCodecDeriver = new ToonBinaryCodecDeriver(\n    fieldNameMapper, caseNameMapper, discriminatorKind, arrayFormat,\n    delimiter, rejectExtraFields, enumValuesAsStrings, transientNone,\n    requireOptionFields, transientEmptyCollection, requireCollectionFields,\n    transientDefaultValue, requireDefaultValueFields, enableKeyFolding\n  )\n\n  // Deriver implementation\n  override def derivePrimitive[F[_, _], A](\n    primitiveType: PrimitiveType[A],\n    typeName: TypeName[A],\n    binding: Binding[BindingType.Primitive, A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  ): Lazy[ToonBinaryCodec[A]] = Lazy {\n    // Implementation: return appropriate codec for primitive type\n    ???\n  }\n\n  override def deriveRecord[F[_, _], A](\n    fields: IndexedSeq[Term[F, A, ?]],\n    typeName: TypeName[A],\n    binding: Binding[BindingType.Record, A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[ToonBinaryCodec[A]] = Lazy {\n    // Implementation: derive codec for case class / record\n    ???\n  }\n\n  override def deriveVariant[F[_, _], A](\n    cases: IndexedSeq[Term[F, A, ?]],\n    typeName: TypeName[A],\n    binding: Binding[BindingType.Variant, A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[ToonBinaryCodec[A]] = Lazy {\n    // Implementation: derive codec for sealed trait / enum\n    // Handle discriminatorKind, enumValuesAsStrings, caseNameMapper\n    ???\n  }\n\n  override def deriveSequence[F[_, _], C[_], A](\n    element: Reflect[F, A],\n    typeName: TypeName[C[A]],\n    binding: Binding[BindingType.Seq[C], C[A]],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[ToonBinaryCodec[C[A]]] = Lazy {\n    // Implementation: derive codec for sequences\n    // Key TOON logic: select array format based on arrayFormat setting\n    // and element uniformity analysis\n    ???\n  }\n\n  override def deriveMap[F[_, _], M[_, _], K, V](\n    key: Reflect[F, K],\n    value: Reflect[F, V],\n    typeName: TypeName[M[K, V]],\n    binding: Binding[BindingType.Map[M], M[K, V]],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[ToonBinaryCodec[M[K, V]]] = Lazy {\n    // Implementation: derive codec for maps\n    ???\n  }\n\n  override def deriveDynamic[F[_, _]](\n    binding: Binding[BindingType.Dynamic, DynamicValue],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[ToonBinaryCodec[DynamicValue]] = Lazy {\n    // Implementation: derive codec for dynamic values\n    ???\n  }\n\n  override def deriveWrapper[F[_, _], A, B](\n    wrapped: Reflect[F, B],\n    typeName: TypeName[A],\n    wrapperPrimitiveType: Option[PrimitiveType[A]],\n    binding: Binding[BindingType.Wrapper[A, B], A],\n    doc: Doc,\n    modifiers: Seq[Modifier.Reflect]\n  )(implicit F: HasBinding[F], D: HasInstance[F]): Lazy[ToonBinaryCodec[A]] = Lazy {\n    // Implementation: derive codec for wrapper types (newtypes)\n    ???\n  }\n}\n```\n\n### 3.5 ToonBinaryCodec\n\n```scala\npackage zio.blocks.schema.toon\n\nimport zio.blocks.schema.SchemaError\nimport zio.blocks.schema.codec.BinaryCodec\nimport java.nio.ByteBuffer\n\n/**\n * Abstract codec for TOON encoding/decoding.\n *\n * @param valueType Optimization hint for primitive types\n */\nabstract class ToonBinaryCodec[A](val valueType: Int = ToonBinaryCodec.objectType) \n    extends BinaryCodec[A] {\n\n  /**\n   * Decode a value from a TOON reader.\n   *\n   * @param in      The TOON reader providing input\n   * @param default Default value for initialization\n   * @return The decoded value\n   */\n  def decodeValue(in: ToonReader, default: A): A\n\n  /**\n   * Encode a value to a TOON writer.\n   *\n   * @param x   The value to encode\n   * @param out The TOON writer for output\n   */\n  def encodeValue(x: A, out: ToonWriter): Unit\n\n  /**\n   * Decode a value used as a map key.\n   */\n  def decodeKey(in: ToonReader): A = \n    in.decodeError(\"decoding as TOON key is not supported\")\n\n  /**\n   * Encode a value as a map key.\n   */\n  def encodeKey(x: A, out: ToonWriter): Unit = \n    out.encodeError(\"encoding as TOON key is not supported\")\n\n  /**\n   * The null/default value for this type.\n   */\n  def nullValue: A = null.asInstanceOf[A]\n\n  // Public API\n  override def decode(input: ByteBuffer): Either[SchemaError, A] = \n    decode(input, ToonReaderConfig)\n\n  override def encode(value: A, output: ByteBuffer): Unit = \n    encode(value, output, ToonWriterConfig)\n\n  def decode(input: ByteBuffer, config: ToonReaderConfig): Either[SchemaError, A]\n  \n  def encode(value: A, output: ByteBuffer, config: ToonWriterConfig): Unit\n\n  // Convenience methods for byte arrays and strings\n  def decodeFromString(input: String): Either[SchemaError, A]\n  def encodeToString(value: A): String\n}\n\nobject ToonBinaryCodec {\n  val objectType  = 0\n  val intType     = 1\n  val longType    = 2\n  val floatType   = 3\n  val doubleType  = 4\n  val booleanType = 5\n  val byteType    = 6\n  val charType    = 7\n  val shortType   = 8\n  val unitType    = 9\n  \n  // Predefined primitive codecs\n  val unitCodec: ToonBinaryCodec[Unit] = ???\n  val booleanCodec: ToonBinaryCodec[Boolean] = ???\n  val byteCodec: ToonBinaryCodec[Byte] = ???\n  val shortCodec: ToonBinaryCodec[Short] = ???\n  val intCodec: ToonBinaryCodec[Int] = ???\n  val longCodec: ToonBinaryCodec[Long] = ???\n  val floatCodec: ToonBinaryCodec[Float] = ???\n  val doubleCodec: ToonBinaryCodec[Double] = ???\n  val charCodec: ToonBinaryCodec[Char] = ???\n  val stringCodec: ToonBinaryCodec[String] = ???\n  val bigIntCodec: ToonBinaryCodec[BigInt] = ???\n  val bigDecimalCodec: ToonBinaryCodec[BigDecimal] = ???\n  // ... java.time codecs, UUID, Currency, etc.\n}\n```\n\n### 3.6 Configuration Classes\n\n```scala\npackage zio.blocks.schema.toon\n\n/**\n * Configuration for ToonReader.\n *\n * @param preferredBufSize     Preferred byte buffer size\n * @param preferredCharBufSize Preferred char buffer size  \n * @param maxBufSize           Maximum byte buffer size\n * @param maxCharBufSize       Maximum char buffer size\n * @param checkForEndOfInput   Verify no trailing content after parsing\n * @param strictArrayLength    Validate array length markers match actual count\n */\nclass ToonReaderConfig private (\n  val preferredBufSize: Int,\n  val preferredCharBufSize: Int,\n  val maxBufSize: Int,\n  val maxCharBufSize: Int,\n  val checkForEndOfInput: Boolean,\n  val strictArrayLength: Boolean\n) extends Serializable {\n  def withStrictArrayLength(strict: Boolean): ToonReaderConfig =\n    copy(strictArrayLength = strict)\n  // ... other builder methods\n}\n\nobject ToonReaderConfig extends ToonReaderConfig(\n  preferredBufSize = 32768,\n  preferredCharBufSize = 4096,\n  maxBufSize = 33554432,\n  maxCharBufSize = 4194304,\n  checkForEndOfInput = true,\n  strictArrayLength = true\n)\n\n/**\n * Configuration for ToonWriter.\n *\n * @param indentSize       Spaces per indentation level (default: 2)\n * @param preferredBufSize Preferred output buffer size\n * @param lineEnding       Line ending style (LF recommended per spec)\n */\nclass ToonWriterConfig private (\n  val indentSize: Int,\n  val preferredBufSize: Int,\n  val lineEnding: String\n) extends Serializable {\n  def withIndentSize(size: Int): ToonWriterConfig =\n    copy(indentSize = size)\n  // ... other builder methods\n}\n\nobject ToonWriterConfig extends ToonWriterConfig(\n  indentSize = 2,\n  preferredBufSize = 32768,\n  lineEnding = \"\\n\"\n)\n```\n\n---\n\n## Part 4: Encoding Rules and Algorithms\n\n### 4.1 Array Format Selection Algorithm\n\nWhen `ArrayFormat.Auto` is configured, the encoder must analyze array contents:\n\n```scala\ndef selectArrayFormat[A](elements: Iterable[A], elementCodec: ToonBinaryCodec[A]): ArrayFormat = {\n  if (elements.isEmpty) {\n    ArrayFormat.Inline  // Empty arrays: items[0]:\n  } else if (isPrimitiveCodec(elementCodec)) {\n    ArrayFormat.Inline  // Primitive arrays: items[3]: a,b,c\n  } else if (isUniformObjectArray(elements)) {\n    ArrayFormat.Tabular // Uniform objects: items[N]{fields}: rows...\n  } else {\n    ArrayFormat.List    // Everything else: - item format\n  }\n}\n\ndef isUniformObjectArray[A](elements: Iterable[A]): Boolean = {\n  // Check that:\n  // 1. All elements are objects (case classes)\n  // 2. All have identical field names in same order\n  // 3. All field values are primitives (not nested objects/arrays)\n  ???\n}\n```\n\n### 4.2 String Encoding Rules\n\n```scala\ndef requiresQuoting(s: String, delimiter: Char): Boolean = {\n  s.isEmpty ||\n  s.charAt(0).isWhitespace ||\n  s.charAt(s.length - 1).isWhitespace ||\n  s.indexOf(delimiter) >= 0 ||\n  s.indexOf(':') >= 0 ||\n  s.indexOf('{') >= 0 ||\n  s.indexOf('}') >= 0 ||\n  s.indexOf('[') >= 0 ||\n  s.indexOf(']') >= 0 ||\n  containsControlCharacters(s)\n}\n\ndef encodeString(s: String, delimiter: Char, out: ToonWriter): Unit = {\n  if (requiresQuoting(s, delimiter)) {\n    out.writeQuotedString(s)  // Escape \\, \", \\n, \\r, \\t\n  } else {\n    out.writeRawString(s)\n  }\n}\n```\n\n### 4.3 Number Encoding Rules\n\n```scala\ndef encodeNumber(n: BigDecimal, out: ToonWriter): Unit = {\n  if (n.isNaN || n.isInfinity) {\n    out.writeNull()\n  } else if (n == BigDecimal(0) && n.signum < 0) {\n    out.writeRaw(\"0\")  // Normalize -0 to 0\n  } else {\n    // Convert to non-exponential decimal form\n    out.writeRaw(n.bigDecimal.toPlainString)\n  }\n}\n```\n\n### 4.4 ADT Encoding with Discriminators\n\n**DiscriminatorKind.Key (default):**\n```toon\nCat:\n  name: Whiskers\n  lives: 9\n```\n\n**DiscriminatorKind.Field(\"type\"):**\n```toon\ntype: Cat\nname: Whiskers\nlives: 9\n```\n\n**DiscriminatorKind.None:**\n```toon\nname: Whiskers\nlives: 9\n```\n(Decoder tries each case sequentially)\n\n### 4.5 Tabular Array Encoding\n\nFor uniform object arrays:\n\n```scala\ndef encodeTabularArray[A](\n  fieldName: String,\n  elements: IndexedSeq[A],\n  fieldNames: IndexedSeq[String],\n  fieldCodecs: IndexedSeq[ToonBinaryCodec[?]],\n  out: ToonWriter\n): Unit = {\n  // Header: fieldName[count]{field1,field2,...}:\n  out.writeRaw(fieldName)\n  out.writeRaw(\"[\")\n  out.writeRaw(elements.length.toString)\n  out.writeRaw(\"]{\")\n  out.writeRaw(fieldNames.mkString(\",\"))\n  out.writeRaw(\"}:\")\n  out.newLine()\n  \n  // Rows: value1,value2,...\n  elements.foreach { element =>\n    out.writeIndent()\n    fieldCodecs.zipWithIndex.foreach { case (codec, idx) =>\n      if (idx > 0) out.writeRaw(\",\")\n      codec.encodeValue(getField(element, idx), out)\n    }\n    out.newLine()\n  }\n}\n```\n\n---\n\n## Part 5: Acceptance Criteria\n\n### 5.1 Functional Requirements\n\n#### Primitive Types\n- [ ] All primitive types encode/decode correctly: Unit, Boolean, Byte, Short, Int, Long, Float, Double, Char, String, BigInt, BigDecimal\n- [ ] All java.time types: Instant, LocalDate, LocalTime, LocalDateTime, OffsetDateTime, ZonedDateTime, Duration, Period, Year, YearMonth, MonthDay, Month, DayOfWeek, ZoneId, ZoneOffset\n- [ ] UUID and Currency types\n- [ ] Numbers use decimal form (no scientific notation)\n- [ ] NaN and Infinity encode as `null`\n- [ ] -0 normalizes to 0\n\n#### Strings\n- [ ] Unquoted strings work for simple values\n- [ ] Quoted strings handle delimiters, colons, whitespace, control characters\n- [ ] Only valid escape sequences: `\\\\`, `\\\"`, `\\n`, `\\r`, `\\t`\n- [ ] UTF-8 encoding with LF line endings\n\n#### Arrays\n- [ ] ArrayFormat.Auto selects optimal format\n- [ ] Tabular format for uniform object arrays\n- [ ] Inline format for primitive arrays\n- [ ] List format for heterogeneous data\n- [ ] Array length markers `[N]` are accurate\n- [ ] Empty arrays encode correctly: `items[0]:`\n- [ ] Custom delimiter support (comma, tab, pipe)\n\n#### Objects/Records\n- [ ] Indentation-based nesting works correctly\n- [ ] Field name transformation via NameMapper\n- [ ] Transient field handling (None, empty collections, defaults)\n- [ ] Required field validation\n- [ ] Extra field rejection (configurable)\n- [ ] Modifier.rename and Modifier.alias support\n\n#### ADTs/Variants\n- [ ] DiscriminatorKind.Key (wrapper object) works\n- [ ] DiscriminatorKind.Field embeds discriminator\n- [ ] DiscriminatorKind.None tries cases sequentially\n- [ ] Case name transformation via NameMapper\n- [ ] enumValuesAsStrings for case object enums\n- [ ] Nested ADTs work correctly\n- [ ] Modifier.rename and Modifier.alias on cases\n\n#### Maps\n- [ ] String-keyed maps encode as objects\n- [ ] Non-string-keyed maps use array of pairs or error\n\n#### Wrappers/Newtypes\n- [ ] Wrapper types encode as their underlying type\n- [ ] Validation on decode (partial wrappers)\n\n#### DynamicValue\n- [ ] Full DynamicValue support for schema-less data\n\n### 5.2 Non-Functional Requirements\n\n#### Performance\n- [ ] Zero-allocation encoding for primitives (use value types)\n- [ ] Streaming encode/decode (no full materialization)\n- [ ] Buffer reuse via thread-local pools\n- [ ] Comparable performance to JSON codec\n\n#### Compatibility\n- [ ] Cross-platform: JVM, Scala.js, Scala Native\n- [ ] Scala 2.13 and Scala 3 support\n- [ ] No runtime reflection\n\n#### Specification Compliance\n- [ ] UTF-8 output with LF line endings\n- [ ] Consistent indentation (configurable, default 2 spaces)\n- [ ] No trailing whitespace\n- [ ] No trailing newline\n- [ ] Accurate array length markers\n- [ ] Preserve object key order\n\n### 5.3 Test Coverage\n\n#### Unit Tests\n- [ ] All primitive codecs round-trip correctly\n- [ ] All array formats encode/decode correctly\n- [ ] All discriminator kinds work\n- [ ] All NameMapper variants work\n- [ ] Error messages include path information\n- [ ] Edge cases: empty strings, empty arrays, empty objects, deeply nested structures\n\n#### Property-Based Tests\n- [ ] Arbitrary case classes round-trip\n- [ ] Arbitrary sealed traits round-trip\n- [ ] JSONTOON conversion is lossless\n\n#### Integration Tests\n- [ ] Large documents (>1MB)\n- [ ] Deeply nested structures (>100 levels)\n- [ ] Wide objects (>100 fields)\n- [ ] Unicode content\n\n### 5.4 Documentation\n\n- [ ] Scaladoc on all public APIs\n- [ ] Usage examples in tests\n- [ ] README with quick start guide\n- [ ] Configuration reference\n\n---\n\n## Part 6: Reference Implementation Notes\n\n### 6.1 Existing TOON Libraries\n\n**toon4s** (github.com/vim89/toon4s) provides a Scala TOON implementation with:\n- Sealed ADT for TOON values: `ToonValue = TNull | TBool | TNumber | TString | TArray | TObj`\n- JSONTOON bidirectional conversion\n- Does NOT provide automatic derivation for case classes\n\n**TypeScript SDK** (github.com/toon-format/toon) is the reference implementation with:\n- Complete parser and serializer\n- Schema-aware encoding\n- Comprehensive test suite\n\n### 6.2 JSON Codec Reference\n\nThe `JsonBinaryCodecDeriver` in zio-blocks serves as the primary reference for implementation patterns:\n- Thread-local caching for recursive types\n- Field info classes for optimized encoding\n- String map for O(1) field lookup during decoding\n- Specialized codecs for primitive arrays\n\n### 6.3 Test Data\n\nThe TOON specification repository includes a test suite at `github.com/toon-format/spec/tree/main/tests` with:\n- Valid TOON documents\n- Invalid TOON documents with expected errors\n- JSONTOON conversion pairs\n\n---\n\n## Appendix A: Example Encodings\n\n### Simple Record\n```scala\ncase class Person(name: String, age: Int)\nval person = Person(\"Alice\", 30)\n```\n\n**TOON:**\n```toon\nname: Alice\nage: 30\n```\n\n### Nested Record\n```scala\ncase class Address(street: String, city: String)\ncase class Person(name: String, address: Address)\nval person = Person(\"Alice\", Address(\"123 Main\", \"Springfield\"))\n```\n\n**TOON:**\n```toon\nname: Alice\naddress:\n  street: 123 Main\n  city: Springfield\n```\n\n### Uniform Array (Tabular)\n```scala\ncase class User(id: Int, name: String)\nval users = List(User(1, \"Alice\"), User(2, \"Bob\"))\n```\n\n**TOON:**\n```toon\n[2]{id,name}:\n  1,Alice\n  2,Bob\n```\n\n### Sealed Trait (Key Discriminator)\n```scala\nsealed trait Pet\ncase class Cat(name: String, lives: Int) extends Pet\ncase class Dog(name: String, breed: String) extends Pet\n\nval pet: Pet = Cat(\"Whiskers\", 9)\n```\n\n**TOON:**\n```toon\nCat:\n  name: Whiskers\n  lives: 9\n```\n\n### Sealed Trait (Field Discriminator)\n```scala\n// With: .withDiscriminatorKind(DiscriminatorKind.Field(\"type\"))\n```\n\n**TOON:**\n```toon\ntype: Cat\nname: Whiskers\nlives: 9\n```\n\n### Case Object Enum\n```scala\nsealed trait Color\ncase object Red extends Color\ncase object Green extends Color\ncase object Blue extends Color\n\nval color: Color = Green\n```\n\n**TOON (enumValuesAsStrings = true, default):**\n```toon\nGreen\n```\n\n**TOON (enumValuesAsStrings = false):**\n```toon\nGreen:\n```\n\n### Option Types\n```scala\ncase class Config(name: String, timeout: Option[Int])\nval config = Config(\"app\", Some(30))\n```\n\n**TOON (transientNone = true, default):**\n```toon\nname: app\ntimeout: 30\n```\n\n**TOON (None value, transientNone = true):**\n```toon\nname: app\n```\n\n---\n\n## Appendix B: Error Messages\n\nError messages should follow the JSON codec pattern with path information:\n\n```\nillegal number with leading zero at: .users[2].age\nmissing required field \"name\" at: .config\nillegal discriminator at: .event\nexpected '}' or ',' at: .response.data\nunexpected field \"extra\" at: .request  (when rejectExtraFields = true)\narray length mismatch: expected 3, got 2 at: .items  (when strictArrayLength = true)\n```\n\n---\n\n## Appendix C: Configuration Quick Reference\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `fieldNameMapper` | `NameMapper` | `Identity` | Field name transformation |\n| `caseNameMapper` | `NameMapper` | `Identity` | Case name transformation |\n| `discriminatorKind` | `DiscriminatorKind` | `Key` | ADT encoding strategy |\n| `arrayFormat` | `ArrayFormat` | `Auto` | Array encoding preference |\n| `delimiter` | `Char` | `,` | Array value separator |\n| `rejectExtraFields` | `Boolean` | `false` | Fail on unknown fields |\n| `enumValuesAsStrings` | `Boolean` | `true` | Case objects as strings |\n| `transientNone` | `Boolean` | `true` | Omit None values |\n| `requireOptionFields` | `Boolean` | `false` | Require Option fields |\n| `transientEmptyCollection` | `Boolean` | `true` | Omit empty collections |\n| `requireCollectionFields` | `Boolean` | `false` | Require collections |\n| `transientDefaultValue` | `Boolean` | `true` | Omit default values |\n| `requireDefaultValueFields` | `Boolean` | `false` | Require default fields |\n| `enableKeyFolding` | `Boolean` | `false` | Dotted key expansion |",
              "url": "https://github.com/zio/zio-blocks/issues/654",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#519",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-12T11:36:03.175Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:36:03.175Z",
            "created_at": "2026-01-12T11:36:03.175Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#519",
              "status": "open",
              "type": "issue",
              "number": 519,
              "title": "Schema Migration System for ZIO Schema 2",
              "source": {
                "data": {
                  "id": "source-ZIO#519",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Schema Migration System for ZIO Schema 2",
                  "body": "## Overview\n\nImplement a **pure, algebraic migration system** for ZIO Schema 2 that represents **structural transformations between schema versions** as first-class, serializable data.\n\nA migration describes how to transform data from one schema version to another, enabling:\n\n* schema evolution\n* backward / forward compatibility\n* data versioning\n* offline migrations (JSON, SQL, data lakes, registries, etc.)\n\nThe system provides a **typed, macro-validated user API** (`Migration[A, B]`) built on a **pure, serializable core** (`DynamicMigration`) that operates on `DynamicValue`. \n\nThe ADT is fully introspectable and can be used to generate DDL, etc.\n\n## Motivation & Big Picture\n\n### Why structural types?\n\nWhen evolving schemas over time, **older versions of data types should not require runtime representations**.\n\nIn this design:\n\n* **Current versions** are represented by real case classes / enums\n* **Past versions** are represented using:\n\n  * **structural types** for records\n  * **abstract types + intersection types** for sum types\n\nThese types:\n\n* exist **only at compile time**\n* have **no runtime representation**\n* introduce **zero runtime overhead**\n* do **not require optics or instances to be kept around**\n\nThis allows you to describe arbitrarily old versions of data *without polluting your runtime or codebase*.\n\n#### Typical Workflow\n\nA typical workflow looks like:\n\n1. You have a current type:\n\n   ```scala\n   @schema\n   case class Person(name: String, age: Int)\n   ```\n\n2. You derive and copy its structural shape:\n\n   ```scala\n   type PersonV1 = { def name: String; def age: Int }\n   ```\n\n3. You evolve the real type:\n\n   ```scala\n   @schema\n   case class Person(fullName: String, age: Int, country: String)\n   ```\n\n4. You keep only:\n\n   * the **current** runtime type\n   * the **structural type** for the old version\n   * a **pure migration** between them\n\nNo old case classes. No old optics. No runtime baggage.\n\nNote there is no requirement that the \"current\" type actually be a real case class, enum, etc.--so you can work purely with structural types, allowing you to define migrations for data types that are never materialized as runtime structures.\n\n---\n\n### Why pure data migrations?\n\nMigrations are represented entirely as **pure data**:\n\n* no user functions\n* no closures\n* no reflection\n* no runtime code generation\n\nAs a result:\n\n* migrations can be **serialized**\n* stored in **registries**\n* applied **dynamically**\n* inspected and transformed\n* used to generate:\n\n  * upgraders\n  * downgraders\n  * SQL DDL / DML\n  * offline data transforms\n\nWhile code generation is **out of scope for this ticket**, this explains many design decisions (invertibility, path-based actions, no functions).\n\n---\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed migration (user-facing API)\ncase class Migration[A, B](\n  dynamicMigration: DynamicMigration,\n  sourceSchema: Schema[A], // These are structural schemas!!!\n  targetSchema: Schema[B] // These are structural schemas!!!\n) {\n  /** Apply migration to transform A to B */\n  def apply(value: A): Either[MigrationError, B]\n\n  /** Compose migrations sequentially */\n  def ++[C](that: Migration[B, C]): Migration[A, C]\n\n  /** Alias for ++ */\n  def andThen[C](that: Migration[B, C]): Migration[A, C] = this ++ that\n\n  /** Reverse migration (structural inverse; runtime is best-effort) */\n  def reverse: Migration[B, A]\n}\n```\n\n```scala\n// Untyped migration (pure data, fully serializable)\ncase class DynamicMigration(\n  actions: Vector[MigrationAction]\n) {\n  def apply(value: DynamicValue): Either[MigrationError, DynamicValue]\n  def ++(that: DynamicMigration): DynamicMigration\n  def reverse: DynamicMigration\n}\n```\n\n* `Migration[A, B]` is introspectable, but not pure data due to bindings inside schemas\n* `DynamicMigration` is **fully serializable**\n\n---\n\n## User-Facing API: Selector Expressions\n\n### Selectors, not optics\n\nThe user-facing API **does not expose optics**.\n\nInstead, all locations are specified using **selector expressions**:\n\n```scala\nS => A\n```\n\nExamples:\n\n```scala\n_.name\n_.address.street\n_.addresses.each.streetNumber\n_.country.when[UK]\n```\n\nTo see the syntax, one can look at the `optic` macro, which utilizes the same selector syntax for optic creation (e.g. `optic(_.address.street)`, etc.).\n\n### Macro extraction\n\nAll builder methods that accept selectors are **implemented via macros** (or via a macro-generated type class such as `ToDynamicOptic`).\n\nThe macro:\n\n1. Inspects the selector expression\n2. Validates it is a supported projection\n3. Converts it into a `DynamicOptic`\n4. Stores that optic in the migration action\n\nSupported projections include:\n\n* field access (`_.foo.bar`)\n* case selection (`_.country.when[UK]`)\n* collection traversal (`_.items.each`)\n* (future) key access, wrappers, etc.\n\n`DynamicOptic` is **never exposed publicly**.\n\n---\n\n## Migration Builder\n\nAll selector-accepting methods are implemented via macros. For simplicity, these are shown as functions (e.g. `A => Any`), but this is NOT the way to implement them. Either all these functions need to be macros, or a macro needs to be used to generate an implicit / given at each call site. Macros may do additional validation to constrain the validity of these different types of transformations.\n\n```scala\nclass MigrationBuilder[A, B](\n  sourceSchema: Schema[A],\n  targetSchema: Schema[B],\n  actions: Vector[MigrationAction]\n) {\n\n  // ----- Record operations -----\n\n  def addField(\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def dropField(\n    source: A => Any,\n    defaultForReverse: SchemaExpr[B, ?] = SchemaExpr.DefaultValue\n  ): MigrationBuilder[A, B]\n\n  def renameField(\n    from: A => Any,\n    to: B => Any\n  ): MigrationBuilder[A, B]\n\n  def transformField(\n    from: A => Any,\n    to: B => Any,\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def mandateField(\n    source: A => Option[?],\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def optionalizeField(\n    source: A => Any,\n    target: B => Option[?]\n  ): MigrationBuilder[A, B]\n\n  def changeFieldType(\n    source: A => Any,\n    target: B => Any,\n    converter: SchemaExpr[A, ?]  // primitive-to-primitive only\n  ): MigrationBuilder[A, B]\n\n  // ----- Enum operations (limited) -----\n\n  def renameCase[SumA, SumB](\n    from: String,\n    to: String\n  ): MigrationBuilder[A, B]\n\n  def transformCase[SumA, CaseA, SumB, CaseB](\n    caseMigration: MigrationBuilder[CaseA, CaseB] => MigrationBuilder[CaseA, CaseB]\n  ): MigrationBuilder[A, B]\n\n  // ----- Collections -----\n\n  def transformElements(\n    at: A => Vector[?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  // ----- Maps -----\n\n  def transformKeys(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def transformValues(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  /** Build migration with full macro validation */\n  def build: Migration[A, B]\n\n  /** Build migration without full validation */\n  def buildPartial: Migration[A, B]\n}\n```\n\n---\n\n## Migration Actions (Untyped Core)\n\nAll actions operate at a **path**, represented by `DynamicOptic`.\n\n```scala\nsealed trait MigrationAction {\n  def at: DynamicOptic\n  def reverse: MigrationAction\n}\n```\n\n### Record Actions\n\n```scala\ncase class AddField(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class DropField(\n  at: DynamicOptic,\n  defaultForReverse: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Rename(\n  at: DynamicOptic,\n  to: String\n) extends MigrationAction\n\ncase class TransformValue(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Mandate(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Optionalize(\n  at: DynamicOptic\n) extends MigrationAction\n\ncase class Join(\n  at: DynamicOptic,\n  sourcePaths: Vector[DynamicOptic],\n  combiner: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Split(\n  at: DynamicOptic,\n  targetPaths: Vector[DynamicOptic],\n  splitter: SchemaExpr[?]\n) extends MigrationAction\n\ncase class ChangeType(\n  at: DynamicOptic,\n  converter: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n### Enum Actions (Supported)\n\n```scala\ncase class RenameCase(\n  at: DynamicOptic,\n  from: String,\n  to: String\n) extends MigrationAction\n\ncase class TransformCase(\n  at: DynamicOptic,\n  actions: Vector[MigrationAction]\n) extends MigrationAction\n```\n\n> Enum case addition / removal is **out of scope** for this ticket\n> (requires composite value construction).\n\n---\n\n### Collection / Map Actions\n\n```scala\ncase class TransformElements(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformKeys(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformValues(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n## SchemaExpr Integration\n\n* Used for all value-level transformations\n* **Constraints for this ticket**:\n\n  * primitive  primitive only\n  * joins / splits must produce primitives\n  * no record / enum construction\n\n### `SchemaExpr.DefaultValue`\n\nA special expression that:\n\n1. uses the macro-captured field schema\n2. calls `schema.defaultValue`\n3. converts the value to `DynamicValue`\n4. is stored for reverse migrations\n\n---\n\n## Type Modeling\n\n### Records (Structural Types)\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\ntype PersonV1 = { val fullName: String; val age: Int }\n\nimplicit val v0Schema: Schema[PersonV0] = Schema.structural[PersonV0]\nimplicit val v1Schema: Schema[PersonV1] = Schema.structural[PersonV1]\n```\n\n---\n\n### Enums (Union of Structural Types with Tags)\n\nEnums are encoded into structural types by using union types, together with singleton types (string literals, which represent the name of the case of the enum).\n\nIn structural types, the names of the type aliases shown below are not relevant, nor are they used.\n\n```scala\ntype OldCreditCard =\n  { type Tag = \"CreditCard\"; def number: String; def exp: String }\ntype OldWireTransfer =\n  { type Tag = \"WireTransfer\"; def account: String; def routing: String }\ntype OldPaymentMethod = OldCreditCard | OldWireTransfer\n```\n\nMacros extract:\n\n* refinement type  structure of the case\n* type `Tag` with singleton type  case tag\n\n---\n\n## Laws\n\n### Identity\n\n```scala\nMigration.identity[A].apply(a) == Right(a)\n```\n\n### Associativity\n\n```scala\n(m1 ++ m2) ++ m3 == m1 ++ (m2 ++ m3)\n```\n\n### Structural Reverse\n\n```scala\nm.reverse.reverse == m\n```\n\n### Best-Effort Semantic Inverse\n\n```scala\nm.apply(a) == Right(b)  m.reverse.apply(b) == Right(a)\n```\n\n(when sufficient information exists)\n\n---\n\n## Error Handling\n\n* All runtime errors return `MigrationError`\n* Errors must capture **path information** (`DynamicOptic`)\n* Enables diagnostics such as:\n\n> Failed to apply TransformValue at `.addresses.each.streetNumber`\n\n---\n\n## Example\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\n\n@schema\ncase class Person(fullName: String, age: Int)\n\nval migration =\n  Migration.newBuilder[PersonV0, Person]\n    .addField(_.age, 0)\n    .build\n\nval old =\n  new { val firstName = \"John\"; val lastName = \"Doe\" }\n\nmigration(old)\n// Right(Person(\"John Doe\", 0))\n```\n\n---\n\n## Success Criteria\n\n* [ ] `DynamicMigration` fully serializable\n* [ ] `Migration[A, B]` wraps schemas and actions\n* [ ] All actions path-based via `DynamicOptic`\n* [ ] User API uses selector functions (`S => A`) for \"optics\" on old and new types\n* [ ] Macro validation in `.build` to confirm \"old\" has been migrated to \"new\"\n* [ ] `.buildPartial` supported\n* [ ] Structural reverse implemented\n* [ ] Identity & associativity laws hold\n* [ ] Enum rename / transform supported\n* [ ] Errors include path information\n* [ ] Comprehensive tests\n* [ ] Scala 2.13 and Scala 3.5+ supported\n",
                  "html_url": "https://github.com/zio/zio-blocks/issues/519"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#519",
              "body": "## Overview\n\nImplement a **pure, algebraic migration system** for ZIO Schema 2 that represents **structural transformations between schema versions** as first-class, serializable data.\n\nA migration describes how to transform data from one schema version to another, enabling:\n\n* schema evolution\n* backward / forward compatibility\n* data versioning\n* offline migrations (JSON, SQL, data lakes, registries, etc.)\n\nThe system provides a **typed, macro-validated user API** (`Migration[A, B]`) built on a **pure, serializable core** (`DynamicMigration`) that operates on `DynamicValue`. \n\nThe ADT is fully introspectable and can be used to generate DDL, etc.\n\n## Motivation & Big Picture\n\n### Why structural types?\n\nWhen evolving schemas over time, **older versions of data types should not require runtime representations**.\n\nIn this design:\n\n* **Current versions** are represented by real case classes / enums\n* **Past versions** are represented using:\n\n  * **structural types** for records\n  * **abstract types + intersection types** for sum types\n\nThese types:\n\n* exist **only at compile time**\n* have **no runtime representation**\n* introduce **zero runtime overhead**\n* do **not require optics or instances to be kept around**\n\nThis allows you to describe arbitrarily old versions of data *without polluting your runtime or codebase*.\n\n#### Typical Workflow\n\nA typical workflow looks like:\n\n1. You have a current type:\n\n   ```scala\n   @schema\n   case class Person(name: String, age: Int)\n   ```\n\n2. You derive and copy its structural shape:\n\n   ```scala\n   type PersonV1 = { def name: String; def age: Int }\n   ```\n\n3. You evolve the real type:\n\n   ```scala\n   @schema\n   case class Person(fullName: String, age: Int, country: String)\n   ```\n\n4. You keep only:\n\n   * the **current** runtime type\n   * the **structural type** for the old version\n   * a **pure migration** between them\n\nNo old case classes. No old optics. No runtime baggage.\n\nNote there is no requirement that the \"current\" type actually be a real case class, enum, etc.--so you can work purely with structural types, allowing you to define migrations for data types that are never materialized as runtime structures.\n\n---\n\n### Why pure data migrations?\n\nMigrations are represented entirely as **pure data**:\n\n* no user functions\n* no closures\n* no reflection\n* no runtime code generation\n\nAs a result:\n\n* migrations can be **serialized**\n* stored in **registries**\n* applied **dynamically**\n* inspected and transformed\n* used to generate:\n\n  * upgraders\n  * downgraders\n  * SQL DDL / DML\n  * offline data transforms\n\nWhile code generation is **out of scope for this ticket**, this explains many design decisions (invertibility, path-based actions, no functions).\n\n---\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed migration (user-facing API)\ncase class Migration[A, B](\n  dynamicMigration: DynamicMigration,\n  sourceSchema: Schema[A], // These are structural schemas!!!\n  targetSchema: Schema[B] // These are structural schemas!!!\n) {\n  /** Apply migration to transform A to B */\n  def apply(value: A): Either[MigrationError, B]\n\n  /** Compose migrations sequentially */\n  def ++[C](that: Migration[B, C]): Migration[A, C]\n\n  /** Alias for ++ */\n  def andThen[C](that: Migration[B, C]): Migration[A, C] = this ++ that\n\n  /** Reverse migration (structural inverse; runtime is best-effort) */\n  def reverse: Migration[B, A]\n}\n```\n\n```scala\n// Untyped migration (pure data, fully serializable)\ncase class DynamicMigration(\n  actions: Vector[MigrationAction]\n) {\n  def apply(value: DynamicValue): Either[MigrationError, DynamicValue]\n  def ++(that: DynamicMigration): DynamicMigration\n  def reverse: DynamicMigration\n}\n```\n\n* `Migration[A, B]` is introspectable, but not pure data due to bindings inside schemas\n* `DynamicMigration` is **fully serializable**\n\n---\n\n## User-Facing API: Selector Expressions\n\n### Selectors, not optics\n\nThe user-facing API **does not expose optics**.\n\nInstead, all locations are specified using **selector expressions**:\n\n```scala\nS => A\n```\n\nExamples:\n\n```scala\n_.name\n_.address.street\n_.addresses.each.streetNumber\n_.country.when[UK]\n```\n\nTo see the syntax, one can look at the `optic` macro, which utilizes the same selector syntax for optic creation (e.g. `optic(_.address.street)`, etc.).\n\n### Macro extraction\n\nAll builder methods that accept selectors are **implemented via macros** (or via a macro-generated type class such as `ToDynamicOptic`).\n\nThe macro:\n\n1. Inspects the selector expression\n2. Validates it is a supported projection\n3. Converts it into a `DynamicOptic`\n4. Stores that optic in the migration action\n\nSupported projections include:\n\n* field access (`_.foo.bar`)\n* case selection (`_.country.when[UK]`)\n* collection traversal (`_.items.each`)\n* (future) key access, wrappers, etc.\n\n`DynamicOptic` is **never exposed publicly**.\n\n---\n\n## Migration Builder\n\nAll selector-accepting methods are implemented via macros. For simplicity, these are shown as functions (e.g. `A => Any`), but this is NOT the way to implement them. Either all these functions need to be macros, or a macro needs to be used to generate an implicit / given at each call site. Macros may do additional validation to constrain the validity of these different types of transformations.\n\n```scala\nclass MigrationBuilder[A, B](\n  sourceSchema: Schema[A],\n  targetSchema: Schema[B],\n  actions: Vector[MigrationAction]\n) {\n\n  // ----- Record operations -----\n\n  def addField(\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def dropField(\n    source: A => Any,\n    defaultForReverse: SchemaExpr[B, ?] = SchemaExpr.DefaultValue\n  ): MigrationBuilder[A, B]\n\n  def renameField(\n    from: A => Any,\n    to: B => Any\n  ): MigrationBuilder[A, B]\n\n  def transformField(\n    from: A => Any,\n    to: B => Any,\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def mandateField(\n    source: A => Option[?],\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def optionalizeField(\n    source: A => Any,\n    target: B => Option[?]\n  ): MigrationBuilder[A, B]\n\n  def changeFieldType(\n    source: A => Any,\n    target: B => Any,\n    converter: SchemaExpr[A, ?]  // primitive-to-primitive only\n  ): MigrationBuilder[A, B]\n\n  // ----- Enum operations (limited) -----\n\n  def renameCase[SumA, SumB](\n    from: String,\n    to: String\n  ): MigrationBuilder[A, B]\n\n  def transformCase[SumA, CaseA, SumB, CaseB](\n    caseMigration: MigrationBuilder[CaseA, CaseB] => MigrationBuilder[CaseA, CaseB]\n  ): MigrationBuilder[A, B]\n\n  // ----- Collections -----\n\n  def transformElements(\n    at: A => Vector[?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  // ----- Maps -----\n\n  def transformKeys(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def transformValues(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  /** Build migration with full macro validation */\n  def build: Migration[A, B]\n\n  /** Build migration without full validation */\n  def buildPartial: Migration[A, B]\n}\n```\n\n---\n\n## Migration Actions (Untyped Core)\n\nAll actions operate at a **path**, represented by `DynamicOptic`.\n\n```scala\nsealed trait MigrationAction {\n  def at: DynamicOptic\n  def reverse: MigrationAction\n}\n```\n\n### Record Actions\n\n```scala\ncase class AddField(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class DropField(\n  at: DynamicOptic,\n  defaultForReverse: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Rename(\n  at: DynamicOptic,\n  to: String\n) extends MigrationAction\n\ncase class TransformValue(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Mandate(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Optionalize(\n  at: DynamicOptic\n) extends MigrationAction\n\ncase class Join(\n  at: DynamicOptic,\n  sourcePaths: Vector[DynamicOptic],\n  combiner: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Split(\n  at: DynamicOptic,\n  targetPaths: Vector[DynamicOptic],\n  splitter: SchemaExpr[?]\n) extends MigrationAction\n\ncase class ChangeType(\n  at: DynamicOptic,\n  converter: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n### Enum Actions (Supported)\n\n```scala\ncase class RenameCase(\n  at: DynamicOptic,\n  from: String,\n  to: String\n) extends MigrationAction\n\ncase class TransformCase(\n  at: DynamicOptic,\n  actions: Vector[MigrationAction]\n) extends MigrationAction\n```\n\n> Enum case addition / removal is **out of scope** for this ticket\n> (requires composite value construction).\n\n---\n\n### Collection / Map Actions\n\n```scala\ncase class TransformElements(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformKeys(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformValues(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n## SchemaExpr Integration\n\n* Used for all value-level transformations\n* **Constraints for this ticket**:\n\n  * primitive  primitive only\n  * joins / splits must produce primitives\n  * no record / enum construction\n\n### `SchemaExpr.DefaultValue`\n\nA special expression that:\n\n1. uses the macro-captured field schema\n2. calls `schema.defaultValue`\n3. converts the value to `DynamicValue`\n4. is stored for reverse migrations\n\n---\n\n## Type Modeling\n\n### Records (Structural Types)\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\ntype PersonV1 = { val fullName: String; val age: Int }\n\nimplicit val v0Schema: Schema[PersonV0] = Schema.structural[PersonV0]\nimplicit val v1Schema: Schema[PersonV1] = Schema.structural[PersonV1]\n```\n\n---\n\n### Enums (Union of Structural Types with Tags)\n\nEnums are encoded into structural types by using union types, together with singleton types (string literals, which represent the name of the case of the enum).\n\nIn structural types, the names of the type aliases shown below are not relevant, nor are they used.\n\n```scala\ntype OldCreditCard =\n  { type Tag = \"CreditCard\"; def number: String; def exp: String }\ntype OldWireTransfer =\n  { type Tag = \"WireTransfer\"; def account: String; def routing: String }\ntype OldPaymentMethod = OldCreditCard | OldWireTransfer\n```\n\nMacros extract:\n\n* refinement type  structure of the case\n* type `Tag` with singleton type  case tag\n\n---\n\n## Laws\n\n### Identity\n\n```scala\nMigration.identity[A].apply(a) == Right(a)\n```\n\n### Associativity\n\n```scala\n(m1 ++ m2) ++ m3 == m1 ++ (m2 ++ m3)\n```\n\n### Structural Reverse\n\n```scala\nm.reverse.reverse == m\n```\n\n### Best-Effort Semantic Inverse\n\n```scala\nm.apply(a) == Right(b)  m.reverse.apply(b) == Right(a)\n```\n\n(when sufficient information exists)\n\n---\n\n## Error Handling\n\n* All runtime errors return `MigrationError`\n* Errors must capture **path information** (`DynamicOptic`)\n* Enables diagnostics such as:\n\n> Failed to apply TransformValue at `.addresses.each.streetNumber`\n\n---\n\n## Example\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\n\n@schema\ncase class Person(fullName: String, age: Int)\n\nval migration =\n  Migration.newBuilder[PersonV0, Person]\n    .addField(_.age, 0)\n    .build\n\nval old =\n  new { val firstName = \"John\"; val lastName = \"Doe\" }\n\nmigration(old)\n// Right(Person(\"John Doe\", 0))\n```\n\n---\n\n## Success Criteria\n\n* [ ] `DynamicMigration` fully serializable\n* [ ] `Migration[A, B]` wraps schemas and actions\n* [ ] All actions path-based via `DynamicOptic`\n* [ ] User API uses selector functions (`S => A`) for \"optics\" on old and new types\n* [ ] Macro validation in `.build` to confirm \"old\" has been migrated to \"new\"\n* [ ] `.buildPartial` supported\n* [ ] Structural reverse implemented\n* [ ] Identity & associativity laws hold\n* [ ] Enum rename / transform supported\n* [ ] Errors include path information\n* [ ] Comprehensive tests\n* [ ] Scala 2.13 and Scala 3.5+ supported\n",
              "url": "https://github.com/zio/zio-blocks/issues/519",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#518",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-12T11:36:03.332Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:36:03.332Z",
            "created_at": "2026-01-12T11:36:03.332Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#518",
              "status": "open",
              "type": "issue",
              "number": 518,
              "title": "Add `Into[A, B]` and `As[A, B]` Type Classes with Macro Derivation",
              "source": {
                "data": {
                  "id": "source-ZIO#518",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add `Into[A, B]` and `As[A, B]` Type Classes with Macro Derivation",
                  "body": "## Overview\n\nAdd two related type classes for type-safe schema evolution:\n\n1. **`Into[A, B]`**: One-way conversion from `A` to `B` with runtime validation\n2. **`As[A, B]`**: Bidirectional conversion establishing a partial equivalence between `A` and `B`\n\nBoth type classes are automatically derived via macros that intelligently map fields using names, positions, and types, with support for validation, coercion, and schema evolution patterns.\n\n---\n\n## Type Class Definitions\n\n### Into[A, B] - One-Way Conversion\n\n```scala\ntrait Into[-A, +B] {\n  def into(input: A): Either[SchemaError, B]\n}\n```\n\n**Purpose**: Convert from source type `A` to target type `B`, potentially failing at runtime when validation constraints cannot be satisfied.\n\n**Use Cases**:\n- Migrating between schema versions\n- Converting between equivalent representations\n- Validating conversions with opaque types\n- Transforming external data into internal models\n\n### As[A, B] - Bidirectional Conversion\n\n```scala\ntrait As[A, B] {\n  def into(input: A): Either[SchemaError, B]\n  def from(input: B): Either[SchemaError, A]\n}\n```\n\n**Purpose**: Establish a partial equivalence between types `A` and `B` where conversion can fail in either direction due to runtime validation.\n\n**Use Cases**:\n- Isomorphic schema versions\n- Equivalent representations (e.g., case class  tuple)\n- Reversible transformations with runtime validation\n- Round-trip serialization/deserialization\n\n**Relationship**: `As[A, B]` implies both `Into[A, B]` and `Into[B, A]` exist, but with the additional guarantee that both conversions use compatible mapping logic and can round-trip (subject to runtime validation).\n\n**Note**: `SchemaError` is composable, allowing multiple validation failures to be combined into a single error.\n\n---\n\n## Core Conversion Rules\n\n### Field Mapping Algorithm\n\nThe macro establishes field mappings using three attributes:\n1. **Field name** (identifier in source code)\n2. **Field position** (ordinal position in declaration)\n3. **Field type** (including coercible types)\n\n**Priority for disambiguation:**\n1. **Exact match**: Same name + same type\n2. **Name match with coercion**: Same name + coercible type\n3. **Unique type match**: Type appears only once in both source and target\n4. **Position + unique type**: Positional correspondence with unambiguous type\n5. **Fallback**: If no unambiguous mapping exists, derivation fails at compile-time\n\n### Mapping Examples\n\n#### Unambiguous by Unique Types\n```scala\ncase class Person(name: String, age: Int, active: Boolean)\ncase class User(username: String, yearsOld: Int, enabled: Boolean)\n\n// Success: Each type appears exactly once\n// Mapping: StringString, IntInt, BooleanBoolean\n```\n\n#### Unambiguous by Names\n```scala\ncase class Point(x: Int, y: Int)\ncase class Coord(y: Int, x: Int)\n\n// Success: Names uniquely identify despite reordering\n// Mapping: xx, yy\n```\n\n#### Ambiguous - Compile Failure\n```scala\ncase class Dimensions(width: Int, height: Int)\ncase class Measurements(first: Int, second: Int)\n\n// COMPILE ERROR: Cannot determine mapping\n// Both Int types, different names, ambiguous positional match\n```\n\n#### Disambiguation by Position (Tuples)\n```scala\ncase class RGB(r: Int, g: Int, b: Int)\ntype ColorTuple = (Int, Int, Int)\n\n// Success: Position disambiguates\n// Mapping: r_1, g_2, b_3\n```\n\n---\n\n## Supported Conversions\n\n### 1. Product Types (Records)\n\n#### Case Class to Case Class\n```scala\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(fullName: String, age: Int)\n\n// Success if 'name' is unique String in V1 and 'fullName' is unique String in V2\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30))\n// => Right(PersonV2(\"Alice\", 30))\n```\n\n#### Case Class to Tuple\n```scala\ncase class Point(x: Double, y: Double)\n\nInto[Point, (Double, Double)].into(Point(1.0, 2.0))\n// => Right((1.0, 2.0))\n```\n\n#### Tuple to Case Class\n```scala\ncase class RGB(red: Int, green: Int, blue: Int)\n\nInto[(Int, Int, Int), RGB].into((255, 128, 64))\n// => Right(RGB(255, 128, 64))\n```\n\n#### Tuple to Tuple\n```scala\nInto[(Int, String), (Long, String)].into((42, \"hello\"))\n// => Right((42L, \"hello\"))\n```\n\n### 2. Coproduct Types (Sum Types)\n\n#### Sealed Trait to Sealed Trait (by name)\n```scala\nsealed trait Color\ncase object Red extends Color\ncase object Blue extends Color\n\nsealed trait Hue\ncase object Red extends Hue\ncase object Blue extends Hue\n\nInto[Color, Hue].into(Red)\n// => Right(Red)\n```\n\n#### Sealed Trait to Sealed Trait (by signature)\n```scala\nsealed trait EventV1\ncase class Created(id: String, ts: Long) extends EventV1\ncase class Deleted(id: String) extends EventV1\n\nsealed trait EventV2\ncase class Spawned(id: String, ts: Long) extends EventV2\ncase class Removed(id: String) extends EventV2\n\nInto[EventV1, EventV2].into(Created(\"abc\", 123L))\n// => Right(Spawned(\"abc\", 123L))\n// Matched by constructor signature (String, Long)\n```\n\n#### Enum to Enum (Scala 3)\n```scala\nenum Status:\n  case Active, Inactive, Suspended\n\nenum State:\n  case Active, Inactive, Suspended\n\nInto[Status, State].into(Status.Active)\n// => Right(State.Active)\n```\n\n#### ADT with Payload Conversion\n```scala\nsealed trait ResultV1\ncase class Success(value: Int) extends ResultV1\ncase class Failure(msg: String) extends ResultV1\n\nsealed trait ResultV2\ncase class Success(value: Long) extends ResultV2\ncase class Failure(msg: String) extends ResultV2\n\nInto[ResultV1, ResultV2].into(Success(42))\n// => Right(Success(42L))\n// Field type coercion within matched case\n```\n\n### 3. Primitive Type Coercions\n\n#### Numeric Widening (Lossless)\n```scala\nInto[Byte, Short].into(42.toByte)    // => Right(42.toShort)\nInto[Short, Int].into(1000.toShort)  // => Right(1000)\nInto[Int, Long].into(100000)         // => Right(100000L)\nInto[Float, Double].into(3.14f)      // => Right(3.14)\n```\n\n#### Numeric Narrowing (with Runtime Validation)\n```scala\nInto[Long, Int].into(42L)\n// => Right(42)\n\nInto[Long, Int].into(3000000000L)\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n\nInto[Double, Float].into(3.14)\n// => Right(3.14f)\n\nInto[Double, Float].into(1e100)\n// => Left(SchemaError(\"Value 1.0E100 exceeds Float.MaxValue\"))\n```\n\n#### Collection Element Coercion\n```scala\nInto[List[Int], List[Long]].into(List(1, 2, 3))\n// => Right(List(1L, 2L, 3L))\n\nInto[Vector[Float], Vector[Double]].into(Vector(1.5f, 2.5f))\n// => Right(Vector(1.5, 2.5))\n\nInto[Set[Short], Set[Int]].into(Set(10.toShort, 20.toShort))\n// => Right(Set(10, 20))\n\nInto[List[Long], List[Int]].into(List(42L, 3000000000L))\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n```\n\n#### Nested Collection Coercion\n```scala\nInto[List[List[Int]], List[List[Long]]].into(List(List(1, 2), List(3, 4)))\n// => Right(List(List(1L, 2L), List(3L, 4L)))\n```\n\n#### Map Key/Value Coercion\n```scala\nInto[Map[Int, Float], Map[Long, Double]].into(Map(1 -> 1.5f, 2 -> 2.5f))\n// => Right(Map(1L -> 1.5, 2L -> 2.5))\n\nInto[Map[Long, String], Map[Int, String]].into(Map(42L -> \"a\", 3000000000L -> \"b\"))\n// => Left(SchemaError(\"Key 3000000000 exceeds Int.MaxValue\"))\n```\n\n#### Option Type Coercion\n```scala\nInto[Option[Int], Option[Long]].into(Some(42))\n// => Right(Some(42L))\n\nInto[Option[Int], Option[Long]].into(None)\n// => Right(None)\n\nInto[Option[Long], Option[Int]].into(Some(3000000000L))\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n```\n\n#### Either Type Coercion\n```scala\nInto[Either[String, Int], Either[String, Long]].into(Right(42))\n// => Right(Right(42L))\n\nInto[Either[Int, String], Either[Long, String]].into(Left(100))\n// => Right(Left(100L))\n```\n\n### 4. Collection Type Conversions\n\n#### Between Standard Collection Types\n```scala\nInto[List[Int], Vector[Int]].into(List(1, 2, 3))\n// => Right(Vector(1, 2, 3))\n\nInto[Vector[String], List[String]].into(Vector(\"a\", \"b\", \"c\"))\n// => Right(List(\"a\", \"b\", \"c\"))\n\nInto[Array[Int], List[Int]].into(Array(1, 2, 3))\n// => Right(List(1, 2, 3))\n\nInto[List[Int], Array[Int]].into(List(1, 2, 3))\n// => Right(Array(1, 2, 3))\n\nInto[Seq[Int], List[Int]].into(Seq(1, 2, 3))\n// => Right(List(1, 2, 3))\n\nInto[List[Int], Seq[Int]].into(List(1, 2, 3))\n// => Right(Seq(1, 2, 3))\n```\n\n#### Set Conversions (Order-Preserving Collections to Set)\n```scala\nInto[List[Int], Set[Int]].into(List(1, 2, 2, 3))\n// => Right(Set(1, 2, 3))\n// Note: Duplicates are removed\n\nInto[Vector[String], Set[String]].into(Vector(\"a\", \"b\", \"a\"))\n// => Right(Set(\"a\", \"b\"))\n```\n\n#### Set to Order-Preserving Collections\n```scala\nInto[Set[Int], List[Int]].into(Set(3, 1, 2))\n// => Right(List(1, 2, 3))\n// Note: Order is determined by Set's iteration order\n\nInto[Set[String], Vector[String]].into(Set(\"c\", \"a\", \"b\"))\n// => Right(Vector(\"a\", \"b\", \"c\"))\n```\n\n#### Combined Element and Collection Type Conversion\n```scala\nInto[List[Int], Vector[Long]].into(List(1, 2, 3))\n// => Right(Vector(1L, 2L, 3L))\n\nInto[Array[Short], List[Int]].into(Array(10.toShort, 20.toShort))\n// => Right(List(10, 20))\n\nInto[Set[Int], List[Long]].into(Set(1, 2, 3))\n// => Right(List(1L, 2L, 3L))\n```\n\n#### Nested Collection Type Conversions\n```scala\nInto[List[Vector[Int]], Vector[List[Long]]].into(List(Vector(1, 2), Vector(3, 4)))\n// => Right(Vector(List(1L, 2L), List(3L, 4L)))\n```\n\n### 5. Structural Types\n\n#### Structural Type Targets (Scala 3 with Selectable)\n```scala\ncase class Point(x: Int, y: Int)\ntype Coord = { def x: Int; def y: Int }\n\nInto[Point, Coord].into(Point(5, 10))\n// => Right(<structural instance with x=5, y=10>)\n```\n\n#### Structural Type Targets (Scala 2 with Dynamic)\n```scala\ncase class Person(name: String, age: Int)\ntype Record = { def name: String; def age: Int }\n\nInto[Person, Record].into(Person(\"Alice\", 30))\n// => Right(<dynamic instance with name=\"Alice\", age=30>)\n```\n\n#### Structural Type Sources\n```scala\ntype PersonLike = { def name: String; def age: Int }\ncase class User(name: String, age: Int)\n\nval personLike: PersonLike = ??? // some structural instance\nInto[PersonLike, User].into(personLike)\n// => Right(User(\"Alice\", 30))\n```\n\n### 6. Schema Evolution Patterns\n\n#### Adding Optional Fields\n```scala\ncase class UserV1(id: String, name: String)\ncase class UserV2(id: String, name: String, email: Option[String])\n\nInto[UserV1, UserV2].into(UserV1(\"123\", \"Alice\"))\n// => Right(UserV2(\"123\", \"Alice\", None))\n```\n\n#### Removing Optional Fields\n```scala\ncase class UserV2(id: String, name: String, email: Option[String])\ncase class UserV1(id: String, name: String)\n\nInto[UserV2, UserV1].into(UserV2(\"123\", \"Alice\", Some(\"alice@example.com\")))\n// => Right(UserV1(\"123\", \"Alice\"))\n// email field is dropped\n```\n\n#### Adding Required Fields with Defaults (Scala 3)\n```scala\ncase class ProductV1(name: String, price: Double)\ncase class ProductV2(name: String, price: Double, available: Boolean = true)\n\nInto[ProductV1, ProductV2].into(ProductV1(\"Widget\", 19.99))\n// => Right(ProductV2(\"Widget\", 19.99, true))\n```\n\n#### Field Reordering\n```scala\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(email: String, name: String, age: Int)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"alice@example.com\"))\n// => Right(PersonV2(\"alice@example.com\", \"Alice\", 30))\n```\n\n#### Field Renaming (with unique types)\n```scala\ncase class PersonV1(fullName: String, yearOfBirth: Int)\ncase class PersonV2(name: String, birthYear: Int)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice Smith\", 1990))\n// => Right(PersonV2(\"Alice Smith\", 1990))\n```\n\n#### Type Refinement\n```scala\ncase class ConfigV1(port: Int, timeout: Int)\ncase class ConfigV2(port: Int, timeout: Long)\n\nInto[ConfigV1, ConfigV2].into(ConfigV1(8080, 30))\n// => Right(ConfigV2(8080, 30L))\n```\n\n### 7. Nested Conversions\n\n#### Nested Products\n```scala\ncase class AddressV1(street: String, zip: Int)\ncase class PersonV1(name: String, address: AddressV1)\n\ncase class AddressV2(street: String, zip: Long)\ncase class PersonV2(name: String, address: AddressV2)\n\nInto[PersonV1, PersonV2].into(\n  PersonV1(\"Alice\", AddressV1(\"Main St\", 12345))\n)\n// => Right(PersonV2(\"Alice\", AddressV2(\"Main St\", 12345L)))\n```\n\n#### Nested Coproducts\n```scala\nsealed trait Inner\ncase class A(x: Int) extends Inner\ncase class B(y: String) extends Inner\n\nsealed trait Outer\ncase class Container(inner: Inner, label: String) extends Outer\n\n// Similar target types with Long instead of Int\nsealed trait InnerV2\ncase class A(x: Long) extends InnerV2\ncase class B(y: String) extends InnerV2\n\nsealed trait OuterV2\ncase class Container(inner: InnerV2, label: String) extends OuterV2\n\nInto[Outer, OuterV2].into(Container(A(42), \"test\"))\n// => Right(Container(A(42L), \"test\"))\n```\n\n#### Collections of Complex Types\n```scala\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(name: String, age: Long)\n\nInto[List[PersonV1], List[PersonV2]].into(\n  List(PersonV1(\"Alice\", 30), PersonV1(\"Bob\", 25))\n)\n// => Right(List(PersonV2(\"Alice\", 30L), PersonV2(\"Bob\", 25L)))\n```\n\n#### Nested Collections with Type Conversions\n```scala\ncase class DataV1(values: List[Vector[Int]])\ncase class DataV2(values: Vector[List[Long]])\n\nInto[DataV1, DataV2].into(\n  DataV1(List(Vector(1, 2), Vector(3, 4)))\n)\n// => Right(DataV2(Vector(List(1L, 2L), List(3L, 4L))))\n```\n\n---\n\n## Special Type Support\n\n### Opaque Types (Scala 3)\n\nOpaque types with validation are fully supported. The macro generates runtime validation calls.\n\n```scala\n// Definition with validation\nobject Domain:\n  opaque type Age = Int\n  object Age:\n    def apply(value: Int): Either[String, Age] =\n      if value >= 0 && value <= 150 then Right(value)\n      else Left(s\"Invalid age: $value\")\n    \n    def unsafe(value: Int): Age = value\n    \n    extension (age: Age)\n      def toInt: Int = age\n\n  opaque type Email = String\n  object Email:\n    def apply(value: String): Either[String, Email] =\n      if value.contains(\"@\") then Right(value)\n      else Left(s\"Invalid email: $value\")\n    \n    extension (email: Email)\n      def toString: String = email\n\nimport Domain._\n\n// Usage\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(name: String, age: Age, email: Email)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"alice@example.com\"))\n// => Right(PersonV2(\"Alice\", Age.unsafe(30), Email.unsafe(\"alice@example.com\")))\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", -5, \"alice@example.com\"))\n// => Left(SchemaError(\"Age validation failed: Invalid age: -5\"))\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"invalid\"))\n// => Left(SchemaError(\"Email validation failed: Invalid email: invalid\"))\n```\n\n**Macro Behavior**:\n- Detects opaque type companion objects with `apply(underlying): Either[_, OpaqueType]` method\n- Generates validation calls for each opaque type field\n- Accumulates all validation errors using `SchemaError` composition\n- Falls back to direct conversion if no validation method exists\n\n### Newtype Libraries (Scala 2)\n\n#### ZIO Prelude Newtypes (Built-in Support)\n\nThe macro includes hardcoded support for ZIO Prelude newtypes without requiring a compile-time dependency.\n\n```scala\nimport zio.prelude._\n\n// Definition with validation\nobject Domain {\n  object Age extends Subtype[Int] {\n    override def assertion = assert {\n      Assertion.between(0, 150)\n    }\n  }\n  type Age = Age.Type\n\n  object Email extends Newtype[String] {\n    override def assertion = assert {\n      Assertion.matches(\".*@.*\")\n    }\n  }\n  type Email = Email.Type\n}\n\nimport Domain._\n\n// Usage\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(name: String, age: Age, email: Email)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"alice@example.com\"))\n// => Right(PersonV2(\"Alice\", Age(30), Email(\"alice@example.com\")))\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 200, \"invalid\"))\n// => Left(SchemaError(\"Validation failed: age: 200 is not between 0 and 150, email: invalid does not match .*@.*\"))\n```\n\n**Macro Detection** (no ZIO Prelude dependency required):\n```scala\n// The macro detects ZIO Prelude newtypes by checking:\n// 1. Type extends Newtype[A] or Subtype[A]\n// 2. Companion object exists\n// 3. Has apply/wrap method with validation\n\n// Low-level AST matching in Scala 2 macro:\ndef isZIONewtype(tpe: Type): Boolean = {\n  tpe.typeSymbol.fullName.startsWith(\"zio.prelude.Newtype\") ||\n  tpe.typeSymbol.fullName.startsWith(\"zio.prelude.Subtype\")\n}\n```\n\n#### Other Newtype Libraries\n\nFor other newtype libraries, users can provide explicit `Into` instances. The macro will use these instances when available.\n\n```scala\n// User-provided instance for their newtype library\nimplicit val stringToMyNewtype: Into[String, MyNewtype] = \n  new Into[String, MyNewtype] {\n    def into(s: String): Either[SchemaError, MyNewtype] =\n      MyNewtype.make(s).left.map(e => SchemaError(e.toString))\n  }\n\n// The macro will automatically use this instance\ncase class PersonV1(email: String)\ncase class PersonV2(email: MyNewtype)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"test@example.com\"))\n// Uses the user-provided instance automatically\n```\n\n### Validation Error Accumulation\n\nWhen multiple validations fail, all errors are accumulated using `SchemaError` composition:\n\n```scala\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(name: String, age: Age, email: Email)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"\", -5, \"invalid\"))\n// => Left(SchemaError(...)) // Combined error containing all validation failures\n```\n\n---\n\n## As[A, B] Additional Requirements\n\nFor `As[A, B]` to be derivable, the bidirectional conversion must be **compatible**:\n\n### Compatibility Rules\n\n1. **Field mappings must be consistent**: The same field correspondence in both directions\n2. **Coercions must be invertible with runtime validation**: \n   -  `Int`  `Long` is valid (narrowing validated at runtime)\n   -  `Float`  `Double` is valid (narrowing validated at runtime)\n   -  All numeric coercions are valid with runtime checks\n3. **Optional fields**: \n   -  Can add optional fields in one direction (becomes `None` in reverse)\n   -  Can remove optional fields in one direction (value is dropped)\n4. **Default values**:\n   -  Cannot use default arguments (breaks round-trip guarantee)\n5. **Collection types**:\n   -  Can convert between different collection types\n   -   Set  List  Set may not preserve original order\n   -   List  Set  List loses duplicates\n\n### Valid As[A, B] Examples\n\n```scala\n// Valid: Same structure, different names\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(fullName: String, yearsOld: Int)\n\nAs[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30))\n// => Right(PersonV2(\"Alice\", 30))\n\nAs[PersonV1, PersonV2].from(PersonV2(\"Bob\", 25))\n// => Right(PersonV1(\"Bob\", 25))\n```\n\n```scala\n// Valid: Case class  Tuple\ncase class Point(x: Double, y: Double)\n\nAs[Point, (Double, Double)].into(Point(1.0, 2.0))\n// => Right((1.0, 2.0))\n\nAs[Point, (Double, Double)].from((3.0, 4.0))\n// => Right(Point(3.0, 4.0))\n```\n\n```scala\n// Valid: Numeric coercion with runtime validation\ncase class ConfigV1(timeout: Int)\ncase class ConfigV2(timeout: Long)\n\nAs[ConfigV1, ConfigV2].into(ConfigV1(30))\n// => Right(ConfigV2(30L))\n\nAs[ConfigV1, ConfigV2].from(ConfigV2(30L))\n// => Right(ConfigV1(30))\n\nAs[ConfigV1, ConfigV2].from(ConfigV2(3000000000L))\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n```\n\n```scala\n// Valid: Opaque types (reversible via unwrap)\ncase class PersonRaw(name: String, age: Int)\ncase class PersonValidated(name: String, age: Age)\n\nAs[PersonRaw, PersonValidated].into(PersonRaw(\"Alice\", 30))\n// => Right(PersonValidated(\"Alice\", Age.unsafe(30)))\n\nAs[PersonRaw, PersonValidated].from(PersonValidated(\"Bob\", Age.unsafe(25)))\n// => Right(PersonRaw(\"Bob\", 25))\n\nAs[PersonRaw, PersonValidated].into(PersonRaw(\"Charlie\", -5))\n// => Left(SchemaError(\"Age validation failed: Invalid age: -5\"))\n```\n\n```scala\n// Valid: Collection type conversions\ncase class DataV1(items: List[Int])\ncase class DataV2(items: Vector[Int])\n\nAs[DataV1, DataV2].into(DataV1(List(1, 2, 3)))\n// => Right(DataV2(Vector(1, 2, 3)))\n\nAs[DataV1, DataV2].from(DataV2(Vector(4, 5, 6)))\n// => Right(DataV1(List(4, 5, 6)))\n```\n\n```scala\n// Valid: Optional field in one direction\ncase class UserV1(id: String, name: String)\ncase class UserV2(id: String, name: String, email: Option[String])\n\nAs[UserV1, UserV2].into(UserV1(\"123\", \"Alice\"))\n// => Right(UserV2(\"123\", \"Alice\", None))\n\nAs[UserV1, UserV2].from(UserV2(\"456\", \"Bob\", Some(\"bob@example.com\")))\n// => Right(UserV1(\"456\", \"Bob\"))\n// email is dropped in reverse direction\n```\n\n### Non-Ideal As[A, B] Examples (Valid but Lossy)\n\n```scala\n// Valid but lossy: List with duplicates  Set  List\ncase class DataV1(values: List[Int])\ncase class DataV2(values: Set[Int])\n\nAs[DataV1, DataV2].into(DataV1(List(1, 2, 2, 3)))\n// => Right(DataV2(Set(1, 2, 3)))\n\nAs[DataV1, DataV2].from(DataV2(Set(1, 2, 3)))\n// => Right(DataV1(List(1, 2, 3)))\n// Original duplicates are lost, but conversion is valid\n```\n\n```scala\n// Valid but lossy: Set  List  Set (order may change)\ncase class DataV1(values: Set[Int])\ncase class DataV2(values: List[Int])\n\nval original = DataV1(Set(3, 1, 2))\nval converted = As[DataV1, DataV2].into(original).right.get\n// converted.values might be List(1, 2, 3) depending on Set iteration order\n\nval roundTrip = As[DataV1, DataV2].from(converted).right.get\n// roundTrip.values == Set(1, 2, 3) - same elements, possibly different internal order\n```\n\n### Invalid As[A, B] Examples\n\n```scala\n// Invalid: Default values break round-trip guarantee\ncase class ProductV1(name: String, price: Double)\ncase class ProductV2(name: String, price: Double, taxable: Boolean = true)\n\n// COMPILE ERROR: Cannot derive As[ProductV1, ProductV2]\n// Reason: Default value for 'taxable' cannot be recovered in reverse direction\n// (We can't distinguish between explicitly set 'true' and default 'true')\n```\n\n---\n\n## Testing Requirements\n\n### Test Matrix Dimensions\n\n1. **Type Combinations** (both `Into` and `As`)\n   - Primitive  Primitive (all coercion pairs, including narrowing)\n   - Product  Product (case classes)\n   - Product  Tuple\n   - Tuple  Product\n   - Tuple  Tuple\n   - Coproduct  Coproduct (sealed traits, enums)\n   - Collection[A]  Collection[B] (List, Vector, Set, Map, Option, Either, Array, Seq)\n   - Collection type conversions (List  Vector  Set  Array  Seq)\n   - Nested conversions\n   - Structural types\n\n2. **Disambiguation Scenarios**\n   - Unique types (names irrelevant)\n   - Matching names (types irrelevant with coercion)\n   - Duplicate types with name disambiguation\n   - Duplicate types with position disambiguation\n   - Ambiguous cases (must fail at compile-time)\n\n3. **Schema Evolution**\n   - Field reordering\n   - Field renaming (with unique types)\n   - Adding optional fields\n   - Removing optional fields\n   - Type refinement (Int  Long, with narrowing validation)\n   - Adding default values (Scala 3)\n\n4. **Validation** (Scala 3 opaque types)\n   - Valid values pass through\n   - Invalid values produce SchemaError\n   - Multiple validation failures accumulate\n   - Nested validation in products\n   - Validation in coproduct cases\n   - Validation in collections\n   - Narrowing conversions (Long  Int with overflow check)\n\n5. **Validation** (Scala 2 ZIO Prelude newtypes)\n   - Newtype validation success\n   - Newtype validation failure\n   - Subtype validation with assertions\n   - Multiple newtype fields\n\n6. **Collection Type Conversions**\n   - List  Vector\n   - List  Array\n   - List  Set (with duplicate handling)\n   - List  Seq\n   - Vector  Set\n   - Array  Vector\n   - All combinations with element type coercion\n   - Nested collection type conversions\n\n7. **Runtime Validation** (for `As[A, B]`)\n   - Numeric narrowing validation\n   - Round-trip with valid narrowing\n   - Round-trip failure with overflow\n   - Collection conversions with duplicates\n   - Optional field round-trips\n\n8. **Error Cases**\n   - Ambiguous field mapping (compile error)\n   - Ambiguous case mapping (compile error)\n   - Default value in `As` (compile error)\n   - Runtime validation failures\n   - Type mismatch (compile error)\n   - Overflow in narrowing conversions\n\n9. **Edge Cases**\n   - Empty case classes\n   - Single-field case classes\n   - Case objects\n   - Sealed traits with case objects only\n   - Deeply nested structures (5+ levels)\n   - Large products (20+ fields)\n   - Large coproducts (20+ cases)\n   - Recursive types (e.g., `case class Tree(value: Int, children: List[Tree])`)\n   - Mutually recursive types\n\n### Test Organization\n\n```\nsrc/test/scala/\n  into/\n    products/\n      CaseClassToCaseClassSpec.scala\n      CaseClassToTupleSpec.scala\n      TupleToCaseClassSpec.scala\n      TupleToTupleSpec.scala\n      FieldReorderingSpec.scala\n      FieldRenamingSpec.scala\n      NestedProductsSpec.scala\n    coproducts/\n      SealedTraitToSealedTraitSpec.scala\n      EnumToEnumSpec.scala (Scala 3 only)\n      CaseMatchingSpec.scala\n      SignatureMatchingSpec.scala\n      AmbiguousCaseSpec.scala\n      NestedCoproductsSpec.scala\n    primitives/\n      NumericWideningSpec.scala\n      NumericNarrowingSpec.scala\n      CollectionCoercionSpec.scala\n      OptionCoercionSpec.scala\n      EitherCoercionSpec.scala\n      NestedCollectionSpec.scala\n    collections/\n      ListToVectorSpec.scala\n      ListToSetSpec.scala\n      VectorToArraySpec.scala\n      CollectionTypeWithCoercionSpec.scala\n      NestedCollectionTypeSpec.scala\n      SetDuplicateHandlingSpec.scala\n    structural/\n      StructuralTypeTargetSpec.scala (Scala 3 Selectable)\n      DynamicTypeTargetSpec.scala (Scala 2 Dynamic)\n      StructuralTypeSourceSpec.scala\n    validation/\n      OpaqueTypeValidationSpec.scala (Scala 3 only)\n      ZIONewtypeValidationSpec.scala (Scala 2 only)\n      ValidationErrorAccumulationSpec.scala\n      NestedValidationSpec.scala\n      NarrowingValidationSpec.scala\n    evolution/\n      AddOptionalFieldSpec.scala\n      RemoveOptionalFieldSpec.scala\n      TypeRefinementSpec.scala\n      AddDefaultFieldSpec.scala (Scala 3 only)\n    disambiguation/\n      UniqueTypeDisambiguationSpec.scala\n      NameDisambiguationSpec.scala\n      PositionDisambiguationSpec.scala\n      AmbiguousCompileErrorSpec.scala\n    edge/\n      EmptyProductSpec.scala\n      SingleFieldSpec.scala\n      CaseObjectSpec.scala\n      DeepNestingSpec.scala\n      LargeProductSpec.scala\n      LargeCoproductSpec.scala\n      RecursiveTypeSpec.scala\n      MutuallyRecursiveTypeSpec.scala\n  \n  as/\n    reversibility/\n      RoundTripProductSpec.scala\n      RoundTripCoproductSpec.scala\n      RoundTripTupleSpec.scala\n      RoundTripCollectionTypeSpec.scala\n      OpaqueTypeRoundTripSpec.scala\n      NumericNarrowingRoundTripSpec.scala\n      OptionalFieldRoundTripSpec.scala\n    validation/\n      OverflowDetectionSpec.scala\n      NarrowingFailureSpec.scala\n      CollectionLossyConversionSpec.scala\n    compile_errors/\n      DefaultValueSpec.scala\n    (similar structure to into/ for applicable tests)\n```\n\n### Specific Test Cases\n\n#### Disambiguation Tests\n\n```scala\n// Test: Unique types make names irrelevant\ncase class A(x: String, y: Int, z: Boolean)\ncase class B(a: String, b: Int, c: Boolean)\nassert(Into[A, B].into(A(\"test\", 42, true)) == Right(B(\"test\", 42, true)))\n\n// Test: Names disambiguate duplicate types\ncase class Point(x: Int, y: Int)\ncase class Coord(y: Int, x: Int)\nassert(Into[Point, Coord].into(Point(1, 2)) == Right(Coord(2, 1)))\n\n// Test: Ambiguous mapping fails at compile-time\ncase class Dim(width: Int, height: Int)\ncase class Measure(first: Int, second: Int)\n// Must not compile: Into[Dim, Measure]\nassertDoesNotCompile(\"Into[Dim, Measure]\")\n```\n\n#### Numeric Narrowing Validation Tests\n\n```scala\n// Test: Valid narrowing conversion\ncase class V1(value: Long)\ncase class V2(value: Int)\nassert(Into[V1, V2].into(V1(42L)) == Right(V2(42)))\n\n// Test: Invalid narrowing (overflow)\nassert(Into[V1, V2].into(V1(3000000000L)).isLeft)\n\n// Test: Narrowing in collections\ncase class Data1(values: List[Long])\ncase class Data2(values: List[Int])\nassert(Into[Data1, Data2].into(Data1(List(1L, 2L, 3L))) == Right(Data2(List(1, 2, 3))))\nassert(Into[Data1, Data2].into(Data1(List(1L, 3000000000L))).isLeft)\n```\n\n#### Collection Type Conversion Tests\n\n```scala\n// Test: List to Vector\ncase class A(items: List[Int])\ncase class B(items: Vector[Int])\nassert(Into[A, B].into(A(List(1, 2, 3))) == Right(B(Vector(1, 2, 3))))\n\n// Test: List to Set (removes duplicates)\ncase class C(items: List[Int])\ncase class D(items: Set[Int])\nassert(Into[C, D].into(C(List(1, 2, 2, 3))) == Right(D(Set(1, 2, 3))))\n\n// Test: Vector to Array\ncase class E(items: Vector[String])\ncase class F(items: Array[String])\nval result = Into[E, F].into(E(Vector(\"a\", \"b\")))\nassert(result.isRight)\nassert(result.right.get.items.sameElements(Array(\"a\", \"b\")))\n\n// Test: Combined collection and element coercion\ncase class G(items: List[Int])\ncase class H(items: Vector[Long])\nassert(Into[G, H].into(G(List(1, 2, 3))) == Right(H(Vector(1L, 2L, 3L))))\n```\n\n#### Validation Tests (Scala 3)\n\n```scala\n// Test: Valid opaque type conversion\ncase class Raw(age: Int)\ncase class Validated(age: Age)\nassert(Into[Raw, Validated].into(Raw(30)).isRight)\n\n// Test: Invalid opaque type conversion\nassert(Into[Raw, Validated].into(Raw(-5)).isLeft)\n\n// Test: Multiple validation failures accumulate\ncase class RawPerson(age: Int, email: String)\ncase class ValidPerson(age: Age, email: Email)\nval result = Into[RawPerson, ValidPerson].into(RawPerson(-5, \"invalid\"))\nassert(result.isLeft)\n// SchemaError contains both validation failures\n```\n\n#### Round-Trip Tests (As)\n\n```scala\n// Test: Case class round-trip\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(fullName: String, yearsOld: Int)\n\nval v1 = PersonV1(\"Alice\", 30)\nval v2 = As[PersonV1, PersonV2].into(v1).right.get\nval roundTrip = As[PersonV1, PersonV2].from(v2).right.get\n\nassert(roundTrip == v1)\n\n// Test: Numeric narrowing round-trip (valid)\ncase class ConfigV1(timeout: Int)\ncase class ConfigV2(timeout: Long)\n\nval config1 = ConfigV1(30)\nval config2 = As[ConfigV1, ConfigV2].into(config1).right.get\nval back = As[ConfigV1, ConfigV2].from(config2).right.get\n\nassert(back == config1)\n\n// Test: Numeric narrowing round-trip (overflow failure)\nval config2Overflow = ConfigV2(3000000000L)\nassert(As[ConfigV1, ConfigV2].from(config2Overflow).isLeft)\n\n// Test: Collection type round-trip\ncase class Data1(items: List[Int])\ncase class Data2(items: Vector[Int])\n\nval data1 = Data1(List(1, 2, 3))\nval data2 = As[Data1, Data2].into(data1).right.get\nval backToData1 = As[Data1, Data2].from(data2).right.get\n\nassert(backToData1 == data1)\n\n// Test: Lossy collection round-trip (Set loses duplicates)\ncase class WithDuplicates(items: List[Int])\ncase class NoDuplicates(items: Set[Int])\n\nval original = WithDuplicates(List(1, 2, 2, 3))\nval asSet = As[WithDuplicates, NoDuplicates].into(original).right.get\nval backToList = As[WithDuplicates, NoDuplicates].from(asSet).right.get\n\nassert(asSet.items == Set(1, 2, 3))\nassert(backToList.items.toSet == Set(1, 2, 3)) // Order may differ, duplicates lost\n```\n\n#### Edge Case Tests\n\n```scala\n// Test: Empty case class\ncase class Empty()\nassert(Into[Empty, Empty].into(Empty()) == Right(Empty()))\n\n// Test: Large product (21 fields)\ncase class Large21(f1: Int, f2: Int, /* ... */, f21: Int)\ncase class Large21V2(f1: Long, f2: Long, /* ... */, f21: Long)\n// Must compile and work correctly\n\n// Test: Recursive type\ncase class Tree(value: Int, children: List[Tree])\ncase class TreeV2(value: Long, children: List[TreeV2])\nval tree = Tree(1, List(Tree(2, Nil), Tree(3, Nil)))\nval treeV2 = Into[Tree, TreeV2].into(tree).right.get\nassert(treeV2.value == 1L)\nassert(treeV2.children.head.value == 2L)\n\n// Test: Mutually recursive types\ncase class Node(id: Int, edges: List[Edge])\ncase class Edge(from: Int, to: Node)\ncase class NodeV2(id: Long, edges: List[EdgeV2])\ncase class EdgeV2(from: Long, to: NodeV2)\n// Must compile and handle mutual recursion\n```\n\n---\n\n## Implementation Signatures\n\n### Scala 3.5\n\n```scala\npackage zio.blocks.schema\n\nimport scala.quoted.*\n\n// One-way conversion\ntrait Into[-A, +B] {\n  def into(input: A): Either[SchemaError, B]\n}\n\nobject Into {\n  inline given [A, B]: Into[A, B] = ${intoMacro[A, B]}\n  \n  private def intoMacro[A: Type, B: Type](using Quotes): Expr[Into[A, B]] = {\n    import quotes.reflect.*\n    // Implementation:\n    // 1. Analyze types A and B\n    // 2. Build field mapping using disambiguation algorithm\n    // 3. Detect opaque types and generate validation calls\n    // 4. Generate narrowing validation for numeric coercions\n    // 5. Handle collection type conversions\n    // 6. Generate conversion code\n    // 7. Handle nested conversions recursively\n    ???\n  }\n}\n\n// Bidirectional conversion\ntrait As[A, B] {\n  def into(input: A): Either[SchemaError, B]\n  def from(input: B): Either[SchemaError, A]\n}\n\nobject As {\n  inline given [A, B]: As[A, B] = ${asMacro[A, B]}\n  \n  private def asMacro[A: Type, B: Type](using Quotes): Expr[As[A, B]] = {\n    import quotes.reflect.*\n    // Implementation:\n    // 1. Verify bidirectional compatibility\n    // 2. Check for default values (compile error if found)\n    // 3. Build bidirectional field mapping\n    // 4. Generate both conversion directions with validation\n    // 5. Ensure opaque type wrapping/unwrapping is symmetric\n    // 6. Handle numeric narrowing with runtime validation\n    // 7. Handle collection type conversions bidirectionally\n    ???\n  }\n}\n```\n\n### Scala 2.13\n\n```scala\npackage com.yourorg.schema\n\nimport scala.reflect.macros.blackbox.Context\nimport scala.language.experimental.macros\n\ncase class SchemaError(msg: String) {\n  // SchemaError is composable - can combine multiple errors\n}\n\n// One-way conversion\ntrait Into[-A, +B] {\n  def into(input: A): Either[SchemaError, B]\n}\n\nobject Into {\n  implicit def materializeInto[A, B]: Into[A, B] = macro materializeIntoImpl[A, B]\n  \n  def materializeIntoImpl[A: c.WeakTypeTag, B: c.WeakTypeTag](c: Context): c.Tree = {\n    import c.universe._\n    // Implementation:\n    // 1. Analyze types A and B using reflection\n    // 2. Build field mapping using disambiguation algorithm\n    // 3. Detect ZIO Prelude newtypes via AST pattern matching\n    // 4. Generate narrowing validation for numeric coercions\n    // 5. Handle collection type conversions\n    // 6. Generate conversion code using quasiquotes\n    // 7. Handle nested conversions recursively\n    ???\n  }\n}\n\n// Bidirectional conversion\ntrait As[A, B] {\n  def into(input: A): Either[SchemaError, B]\n  def from(input: B): Either[SchemaError, A]\n}\n\nobject As {\n  implicit def materializeAs[A, B]: As[A, B] = macro materializeAsImpl[A, B]\n  \n  def materializeAsImpl[A: c.WeakTypeTag, B: c.WeakTypeTag](c: Context): c.Tree = {\n    import c.universe._\n    // Implementation:\n    // 1. Verify bidirectional compatibility\n    // 2. Check for default values (compile error if found)\n    // 3. Build bidirectional field mapping\n    // 4. Generate both conversion directions with validation\n    // 5. Ensure newtype wrapping/unwrapping is symmetric\n    // 6. Handle numeric narrowing with runtime validation\n    // 7. Handle collection type conversions bidirectionally\n    ???\n  }\n}\n```\n\n---\n\n## Implementation Notes\n\n### Error Messages\n\nProvide helpful compile-time errors:\n\n```scala\n// Good error message example:\n\"\"\"\nCannot derive Into[PersonV1, PersonV2]: Ambiguous field mapping\n\n  PersonV1(width: Int, height: Int)\n  PersonV2(first: Int, second: Int)\n\nCannot determine unique mapping between fields of type Int.\nConsider:\n  - Using matching field names (width/height)\n  - Making field types unique\n  - Providing an explicit Into instance\n\"\"\"\n```\n\n### Cross-Version Compatibility\n\n- Share test cases between Scala 2 and Scala 3 where possible\n\n---\n\n## Deliverables\n\n1.  `Into[A, B]` trait and macro for Scala 2.13\n2.  `Into[A, B]` trait and macro for Scala 3.5\n3.  `As[A, B]` trait and macro for Scala 2.13\n4.  `As[A, B]` trait and macro for Scala 3.5\n5.  Comprehensive test suite\n6.  Documentation with examples\n",
                  "html_url": "https://github.com/zio/zio-blocks/issues/518"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#518",
              "body": "## Overview\n\nAdd two related type classes for type-safe schema evolution:\n\n1. **`Into[A, B]`**: One-way conversion from `A` to `B` with runtime validation\n2. **`As[A, B]`**: Bidirectional conversion establishing a partial equivalence between `A` and `B`\n\nBoth type classes are automatically derived via macros that intelligently map fields using names, positions, and types, with support for validation, coercion, and schema evolution patterns.\n\n---\n\n## Type Class Definitions\n\n### Into[A, B] - One-Way Conversion\n\n```scala\ntrait Into[-A, +B] {\n  def into(input: A): Either[SchemaError, B]\n}\n```\n\n**Purpose**: Convert from source type `A` to target type `B`, potentially failing at runtime when validation constraints cannot be satisfied.\n\n**Use Cases**:\n- Migrating between schema versions\n- Converting between equivalent representations\n- Validating conversions with opaque types\n- Transforming external data into internal models\n\n### As[A, B] - Bidirectional Conversion\n\n```scala\ntrait As[A, B] {\n  def into(input: A): Either[SchemaError, B]\n  def from(input: B): Either[SchemaError, A]\n}\n```\n\n**Purpose**: Establish a partial equivalence between types `A` and `B` where conversion can fail in either direction due to runtime validation.\n\n**Use Cases**:\n- Isomorphic schema versions\n- Equivalent representations (e.g., case class  tuple)\n- Reversible transformations with runtime validation\n- Round-trip serialization/deserialization\n\n**Relationship**: `As[A, B]` implies both `Into[A, B]` and `Into[B, A]` exist, but with the additional guarantee that both conversions use compatible mapping logic and can round-trip (subject to runtime validation).\n\n**Note**: `SchemaError` is composable, allowing multiple validation failures to be combined into a single error.\n\n---\n\n## Core Conversion Rules\n\n### Field Mapping Algorithm\n\nThe macro establishes field mappings using three attributes:\n1. **Field name** (identifier in source code)\n2. **Field position** (ordinal position in declaration)\n3. **Field type** (including coercible types)\n\n**Priority for disambiguation:**\n1. **Exact match**: Same name + same type\n2. **Name match with coercion**: Same name + coercible type\n3. **Unique type match**: Type appears only once in both source and target\n4. **Position + unique type**: Positional correspondence with unambiguous type\n5. **Fallback**: If no unambiguous mapping exists, derivation fails at compile-time\n\n### Mapping Examples\n\n#### Unambiguous by Unique Types\n```scala\ncase class Person(name: String, age: Int, active: Boolean)\ncase class User(username: String, yearsOld: Int, enabled: Boolean)\n\n// Success: Each type appears exactly once\n// Mapping: StringString, IntInt, BooleanBoolean\n```\n\n#### Unambiguous by Names\n```scala\ncase class Point(x: Int, y: Int)\ncase class Coord(y: Int, x: Int)\n\n// Success: Names uniquely identify despite reordering\n// Mapping: xx, yy\n```\n\n#### Ambiguous - Compile Failure\n```scala\ncase class Dimensions(width: Int, height: Int)\ncase class Measurements(first: Int, second: Int)\n\n// COMPILE ERROR: Cannot determine mapping\n// Both Int types, different names, ambiguous positional match\n```\n\n#### Disambiguation by Position (Tuples)\n```scala\ncase class RGB(r: Int, g: Int, b: Int)\ntype ColorTuple = (Int, Int, Int)\n\n// Success: Position disambiguates\n// Mapping: r_1, g_2, b_3\n```\n\n---\n\n## Supported Conversions\n\n### 1. Product Types (Records)\n\n#### Case Class to Case Class\n```scala\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(fullName: String, age: Int)\n\n// Success if 'name' is unique String in V1 and 'fullName' is unique String in V2\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30))\n// => Right(PersonV2(\"Alice\", 30))\n```\n\n#### Case Class to Tuple\n```scala\ncase class Point(x: Double, y: Double)\n\nInto[Point, (Double, Double)].into(Point(1.0, 2.0))\n// => Right((1.0, 2.0))\n```\n\n#### Tuple to Case Class\n```scala\ncase class RGB(red: Int, green: Int, blue: Int)\n\nInto[(Int, Int, Int), RGB].into((255, 128, 64))\n// => Right(RGB(255, 128, 64))\n```\n\n#### Tuple to Tuple\n```scala\nInto[(Int, String), (Long, String)].into((42, \"hello\"))\n// => Right((42L, \"hello\"))\n```\n\n### 2. Coproduct Types (Sum Types)\n\n#### Sealed Trait to Sealed Trait (by name)\n```scala\nsealed trait Color\ncase object Red extends Color\ncase object Blue extends Color\n\nsealed trait Hue\ncase object Red extends Hue\ncase object Blue extends Hue\n\nInto[Color, Hue].into(Red)\n// => Right(Red)\n```\n\n#### Sealed Trait to Sealed Trait (by signature)\n```scala\nsealed trait EventV1\ncase class Created(id: String, ts: Long) extends EventV1\ncase class Deleted(id: String) extends EventV1\n\nsealed trait EventV2\ncase class Spawned(id: String, ts: Long) extends EventV2\ncase class Removed(id: String) extends EventV2\n\nInto[EventV1, EventV2].into(Created(\"abc\", 123L))\n// => Right(Spawned(\"abc\", 123L))\n// Matched by constructor signature (String, Long)\n```\n\n#### Enum to Enum (Scala 3)\n```scala\nenum Status:\n  case Active, Inactive, Suspended\n\nenum State:\n  case Active, Inactive, Suspended\n\nInto[Status, State].into(Status.Active)\n// => Right(State.Active)\n```\n\n#### ADT with Payload Conversion\n```scala\nsealed trait ResultV1\ncase class Success(value: Int) extends ResultV1\ncase class Failure(msg: String) extends ResultV1\n\nsealed trait ResultV2\ncase class Success(value: Long) extends ResultV2\ncase class Failure(msg: String) extends ResultV2\n\nInto[ResultV1, ResultV2].into(Success(42))\n// => Right(Success(42L))\n// Field type coercion within matched case\n```\n\n### 3. Primitive Type Coercions\n\n#### Numeric Widening (Lossless)\n```scala\nInto[Byte, Short].into(42.toByte)    // => Right(42.toShort)\nInto[Short, Int].into(1000.toShort)  // => Right(1000)\nInto[Int, Long].into(100000)         // => Right(100000L)\nInto[Float, Double].into(3.14f)      // => Right(3.14)\n```\n\n#### Numeric Narrowing (with Runtime Validation)\n```scala\nInto[Long, Int].into(42L)\n// => Right(42)\n\nInto[Long, Int].into(3000000000L)\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n\nInto[Double, Float].into(3.14)\n// => Right(3.14f)\n\nInto[Double, Float].into(1e100)\n// => Left(SchemaError(\"Value 1.0E100 exceeds Float.MaxValue\"))\n```\n\n#### Collection Element Coercion\n```scala\nInto[List[Int], List[Long]].into(List(1, 2, 3))\n// => Right(List(1L, 2L, 3L))\n\nInto[Vector[Float], Vector[Double]].into(Vector(1.5f, 2.5f))\n// => Right(Vector(1.5, 2.5))\n\nInto[Set[Short], Set[Int]].into(Set(10.toShort, 20.toShort))\n// => Right(Set(10, 20))\n\nInto[List[Long], List[Int]].into(List(42L, 3000000000L))\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n```\n\n#### Nested Collection Coercion\n```scala\nInto[List[List[Int]], List[List[Long]]].into(List(List(1, 2), List(3, 4)))\n// => Right(List(List(1L, 2L), List(3L, 4L)))\n```\n\n#### Map Key/Value Coercion\n```scala\nInto[Map[Int, Float], Map[Long, Double]].into(Map(1 -> 1.5f, 2 -> 2.5f))\n// => Right(Map(1L -> 1.5, 2L -> 2.5))\n\nInto[Map[Long, String], Map[Int, String]].into(Map(42L -> \"a\", 3000000000L -> \"b\"))\n// => Left(SchemaError(\"Key 3000000000 exceeds Int.MaxValue\"))\n```\n\n#### Option Type Coercion\n```scala\nInto[Option[Int], Option[Long]].into(Some(42))\n// => Right(Some(42L))\n\nInto[Option[Int], Option[Long]].into(None)\n// => Right(None)\n\nInto[Option[Long], Option[Int]].into(Some(3000000000L))\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n```\n\n#### Either Type Coercion\n```scala\nInto[Either[String, Int], Either[String, Long]].into(Right(42))\n// => Right(Right(42L))\n\nInto[Either[Int, String], Either[Long, String]].into(Left(100))\n// => Right(Left(100L))\n```\n\n### 4. Collection Type Conversions\n\n#### Between Standard Collection Types\n```scala\nInto[List[Int], Vector[Int]].into(List(1, 2, 3))\n// => Right(Vector(1, 2, 3))\n\nInto[Vector[String], List[String]].into(Vector(\"a\", \"b\", \"c\"))\n// => Right(List(\"a\", \"b\", \"c\"))\n\nInto[Array[Int], List[Int]].into(Array(1, 2, 3))\n// => Right(List(1, 2, 3))\n\nInto[List[Int], Array[Int]].into(List(1, 2, 3))\n// => Right(Array(1, 2, 3))\n\nInto[Seq[Int], List[Int]].into(Seq(1, 2, 3))\n// => Right(List(1, 2, 3))\n\nInto[List[Int], Seq[Int]].into(List(1, 2, 3))\n// => Right(Seq(1, 2, 3))\n```\n\n#### Set Conversions (Order-Preserving Collections to Set)\n```scala\nInto[List[Int], Set[Int]].into(List(1, 2, 2, 3))\n// => Right(Set(1, 2, 3))\n// Note: Duplicates are removed\n\nInto[Vector[String], Set[String]].into(Vector(\"a\", \"b\", \"a\"))\n// => Right(Set(\"a\", \"b\"))\n```\n\n#### Set to Order-Preserving Collections\n```scala\nInto[Set[Int], List[Int]].into(Set(3, 1, 2))\n// => Right(List(1, 2, 3))\n// Note: Order is determined by Set's iteration order\n\nInto[Set[String], Vector[String]].into(Set(\"c\", \"a\", \"b\"))\n// => Right(Vector(\"a\", \"b\", \"c\"))\n```\n\n#### Combined Element and Collection Type Conversion\n```scala\nInto[List[Int], Vector[Long]].into(List(1, 2, 3))\n// => Right(Vector(1L, 2L, 3L))\n\nInto[Array[Short], List[Int]].into(Array(10.toShort, 20.toShort))\n// => Right(List(10, 20))\n\nInto[Set[Int], List[Long]].into(Set(1, 2, 3))\n// => Right(List(1L, 2L, 3L))\n```\n\n#### Nested Collection Type Conversions\n```scala\nInto[List[Vector[Int]], Vector[List[Long]]].into(List(Vector(1, 2), Vector(3, 4)))\n// => Right(Vector(List(1L, 2L), List(3L, 4L)))\n```\n\n### 5. Structural Types\n\n#### Structural Type Targets (Scala 3 with Selectable)\n```scala\ncase class Point(x: Int, y: Int)\ntype Coord = { def x: Int; def y: Int }\n\nInto[Point, Coord].into(Point(5, 10))\n// => Right(<structural instance with x=5, y=10>)\n```\n\n#### Structural Type Targets (Scala 2 with Dynamic)\n```scala\ncase class Person(name: String, age: Int)\ntype Record = { def name: String; def age: Int }\n\nInto[Person, Record].into(Person(\"Alice\", 30))\n// => Right(<dynamic instance with name=\"Alice\", age=30>)\n```\n\n#### Structural Type Sources\n```scala\ntype PersonLike = { def name: String; def age: Int }\ncase class User(name: String, age: Int)\n\nval personLike: PersonLike = ??? // some structural instance\nInto[PersonLike, User].into(personLike)\n// => Right(User(\"Alice\", 30))\n```\n\n### 6. Schema Evolution Patterns\n\n#### Adding Optional Fields\n```scala\ncase class UserV1(id: String, name: String)\ncase class UserV2(id: String, name: String, email: Option[String])\n\nInto[UserV1, UserV2].into(UserV1(\"123\", \"Alice\"))\n// => Right(UserV2(\"123\", \"Alice\", None))\n```\n\n#### Removing Optional Fields\n```scala\ncase class UserV2(id: String, name: String, email: Option[String])\ncase class UserV1(id: String, name: String)\n\nInto[UserV2, UserV1].into(UserV2(\"123\", \"Alice\", Some(\"alice@example.com\")))\n// => Right(UserV1(\"123\", \"Alice\"))\n// email field is dropped\n```\n\n#### Adding Required Fields with Defaults (Scala 3)\n```scala\ncase class ProductV1(name: String, price: Double)\ncase class ProductV2(name: String, price: Double, available: Boolean = true)\n\nInto[ProductV1, ProductV2].into(ProductV1(\"Widget\", 19.99))\n// => Right(ProductV2(\"Widget\", 19.99, true))\n```\n\n#### Field Reordering\n```scala\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(email: String, name: String, age: Int)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"alice@example.com\"))\n// => Right(PersonV2(\"alice@example.com\", \"Alice\", 30))\n```\n\n#### Field Renaming (with unique types)\n```scala\ncase class PersonV1(fullName: String, yearOfBirth: Int)\ncase class PersonV2(name: String, birthYear: Int)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice Smith\", 1990))\n// => Right(PersonV2(\"Alice Smith\", 1990))\n```\n\n#### Type Refinement\n```scala\ncase class ConfigV1(port: Int, timeout: Int)\ncase class ConfigV2(port: Int, timeout: Long)\n\nInto[ConfigV1, ConfigV2].into(ConfigV1(8080, 30))\n// => Right(ConfigV2(8080, 30L))\n```\n\n### 7. Nested Conversions\n\n#### Nested Products\n```scala\ncase class AddressV1(street: String, zip: Int)\ncase class PersonV1(name: String, address: AddressV1)\n\ncase class AddressV2(street: String, zip: Long)\ncase class PersonV2(name: String, address: AddressV2)\n\nInto[PersonV1, PersonV2].into(\n  PersonV1(\"Alice\", AddressV1(\"Main St\", 12345))\n)\n// => Right(PersonV2(\"Alice\", AddressV2(\"Main St\", 12345L)))\n```\n\n#### Nested Coproducts\n```scala\nsealed trait Inner\ncase class A(x: Int) extends Inner\ncase class B(y: String) extends Inner\n\nsealed trait Outer\ncase class Container(inner: Inner, label: String) extends Outer\n\n// Similar target types with Long instead of Int\nsealed trait InnerV2\ncase class A(x: Long) extends InnerV2\ncase class B(y: String) extends InnerV2\n\nsealed trait OuterV2\ncase class Container(inner: InnerV2, label: String) extends OuterV2\n\nInto[Outer, OuterV2].into(Container(A(42), \"test\"))\n// => Right(Container(A(42L), \"test\"))\n```\n\n#### Collections of Complex Types\n```scala\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(name: String, age: Long)\n\nInto[List[PersonV1], List[PersonV2]].into(\n  List(PersonV1(\"Alice\", 30), PersonV1(\"Bob\", 25))\n)\n// => Right(List(PersonV2(\"Alice\", 30L), PersonV2(\"Bob\", 25L)))\n```\n\n#### Nested Collections with Type Conversions\n```scala\ncase class DataV1(values: List[Vector[Int]])\ncase class DataV2(values: Vector[List[Long]])\n\nInto[DataV1, DataV2].into(\n  DataV1(List(Vector(1, 2), Vector(3, 4)))\n)\n// => Right(DataV2(Vector(List(1L, 2L), List(3L, 4L))))\n```\n\n---\n\n## Special Type Support\n\n### Opaque Types (Scala 3)\n\nOpaque types with validation are fully supported. The macro generates runtime validation calls.\n\n```scala\n// Definition with validation\nobject Domain:\n  opaque type Age = Int\n  object Age:\n    def apply(value: Int): Either[String, Age] =\n      if value >= 0 && value <= 150 then Right(value)\n      else Left(s\"Invalid age: $value\")\n    \n    def unsafe(value: Int): Age = value\n    \n    extension (age: Age)\n      def toInt: Int = age\n\n  opaque type Email = String\n  object Email:\n    def apply(value: String): Either[String, Email] =\n      if value.contains(\"@\") then Right(value)\n      else Left(s\"Invalid email: $value\")\n    \n    extension (email: Email)\n      def toString: String = email\n\nimport Domain._\n\n// Usage\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(name: String, age: Age, email: Email)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"alice@example.com\"))\n// => Right(PersonV2(\"Alice\", Age.unsafe(30), Email.unsafe(\"alice@example.com\")))\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", -5, \"alice@example.com\"))\n// => Left(SchemaError(\"Age validation failed: Invalid age: -5\"))\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"invalid\"))\n// => Left(SchemaError(\"Email validation failed: Invalid email: invalid\"))\n```\n\n**Macro Behavior**:\n- Detects opaque type companion objects with `apply(underlying): Either[_, OpaqueType]` method\n- Generates validation calls for each opaque type field\n- Accumulates all validation errors using `SchemaError` composition\n- Falls back to direct conversion if no validation method exists\n\n### Newtype Libraries (Scala 2)\n\n#### ZIO Prelude Newtypes (Built-in Support)\n\nThe macro includes hardcoded support for ZIO Prelude newtypes without requiring a compile-time dependency.\n\n```scala\nimport zio.prelude._\n\n// Definition with validation\nobject Domain {\n  object Age extends Subtype[Int] {\n    override def assertion = assert {\n      Assertion.between(0, 150)\n    }\n  }\n  type Age = Age.Type\n\n  object Email extends Newtype[String] {\n    override def assertion = assert {\n      Assertion.matches(\".*@.*\")\n    }\n  }\n  type Email = Email.Type\n}\n\nimport Domain._\n\n// Usage\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(name: String, age: Age, email: Email)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30, \"alice@example.com\"))\n// => Right(PersonV2(\"Alice\", Age(30), Email(\"alice@example.com\")))\n\nInto[PersonV1, PersonV2].into(PersonV1(\"Alice\", 200, \"invalid\"))\n// => Left(SchemaError(\"Validation failed: age: 200 is not between 0 and 150, email: invalid does not match .*@.*\"))\n```\n\n**Macro Detection** (no ZIO Prelude dependency required):\n```scala\n// The macro detects ZIO Prelude newtypes by checking:\n// 1. Type extends Newtype[A] or Subtype[A]\n// 2. Companion object exists\n// 3. Has apply/wrap method with validation\n\n// Low-level AST matching in Scala 2 macro:\ndef isZIONewtype(tpe: Type): Boolean = {\n  tpe.typeSymbol.fullName.startsWith(\"zio.prelude.Newtype\") ||\n  tpe.typeSymbol.fullName.startsWith(\"zio.prelude.Subtype\")\n}\n```\n\n#### Other Newtype Libraries\n\nFor other newtype libraries, users can provide explicit `Into` instances. The macro will use these instances when available.\n\n```scala\n// User-provided instance for their newtype library\nimplicit val stringToMyNewtype: Into[String, MyNewtype] = \n  new Into[String, MyNewtype] {\n    def into(s: String): Either[SchemaError, MyNewtype] =\n      MyNewtype.make(s).left.map(e => SchemaError(e.toString))\n  }\n\n// The macro will automatically use this instance\ncase class PersonV1(email: String)\ncase class PersonV2(email: MyNewtype)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"test@example.com\"))\n// Uses the user-provided instance automatically\n```\n\n### Validation Error Accumulation\n\nWhen multiple validations fail, all errors are accumulated using `SchemaError` composition:\n\n```scala\ncase class PersonV1(name: String, age: Int, email: String)\ncase class PersonV2(name: String, age: Age, email: Email)\n\nInto[PersonV1, PersonV2].into(PersonV1(\"\", -5, \"invalid\"))\n// => Left(SchemaError(...)) // Combined error containing all validation failures\n```\n\n---\n\n## As[A, B] Additional Requirements\n\nFor `As[A, B]` to be derivable, the bidirectional conversion must be **compatible**:\n\n### Compatibility Rules\n\n1. **Field mappings must be consistent**: The same field correspondence in both directions\n2. **Coercions must be invertible with runtime validation**: \n   -  `Int`  `Long` is valid (narrowing validated at runtime)\n   -  `Float`  `Double` is valid (narrowing validated at runtime)\n   -  All numeric coercions are valid with runtime checks\n3. **Optional fields**: \n   -  Can add optional fields in one direction (becomes `None` in reverse)\n   -  Can remove optional fields in one direction (value is dropped)\n4. **Default values**:\n   -  Cannot use default arguments (breaks round-trip guarantee)\n5. **Collection types**:\n   -  Can convert between different collection types\n   -   Set  List  Set may not preserve original order\n   -   List  Set  List loses duplicates\n\n### Valid As[A, B] Examples\n\n```scala\n// Valid: Same structure, different names\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(fullName: String, yearsOld: Int)\n\nAs[PersonV1, PersonV2].into(PersonV1(\"Alice\", 30))\n// => Right(PersonV2(\"Alice\", 30))\n\nAs[PersonV1, PersonV2].from(PersonV2(\"Bob\", 25))\n// => Right(PersonV1(\"Bob\", 25))\n```\n\n```scala\n// Valid: Case class  Tuple\ncase class Point(x: Double, y: Double)\n\nAs[Point, (Double, Double)].into(Point(1.0, 2.0))\n// => Right((1.0, 2.0))\n\nAs[Point, (Double, Double)].from((3.0, 4.0))\n// => Right(Point(3.0, 4.0))\n```\n\n```scala\n// Valid: Numeric coercion with runtime validation\ncase class ConfigV1(timeout: Int)\ncase class ConfigV2(timeout: Long)\n\nAs[ConfigV1, ConfigV2].into(ConfigV1(30))\n// => Right(ConfigV2(30L))\n\nAs[ConfigV1, ConfigV2].from(ConfigV2(30L))\n// => Right(ConfigV1(30))\n\nAs[ConfigV1, ConfigV2].from(ConfigV2(3000000000L))\n// => Left(SchemaError(\"Value 3000000000 exceeds Int.MaxValue\"))\n```\n\n```scala\n// Valid: Opaque types (reversible via unwrap)\ncase class PersonRaw(name: String, age: Int)\ncase class PersonValidated(name: String, age: Age)\n\nAs[PersonRaw, PersonValidated].into(PersonRaw(\"Alice\", 30))\n// => Right(PersonValidated(\"Alice\", Age.unsafe(30)))\n\nAs[PersonRaw, PersonValidated].from(PersonValidated(\"Bob\", Age.unsafe(25)))\n// => Right(PersonRaw(\"Bob\", 25))\n\nAs[PersonRaw, PersonValidated].into(PersonRaw(\"Charlie\", -5))\n// => Left(SchemaError(\"Age validation failed: Invalid age: -5\"))\n```\n\n```scala\n// Valid: Collection type conversions\ncase class DataV1(items: List[Int])\ncase class DataV2(items: Vector[Int])\n\nAs[DataV1, DataV2].into(DataV1(List(1, 2, 3)))\n// => Right(DataV2(Vector(1, 2, 3)))\n\nAs[DataV1, DataV2].from(DataV2(Vector(4, 5, 6)))\n// => Right(DataV1(List(4, 5, 6)))\n```\n\n```scala\n// Valid: Optional field in one direction\ncase class UserV1(id: String, name: String)\ncase class UserV2(id: String, name: String, email: Option[String])\n\nAs[UserV1, UserV2].into(UserV1(\"123\", \"Alice\"))\n// => Right(UserV2(\"123\", \"Alice\", None))\n\nAs[UserV1, UserV2].from(UserV2(\"456\", \"Bob\", Some(\"bob@example.com\")))\n// => Right(UserV1(\"456\", \"Bob\"))\n// email is dropped in reverse direction\n```\n\n### Non-Ideal As[A, B] Examples (Valid but Lossy)\n\n```scala\n// Valid but lossy: List with duplicates  Set  List\ncase class DataV1(values: List[Int])\ncase class DataV2(values: Set[Int])\n\nAs[DataV1, DataV2].into(DataV1(List(1, 2, 2, 3)))\n// => Right(DataV2(Set(1, 2, 3)))\n\nAs[DataV1, DataV2].from(DataV2(Set(1, 2, 3)))\n// => Right(DataV1(List(1, 2, 3)))\n// Original duplicates are lost, but conversion is valid\n```\n\n```scala\n// Valid but lossy: Set  List  Set (order may change)\ncase class DataV1(values: Set[Int])\ncase class DataV2(values: List[Int])\n\nval original = DataV1(Set(3, 1, 2))\nval converted = As[DataV1, DataV2].into(original).right.get\n// converted.values might be List(1, 2, 3) depending on Set iteration order\n\nval roundTrip = As[DataV1, DataV2].from(converted).right.get\n// roundTrip.values == Set(1, 2, 3) - same elements, possibly different internal order\n```\n\n### Invalid As[A, B] Examples\n\n```scala\n// Invalid: Default values break round-trip guarantee\ncase class ProductV1(name: String, price: Double)\ncase class ProductV2(name: String, price: Double, taxable: Boolean = true)\n\n// COMPILE ERROR: Cannot derive As[ProductV1, ProductV2]\n// Reason: Default value for 'taxable' cannot be recovered in reverse direction\n// (We can't distinguish between explicitly set 'true' and default 'true')\n```\n\n---\n\n## Testing Requirements\n\n### Test Matrix Dimensions\n\n1. **Type Combinations** (both `Into` and `As`)\n   - Primitive  Primitive (all coercion pairs, including narrowing)\n   - Product  Product (case classes)\n   - Product  Tuple\n   - Tuple  Product\n   - Tuple  Tuple\n   - Coproduct  Coproduct (sealed traits, enums)\n   - Collection[A]  Collection[B] (List, Vector, Set, Map, Option, Either, Array, Seq)\n   - Collection type conversions (List  Vector  Set  Array  Seq)\n   - Nested conversions\n   - Structural types\n\n2. **Disambiguation Scenarios**\n   - Unique types (names irrelevant)\n   - Matching names (types irrelevant with coercion)\n   - Duplicate types with name disambiguation\n   - Duplicate types with position disambiguation\n   - Ambiguous cases (must fail at compile-time)\n\n3. **Schema Evolution**\n   - Field reordering\n   - Field renaming (with unique types)\n   - Adding optional fields\n   - Removing optional fields\n   - Type refinement (Int  Long, with narrowing validation)\n   - Adding default values (Scala 3)\n\n4. **Validation** (Scala 3 opaque types)\n   - Valid values pass through\n   - Invalid values produce SchemaError\n   - Multiple validation failures accumulate\n   - Nested validation in products\n   - Validation in coproduct cases\n   - Validation in collections\n   - Narrowing conversions (Long  Int with overflow check)\n\n5. **Validation** (Scala 2 ZIO Prelude newtypes)\n   - Newtype validation success\n   - Newtype validation failure\n   - Subtype validation with assertions\n   - Multiple newtype fields\n\n6. **Collection Type Conversions**\n   - List  Vector\n   - List  Array\n   - List  Set (with duplicate handling)\n   - List  Seq\n   - Vector  Set\n   - Array  Vector\n   - All combinations with element type coercion\n   - Nested collection type conversions\n\n7. **Runtime Validation** (for `As[A, B]`)\n   - Numeric narrowing validation\n   - Round-trip with valid narrowing\n   - Round-trip failure with overflow\n   - Collection conversions with duplicates\n   - Optional field round-trips\n\n8. **Error Cases**\n   - Ambiguous field mapping (compile error)\n   - Ambiguous case mapping (compile error)\n   - Default value in `As` (compile error)\n   - Runtime validation failures\n   - Type mismatch (compile error)\n   - Overflow in narrowing conversions\n\n9. **Edge Cases**\n   - Empty case classes\n   - Single-field case classes\n   - Case objects\n   - Sealed traits with case objects only\n   - Deeply nested structures (5+ levels)\n   - Large products (20+ fields)\n   - Large coproducts (20+ cases)\n   - Recursive types (e.g., `case class Tree(value: Int, children: List[Tree])`)\n   - Mutually recursive types\n\n### Test Organization\n\n```\nsrc/test/scala/\n  into/\n    products/\n      CaseClassToCaseClassSpec.scala\n      CaseClassToTupleSpec.scala\n      TupleToCaseClassSpec.scala\n      TupleToTupleSpec.scala\n      FieldReorderingSpec.scala\n      FieldRenamingSpec.scala\n      NestedProductsSpec.scala\n    coproducts/\n      SealedTraitToSealedTraitSpec.scala\n      EnumToEnumSpec.scala (Scala 3 only)\n      CaseMatchingSpec.scala\n      SignatureMatchingSpec.scala\n      AmbiguousCaseSpec.scala\n      NestedCoproductsSpec.scala\n    primitives/\n      NumericWideningSpec.scala\n      NumericNarrowingSpec.scala\n      CollectionCoercionSpec.scala\n      OptionCoercionSpec.scala\n      EitherCoercionSpec.scala\n      NestedCollectionSpec.scala\n    collections/\n      ListToVectorSpec.scala\n      ListToSetSpec.scala\n      VectorToArraySpec.scala\n      CollectionTypeWithCoercionSpec.scala\n      NestedCollectionTypeSpec.scala\n      SetDuplicateHandlingSpec.scala\n    structural/\n      StructuralTypeTargetSpec.scala (Scala 3 Selectable)\n      DynamicTypeTargetSpec.scala (Scala 2 Dynamic)\n      StructuralTypeSourceSpec.scala\n    validation/\n      OpaqueTypeValidationSpec.scala (Scala 3 only)\n      ZIONewtypeValidationSpec.scala (Scala 2 only)\n      ValidationErrorAccumulationSpec.scala\n      NestedValidationSpec.scala\n      NarrowingValidationSpec.scala\n    evolution/\n      AddOptionalFieldSpec.scala\n      RemoveOptionalFieldSpec.scala\n      TypeRefinementSpec.scala\n      AddDefaultFieldSpec.scala (Scala 3 only)\n    disambiguation/\n      UniqueTypeDisambiguationSpec.scala\n      NameDisambiguationSpec.scala\n      PositionDisambiguationSpec.scala\n      AmbiguousCompileErrorSpec.scala\n    edge/\n      EmptyProductSpec.scala\n      SingleFieldSpec.scala\n      CaseObjectSpec.scala\n      DeepNestingSpec.scala\n      LargeProductSpec.scala\n      LargeCoproductSpec.scala\n      RecursiveTypeSpec.scala\n      MutuallyRecursiveTypeSpec.scala\n  \n  as/\n    reversibility/\n      RoundTripProductSpec.scala\n      RoundTripCoproductSpec.scala\n      RoundTripTupleSpec.scala\n      RoundTripCollectionTypeSpec.scala\n      OpaqueTypeRoundTripSpec.scala\n      NumericNarrowingRoundTripSpec.scala\n      OptionalFieldRoundTripSpec.scala\n    validation/\n      OverflowDetectionSpec.scala\n      NarrowingFailureSpec.scala\n      CollectionLossyConversionSpec.scala\n    compile_errors/\n      DefaultValueSpec.scala\n    (similar structure to into/ for applicable tests)\n```\n\n### Specific Test Cases\n\n#### Disambiguation Tests\n\n```scala\n// Test: Unique types make names irrelevant\ncase class A(x: String, y: Int, z: Boolean)\ncase class B(a: String, b: Int, c: Boolean)\nassert(Into[A, B].into(A(\"test\", 42, true)) == Right(B(\"test\", 42, true)))\n\n// Test: Names disambiguate duplicate types\ncase class Point(x: Int, y: Int)\ncase class Coord(y: Int, x: Int)\nassert(Into[Point, Coord].into(Point(1, 2)) == Right(Coord(2, 1)))\n\n// Test: Ambiguous mapping fails at compile-time\ncase class Dim(width: Int, height: Int)\ncase class Measure(first: Int, second: Int)\n// Must not compile: Into[Dim, Measure]\nassertDoesNotCompile(\"Into[Dim, Measure]\")\n```\n\n#### Numeric Narrowing Validation Tests\n\n```scala\n// Test: Valid narrowing conversion\ncase class V1(value: Long)\ncase class V2(value: Int)\nassert(Into[V1, V2].into(V1(42L)) == Right(V2(42)))\n\n// Test: Invalid narrowing (overflow)\nassert(Into[V1, V2].into(V1(3000000000L)).isLeft)\n\n// Test: Narrowing in collections\ncase class Data1(values: List[Long])\ncase class Data2(values: List[Int])\nassert(Into[Data1, Data2].into(Data1(List(1L, 2L, 3L))) == Right(Data2(List(1, 2, 3))))\nassert(Into[Data1, Data2].into(Data1(List(1L, 3000000000L))).isLeft)\n```\n\n#### Collection Type Conversion Tests\n\n```scala\n// Test: List to Vector\ncase class A(items: List[Int])\ncase class B(items: Vector[Int])\nassert(Into[A, B].into(A(List(1, 2, 3))) == Right(B(Vector(1, 2, 3))))\n\n// Test: List to Set (removes duplicates)\ncase class C(items: List[Int])\ncase class D(items: Set[Int])\nassert(Into[C, D].into(C(List(1, 2, 2, 3))) == Right(D(Set(1, 2, 3))))\n\n// Test: Vector to Array\ncase class E(items: Vector[String])\ncase class F(items: Array[String])\nval result = Into[E, F].into(E(Vector(\"a\", \"b\")))\nassert(result.isRight)\nassert(result.right.get.items.sameElements(Array(\"a\", \"b\")))\n\n// Test: Combined collection and element coercion\ncase class G(items: List[Int])\ncase class H(items: Vector[Long])\nassert(Into[G, H].into(G(List(1, 2, 3))) == Right(H(Vector(1L, 2L, 3L))))\n```\n\n#### Validation Tests (Scala 3)\n\n```scala\n// Test: Valid opaque type conversion\ncase class Raw(age: Int)\ncase class Validated(age: Age)\nassert(Into[Raw, Validated].into(Raw(30)).isRight)\n\n// Test: Invalid opaque type conversion\nassert(Into[Raw, Validated].into(Raw(-5)).isLeft)\n\n// Test: Multiple validation failures accumulate\ncase class RawPerson(age: Int, email: String)\ncase class ValidPerson(age: Age, email: Email)\nval result = Into[RawPerson, ValidPerson].into(RawPerson(-5, \"invalid\"))\nassert(result.isLeft)\n// SchemaError contains both validation failures\n```\n\n#### Round-Trip Tests (As)\n\n```scala\n// Test: Case class round-trip\ncase class PersonV1(name: String, age: Int)\ncase class PersonV2(fullName: String, yearsOld: Int)\n\nval v1 = PersonV1(\"Alice\", 30)\nval v2 = As[PersonV1, PersonV2].into(v1).right.get\nval roundTrip = As[PersonV1, PersonV2].from(v2).right.get\n\nassert(roundTrip == v1)\n\n// Test: Numeric narrowing round-trip (valid)\ncase class ConfigV1(timeout: Int)\ncase class ConfigV2(timeout: Long)\n\nval config1 = ConfigV1(30)\nval config2 = As[ConfigV1, ConfigV2].into(config1).right.get\nval back = As[ConfigV1, ConfigV2].from(config2).right.get\n\nassert(back == config1)\n\n// Test: Numeric narrowing round-trip (overflow failure)\nval config2Overflow = ConfigV2(3000000000L)\nassert(As[ConfigV1, ConfigV2].from(config2Overflow).isLeft)\n\n// Test: Collection type round-trip\ncase class Data1(items: List[Int])\ncase class Data2(items: Vector[Int])\n\nval data1 = Data1(List(1, 2, 3))\nval data2 = As[Data1, Data2].into(data1).right.get\nval backToData1 = As[Data1, Data2].from(data2).right.get\n\nassert(backToData1 == data1)\n\n// Test: Lossy collection round-trip (Set loses duplicates)\ncase class WithDuplicates(items: List[Int])\ncase class NoDuplicates(items: Set[Int])\n\nval original = WithDuplicates(List(1, 2, 2, 3))\nval asSet = As[WithDuplicates, NoDuplicates].into(original).right.get\nval backToList = As[WithDuplicates, NoDuplicates].from(asSet).right.get\n\nassert(asSet.items == Set(1, 2, 3))\nassert(backToList.items.toSet == Set(1, 2, 3)) // Order may differ, duplicates lost\n```\n\n#### Edge Case Tests\n\n```scala\n// Test: Empty case class\ncase class Empty()\nassert(Into[Empty, Empty].into(Empty()) == Right(Empty()))\n\n// Test: Large product (21 fields)\ncase class Large21(f1: Int, f2: Int, /* ... */, f21: Int)\ncase class Large21V2(f1: Long, f2: Long, /* ... */, f21: Long)\n// Must compile and work correctly\n\n// Test: Recursive type\ncase class Tree(value: Int, children: List[Tree])\ncase class TreeV2(value: Long, children: List[TreeV2])\nval tree = Tree(1, List(Tree(2, Nil), Tree(3, Nil)))\nval treeV2 = Into[Tree, TreeV2].into(tree).right.get\nassert(treeV2.value == 1L)\nassert(treeV2.children.head.value == 2L)\n\n// Test: Mutually recursive types\ncase class Node(id: Int, edges: List[Edge])\ncase class Edge(from: Int, to: Node)\ncase class NodeV2(id: Long, edges: List[EdgeV2])\ncase class EdgeV2(from: Long, to: NodeV2)\n// Must compile and handle mutual recursion\n```\n\n---\n\n## Implementation Signatures\n\n### Scala 3.5\n\n```scala\npackage zio.blocks.schema\n\nimport scala.quoted.*\n\n// One-way conversion\ntrait Into[-A, +B] {\n  def into(input: A): Either[SchemaError, B]\n}\n\nobject Into {\n  inline given [A, B]: Into[A, B] = ${intoMacro[A, B]}\n  \n  private def intoMacro[A: Type, B: Type](using Quotes): Expr[Into[A, B]] = {\n    import quotes.reflect.*\n    // Implementation:\n    // 1. Analyze types A and B\n    // 2. Build field mapping using disambiguation algorithm\n    // 3. Detect opaque types and generate validation calls\n    // 4. Generate narrowing validation for numeric coercions\n    // 5. Handle collection type conversions\n    // 6. Generate conversion code\n    // 7. Handle nested conversions recursively\n    ???\n  }\n}\n\n// Bidirectional conversion\ntrait As[A, B] {\n  def into(input: A): Either[SchemaError, B]\n  def from(input: B): Either[SchemaError, A]\n}\n\nobject As {\n  inline given [A, B]: As[A, B] = ${asMacro[A, B]}\n  \n  private def asMacro[A: Type, B: Type](using Quotes): Expr[As[A, B]] = {\n    import quotes.reflect.*\n    // Implementation:\n    // 1. Verify bidirectional compatibility\n    // 2. Check for default values (compile error if found)\n    // 3. Build bidirectional field mapping\n    // 4. Generate both conversion directions with validation\n    // 5. Ensure opaque type wrapping/unwrapping is symmetric\n    // 6. Handle numeric narrowing with runtime validation\n    // 7. Handle collection type conversions bidirectionally\n    ???\n  }\n}\n```\n\n### Scala 2.13\n\n```scala\npackage com.yourorg.schema\n\nimport scala.reflect.macros.blackbox.Context\nimport scala.language.experimental.macros\n\ncase class SchemaError(msg: String) {\n  // SchemaError is composable - can combine multiple errors\n}\n\n// One-way conversion\ntrait Into[-A, +B] {\n  def into(input: A): Either[SchemaError, B]\n}\n\nobject Into {\n  implicit def materializeInto[A, B]: Into[A, B] = macro materializeIntoImpl[A, B]\n  \n  def materializeIntoImpl[A: c.WeakTypeTag, B: c.WeakTypeTag](c: Context): c.Tree = {\n    import c.universe._\n    // Implementation:\n    // 1. Analyze types A and B using reflection\n    // 2. Build field mapping using disambiguation algorithm\n    // 3. Detect ZIO Prelude newtypes via AST pattern matching\n    // 4. Generate narrowing validation for numeric coercions\n    // 5. Handle collection type conversions\n    // 6. Generate conversion code using quasiquotes\n    // 7. Handle nested conversions recursively\n    ???\n  }\n}\n\n// Bidirectional conversion\ntrait As[A, B] {\n  def into(input: A): Either[SchemaError, B]\n  def from(input: B): Either[SchemaError, A]\n}\n\nobject As {\n  implicit def materializeAs[A, B]: As[A, B] = macro materializeAsImpl[A, B]\n  \n  def materializeAsImpl[A: c.WeakTypeTag, B: c.WeakTypeTag](c: Context): c.Tree = {\n    import c.universe._\n    // Implementation:\n    // 1. Verify bidirectional compatibility\n    // 2. Check for default values (compile error if found)\n    // 3. Build bidirectional field mapping\n    // 4. Generate both conversion directions with validation\n    // 5. Ensure newtype wrapping/unwrapping is symmetric\n    // 6. Handle numeric narrowing with runtime validation\n    // 7. Handle collection type conversions bidirectionally\n    ???\n  }\n}\n```\n\n---\n\n## Implementation Notes\n\n### Error Messages\n\nProvide helpful compile-time errors:\n\n```scala\n// Good error message example:\n\"\"\"\nCannot derive Into[PersonV1, PersonV2]: Ambiguous field mapping\n\n  PersonV1(width: Int, height: Int)\n  PersonV2(first: Int, second: Int)\n\nCannot determine unique mapping between fields of type Int.\nConsider:\n  - Using matching field names (width/height)\n  - Making field types unique\n  - Providing an explicit Into instance\n\"\"\"\n```\n\n### Cross-Version Compatibility\n\n- Share test cases between Scala 2 and Scala 3 where possible\n\n---\n\n## Deliverables\n\n1.  `Into[A, B]` trait and macro for Scala 2.13\n2.  `Into[A, B]` trait and macro for Scala 3.5\n3.  `As[A, B]` trait and macro for Scala 2.13\n4.  `As[A, B]` trait and macro for Scala 3.5\n5.  Comprehensive test suite\n6.  Documentation with examples\n",
              "url": "https://github.com/zio/zio-blocks/issues/518",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#517",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-12T11:36:03.470Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:36:03.470Z",
            "created_at": "2026-01-12T11:36:03.470Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#517",
              "status": "open",
              "type": "issue",
              "number": 517,
              "title": "Add structural schemas",
              "source": {
                "data": {
                  "id": "source-ZIO#517",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add structural schemas",
                  "body": "# Structural Type Schema Support\n\n## Overview\n\nExtend `Schema[A]` to support structural types, enabling schema derivation for types defined by their structure rather than their nominal identity. This allows for duck-typed schema validation and conversion between nominal and structural representations.\n\n## Core Concepts\n\n### Direct Structural Schema Derivation\n\nSchemas can be derived directly for structural types:\n\n```scala\n// Scala 3\ntype Person = { def name: String; def age: Int }\nval schema = Schema.derived[Person]\n\n// Scala 2\ntype Person = { def name: String; def age: Int }\nval schema = Schema.derived[Person]\n```\n\n**Note**: Both Scala 2 and Scala 3 use `def` for uniformity, even though Scala 3 supports `val` in structural types.\n\n**Implementation**: Schemas have bindings, which allow construction / deconstruction of values. Values for structural types are backed by:\n- **Scala 3**: `Selectable` \n- **Scala 2**: `Dynamic`\n\n### Nominal to Structural Conversion\n\nConvert nominal type schemas to their structural equivalents:\n\n```scala\ncase class Person(name: String, age: Int)\n\n// Get the structural schema corresponding to Person's shape\nval structuralSchema: Schema[{ def name: String; def age: Int }] = \n  Schema.derived[Person].structural\n```\n\n### Schema API Extension\n\n```scala\ncase class Schema[A](/* existing fields */) {\n  /**\n   * Convert this schema to a structural type schema.\n   * \n   * The structural type represents the \"shape\" of A without its nominal identity.\n   * This enables duck typing and structural validation.\n   * \n   * @param toStructural Macro-generated conversion to structural representation\n   * @return Schema for the structural type corresponding to A\n   */\n  def structural(implicit toStructural: ToStructural[A]): Schema[toStructural.StructuralType] = \n    toStructural.apply(this)\n}\n\n/**\n * Type class for converting nominal schemas to structural schemas.\n * Generated by macro for all supported types. Macro fails if a structural\n * type cannot be generated.\n *\n * NOTE: This approach has to be tested to yield inferrable types, and revised\n * if necessary. Inferrable types (from calling Schema#structural) are a must-have.\n */\ntrait ToStructural[A] {\n  type StructuralType\n  def apply(schema: Schema[A]): Schema[StructuralType]\n}\n\nobject ToStructural {\n  type Aux[A, S] = ToStructural[A] { type StructuralType = S }\n  \n  // Scala 3\n  transparent inline given [A]: ToStructural[A] = ${toStructuralMacro[A]}\n  \n  // Scala 2\n  implicit def materialize[A]: ToStructural[A] = macro toStructuralImpl[A]\n}\n```\n\n---\n\n## Examples\n\n### 1. Simple Product Types\n\n#### Case Class to Structural\n\n```scala\n// Both Scala 2 and Scala 3\ncase class Person(name: String, age: Int)\n\n// Original nominal schema\nval nominalSchema: Schema[Person] = Schema.derived[Person]\n\n// Convert to structural\nval structuralSchema: Schema[{ def name: String; def age: Int }] = \n  nominalSchema.structural\n\n// Direct structural derivation (equivalent)\nval directStructural: Schema[{ def name: String; def age: Int }] = \n  Schema.derived[{ def name: String; def age: Int }]\n```\n\n### 2. Nested Structures\n\n```scala\ncase class Address(street: String, city: String, zip: Int)\ncase class Person(name: String, age: Int, address: Address)\n\nval structuralSchema = Schema.derived[Person].structural\n// Type: Schema[{ \n//   def name: String\n//   def age: Int\n//   def address: { def street: String; def city: String; def zip: Int }\n// }]\n```\n\n### 3. Collections and Options\n\n```scala\ncase class Team(name: String, members: List[String], leader: Option[String])\n\nval structuralSchema = Schema.derived[Team].structural\n// Type: Schema[{\n//   def name: String\n//   def members: List[String]\n//   def leader: Option[String]\n// }]\n```\n\n### 4. Tuples to Structural\n\n```scala\n// Tuples can be converted to structural types\nval tupleSchema: Schema[(String, Int, Boolean)] = Schema.derived[(String, Int, Boolean)]\n\nval structuralSchema = tupleSchema.structural\n// Type: Schema[{ def _1: String; def _2: Int; def _3: Boolean }]\n```\n\n### 5. Sum Types (Sealed Traits) - Scala 3 Only\n\nSealed traits become union types of structural representations, with tag information stored at the type level:\n\n```scala\n// Scala 3 only\nsealed trait Result\ncase class Success(value: Int) extends Result\ncase class Failure(error: String) extends Result\n\nval structuralSchema = Schema.derived[Result].structural\n// Type: Schema[\n//   { type Tag = \"Success\"; def value: Int } | { type Tag = \"Failure\"; def error: String }\n// ]\n```\n\n**Note**: Sum type to structural conversion is **not supported in Scala 2** because it requires union types. Attempting to call `.structural` on a sealed trait schema in Scala 2 will result in a compile-time error.\n\n### 6. Enums (Scala 3 Only)\n\n```scala\nenum Status:\n  case Active, Inactive, Suspended\n\nval structuralSchema = Schema.derived[Status].structural\n// Type: Schema[{type Tag = \"Active\"} | {type Tag = \"Inactive\"} | {type Tag = \"Suspended\"}]\n```\n\n### 7. Opaque Types (Scala 3)\n\n```scala\nopaque type UserId = String\nobject UserId:\n  def apply(value: String): Either[String, UserId] = \n    if value.nonEmpty then Right(value) else Left(\"Empty user ID\")\n\ncase class User(id: UserId, name: String)\n\nval structuralSchema = Schema.derived[User].structural\n// Type: Schema[{ def id: String; def name: String }]\n// Opaque type is unwrapped to its underlying type\n```\n\n### 8. Bidirectional Conversion\n\nStructural schemas work seamlessly with `Into`/`As` (if this ticket is implemented **after** that ticket):\n\n```scala\ncase class Person(name: String, age: Int)\n\nval structuralSchema = Schema.derived[Person].structural\n\n// Create structural value (Scala 3)\nval structuralPerson = new Selectable {\n  def selectDynamic(field: String): Any = field match {\n    case \"name\" => \"Alice\"\n    case \"age\" => 30\n  }\n}\n\n// Convert structural to nominal using Into\nval person: Either[SchemaError, Person] = \n  Into[{ def name: String; def age: Int }, Person].into(structuralPerson)\n// => Right(Person(\"Alice\", 30))\n\n// Convert nominal to structural\nval backToStructural: Either[SchemaError, { def name: String; def age: Int }] = \n  Into[Person, { def name: String; def age: Int }].into(Person(\"Bob\", 25))\n```\n\n### 9. Empty and Single-Field Products\n\n```scala\n// Empty case class\ncase class Empty()\nval emptyStructural = Schema.derived[Empty].structural\n// Type: Schema[{}]\n\n// Single field\ncase class Id(value: String)\nval idStructural = Schema.derived[Id].structural\n// Type: Schema[{ def value: String }]\n```\n\n### 10. Large Products\n\n```scala\ncase class LargeRecord(\n  f1: String, f2: Int, f3: Boolean, f4: Double, f5: Long,\n  f6: String, f7: Int, f8: Boolean, f9: Double, f10: Long,\n  f11: String, f12: Int, f13: Boolean, f14: Double, f15: Long,\n  f16: String, f17: Int, f18: Boolean, f19: Double, f20: Long,\n  f21: String\n)\n\nval structuralSchema = Schema.derived[LargeRecord].structural\n// Type: Schema[{\n//   def f1: String; def f2: Int; def f3: Boolean; ...\n//   def f21: String\n// }]\n```\n\n---\n\n## Type Name Handling\n\n### Current Limitation\n\nSchemas currently use `TypeName[A]` to identify types. Structural types don't have meaningful nominal type names, which creates a mismatch.\n\n### Temporary Solution\n\nUntil `TypeName[A]` is replaced with `TypeId[A]` (see issue #471), structural schemas will use a normalized string representation of the structural type as a fake type name:\n\n```scala\ncase class Person(name: String, age: Int)\n\nval schema = Schema.derived[Person]\nschema.typeName // => TypeName for \"Person\"\n\nval structural = schema.structural\nstructural.typeName // => TypeName for \"{age:Int,name:String}\"\n// Normalized: fields sorted alphabetically, types fully qualified\n```\n\n### Normalization Rules\n\n1. **Field ordering**: Alphabetical by field name\n2. **Type qualification**: Use simple names for primitives and standard library types\n3. **Whitespace**: No whitespace in generated names\n4. **Collections**: Standard notation (e.g., `List[Int]`)\n5. **Options**: Explicit `Option[T]` notation\n6. **Nested structures**: Recursive application of rules\n7. **Deterministic**: Same structure always produces same normalized name\n\n### Examples\n\n```scala\n// Simple product\ncase class Point(x: Int, y: Int)\nSchema.derived[Point].structural.typeName \n// => \"{x:Int,y:Int}\"\n\n// Nested product\ncase class Address(street: String, zip: Int)\ncase class Person(name: String, address: Address)\nSchema.derived[Person].structural.typeName\n// => \"{address:{street:String,zip:Int},name:String}\"\n\n// With collections\ncase class Team(name: String, members: List[String])\nSchema.derived[Team].structural.typeName\n// => \"{members:List[String],name:String}\"\n\n// Union type (Scala 3)\nsealed trait Result\ncase class Success(value: Int) extends Result\ncase class Failure(error: String) extends Result\nSchema.derived[Result].structural.typeName\n// => \"{error:String}|{value:Int}\"\n```\n\n### Future: TypeId[A]\n\nThe upcoming `TypeId[A]` replacement will properly handle structural types by representing them by their structure rather than a string-based hack. See issue #471 for details.\n\n---\n\n## Limitations and Edge Cases\n\n### 1. Generic Types\n\n**Behavior depends on existing Schema derivation support for generic types.**\n\nIf `Schema.derived[Container[Int]]` already works, then structural conversion should work:\n\n```scala\ncase class Container[T](value: T)\n\n// If this works:\nval schema = Schema.derived[Container[Int]]\n\n// Then this should work:\nval structural = schema.structural\n// Type: Schema[{ def value: Int }]\n```\n\nIf generic type derivation is not currently supported, this ticket **does not require implementing it**. The macro should produce a clear compile-time error for unsupported generic types.\n\n### 2. Recursive Types\n\nRecursive types will **fail at compile-time** because Scala does not support infinite types:\n\n```scala\ncase class Tree(value: Int, children: List[Tree])\n\n// This will FAIL at compile-time:\nval structural = Schema.derived[Tree].structural\n// Compile error: Cannot generate infinite structural type\n\n// The structural type would need to be:\n// { def value: Int; def children: List[{ def value: Int; def children: List[...] }] }\n// which is infinite and unsupported\n```\n\nThe macro must detect recursive types and produce a helpful error message:\n\n```\nCompile error: Cannot generate structural type for recursive type Tree.\nStructural types cannot represent recursive structures.\n```\n\n### 3. Mutually Recursive Types\n\nSimilarly, mutually recursive types are unsupported:\n\n```scala\ncase class Node(id: Int, edges: List[Edge])\ncase class Edge(from: Int, to: Node)\n\n// This will FAIL at compile-time:\nval nodeStructural = Schema.derived[Node].structural\n// Compile error: Cannot generate structural type for mutually recursive types\n```\n\n### 4. Sum Types in Scala 2\n\nSealed traits and sum types **cannot be converted to structural types in Scala 2** because they require union types:\n\n```scala\n// Scala 2\nsealed trait Result\ncase class Success(value: Int) extends Result\ncase class Failure(error: String) extends Result\n\n// This will FAIL at compile-time in Scala 2:\nval structural = Schema.derived[Result].structural\n// Compile error: Cannot generate structural type for sum types in Scala 2.\n// Union types are required, which are only available in Scala 3.\n```\n\nThe macro must detect sum types in Scala 2 and produce a clear error.\n\n### 5. Case Objects\n\nCase objects become empty structural types:\n\n```scala\ncase object Singleton\n\nval structural = Schema.derived[Singleton.type].structural\n// Type: Schema[{}]\n```\n\nFor sum types with case objects (Scala 3):\n\n```scala\nsealed trait Status\ncase object Active extends Status\ncase object Inactive extends Status\n\nval structural = Schema.derived[Status].structural\n// Type: Schema[{} | {}]\n// Not particularly useful, but valid\n```\n\n### 6. Structural Types as Source\n\nDeriving schemas directly for structural types is supported:\n\n```scala\ntype PersonStructure = { def name: String; def age: Int }\n\nval schema = Schema.derived[PersonStructure]\n// Should work if structural type derivation is implemented\n```\n\nThe schema's bindings will use `Selectable` (Scala 3) or `Dynamic` (Scala 2) to construct and deconstruct values.\n\n---\n\n## Integration with Into/As\n\nStructural schemas compose naturally with `Into`/`As` conversions.\n\n### Nominal  Structural\n\n```scala\ncase class Person(name: String, age: Int)\n\n// Auto-derived conversion\nval nominalToStructural: Into[Person, { def name: String; def age: Int }] = \n  Into.derived\n\nval person = Person(\"Alice\", 30)\nval structural = nominalToStructural.into(person)\n// => Right(<Selectable/Dynamic instance>)\n```\n\n### Structural  Nominal\n\n```scala\ntype PersonStructure = { def name: String; def age: Int }\ncase class Person(name: String, age: Int)\n\n// Auto-derived conversion\nval structuralToNominal: Into[PersonStructure, Person] = \n  Into.derived\n\nval structural: PersonStructure = new Selectable {\n  def selectDynamic(field: String): Any = field match {\n    case \"name\" => \"Bob\"\n    case \"age\" => 25\n  }\n}\n\nval person = structuralToNominal.into(structural)\n// => Right(Person(\"Bob\", 25))\n```\n\n### Bidirectional (As)\n\n```scala\ncase class Person(name: String, age: Int)\n\n// Bidirectional conversion\nval personAs: As[Person, { def name: String; def age: Int }] = \n  As.derived\n\n// Nominal  Structural\nval structural = personAs.into(Person(\"Alice\", 30))\n\n// Structural  Nominal\nval nominal = structural.flatMap(personAs.from)\n// Round-trip successful\n```\n\n### Schema-Guided Conversion\n\n```scala\ncase class PersonV1(firstName: String, lastName: String, age: Int)\ncase class PersonV2(name: String, age: Int)\n\n// Use structural type as intermediary\ntype PersonStructure = { def name: String; def age: Int }\n\n// Step 1: Transform V1 to structural (custom logic)\nval v1ToStructural: Into[PersonV1, PersonStructure] = \n  new Into[PersonV1, PersonStructure] {\n    def into(v1: PersonV1): Either[SchemaError, PersonStructure] = {\n      Right(new Selectable {\n        def selectDynamic(field: String): Any = field match {\n          case \"name\" => s\"${v1.firstName} ${v1.lastName}\"\n          case \"age\" => v1.age\n        }\n      })\n    }\n  }\n\n// Step 2: Auto-convert structural to V2\nval structuralToV2: Into[PersonStructure, PersonV2] = Into.derived\n\n// Composed migration\ndef migrate(v1: PersonV1): Either[SchemaError, PersonV2] = {\n  v1ToStructural.into(v1).flatMap(structuralToV2.into)\n}\n```\n\n---\n\n## Testing Requirements\n\n### Test Matrix\n\n1. **Direct Structural Derivation**\n   - Simple products (case classes)\n   - Nested products\n   - Collections (List, Vector, Set, Map, Option, Either)\n   - Tuples (2-22 elements)\n   - Empty case classes\n   - Single-field case classes\n   - Large products (20+ fields)\n   - Case objects\n\n2. **Nominal to Structural Conversion**\n   - Case class  structural\n   - Tuple  structural\n   - Nested case classes  nested structural\n   - Case class with collections  structural with collections\n   - Empty case class  empty structural\n\n3. **Sum Types (Scala 3 Only)**\n   - Sealed trait  union type structural\n   - Sealed trait with case objects\n   - Enum  union type structural\n   - Nested sum types\n\n4. **Type Name Generation**\n   - Simple product normalized name\n   - Nested product normalized name\n   - Name determinism (same structure = same name)\n   - Alphabetical field ordering in names\n   - Union type names (Scala 3)\n\n5. **Selectable/Dynamic Implementation**\n   - Scala 3 Selectable field access\n   - Scala 2 Dynamic field access\n   - Field access correctness\n   - Missing field behavior\n   - Extra field behavior\n\n6. **Integration with Into/As**\n   - Nominal  Structural via Into\n   - Structural  Nominal via Into\n   - Round-trip via As\n   - Composed conversions with structural intermediary\n\n7. **Error Cases (Compile-Time)**\n   - Recursive types produce error\n   - Mutually recursive types produce error\n   - Sum types in Scala 2 produce error\n   - Unsupported types produce helpful errors\n\n8. **Generic Types** (if supported by existing Schema derivation)\n   - Fully applied generic  structural\n   - Generic with nested structural fields\n\n### Scala 2 vs Scala 3 Test Separation\n\n```\nsrc/test/scala/\n  structural/\n    common/\n      SimpleProductSpec.scala\n      NestedProductSpec.scala\n      CollectionsSpec.scala\n      TuplesSpec.scala\n      EmptyProductSpec.scala\n      SingleFieldSpec.scala\n      LargeProductSpec.scala\n      TypeNameNormalizationSpec.scala\n      IntoIntegrationSpec.scala\n      AsIntegrationSpec.scala\n      \n    scala3/\n      UnionTypesSpec.scala\n      SealedTraitToUnionSpec.scala\n      EnumToUnionSpec.scala\n      SelectableImplementationSpec.scala\n      \n    scala2/\n      DynamicImplementationSpec.scala\n      SumTypeErrorSpec.scala (verifies compile error)\n      \n    errors/\n      RecursiveTypeErrorSpec.scala\n      MutualRecursionErrorSpec.scala\n      UnsupportedTypeErrorSpec.scala\n```\n\n### Test Examples\n\n```scala\n// Test: Simple product to structural\ntest(\"case class converts to structural schema\") {\n  case class Person(name: String, age: Int)\n  \n  val structural = Schema.derived[Person].structural\n  \n  // Type check (this is a compile-time test)\n  val _: Schema[{ def name: String; def age: Int }] = structural\n  \n  assert(structural.typeName.toString.contains(\"name\"))\n  assert(structural.typeName.toString.contains(\"age\"))\n}\n\n// Test: Nested products\ntest(\"nested case classes convert to nested structural\") {\n  case class Address(street: String, zip: Int)\n  case class Person(name: String, address: Address)\n  \n  val structural = Schema.derived[Person].structural\n  \n  val _: Schema[{ \n    def name: String\n    def address: { def street: String; def zip: Int }\n  }] = structural\n}\n\n// Test: Tuple to structural\ntest(\"tuple converts to structural with _N fields\") {\n  val structural = Schema.derived[(String, Int, Boolean)].structural\n  \n  val _: Schema[{ def _1: String; def _2: Int; def _3: Boolean }] = structural\n}\n\n// Test: Union type (Scala 3 only)\ntest(\"sealed trait converts to union type structural\") {\n  sealed trait Result\n  case class Success(value: Int) extends Result\n  case class Failure(error: String) extends Result\n  \n  val structural = Schema.derived[Result].structural\n  \n  val _: Schema[{ def value: Int } | { def error: String }] = structural\n}\n\n// Test: Type name normalization\ntest(\"structural type names are normalized and deterministic\") {\n  case class Person(name: String, age: Int)\n  case class User(age: Int, name: String) // Different field order\n  \n  val personStructural = Schema.derived[Person].structural\n  val userStructural = Schema.derived[User].structural\n  \n  // Same structure, same normalized name\n  assert(personStructural.typeName == userStructural.typeName)\n  \n  // Alphabetical ordering\n  assert(personStructural.typeName.toString.contains(\"age\"))\n  assert(personStructural.typeName.toString.indexOf(\"age\") < \n         personStructural.typeName.toString.indexOf(\"name\"))\n}\n\n// Test: Integration with Into\ntest(\"structural to nominal conversion via Into\") {\n  case class Person(name: String, age: Int)\n  type PersonStructure = { def name: String; def age: Int }\n  \n  val structural: PersonStructure = new Selectable {\n    def selectDynamic(field: String): Any = field match {\n      case \"name\" => \"Alice\"\n      case \"age\" => 30\n    }\n  }\n  \n  val person = Into[PersonStructure, Person].into(structural)\n  assert(person == Right(Person(\"Alice\", 30)))\n}\n\n// Test: Round-trip via As\ntest(\"nominal to structural and back preserves data\") {\n  case class Person(name: String, age: Int)\n  type PersonStructure = { def name: String; def age: Int }\n  \n  val original = Person(\"Alice\", 30)\n  \n  val toStructural = As[Person, PersonStructure].into(original)\n  val backToNominal = toStructural.flatMap(As[Person, PersonStructure].from)\n  \n  assert(backToNominal == Right(original))\n}\n\n// Test: Recursive type compile error\ntest(\"recursive types produce compile error\") {\n  case class Tree(value: Int, children: List[Tree])\n  \n  assertDoesNotCompile(\"Schema.derived[Tree].structural\")\n}\n\n// Test: Sum type in Scala 2 compile error\ntest(\"sum types in Scala 2 produce compile error\") {\n  sealed trait Result\n  case class Success(value: Int) extends Result\n  \n  // Scala 2 only\n  assertDoesNotCompile(\"Schema.derived[Result].structural\")\n}\n```\n\n---\n\n## Implementation Notes\n\n### Macro Behavior\n\nThe macro must:\n\n1. **Detect product types** (case classes, tuples) and generate structural types with `def` members\n2. **Detect sum types** (sealed traits, enums) and:\n   - In Scala 3: Generate union types of structural representations\n   - In Scala 2: Fail with clear error message\n3. **Detect recursive types** and fail with clear error message\n4. **Normalize structural type representations** for type name generation\n5. **Generate `ToStructural` instance** with:\n   - `StructuralType` type member set to the generated structural type\n   - `apply` method that transforms the schema appropriately\n6. **Preserve field metadata** from original schema where applicable\n7. **Generate appropriate bindings** using `Selectable` (Scala 3) or `Dynamic` (Scala 2)\n\n### Schema Transformation\n\nWhen converting `Schema[A]` to `Schema[StructuralType]`:\n\n1. **Preserve field information**: Field names, types, optional/required status\n2. **Update type name**: Use normalized structural representation\n3. **Transform bindings**: Replace nominal constructors/deconstructors with structural equivalents\n4. **Preserve validation**: Maintain any validation logic that applies to field values\n5. **Handle nested schemas**: Recursively transform nested product types\n\n### Error Messages\n\nProvide clear compile-time errors:\n\n```scala\n// Recursive type\ncase class Tree(value: Int, children: List[Tree])\nSchema.derived[Tree].structural\n\n// Error:\n\"\"\"\nCannot generate structural type for recursive type Tree.\nStructural types cannot represent recursive structures.\nScala's type system does not support infinite types.\n\"\"\"\n\n// Sum type in Scala 2\nsealed trait Result\ncase class Success(value: Int) extends Result\nSchema.derived[Result].structural\n\n// Error (Scala 2 only):\n\"\"\"\nCannot generate structural type for sum type Result.\nStructural representation of sum types requires union types,\nwhich are only available in Scala 3.\nConsider upgrading to Scala 3 or using a different approach.\n\"\"\"\n```\n\n---\n\n## Deliverables\n\n1.  `ToStructural[A]` trait and macro for Scala 2.13\n2.  `ToStructural[A]` trait and macro for Scala 3.5\n3.  `structural` method on `Schema[A]`\n4.  Support for product types (case classes, tuples)\n5.  Support for sum types (sealed traits, enums) in Scala 3 only\n6.  Normalized type name generation\n7.  `Selectable` bindings (Scala 3) and `Dynamic` bindings (Scala 2)\n8.  Integration with `Into`/`As` for structural  nominal conversions\n9.  Comprehensive test suite (300+ test cases)\n10.  Clear error messages for unsupported cases\n11.  Documentation with examples",
                  "html_url": "https://github.com/zio/zio-blocks/issues/517"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#517",
              "body": "# Structural Type Schema Support\n\n## Overview\n\nExtend `Schema[A]` to support structural types, enabling schema derivation for types defined by their structure rather than their nominal identity. This allows for duck-typed schema validation and conversion between nominal and structural representations.\n\n## Core Concepts\n\n### Direct Structural Schema Derivation\n\nSchemas can be derived directly for structural types:\n\n```scala\n// Scala 3\ntype Person = { def name: String; def age: Int }\nval schema = Schema.derived[Person]\n\n// Scala 2\ntype Person = { def name: String; def age: Int }\nval schema = Schema.derived[Person]\n```\n\n**Note**: Both Scala 2 and Scala 3 use `def` for uniformity, even though Scala 3 supports `val` in structural types.\n\n**Implementation**: Schemas have bindings, which allow construction / deconstruction of values. Values for structural types are backed by:\n- **Scala 3**: `Selectable` \n- **Scala 2**: `Dynamic`\n\n### Nominal to Structural Conversion\n\nConvert nominal type schemas to their structural equivalents:\n\n```scala\ncase class Person(name: String, age: Int)\n\n// Get the structural schema corresponding to Person's shape\nval structuralSchema: Schema[{ def name: String; def age: Int }] = \n  Schema.derived[Person].structural\n```\n\n### Schema API Extension\n\n```scala\ncase class Schema[A](/* existing fields */) {\n  /**\n   * Convert this schema to a structural type schema.\n   * \n   * The structural type represents the \"shape\" of A without its nominal identity.\n   * This enables duck typing and structural validation.\n   * \n   * @param toStructural Macro-generated conversion to structural representation\n   * @return Schema for the structural type corresponding to A\n   */\n  def structural(implicit toStructural: ToStructural[A]): Schema[toStructural.StructuralType] = \n    toStructural.apply(this)\n}\n\n/**\n * Type class for converting nominal schemas to structural schemas.\n * Generated by macro for all supported types. Macro fails if a structural\n * type cannot be generated.\n *\n * NOTE: This approach has to be tested to yield inferrable types, and revised\n * if necessary. Inferrable types (from calling Schema#structural) are a must-have.\n */\ntrait ToStructural[A] {\n  type StructuralType\n  def apply(schema: Schema[A]): Schema[StructuralType]\n}\n\nobject ToStructural {\n  type Aux[A, S] = ToStructural[A] { type StructuralType = S }\n  \n  // Scala 3\n  transparent inline given [A]: ToStructural[A] = ${toStructuralMacro[A]}\n  \n  // Scala 2\n  implicit def materialize[A]: ToStructural[A] = macro toStructuralImpl[A]\n}\n```\n\n---\n\n## Examples\n\n### 1. Simple Product Types\n\n#### Case Class to Structural\n\n```scala\n// Both Scala 2 and Scala 3\ncase class Person(name: String, age: Int)\n\n// Original nominal schema\nval nominalSchema: Schema[Person] = Schema.derived[Person]\n\n// Convert to structural\nval structuralSchema: Schema[{ def name: String; def age: Int }] = \n  nominalSchema.structural\n\n// Direct structural derivation (equivalent)\nval directStructural: Schema[{ def name: String; def age: Int }] = \n  Schema.derived[{ def name: String; def age: Int }]\n```\n\n### 2. Nested Structures\n\n```scala\ncase class Address(street: String, city: String, zip: Int)\ncase class Person(name: String, age: Int, address: Address)\n\nval structuralSchema = Schema.derived[Person].structural\n// Type: Schema[{ \n//   def name: String\n//   def age: Int\n//   def address: { def street: String; def city: String; def zip: Int }\n// }]\n```\n\n### 3. Collections and Options\n\n```scala\ncase class Team(name: String, members: List[String], leader: Option[String])\n\nval structuralSchema = Schema.derived[Team].structural\n// Type: Schema[{\n//   def name: String\n//   def members: List[String]\n//   def leader: Option[String]\n// }]\n```\n\n### 4. Tuples to Structural\n\n```scala\n// Tuples can be converted to structural types\nval tupleSchema: Schema[(String, Int, Boolean)] = Schema.derived[(String, Int, Boolean)]\n\nval structuralSchema = tupleSchema.structural\n// Type: Schema[{ def _1: String; def _2: Int; def _3: Boolean }]\n```\n\n### 5. Sum Types (Sealed Traits) - Scala 3 Only\n\nSealed traits become union types of structural representations, with tag information stored at the type level:\n\n```scala\n// Scala 3 only\nsealed trait Result\ncase class Success(value: Int) extends Result\ncase class Failure(error: String) extends Result\n\nval structuralSchema = Schema.derived[Result].structural\n// Type: Schema[\n//   { type Tag = \"Success\"; def value: Int } | { type Tag = \"Failure\"; def error: String }\n// ]\n```\n\n**Note**: Sum type to structural conversion is **not supported in Scala 2** because it requires union types. Attempting to call `.structural` on a sealed trait schema in Scala 2 will result in a compile-time error.\n\n### 6. Enums (Scala 3 Only)\n\n```scala\nenum Status:\n  case Active, Inactive, Suspended\n\nval structuralSchema = Schema.derived[Status].structural\n// Type: Schema[{type Tag = \"Active\"} | {type Tag = \"Inactive\"} | {type Tag = \"Suspended\"}]\n```\n\n### 7. Opaque Types (Scala 3)\n\n```scala\nopaque type UserId = String\nobject UserId:\n  def apply(value: String): Either[String, UserId] = \n    if value.nonEmpty then Right(value) else Left(\"Empty user ID\")\n\ncase class User(id: UserId, name: String)\n\nval structuralSchema = Schema.derived[User].structural\n// Type: Schema[{ def id: String; def name: String }]\n// Opaque type is unwrapped to its underlying type\n```\n\n### 8. Bidirectional Conversion\n\nStructural schemas work seamlessly with `Into`/`As` (if this ticket is implemented **after** that ticket):\n\n```scala\ncase class Person(name: String, age: Int)\n\nval structuralSchema = Schema.derived[Person].structural\n\n// Create structural value (Scala 3)\nval structuralPerson = new Selectable {\n  def selectDynamic(field: String): Any = field match {\n    case \"name\" => \"Alice\"\n    case \"age\" => 30\n  }\n}\n\n// Convert structural to nominal using Into\nval person: Either[SchemaError, Person] = \n  Into[{ def name: String; def age: Int }, Person].into(structuralPerson)\n// => Right(Person(\"Alice\", 30))\n\n// Convert nominal to structural\nval backToStructural: Either[SchemaError, { def name: String; def age: Int }] = \n  Into[Person, { def name: String; def age: Int }].into(Person(\"Bob\", 25))\n```\n\n### 9. Empty and Single-Field Products\n\n```scala\n// Empty case class\ncase class Empty()\nval emptyStructural = Schema.derived[Empty].structural\n// Type: Schema[{}]\n\n// Single field\ncase class Id(value: String)\nval idStructural = Schema.derived[Id].structural\n// Type: Schema[{ def value: String }]\n```\n\n### 10. Large Products\n\n```scala\ncase class LargeRecord(\n  f1: String, f2: Int, f3: Boolean, f4: Double, f5: Long,\n  f6: String, f7: Int, f8: Boolean, f9: Double, f10: Long,\n  f11: String, f12: Int, f13: Boolean, f14: Double, f15: Long,\n  f16: String, f17: Int, f18: Boolean, f19: Double, f20: Long,\n  f21: String\n)\n\nval structuralSchema = Schema.derived[LargeRecord].structural\n// Type: Schema[{\n//   def f1: String; def f2: Int; def f3: Boolean; ...\n//   def f21: String\n// }]\n```\n\n---\n\n## Type Name Handling\n\n### Current Limitation\n\nSchemas currently use `TypeName[A]` to identify types. Structural types don't have meaningful nominal type names, which creates a mismatch.\n\n### Temporary Solution\n\nUntil `TypeName[A]` is replaced with `TypeId[A]` (see issue #471), structural schemas will use a normalized string representation of the structural type as a fake type name:\n\n```scala\ncase class Person(name: String, age: Int)\n\nval schema = Schema.derived[Person]\nschema.typeName // => TypeName for \"Person\"\n\nval structural = schema.structural\nstructural.typeName // => TypeName for \"{age:Int,name:String}\"\n// Normalized: fields sorted alphabetically, types fully qualified\n```\n\n### Normalization Rules\n\n1. **Field ordering**: Alphabetical by field name\n2. **Type qualification**: Use simple names for primitives and standard library types\n3. **Whitespace**: No whitespace in generated names\n4. **Collections**: Standard notation (e.g., `List[Int]`)\n5. **Options**: Explicit `Option[T]` notation\n6. **Nested structures**: Recursive application of rules\n7. **Deterministic**: Same structure always produces same normalized name\n\n### Examples\n\n```scala\n// Simple product\ncase class Point(x: Int, y: Int)\nSchema.derived[Point].structural.typeName \n// => \"{x:Int,y:Int}\"\n\n// Nested product\ncase class Address(street: String, zip: Int)\ncase class Person(name: String, address: Address)\nSchema.derived[Person].structural.typeName\n// => \"{address:{street:String,zip:Int},name:String}\"\n\n// With collections\ncase class Team(name: String, members: List[String])\nSchema.derived[Team].structural.typeName\n// => \"{members:List[String],name:String}\"\n\n// Union type (Scala 3)\nsealed trait Result\ncase class Success(value: Int) extends Result\ncase class Failure(error: String) extends Result\nSchema.derived[Result].structural.typeName\n// => \"{error:String}|{value:Int}\"\n```\n\n### Future: TypeId[A]\n\nThe upcoming `TypeId[A]` replacement will properly handle structural types by representing them by their structure rather than a string-based hack. See issue #471 for details.\n\n---\n\n## Limitations and Edge Cases\n\n### 1. Generic Types\n\n**Behavior depends on existing Schema derivation support for generic types.**\n\nIf `Schema.derived[Container[Int]]` already works, then structural conversion should work:\n\n```scala\ncase class Container[T](value: T)\n\n// If this works:\nval schema = Schema.derived[Container[Int]]\n\n// Then this should work:\nval structural = schema.structural\n// Type: Schema[{ def value: Int }]\n```\n\nIf generic type derivation is not currently supported, this ticket **does not require implementing it**. The macro should produce a clear compile-time error for unsupported generic types.\n\n### 2. Recursive Types\n\nRecursive types will **fail at compile-time** because Scala does not support infinite types:\n\n```scala\ncase class Tree(value: Int, children: List[Tree])\n\n// This will FAIL at compile-time:\nval structural = Schema.derived[Tree].structural\n// Compile error: Cannot generate infinite structural type\n\n// The structural type would need to be:\n// { def value: Int; def children: List[{ def value: Int; def children: List[...] }] }\n// which is infinite and unsupported\n```\n\nThe macro must detect recursive types and produce a helpful error message:\n\n```\nCompile error: Cannot generate structural type for recursive type Tree.\nStructural types cannot represent recursive structures.\n```\n\n### 3. Mutually Recursive Types\n\nSimilarly, mutually recursive types are unsupported:\n\n```scala\ncase class Node(id: Int, edges: List[Edge])\ncase class Edge(from: Int, to: Node)\n\n// This will FAIL at compile-time:\nval nodeStructural = Schema.derived[Node].structural\n// Compile error: Cannot generate structural type for mutually recursive types\n```\n\n### 4. Sum Types in Scala 2\n\nSealed traits and sum types **cannot be converted to structural types in Scala 2** because they require union types:\n\n```scala\n// Scala 2\nsealed trait Result\ncase class Success(value: Int) extends Result\ncase class Failure(error: String) extends Result\n\n// This will FAIL at compile-time in Scala 2:\nval structural = Schema.derived[Result].structural\n// Compile error: Cannot generate structural type for sum types in Scala 2.\n// Union types are required, which are only available in Scala 3.\n```\n\nThe macro must detect sum types in Scala 2 and produce a clear error.\n\n### 5. Case Objects\n\nCase objects become empty structural types:\n\n```scala\ncase object Singleton\n\nval structural = Schema.derived[Singleton.type].structural\n// Type: Schema[{}]\n```\n\nFor sum types with case objects (Scala 3):\n\n```scala\nsealed trait Status\ncase object Active extends Status\ncase object Inactive extends Status\n\nval structural = Schema.derived[Status].structural\n// Type: Schema[{} | {}]\n// Not particularly useful, but valid\n```\n\n### 6. Structural Types as Source\n\nDeriving schemas directly for structural types is supported:\n\n```scala\ntype PersonStructure = { def name: String; def age: Int }\n\nval schema = Schema.derived[PersonStructure]\n// Should work if structural type derivation is implemented\n```\n\nThe schema's bindings will use `Selectable` (Scala 3) or `Dynamic` (Scala 2) to construct and deconstruct values.\n\n---\n\n## Integration with Into/As\n\nStructural schemas compose naturally with `Into`/`As` conversions.\n\n### Nominal  Structural\n\n```scala\ncase class Person(name: String, age: Int)\n\n// Auto-derived conversion\nval nominalToStructural: Into[Person, { def name: String; def age: Int }] = \n  Into.derived\n\nval person = Person(\"Alice\", 30)\nval structural = nominalToStructural.into(person)\n// => Right(<Selectable/Dynamic instance>)\n```\n\n### Structural  Nominal\n\n```scala\ntype PersonStructure = { def name: String; def age: Int }\ncase class Person(name: String, age: Int)\n\n// Auto-derived conversion\nval structuralToNominal: Into[PersonStructure, Person] = \n  Into.derived\n\nval structural: PersonStructure = new Selectable {\n  def selectDynamic(field: String): Any = field match {\n    case \"name\" => \"Bob\"\n    case \"age\" => 25\n  }\n}\n\nval person = structuralToNominal.into(structural)\n// => Right(Person(\"Bob\", 25))\n```\n\n### Bidirectional (As)\n\n```scala\ncase class Person(name: String, age: Int)\n\n// Bidirectional conversion\nval personAs: As[Person, { def name: String; def age: Int }] = \n  As.derived\n\n// Nominal  Structural\nval structural = personAs.into(Person(\"Alice\", 30))\n\n// Structural  Nominal\nval nominal = structural.flatMap(personAs.from)\n// Round-trip successful\n```\n\n### Schema-Guided Conversion\n\n```scala\ncase class PersonV1(firstName: String, lastName: String, age: Int)\ncase class PersonV2(name: String, age: Int)\n\n// Use structural type as intermediary\ntype PersonStructure = { def name: String; def age: Int }\n\n// Step 1: Transform V1 to structural (custom logic)\nval v1ToStructural: Into[PersonV1, PersonStructure] = \n  new Into[PersonV1, PersonStructure] {\n    def into(v1: PersonV1): Either[SchemaError, PersonStructure] = {\n      Right(new Selectable {\n        def selectDynamic(field: String): Any = field match {\n          case \"name\" => s\"${v1.firstName} ${v1.lastName}\"\n          case \"age\" => v1.age\n        }\n      })\n    }\n  }\n\n// Step 2: Auto-convert structural to V2\nval structuralToV2: Into[PersonStructure, PersonV2] = Into.derived\n\n// Composed migration\ndef migrate(v1: PersonV1): Either[SchemaError, PersonV2] = {\n  v1ToStructural.into(v1).flatMap(structuralToV2.into)\n}\n```\n\n---\n\n## Testing Requirements\n\n### Test Matrix\n\n1. **Direct Structural Derivation**\n   - Simple products (case classes)\n   - Nested products\n   - Collections (List, Vector, Set, Map, Option, Either)\n   - Tuples (2-22 elements)\n   - Empty case classes\n   - Single-field case classes\n   - Large products (20+ fields)\n   - Case objects\n\n2. **Nominal to Structural Conversion**\n   - Case class  structural\n   - Tuple  structural\n   - Nested case classes  nested structural\n   - Case class with collections  structural with collections\n   - Empty case class  empty structural\n\n3. **Sum Types (Scala 3 Only)**\n   - Sealed trait  union type structural\n   - Sealed trait with case objects\n   - Enum  union type structural\n   - Nested sum types\n\n4. **Type Name Generation**\n   - Simple product normalized name\n   - Nested product normalized name\n   - Name determinism (same structure = same name)\n   - Alphabetical field ordering in names\n   - Union type names (Scala 3)\n\n5. **Selectable/Dynamic Implementation**\n   - Scala 3 Selectable field access\n   - Scala 2 Dynamic field access\n   - Field access correctness\n   - Missing field behavior\n   - Extra field behavior\n\n6. **Integration with Into/As**\n   - Nominal  Structural via Into\n   - Structural  Nominal via Into\n   - Round-trip via As\n   - Composed conversions with structural intermediary\n\n7. **Error Cases (Compile-Time)**\n   - Recursive types produce error\n   - Mutually recursive types produce error\n   - Sum types in Scala 2 produce error\n   - Unsupported types produce helpful errors\n\n8. **Generic Types** (if supported by existing Schema derivation)\n   - Fully applied generic  structural\n   - Generic with nested structural fields\n\n### Scala 2 vs Scala 3 Test Separation\n\n```\nsrc/test/scala/\n  structural/\n    common/\n      SimpleProductSpec.scala\n      NestedProductSpec.scala\n      CollectionsSpec.scala\n      TuplesSpec.scala\n      EmptyProductSpec.scala\n      SingleFieldSpec.scala\n      LargeProductSpec.scala\n      TypeNameNormalizationSpec.scala\n      IntoIntegrationSpec.scala\n      AsIntegrationSpec.scala\n      \n    scala3/\n      UnionTypesSpec.scala\n      SealedTraitToUnionSpec.scala\n      EnumToUnionSpec.scala\n      SelectableImplementationSpec.scala\n      \n    scala2/\n      DynamicImplementationSpec.scala\n      SumTypeErrorSpec.scala (verifies compile error)\n      \n    errors/\n      RecursiveTypeErrorSpec.scala\n      MutualRecursionErrorSpec.scala\n      UnsupportedTypeErrorSpec.scala\n```\n\n### Test Examples\n\n```scala\n// Test: Simple product to structural\ntest(\"case class converts to structural schema\") {\n  case class Person(name: String, age: Int)\n  \n  val structural = Schema.derived[Person].structural\n  \n  // Type check (this is a compile-time test)\n  val _: Schema[{ def name: String; def age: Int }] = structural\n  \n  assert(structural.typeName.toString.contains(\"name\"))\n  assert(structural.typeName.toString.contains(\"age\"))\n}\n\n// Test: Nested products\ntest(\"nested case classes convert to nested structural\") {\n  case class Address(street: String, zip: Int)\n  case class Person(name: String, address: Address)\n  \n  val structural = Schema.derived[Person].structural\n  \n  val _: Schema[{ \n    def name: String\n    def address: { def street: String; def zip: Int }\n  }] = structural\n}\n\n// Test: Tuple to structural\ntest(\"tuple converts to structural with _N fields\") {\n  val structural = Schema.derived[(String, Int, Boolean)].structural\n  \n  val _: Schema[{ def _1: String; def _2: Int; def _3: Boolean }] = structural\n}\n\n// Test: Union type (Scala 3 only)\ntest(\"sealed trait converts to union type structural\") {\n  sealed trait Result\n  case class Success(value: Int) extends Result\n  case class Failure(error: String) extends Result\n  \n  val structural = Schema.derived[Result].structural\n  \n  val _: Schema[{ def value: Int } | { def error: String }] = structural\n}\n\n// Test: Type name normalization\ntest(\"structural type names are normalized and deterministic\") {\n  case class Person(name: String, age: Int)\n  case class User(age: Int, name: String) // Different field order\n  \n  val personStructural = Schema.derived[Person].structural\n  val userStructural = Schema.derived[User].structural\n  \n  // Same structure, same normalized name\n  assert(personStructural.typeName == userStructural.typeName)\n  \n  // Alphabetical ordering\n  assert(personStructural.typeName.toString.contains(\"age\"))\n  assert(personStructural.typeName.toString.indexOf(\"age\") < \n         personStructural.typeName.toString.indexOf(\"name\"))\n}\n\n// Test: Integration with Into\ntest(\"structural to nominal conversion via Into\") {\n  case class Person(name: String, age: Int)\n  type PersonStructure = { def name: String; def age: Int }\n  \n  val structural: PersonStructure = new Selectable {\n    def selectDynamic(field: String): Any = field match {\n      case \"name\" => \"Alice\"\n      case \"age\" => 30\n    }\n  }\n  \n  val person = Into[PersonStructure, Person].into(structural)\n  assert(person == Right(Person(\"Alice\", 30)))\n}\n\n// Test: Round-trip via As\ntest(\"nominal to structural and back preserves data\") {\n  case class Person(name: String, age: Int)\n  type PersonStructure = { def name: String; def age: Int }\n  \n  val original = Person(\"Alice\", 30)\n  \n  val toStructural = As[Person, PersonStructure].into(original)\n  val backToNominal = toStructural.flatMap(As[Person, PersonStructure].from)\n  \n  assert(backToNominal == Right(original))\n}\n\n// Test: Recursive type compile error\ntest(\"recursive types produce compile error\") {\n  case class Tree(value: Int, children: List[Tree])\n  \n  assertDoesNotCompile(\"Schema.derived[Tree].structural\")\n}\n\n// Test: Sum type in Scala 2 compile error\ntest(\"sum types in Scala 2 produce compile error\") {\n  sealed trait Result\n  case class Success(value: Int) extends Result\n  \n  // Scala 2 only\n  assertDoesNotCompile(\"Schema.derived[Result].structural\")\n}\n```\n\n---\n\n## Implementation Notes\n\n### Macro Behavior\n\nThe macro must:\n\n1. **Detect product types** (case classes, tuples) and generate structural types with `def` members\n2. **Detect sum types** (sealed traits, enums) and:\n   - In Scala 3: Generate union types of structural representations\n   - In Scala 2: Fail with clear error message\n3. **Detect recursive types** and fail with clear error message\n4. **Normalize structural type representations** for type name generation\n5. **Generate `ToStructural` instance** with:\n   - `StructuralType` type member set to the generated structural type\n   - `apply` method that transforms the schema appropriately\n6. **Preserve field metadata** from original schema where applicable\n7. **Generate appropriate bindings** using `Selectable` (Scala 3) or `Dynamic` (Scala 2)\n\n### Schema Transformation\n\nWhen converting `Schema[A]` to `Schema[StructuralType]`:\n\n1. **Preserve field information**: Field names, types, optional/required status\n2. **Update type name**: Use normalized structural representation\n3. **Transform bindings**: Replace nominal constructors/deconstructors with structural equivalents\n4. **Preserve validation**: Maintain any validation logic that applies to field values\n5. **Handle nested schemas**: Recursively transform nested product types\n\n### Error Messages\n\nProvide clear compile-time errors:\n\n```scala\n// Recursive type\ncase class Tree(value: Int, children: List[Tree])\nSchema.derived[Tree].structural\n\n// Error:\n\"\"\"\nCannot generate structural type for recursive type Tree.\nStructural types cannot represent recursive structures.\nScala's type system does not support infinite types.\n\"\"\"\n\n// Sum type in Scala 2\nsealed trait Result\ncase class Success(value: Int) extends Result\nSchema.derived[Result].structural\n\n// Error (Scala 2 only):\n\"\"\"\nCannot generate structural type for sum type Result.\nStructural representation of sum types requires union types,\nwhich are only available in Scala 3.\nConsider upgrading to Scala 3 or using a different approach.\n\"\"\"\n```\n\n---\n\n## Deliverables\n\n1.  `ToStructural[A]` trait and macro for Scala 2.13\n2.  `ToStructural[A]` trait and macro for Scala 3.5\n3.  `structural` method on `Schema[A]`\n4.  Support for product types (case classes, tuples)\n5.  Support for sum types (sealed traits, enums) in Scala 3 only\n6.  Normalized type name generation\n7.  `Selectable` bindings (Scala 3) and `Dynamic` bindings (Scala 2)\n8.  Integration with `Into`/`As` for structural  nominal conversions\n9.  Comprehensive test suite (300+ test cases)\n10.  Clear error messages for unsupported cases\n11.  Documentation with examples",
              "url": "https://github.com/zio/zio-blocks/issues/517",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#516",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-12T11:36:03.602Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:36:03.602Z",
            "created_at": "2026-01-12T11:36:03.602Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#516",
              "status": "open",
              "type": "issue",
              "number": 516,
              "title": "Finalize Patch & Diffing",
              "source": {
                "data": {
                  "id": "source-ZIO#516",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Finalize Patch & Diffing",
                  "body": "# Algebraic Patch/Diff System for ZIO Schema 2\n\n## Overview\n\nImplement a pure, algebraic patch/diff system for ZIO Schema 2 that represents structural changes as first-class, serializable data. The system provides a typed API (`Patch[A]`) built on an untyped core (`DynamicPatch`) that operates on `DynamicValue`.\n\nBelow is a rough outline or sketch of the design of patching & diffing, subject to revision by the implementor based on technical feasibility considerations.\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed patch (user-facing API)\ncase class Patch[A](dynamicPatch: DynamicPatch, schema: Schema[A]) {\n  /** Apply patch with specified mode */\n  def apply(value: A, mode: PatchMode = PatchMode.Strict): Either[SchemaError, A]\n  \n  /** Compose patches sequentially (monoid operation) */\n  def ++(that: Patch[A]): Patch[A]\n}\n\n// Untyped patch (operates on DynamicValue)\ncase class DynamicPatch(ops: Vector[DynamicPatchOp]) {\n  /** Apply to dynamic value */\n  def apply(value: DynamicValue, mode: PatchMode): Either[SchemaError, DynamicValue]\n  \n  /** Compose patches */\n  def ++(that: DynamicPatch): DynamicPatch\n}\n```\n\n### Operations\n\n```scala\ncase class DynamicPatchOp(optic: DynamicOptic, operation: Operation)\n\nsealed trait Operation\nobject Operation {\n  case class Set(value: DynamicValue) extends Operation\n  case class PrimitiveDelta(op: PrimitiveOp) extends Operation\n  case class SequenceEdit(ops: Vector[SeqOp]) extends Operation\n  case class MapEdit(ops: Vector[MapOp]) extends Operation\n}\n```\n\n## Typed API\n\nAll typed operations live in `Patch` companion object:\n\n```scala\nobject Patch {\n  /** Empty patch (monoid identity) */\n  def empty[A](implicit schema: Schema[A]): Patch[A]\n  \n  /** Set a field/element to a value (clobber semantics) */\n  def set[S, A](optic: Optic[S, A], value: A)(implicit schema: Schema[S]): Patch[S]\n  \n  /** Increment numeric field */\n  def increment[S](optic: Optic[S, Int], delta: Int)(implicit schema: Schema[S]): Patch[S]\n  def incrementLong[S](optic: Optic[S, Long], delta: Long)(implicit schema: Schema[S]): Patch[S]\n  def incrementDouble[S](optic: Optic[S, Double], delta: Double)(implicit schema: Schema[S]): Patch[S]\n  \n  /** Edit string field */\n  def editString[S](optic: Optic[S, String], edits: Vector[StringOp])(implicit schema: Schema[S]): Patch[S]\n  \n  /** Sequence operations */\n  def append[S, A](optic: Optic[S, Vector[A]], elements: Vector[A])(implicit schema: Schema[S]): Patch[S]\n  def insertAt[S, A](optic: Optic[S, Vector[A]], index: Int, elements: Vector[A])(implicit schema: Schema[S]): Patch[S]\n  def deleteAt[S, A](optic: Optic[S, Vector[A]], index: Int, count: Int)(implicit schema: Schema[S]): Patch[S]\n  \n  /** Map operations */\n  def addKey[S, K, V](optic: Optic[S, Map[K, V]], key: K, value: V)(implicit schema: Schema[S]): Patch[S]\n  def removeKey[S, K, V](optic: Optic[S, Map[K, V]], key: K)(implicit schema: Schema[S]): Patch[S]\n  def modifyKey[S, K, V](optic: Optic[S, Map[K, V]], key: K, valuePatch: Patch[V])(implicit schema: Schema[S]): Patch[S]\n}\n```\n\n## Primitive Operations\n\n```scala\nsealed trait PrimitiveOp\nobject PrimitiveOp {\n  // Numeric deltas\n  case class IntDelta(delta: Int) extends PrimitiveOp\n  case class LongDelta(delta: Long) extends PrimitiveOp\n  case class DoubleDelta(delta: Double) extends PrimitiveOp\n  case class FloatDelta(delta: Float) extends PrimitiveOp\n  case class ShortDelta(delta: Short) extends PrimitiveOp\n  case class ByteDelta(delta: Byte) extends PrimitiveOp\n  case class BigIntDelta(delta: BigInt) extends PrimitiveOp\n  case class BigDecimalDelta(delta: BigDecimal) extends PrimitiveOp\n  \n  // String edits (LCS-based)\n  case class StringEdit(ops: Vector[StringOp]) extends PrimitiveOp\n  \n  // Temporal deltas\n  case class InstantDelta(duration: java.time.Duration) extends PrimitiveOp\n  case class DurationDelta(duration: java.time.Duration) extends PrimitiveOp\n  case class LocalDateDelta(period: java.time.Period) extends PrimitiveOp\n  case class LocalDateTimeDelta(period: java.time.Period, duration: java.time.Duration) extends PrimitiveOp\n  case class PeriodDelta(period: java.time.Period) extends PrimitiveOp\n  // ... other temporal types\n}\n\nsealed trait StringOp\nobject StringOp {\n  case class Insert(index: Int, text: String) extends StringOp\n  case class Delete(index: Int, length: Int) extends StringOp\n}\n```\n\n## Collection Operations\n\n```scala\nsealed trait SeqOp\nobject SeqOp {\n  /** Insert at index (fails if index occupied in Strict mode) */\n  case class Insert(index: Int, values: Vector[DynamicValue]) extends SeqOp\n  \n  /** Append to end (always succeeds) */\n  case class Append(values: Vector[DynamicValue]) extends SeqOp\n  \n  /** Delete count elements starting at index */\n  case class Delete(index: Int, count: Int) extends SeqOp\n  \n  /** Modify element at index with nested operation */\n  case class Modify(index: Int, op: Operation) extends SeqOp\n}\n\nsealed trait MapOp\nobject MapOp {\n  /** Add key-value (fails if key exists in Strict mode) */\n  case class Add(key: DynamicValue, value: DynamicValue) extends MapOp\n  \n  /** Remove key (fails if key missing in Strict mode) */\n  case class Remove(key: DynamicValue) extends MapOp\n  \n  /** Modify value at key with nested operation */\n  case class Modify(key: DynamicValue, op: Operation) extends MapOp\n}\n```\n\n## Patch Application Modes\n\n```scala\nsealed trait PatchMode\nobject PatchMode {\n  /** Fail on precondition violations (e.g. modifying non-existent key) */\n  case object Strict extends PatchMode\n  \n  /** Skip operations that fail preconditions */\n  case object Lenient extends PatchMode\n  \n  /** Replace/overwrite on conflicts */\n  case object Clobber extends PatchMode\n}\n```\n\n## Schema Integration\n\n```scala\ntrait Schema[A] {\n  /** \n   * Compute smart patch from oldValue to newValue.\n   * Uses heuristics to choose between delta/edit vs set operations.\n   */\n  def diff(oldValue: A, newValue: A): Patch[A]\n  \n  /** Convenience method - apply patch with Strict mode */\n  def patch(value: A, patch: Patch[A]): Either[SchemaError, A] =\n    patch.apply(value, PatchMode.Strict)\n}\n```\n\n## Diffing Strategy\n\nThe `Schema#diff` implementation uses smart heuristics:\n\n1. **New elements/keys**: Use `Operation.Set` \n   - Sequence insertions at new indices\n   - Map additions for new keys\n   - Sum type switches to different cases\n\n2. **String modifications**: Use `StringEdit` if edit sequence is shorter than new string, otherwise use `Set`\n\n3. **Numeric modifications**: Use delta operations (`IntDelta`, etc.)\n\n4. **Structural modifications**: Recursively diff nested structures, using field-level patches for records\n\n5. **Temporal modifications**: Use temporal delta operations for date/time types\n\n## Laws\n\n### Roundtrip Law\nFor all values, the following must hold:\n```scala\n (schema: Schema[A], old: A, new: A).\n  schema.diff(old, new).apply(old) == Right(new)\n```\n\n### Monoid Laws\n```scala\n// Identity (empty patch)\n (p: Patch[A]). \n  p ++ Patch.empty == p\n  Patch.empty ++ p == p\n\n// Associativity\n (p1: Patch[A], p2: Patch[A], p3: Patch[A]).\n  (p1 ++ p2) ++ p3 == p1 ++ (p2 ++ p3)\n```\n\n### Serializability\nAll patch types are pure data (DynamicValue, DynamicOptic, primitives) and must be serializable:\n```scala\n (p: Patch[A]). \n  jsonCodec.decode(jsonCodec.encode(p)) == Right(p)\n```\n\n## Implementation Notes\n\n- `Operation.Set` uses `DynamicValue` to represent whole values for materialization cases\n- `Patch[A]` converts typed values to `DynamicValue` via `Schema[A]` before applying `DynamicPatch` constructor\n- String edits use LCS (Longest Common Subsequence) algorithm\n- Sequence edits also use LCS for computing minimal insert/delete sequences\n\n## Success Criteria\n\n- [ ] `DynamicPatch` defined with all operation types, capable of transforming one DynamicValue to another in the most minimal possible way\n- [ ] `Patch[A]` wraps `DynamicPatch` with an additional `Schema[A]`\n- [ ] Typed API in `Patch` companion object for all common operations\n- [ ] `Schema#diff` implements smart diffing strategy\n- [ ] `PatchMode` controls patch application behavior\n- [ ] All fallible operations return `Either[SchemaError, A]` so error information is preserved\n- [ ] Roundtrip law holds for all schema types\n- [ ] Monoid laws hold for patch composition\n- [ ] All patch types serialize/deserialize correctly (except `Patch` itself, which cannot be serialized unless `Schema` is serialized, which in the general case requires a `TypeRegistry`)\n- [ ] String diffs use LCS algorithm\n- [ ] Sequence diffs use LCS algorithm\n- [ ] Comprehensive tests for all operation types, and for serialization of non-`Patch` types such as DynamicPatch and everything it contains\n\n## Example Usage\n\n```scala\n@schema \n@optics\ncase class Person(name: String, age: Int, address: Address)\n\n@schema \n@optics\ncase class Address(street: String, city: String, country: String)\n\nval old = Person(\"Alice\", 30, Address(\"123 Main St\", \"NYC\", \"USA\"))\nval new1 = Person(\"Alice\", 31, Address(\"456 Elm St\", \"NYC\", \"USA\"))\n\n// Automatic diffing\nval patch1: Patch[Person] = Person.schema.diff(old, new1)\npatch1(old) // Right(new1)\n\n// Manual patch construction\nval patch2: Patch[Person] = Patch.increment(Person.age, 1) ++ \n             Patch.set(Person.address(Address.street), \"456 Elm St\")\npatch2(old) // Right(new1)\n\n// Patch composition\nval patch3 = patch1 ++ patch2\npatch3(old) // Applies both patches sequentially\n\n// Different application modes\npatch2(old, PatchMode.Strict)   // Fails if preconditions violated\npatch2(old, PatchMode.Lenient)  // Skips failed operations\npatch2(old, PatchMode.Clobber)  // Replaces on conflicts\n\n// Serialization (via @schema on DynamicPatch)\nval json = jsonCodec.encode(patch1.dynamicPatch)\nval recovered = jsonCodec.decode[DynamicPatch](json)\n```",
                  "html_url": "https://github.com/zio/zio-blocks/issues/516"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#516",
              "body": "# Algebraic Patch/Diff System for ZIO Schema 2\n\n## Overview\n\nImplement a pure, algebraic patch/diff system for ZIO Schema 2 that represents structural changes as first-class, serializable data. The system provides a typed API (`Patch[A]`) built on an untyped core (`DynamicPatch`) that operates on `DynamicValue`.\n\nBelow is a rough outline or sketch of the design of patching & diffing, subject to revision by the implementor based on technical feasibility considerations.\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed patch (user-facing API)\ncase class Patch[A](dynamicPatch: DynamicPatch, schema: Schema[A]) {\n  /** Apply patch with specified mode */\n  def apply(value: A, mode: PatchMode = PatchMode.Strict): Either[SchemaError, A]\n  \n  /** Compose patches sequentially (monoid operation) */\n  def ++(that: Patch[A]): Patch[A]\n}\n\n// Untyped patch (operates on DynamicValue)\ncase class DynamicPatch(ops: Vector[DynamicPatchOp]) {\n  /** Apply to dynamic value */\n  def apply(value: DynamicValue, mode: PatchMode): Either[SchemaError, DynamicValue]\n  \n  /** Compose patches */\n  def ++(that: DynamicPatch): DynamicPatch\n}\n```\n\n### Operations\n\n```scala\ncase class DynamicPatchOp(optic: DynamicOptic, operation: Operation)\n\nsealed trait Operation\nobject Operation {\n  case class Set(value: DynamicValue) extends Operation\n  case class PrimitiveDelta(op: PrimitiveOp) extends Operation\n  case class SequenceEdit(ops: Vector[SeqOp]) extends Operation\n  case class MapEdit(ops: Vector[MapOp]) extends Operation\n}\n```\n\n## Typed API\n\nAll typed operations live in `Patch` companion object:\n\n```scala\nobject Patch {\n  /** Empty patch (monoid identity) */\n  def empty[A](implicit schema: Schema[A]): Patch[A]\n  \n  /** Set a field/element to a value (clobber semantics) */\n  def set[S, A](optic: Optic[S, A], value: A)(implicit schema: Schema[S]): Patch[S]\n  \n  /** Increment numeric field */\n  def increment[S](optic: Optic[S, Int], delta: Int)(implicit schema: Schema[S]): Patch[S]\n  def incrementLong[S](optic: Optic[S, Long], delta: Long)(implicit schema: Schema[S]): Patch[S]\n  def incrementDouble[S](optic: Optic[S, Double], delta: Double)(implicit schema: Schema[S]): Patch[S]\n  \n  /** Edit string field */\n  def editString[S](optic: Optic[S, String], edits: Vector[StringOp])(implicit schema: Schema[S]): Patch[S]\n  \n  /** Sequence operations */\n  def append[S, A](optic: Optic[S, Vector[A]], elements: Vector[A])(implicit schema: Schema[S]): Patch[S]\n  def insertAt[S, A](optic: Optic[S, Vector[A]], index: Int, elements: Vector[A])(implicit schema: Schema[S]): Patch[S]\n  def deleteAt[S, A](optic: Optic[S, Vector[A]], index: Int, count: Int)(implicit schema: Schema[S]): Patch[S]\n  \n  /** Map operations */\n  def addKey[S, K, V](optic: Optic[S, Map[K, V]], key: K, value: V)(implicit schema: Schema[S]): Patch[S]\n  def removeKey[S, K, V](optic: Optic[S, Map[K, V]], key: K)(implicit schema: Schema[S]): Patch[S]\n  def modifyKey[S, K, V](optic: Optic[S, Map[K, V]], key: K, valuePatch: Patch[V])(implicit schema: Schema[S]): Patch[S]\n}\n```\n\n## Primitive Operations\n\n```scala\nsealed trait PrimitiveOp\nobject PrimitiveOp {\n  // Numeric deltas\n  case class IntDelta(delta: Int) extends PrimitiveOp\n  case class LongDelta(delta: Long) extends PrimitiveOp\n  case class DoubleDelta(delta: Double) extends PrimitiveOp\n  case class FloatDelta(delta: Float) extends PrimitiveOp\n  case class ShortDelta(delta: Short) extends PrimitiveOp\n  case class ByteDelta(delta: Byte) extends PrimitiveOp\n  case class BigIntDelta(delta: BigInt) extends PrimitiveOp\n  case class BigDecimalDelta(delta: BigDecimal) extends PrimitiveOp\n  \n  // String edits (LCS-based)\n  case class StringEdit(ops: Vector[StringOp]) extends PrimitiveOp\n  \n  // Temporal deltas\n  case class InstantDelta(duration: java.time.Duration) extends PrimitiveOp\n  case class DurationDelta(duration: java.time.Duration) extends PrimitiveOp\n  case class LocalDateDelta(period: java.time.Period) extends PrimitiveOp\n  case class LocalDateTimeDelta(period: java.time.Period, duration: java.time.Duration) extends PrimitiveOp\n  case class PeriodDelta(period: java.time.Period) extends PrimitiveOp\n  // ... other temporal types\n}\n\nsealed trait StringOp\nobject StringOp {\n  case class Insert(index: Int, text: String) extends StringOp\n  case class Delete(index: Int, length: Int) extends StringOp\n}\n```\n\n## Collection Operations\n\n```scala\nsealed trait SeqOp\nobject SeqOp {\n  /** Insert at index (fails if index occupied in Strict mode) */\n  case class Insert(index: Int, values: Vector[DynamicValue]) extends SeqOp\n  \n  /** Append to end (always succeeds) */\n  case class Append(values: Vector[DynamicValue]) extends SeqOp\n  \n  /** Delete count elements starting at index */\n  case class Delete(index: Int, count: Int) extends SeqOp\n  \n  /** Modify element at index with nested operation */\n  case class Modify(index: Int, op: Operation) extends SeqOp\n}\n\nsealed trait MapOp\nobject MapOp {\n  /** Add key-value (fails if key exists in Strict mode) */\n  case class Add(key: DynamicValue, value: DynamicValue) extends MapOp\n  \n  /** Remove key (fails if key missing in Strict mode) */\n  case class Remove(key: DynamicValue) extends MapOp\n  \n  /** Modify value at key with nested operation */\n  case class Modify(key: DynamicValue, op: Operation) extends MapOp\n}\n```\n\n## Patch Application Modes\n\n```scala\nsealed trait PatchMode\nobject PatchMode {\n  /** Fail on precondition violations (e.g. modifying non-existent key) */\n  case object Strict extends PatchMode\n  \n  /** Skip operations that fail preconditions */\n  case object Lenient extends PatchMode\n  \n  /** Replace/overwrite on conflicts */\n  case object Clobber extends PatchMode\n}\n```\n\n## Schema Integration\n\n```scala\ntrait Schema[A] {\n  /** \n   * Compute smart patch from oldValue to newValue.\n   * Uses heuristics to choose between delta/edit vs set operations.\n   */\n  def diff(oldValue: A, newValue: A): Patch[A]\n  \n  /** Convenience method - apply patch with Strict mode */\n  def patch(value: A, patch: Patch[A]): Either[SchemaError, A] =\n    patch.apply(value, PatchMode.Strict)\n}\n```\n\n## Diffing Strategy\n\nThe `Schema#diff` implementation uses smart heuristics:\n\n1. **New elements/keys**: Use `Operation.Set` \n   - Sequence insertions at new indices\n   - Map additions for new keys\n   - Sum type switches to different cases\n\n2. **String modifications**: Use `StringEdit` if edit sequence is shorter than new string, otherwise use `Set`\n\n3. **Numeric modifications**: Use delta operations (`IntDelta`, etc.)\n\n4. **Structural modifications**: Recursively diff nested structures, using field-level patches for records\n\n5. **Temporal modifications**: Use temporal delta operations for date/time types\n\n## Laws\n\n### Roundtrip Law\nFor all values, the following must hold:\n```scala\n (schema: Schema[A], old: A, new: A).\n  schema.diff(old, new).apply(old) == Right(new)\n```\n\n### Monoid Laws\n```scala\n// Identity (empty patch)\n (p: Patch[A]). \n  p ++ Patch.empty == p\n  Patch.empty ++ p == p\n\n// Associativity\n (p1: Patch[A], p2: Patch[A], p3: Patch[A]).\n  (p1 ++ p2) ++ p3 == p1 ++ (p2 ++ p3)\n```\n\n### Serializability\nAll patch types are pure data (DynamicValue, DynamicOptic, primitives) and must be serializable:\n```scala\n (p: Patch[A]). \n  jsonCodec.decode(jsonCodec.encode(p)) == Right(p)\n```\n\n## Implementation Notes\n\n- `Operation.Set` uses `DynamicValue` to represent whole values for materialization cases\n- `Patch[A]` converts typed values to `DynamicValue` via `Schema[A]` before applying `DynamicPatch` constructor\n- String edits use LCS (Longest Common Subsequence) algorithm\n- Sequence edits also use LCS for computing minimal insert/delete sequences\n\n## Success Criteria\n\n- [ ] `DynamicPatch` defined with all operation types, capable of transforming one DynamicValue to another in the most minimal possible way\n- [ ] `Patch[A]` wraps `DynamicPatch` with an additional `Schema[A]`\n- [ ] Typed API in `Patch` companion object for all common operations\n- [ ] `Schema#diff` implements smart diffing strategy\n- [ ] `PatchMode` controls patch application behavior\n- [ ] All fallible operations return `Either[SchemaError, A]` so error information is preserved\n- [ ] Roundtrip law holds for all schema types\n- [ ] Monoid laws hold for patch composition\n- [ ] All patch types serialize/deserialize correctly (except `Patch` itself, which cannot be serialized unless `Schema` is serialized, which in the general case requires a `TypeRegistry`)\n- [ ] String diffs use LCS algorithm\n- [ ] Sequence diffs use LCS algorithm\n- [ ] Comprehensive tests for all operation types, and for serialization of non-`Patch` types such as DynamicPatch and everything it contains\n\n## Example Usage\n\n```scala\n@schema \n@optics\ncase class Person(name: String, age: Int, address: Address)\n\n@schema \n@optics\ncase class Address(street: String, city: String, country: String)\n\nval old = Person(\"Alice\", 30, Address(\"123 Main St\", \"NYC\", \"USA\"))\nval new1 = Person(\"Alice\", 31, Address(\"456 Elm St\", \"NYC\", \"USA\"))\n\n// Automatic diffing\nval patch1: Patch[Person] = Person.schema.diff(old, new1)\npatch1(old) // Right(new1)\n\n// Manual patch construction\nval patch2: Patch[Person] = Patch.increment(Person.age, 1) ++ \n             Patch.set(Person.address(Address.street), \"456 Elm St\")\npatch2(old) // Right(new1)\n\n// Patch composition\nval patch3 = patch1 ++ patch2\npatch3(old) // Applies both patches sequentially\n\n// Different application modes\npatch2(old, PatchMode.Strict)   // Fails if preconditions violated\npatch2(old, PatchMode.Lenient)  // Skips failed operations\npatch2(old, PatchMode.Clobber)  // Replaces on conflicts\n\n// Serialization (via @schema on DynamicPatch)\nval json = jsonCodec.encode(patch1.dynamicPatch)\nval recovered = jsonCodec.decode[DynamicPatch](json)\n```",
              "url": "https://github.com/zio/zio-blocks/issues/516",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#471",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-12T11:36:03.746Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:36:03.746Z",
            "created_at": "2026-01-12T11:36:03.746Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#471",
              "status": "open",
              "type": "issue",
              "number": 471,
              "title": "Replace TypeName by TypeId & Macro Derivation",
              "source": {
                "data": {
                  "id": "source-ZIO#471",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Replace TypeName by TypeId & Macro Derivation",
                  "body": "```scala\n// ============================================================================\n// Owner: Where a type is defined\n// ============================================================================\n\nfinal case class Owner(segments: List[Owner.Segment]) {\n  def asString: String = segments.map(_.name).mkString(\".\")\n}\n\nobject Owner {\n  sealed trait Segment { def name: String }\n\n  final case class Package(name: String) extends Segment\n  final case class Term(name: String)    extends Segment\n  final case class Type(name: String)    extends Segment\n\n  val Root: Owner = Owner(Nil)\n}\n\n// ============================================================================\n// TypeParam: Type parameter specification\n// ============================================================================\n\nfinal case class TypeParam(\n  name: String,\n  index: Int\n  // Can extend with: variance, bounds, kind\n)\n\n// ============================================================================\n// TypeId: Identity of a type or type constructor (phantom-typed by A)\n// ============================================================================\n\nsealed trait TypeId[A <: AnyKind] {\n  def name: String\n  def owner: Owner\n  def typeParams: List[TypeParam]\n\n  final def arity: Int = typeParams.size\n\n  final def fullName: String =\n    if (owner.segments.isEmpty) name\n    else owner.asString + \".\" + name\n}\n\nobject TypeId {\n  private final case class NominalImpl(\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam]\n  ) extends TypeId[Nothing]\n\n  private final case class AliasImpl(\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    aliased: TypeRepr\n  ) extends TypeId[Nothing]\n\n  private final case class OpaqueImpl(\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    representation: TypeRepr\n  ) extends TypeId[Nothing]\n\n  /** Macro-derived TypeId for any type or type constructor */\n  def derive[A <: AnyKind]: TypeId[A] =\n    macro TypeIdMacros.deriveMacro[A]\n\n  /** Manual construction: nominal type */\n  def nominal[A <: AnyKind](\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam]\n  ): TypeId[A] =\n    NominalImpl(name, owner, typeParams).asInstanceOf[TypeId[A]]\n\n  /** Manual construction: type alias */\n  def alias[A <: AnyKind](\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    aliased: TypeRepr\n  ): TypeId[A] =\n    AliasImpl(name, owner, typeParams, aliased).asInstanceOf[TypeId[A]]\n\n  /** Manual construction: opaque type */\n  def opaque[A <: AnyKind](\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    representation: TypeRepr\n  ): TypeId[A] =\n    OpaqueImpl(name, owner, typeParams, representation).asInstanceOf[TypeId[A]]\n\n  /** Pattern matching support */\n  object Nominal {\n    def unapply(id: TypeId[_]): Option[(String, Owner, List[TypeParam])] = id match {\n      case impl: NominalImpl => Some((impl.name, impl.owner, impl.typeParams))\n      case _                 => None\n    }\n  }\n\n  object Alias {\n    def unapply(id: TypeId[_]): Option[(String, Owner, List[TypeParam], TypeRepr)] = id match {\n      case impl: AliasImpl => Some((impl.name, impl.owner, impl.typeParams, impl.aliased))\n      case _               => None\n    }\n  }\n\n  object Opaque {\n    def unapply(id: TypeId[_]): Option[(String, Owner, List[TypeParam], TypeRepr)] = id match {\n      case impl: OpaqueImpl => Some((impl.name, impl.owner, impl.typeParams, impl.representation))\n      case _                => None\n    }\n  }\n}\n\n// ============================================================================\n// TypeRepr: Type expressions\n// ============================================================================\n\nsealed trait TypeRepr\n\nobject TypeRepr {\n  /** Reference to a named type constructor (unapplied).\n    * - If id.arity == 0, this is already a proper type\n    * - If id.arity > 0, this is a type constructor\n    */\n  final case class Ref(id: TypeId[_ <: AnyKind]) extends TypeRepr\n\n  /** Reference to a type parameter (can itself be a constructor) */\n  final case class ParamRef(param: TypeParam) extends TypeRepr\n\n  /** Application of a type constructor to arguments.\n    * Examples:\n    *   List[Int]    Applied(Ref(listId), List(Ref(intId)))\n    *   F[A]         Applied(ParamRef(F), List(ParamRef(A)))\n    */\n  final case class Applied(\n    tycon: TypeRepr,\n    args: List[TypeRepr]\n  ) extends TypeRepr\n\n  /** Structural/refinement type: { def foo: Int; type T; ... } */\n  final case class Structural(\n    parents: List[TypeRepr],\n    members: List[Member]\n  ) extends TypeRepr\n\n  /** Intersection type: A & B */\n  final case class Intersection(left: TypeRepr, right: TypeRepr) extends TypeRepr\n\n  /** Union type: A | B */\n  final case class Union(left: TypeRepr, right: TypeRepr) extends TypeRepr\n\n  /** Tuple type: (A, B, C) */\n  final case class Tuple(elems: List[TypeRepr]) extends TypeRepr\n\n  /** Function type: (A, B) => C */\n  final case class Function(params: List[TypeRepr], result: TypeRepr) extends TypeRepr\n\n  /** Singleton type: x.type */\n  final case class Singleton(path: TermPath) extends TypeRepr\n\n  /** Constant/literal type: 42, \"foo\", true */\n  final case class Constant(value: Any) extends TypeRepr\n\n  /** Top type */\n  case object AnyType extends TypeRepr\n\n  /** Bottom type */\n  case object NothingType extends TypeRepr\n}\n\n// ============================================================================\n// Member: Structural type members\n// ============================================================================\n\nsealed trait Member\n\nobject Member {\n  final case class Val(\n    name: String,\n    tpe: TypeRepr,\n    isVar: Boolean = false\n  ) extends Member\n\n  final case class Def(\n    name: String,\n    paramLists: List[List[Param]],\n    result: TypeRepr\n  ) extends Member\n\n  final case class TypeMember(\n    name: String,\n    typeParams: List[TypeParam],\n    lowerBound: Option[TypeRepr],\n    upperBound: Option[TypeRepr]\n  ) extends Member\n}\n\nfinal case class Param(name: String, tpe: TypeRepr)\n\n// ============================================================================\n// TermPath: For singleton types\n// ============================================================================\n\nfinal case class TermPath(segments: List[TermPath.Segment])\n\nobject TermPath {\n  sealed trait Segment { def name: String }\n\n  final case class Package(name: String) extends Segment\n  final case class Term(name: String)    extends Segment\n}\n\n// ============================================================================\n// Examples\n// ============================================================================\n\nobject Examples {\n  import TypeId.{nominal, alias, opaque}\n  import TypeRepr._\n  import Member._\n\n  private val pkgScala          = Owner(List(Owner.Package(\"scala\")))\n  private val pkgScalaCollection =\n    Owner(List(Owner.Package(\"scala\"), Owner.Package(\"collection\"), Owner.Package(\"immutable\")))\n  private val pkgJavaLang       = Owner(List(Owner.Package(\"java\"), Owner.Package(\"lang\")))\n  private val pkgMyApp          = Owner(List(Owner.Package(\"myapp\")))\n\n  // ===== Basic nominal types =====\n\n  val intId: TypeId[Int]       = nominal[Int](\"Int\", pkgScala, Nil)\n  val stringId: TypeId[String] = nominal[String](\"String\", pkgJavaLang, Nil)\n  val booleanId: TypeId[Boolean] = nominal[Boolean](\"Boolean\", pkgScala, Nil)\n\n  val intType: TypeRepr     = Ref(intId)\n  val stringType: TypeRepr  = Ref(stringId)\n  val booleanType: TypeRepr = Ref(booleanId)\n\n  // ===== Type constructors =====\n\n  val A = TypeParam(\"A\", 0)\n  val B = TypeParam(\"B\", 1)\n  val K = TypeParam(\"K\", 0)\n  val V = TypeParam(\"V\", 1)\n\n  val listId: TypeId[List]   = nominal[List](\"List\", pkgScalaCollection, List(A))\n  val optionId: TypeId[Option] = nominal[Option](\"Option\", pkgScala, List(A))\n  val mapId: TypeId[Map]     = nominal[Map](\"Map\", pkgScalaCollection, List(K, V))\n  val eitherId: TypeId[Either] = nominal[Either](\"Either\", pkgScala, List(A, B))\n\n  // Type constructors (unapplied)\n  val listConstructor: TypeRepr   = Ref(listId)\n  val optionConstructor: TypeRepr = Ref(optionId)\n\n  // Applied types\n  val listIntType: TypeRepr       = Applied(Ref(listId), List(intType))\n  val optionStringType: TypeRepr  = Applied(Ref(optionId), List(stringType))\n  val mapStringIntType: TypeRepr  = Applied(Ref(mapId), List(stringType, intType))\n\n  // ===== Type aliases =====\n\n  // type Age = Int\n  val ageId: TypeId[Int] = alias[Int](\n    name       = \"Age\",\n    owner      = pkgMyApp,\n    typeParams = Nil,\n    aliased    = intType\n  )\n  val ageType: TypeRepr = Ref(ageId)\n\n  // type MyList[A] = List[A]\n  val myListId: TypeId[List] = alias[List](\n    name       = \"MyList\",\n    owner      = pkgMyApp,\n    typeParams = List(A),\n    aliased    = Applied(Ref(listId), List(ParamRef(A)))\n  )\n\n  // type StringMap[V] = Map[String, V]\n  val stringMapId: TypeId[Map[String, *]] = alias[Map[String, *]](\n    name       = \"StringMap\",\n    owner      = pkgMyApp,\n    typeParams = List(V),\n    aliased    = Applied(Ref(mapId), List(stringType, ParamRef(V)))\n  )\n\n  // type Id[A] = A\n  val idId: TypeId[AnyKind] = alias[AnyKind](\n    name       = \"Id\",\n    owner      = pkgMyApp,\n    typeParams = List(A),\n    aliased    = ParamRef(A)\n  )\n\n  // ===== Opaque types =====\n\n  // opaque type Email = String\n  val emailId: TypeId[String] = opaque[String](\n    name           = \"Email\",\n    owner          = pkgMyApp,\n    typeParams     = Nil,\n    representation = stringType\n  )\n  val emailType: TypeRepr = Ref(emailId)\n\n  // opaque type SafeList[A] = List[A]\n  val safeListId: TypeId[List] = opaque[List](\n    name           = \"SafeList\",\n    owner          = pkgMyApp,\n    typeParams     = List(A),\n    representation = Applied(Ref(listId), List(ParamRef(A)))\n  )\n\n  // ===== Structural types =====\n\n  // { def size: Int; val isEmpty: Boolean }\n  val sizedType: TypeRepr = Structural(\n    parents = Nil,\n    members = List(\n      Def(\"size\", Nil, intType),\n      Val(\"isEmpty\", booleanType, isVar = false)\n    )\n  )\n\n  // type Record[A] = { def value: A }\n  val recordId: TypeId[AnyKind] = alias[AnyKind](\n    name       = \"Record\",\n    owner      = pkgMyApp,\n    typeParams = List(A),\n    aliased    = Structural(\n      parents = Nil,\n      members = List(\n        Def(\"value\", Nil, ParamRef(A))\n      )\n    )\n  )\n\n  // { type T; def get: T }\n  val T = TypeParam(\"T\", 0)\n  val genericGetterType: TypeRepr = Structural(\n    parents = Nil,\n    members = List(\n      TypeMember(\"T\", Nil, None, None),\n      // Note: ParamRef(T) here is a shorthand for \"the type member T\";\n      // if you want precise scoping you can extend the model, but for\n      // most uses you'll just inspect the name.\n      Def(\"get\", Nil, ParamRef(T))\n    )\n  )\n\n  // ===== Higher-kinded example =====\n\n  // type F[G[_], A] = G[A]\n  val G = TypeParam(\"G\", 0)\n  val fId: TypeId[AnyKind] = alias[AnyKind](\n    name       = \"F\",\n    owner      = pkgMyApp,\n    typeParams = List(G, A),\n    aliased    = Applied(\n      tycon = ParamRef(G),  // G is itself a type constructor\n      args  = List(ParamRef(A))\n    )\n  )\n\n  // ===== Singleton and constant types =====\n\n  // 42 (literal type)\n  val fortyTwoType: TypeRepr = Constant(42)\n\n  // \"hello\" (literal type)\n  val helloType: TypeRepr = Constant(\"hello\")\n\n  // myObject.type\n  val myObjectSingleton: TypeRepr = Singleton(\n    TermPath(List(TermPath.Package(\"myapp\"), TermPath.Term(\"myObject\")))\n  )\n\n  // ===== Complex types =====\n\n  // Option[List[String]]\n  val optionListStringType: TypeRepr =\n    Applied(Ref(optionId), List(Applied(Ref(listId), List(stringType))))\n\n  // Map[Email, List[Age]]\n  val emailToAgesType: TypeRepr =\n    Applied(\n      Ref(mapId),\n      List(\n        Ref(emailId),\n        Applied(Ref(listId), List(Ref(ageId)))\n      )\n    )\n\n  // (Int, String) => Boolean\n  val intStringToBoolType: TypeRepr =\n    Function(List(intType, stringType), booleanType)\n\n  // String & { def length: Int }\n  val stringWithLengthType: TypeRepr =\n    Intersection(\n      stringType,\n      Structural(Nil, List(Def(\"length\", Nil, intType)))\n    )\n\n  // ===== Utility: substitute type parameters =====\n\n  def substitute(\n    repr: TypeRepr,\n    substitutions: Map[TypeParam, TypeRepr]\n  ): TypeRepr =\n    repr match {\n      case ParamRef(param) =>\n        substitutions.getOrElse(param, repr)\n\n      case Ref(_) =>\n        repr\n\n      case Applied(tycon, args) =>\n        Applied(\n          substitute(tycon, substitutions),\n          args.map(substitute(_, substitutions))\n        )\n\n      case Structural(parents, members) =>\n        Structural(\n          parents.map(substitute(_, substitutions)),\n          members.map(substituteMember(_, substitutions))\n        )\n\n      case Intersection(l, r) =>\n        Intersection(\n          substitute(l, substitutions),\n          substitute(r, substitutions)\n        )\n\n      case Union(l, r) =>\n        Union(\n          substitute(l, substitutions),\n          substitute(r, substitutions)\n        )\n\n      case Tuple(elems) =>\n        Tuple(elems.map(substitute(_, substitutions)))\n\n      case Function(params, result) =>\n        Function(\n          params.map(substitute(_, substitutions)),\n          substitute(result, substitutions)\n        )\n\n      case Singleton(_) | Constant(_) | AnyType | NothingType =>\n        repr\n    }\n\n  private def substituteMember(\n    m: Member,\n    substitutions: Map[TypeParam, TypeRepr]\n  ): Member =\n    m match {\n      case Val(name, tpe, isVar) =>\n        Val(name, substitute(tpe, substitutions), isVar)\n\n      case Def(name, paramLists, result) =>\n        Def(\n          name,\n          paramLists.map(_.map { p => Param(p.name, substitute(p.tpe, substitutions)) }),\n          substitute(result, substitutions)\n        )\n\n      case TypeMember(name, typeParams, lower, upper) =>\n        TypeMember(\n          name,\n          typeParams,\n          lower.map(substitute(_, substitutions)),\n          upper.map(substitute(_, substitutions))\n        )\n    }\n\n  // Get underlying type for alias/opaque with substitution\n  def underlyingType(\n    id: TypeId[_],\n    args: List[TypeRepr]\n  ): Option[TypeRepr] = id match {\n    case TypeId.Alias(_, _, typeParams, aliased) =>\n      val subs = typeParams.zip(args).toMap\n      Some(substitute(aliased, subs))\n\n    case TypeId.Opaque(_, _, typeParams, representation) =>\n      val subs = typeParams.zip(args).toMap\n      Some(substitute(representation, subs))\n\n    case _ =>\n      None\n  }\n\n  // Examples:\n  // underlyingType(ageId, Nil)                  => Some(Int)\n  // underlyingType(myListId, List(intType))     => Some(List[Int])\n  // underlyingType(stringMapId, List(intType))  => Some(Map[String, Int])\n  // underlyingType(emailId, Nil)                => Some(String)\n\n  // ===== Type safety via phantom types =====\n\n  def processList(id: TypeId[List]): String =\n    s\"Processing list type constructor: ${id.fullName}\"\n\n  def processScalar[A](id: TypeId[A]): String =\n    s\"Processing scalar type: ${id.fullName}\"\n\n  // These compile:\n  val _x: String = processList(listId)\n  val _y: String = processList(myListId)     // MyList is an alias for List\n  val _z: String = processList(safeListId)   // SafeList is opaque over List\n\n  val _s1: String = processScalar(intId)\n  val _s2: String = processScalar(ageId)     // Age is an alias for Int\n  val _s3: String = processScalar(emailId)   // Email is opaque over String\n\n  // These would NOT compile:\n  // processList(intId)     // Type mismatch\n  // processScalar(listId)  // Type mismatch\n}\n```",
                  "html_url": "https://github.com/zio/zio-blocks/issues/471"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#471",
              "body": "```scala\n// ============================================================================\n// Owner: Where a type is defined\n// ============================================================================\n\nfinal case class Owner(segments: List[Owner.Segment]) {\n  def asString: String = segments.map(_.name).mkString(\".\")\n}\n\nobject Owner {\n  sealed trait Segment { def name: String }\n\n  final case class Package(name: String) extends Segment\n  final case class Term(name: String)    extends Segment\n  final case class Type(name: String)    extends Segment\n\n  val Root: Owner = Owner(Nil)\n}\n\n// ============================================================================\n// TypeParam: Type parameter specification\n// ============================================================================\n\nfinal case class TypeParam(\n  name: String,\n  index: Int\n  // Can extend with: variance, bounds, kind\n)\n\n// ============================================================================\n// TypeId: Identity of a type or type constructor (phantom-typed by A)\n// ============================================================================\n\nsealed trait TypeId[A <: AnyKind] {\n  def name: String\n  def owner: Owner\n  def typeParams: List[TypeParam]\n\n  final def arity: Int = typeParams.size\n\n  final def fullName: String =\n    if (owner.segments.isEmpty) name\n    else owner.asString + \".\" + name\n}\n\nobject TypeId {\n  private final case class NominalImpl(\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam]\n  ) extends TypeId[Nothing]\n\n  private final case class AliasImpl(\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    aliased: TypeRepr\n  ) extends TypeId[Nothing]\n\n  private final case class OpaqueImpl(\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    representation: TypeRepr\n  ) extends TypeId[Nothing]\n\n  /** Macro-derived TypeId for any type or type constructor */\n  def derive[A <: AnyKind]: TypeId[A] =\n    macro TypeIdMacros.deriveMacro[A]\n\n  /** Manual construction: nominal type */\n  def nominal[A <: AnyKind](\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam]\n  ): TypeId[A] =\n    NominalImpl(name, owner, typeParams).asInstanceOf[TypeId[A]]\n\n  /** Manual construction: type alias */\n  def alias[A <: AnyKind](\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    aliased: TypeRepr\n  ): TypeId[A] =\n    AliasImpl(name, owner, typeParams, aliased).asInstanceOf[TypeId[A]]\n\n  /** Manual construction: opaque type */\n  def opaque[A <: AnyKind](\n    name: String,\n    owner: Owner,\n    typeParams: List[TypeParam],\n    representation: TypeRepr\n  ): TypeId[A] =\n    OpaqueImpl(name, owner, typeParams, representation).asInstanceOf[TypeId[A]]\n\n  /** Pattern matching support */\n  object Nominal {\n    def unapply(id: TypeId[_]): Option[(String, Owner, List[TypeParam])] = id match {\n      case impl: NominalImpl => Some((impl.name, impl.owner, impl.typeParams))\n      case _                 => None\n    }\n  }\n\n  object Alias {\n    def unapply(id: TypeId[_]): Option[(String, Owner, List[TypeParam], TypeRepr)] = id match {\n      case impl: AliasImpl => Some((impl.name, impl.owner, impl.typeParams, impl.aliased))\n      case _               => None\n    }\n  }\n\n  object Opaque {\n    def unapply(id: TypeId[_]): Option[(String, Owner, List[TypeParam], TypeRepr)] = id match {\n      case impl: OpaqueImpl => Some((impl.name, impl.owner, impl.typeParams, impl.representation))\n      case _                => None\n    }\n  }\n}\n\n// ============================================================================\n// TypeRepr: Type expressions\n// ============================================================================\n\nsealed trait TypeRepr\n\nobject TypeRepr {\n  /** Reference to a named type constructor (unapplied).\n    * - If id.arity == 0, this is already a proper type\n    * - If id.arity > 0, this is a type constructor\n    */\n  final case class Ref(id: TypeId[_ <: AnyKind]) extends TypeRepr\n\n  /** Reference to a type parameter (can itself be a constructor) */\n  final case class ParamRef(param: TypeParam) extends TypeRepr\n\n  /** Application of a type constructor to arguments.\n    * Examples:\n    *   List[Int]    Applied(Ref(listId), List(Ref(intId)))\n    *   F[A]         Applied(ParamRef(F), List(ParamRef(A)))\n    */\n  final case class Applied(\n    tycon: TypeRepr,\n    args: List[TypeRepr]\n  ) extends TypeRepr\n\n  /** Structural/refinement type: { def foo: Int; type T; ... } */\n  final case class Structural(\n    parents: List[TypeRepr],\n    members: List[Member]\n  ) extends TypeRepr\n\n  /** Intersection type: A & B */\n  final case class Intersection(left: TypeRepr, right: TypeRepr) extends TypeRepr\n\n  /** Union type: A | B */\n  final case class Union(left: TypeRepr, right: TypeRepr) extends TypeRepr\n\n  /** Tuple type: (A, B, C) */\n  final case class Tuple(elems: List[TypeRepr]) extends TypeRepr\n\n  /** Function type: (A, B) => C */\n  final case class Function(params: List[TypeRepr], result: TypeRepr) extends TypeRepr\n\n  /** Singleton type: x.type */\n  final case class Singleton(path: TermPath) extends TypeRepr\n\n  /** Constant/literal type: 42, \"foo\", true */\n  final case class Constant(value: Any) extends TypeRepr\n\n  /** Top type */\n  case object AnyType extends TypeRepr\n\n  /** Bottom type */\n  case object NothingType extends TypeRepr\n}\n\n// ============================================================================\n// Member: Structural type members\n// ============================================================================\n\nsealed trait Member\n\nobject Member {\n  final case class Val(\n    name: String,\n    tpe: TypeRepr,\n    isVar: Boolean = false\n  ) extends Member\n\n  final case class Def(\n    name: String,\n    paramLists: List[List[Param]],\n    result: TypeRepr\n  ) extends Member\n\n  final case class TypeMember(\n    name: String,\n    typeParams: List[TypeParam],\n    lowerBound: Option[TypeRepr],\n    upperBound: Option[TypeRepr]\n  ) extends Member\n}\n\nfinal case class Param(name: String, tpe: TypeRepr)\n\n// ============================================================================\n// TermPath: For singleton types\n// ============================================================================\n\nfinal case class TermPath(segments: List[TermPath.Segment])\n\nobject TermPath {\n  sealed trait Segment { def name: String }\n\n  final case class Package(name: String) extends Segment\n  final case class Term(name: String)    extends Segment\n}\n\n// ============================================================================\n// Examples\n// ============================================================================\n\nobject Examples {\n  import TypeId.{nominal, alias, opaque}\n  import TypeRepr._\n  import Member._\n\n  private val pkgScala          = Owner(List(Owner.Package(\"scala\")))\n  private val pkgScalaCollection =\n    Owner(List(Owner.Package(\"scala\"), Owner.Package(\"collection\"), Owner.Package(\"immutable\")))\n  private val pkgJavaLang       = Owner(List(Owner.Package(\"java\"), Owner.Package(\"lang\")))\n  private val pkgMyApp          = Owner(List(Owner.Package(\"myapp\")))\n\n  // ===== Basic nominal types =====\n\n  val intId: TypeId[Int]       = nominal[Int](\"Int\", pkgScala, Nil)\n  val stringId: TypeId[String] = nominal[String](\"String\", pkgJavaLang, Nil)\n  val booleanId: TypeId[Boolean] = nominal[Boolean](\"Boolean\", pkgScala, Nil)\n\n  val intType: TypeRepr     = Ref(intId)\n  val stringType: TypeRepr  = Ref(stringId)\n  val booleanType: TypeRepr = Ref(booleanId)\n\n  // ===== Type constructors =====\n\n  val A = TypeParam(\"A\", 0)\n  val B = TypeParam(\"B\", 1)\n  val K = TypeParam(\"K\", 0)\n  val V = TypeParam(\"V\", 1)\n\n  val listId: TypeId[List]   = nominal[List](\"List\", pkgScalaCollection, List(A))\n  val optionId: TypeId[Option] = nominal[Option](\"Option\", pkgScala, List(A))\n  val mapId: TypeId[Map]     = nominal[Map](\"Map\", pkgScalaCollection, List(K, V))\n  val eitherId: TypeId[Either] = nominal[Either](\"Either\", pkgScala, List(A, B))\n\n  // Type constructors (unapplied)\n  val listConstructor: TypeRepr   = Ref(listId)\n  val optionConstructor: TypeRepr = Ref(optionId)\n\n  // Applied types\n  val listIntType: TypeRepr       = Applied(Ref(listId), List(intType))\n  val optionStringType: TypeRepr  = Applied(Ref(optionId), List(stringType))\n  val mapStringIntType: TypeRepr  = Applied(Ref(mapId), List(stringType, intType))\n\n  // ===== Type aliases =====\n\n  // type Age = Int\n  val ageId: TypeId[Int] = alias[Int](\n    name       = \"Age\",\n    owner      = pkgMyApp,\n    typeParams = Nil,\n    aliased    = intType\n  )\n  val ageType: TypeRepr = Ref(ageId)\n\n  // type MyList[A] = List[A]\n  val myListId: TypeId[List] = alias[List](\n    name       = \"MyList\",\n    owner      = pkgMyApp,\n    typeParams = List(A),\n    aliased    = Applied(Ref(listId), List(ParamRef(A)))\n  )\n\n  // type StringMap[V] = Map[String, V]\n  val stringMapId: TypeId[Map[String, *]] = alias[Map[String, *]](\n    name       = \"StringMap\",\n    owner      = pkgMyApp,\n    typeParams = List(V),\n    aliased    = Applied(Ref(mapId), List(stringType, ParamRef(V)))\n  )\n\n  // type Id[A] = A\n  val idId: TypeId[AnyKind] = alias[AnyKind](\n    name       = \"Id\",\n    owner      = pkgMyApp,\n    typeParams = List(A),\n    aliased    = ParamRef(A)\n  )\n\n  // ===== Opaque types =====\n\n  // opaque type Email = String\n  val emailId: TypeId[String] = opaque[String](\n    name           = \"Email\",\n    owner          = pkgMyApp,\n    typeParams     = Nil,\n    representation = stringType\n  )\n  val emailType: TypeRepr = Ref(emailId)\n\n  // opaque type SafeList[A] = List[A]\n  val safeListId: TypeId[List] = opaque[List](\n    name           = \"SafeList\",\n    owner          = pkgMyApp,\n    typeParams     = List(A),\n    representation = Applied(Ref(listId), List(ParamRef(A)))\n  )\n\n  // ===== Structural types =====\n\n  // { def size: Int; val isEmpty: Boolean }\n  val sizedType: TypeRepr = Structural(\n    parents = Nil,\n    members = List(\n      Def(\"size\", Nil, intType),\n      Val(\"isEmpty\", booleanType, isVar = false)\n    )\n  )\n\n  // type Record[A] = { def value: A }\n  val recordId: TypeId[AnyKind] = alias[AnyKind](\n    name       = \"Record\",\n    owner      = pkgMyApp,\n    typeParams = List(A),\n    aliased    = Structural(\n      parents = Nil,\n      members = List(\n        Def(\"value\", Nil, ParamRef(A))\n      )\n    )\n  )\n\n  // { type T; def get: T }\n  val T = TypeParam(\"T\", 0)\n  val genericGetterType: TypeRepr = Structural(\n    parents = Nil,\n    members = List(\n      TypeMember(\"T\", Nil, None, None),\n      // Note: ParamRef(T) here is a shorthand for \"the type member T\";\n      // if you want precise scoping you can extend the model, but for\n      // most uses you'll just inspect the name.\n      Def(\"get\", Nil, ParamRef(T))\n    )\n  )\n\n  // ===== Higher-kinded example =====\n\n  // type F[G[_], A] = G[A]\n  val G = TypeParam(\"G\", 0)\n  val fId: TypeId[AnyKind] = alias[AnyKind](\n    name       = \"F\",\n    owner      = pkgMyApp,\n    typeParams = List(G, A),\n    aliased    = Applied(\n      tycon = ParamRef(G),  // G is itself a type constructor\n      args  = List(ParamRef(A))\n    )\n  )\n\n  // ===== Singleton and constant types =====\n\n  // 42 (literal type)\n  val fortyTwoType: TypeRepr = Constant(42)\n\n  // \"hello\" (literal type)\n  val helloType: TypeRepr = Constant(\"hello\")\n\n  // myObject.type\n  val myObjectSingleton: TypeRepr = Singleton(\n    TermPath(List(TermPath.Package(\"myapp\"), TermPath.Term(\"myObject\")))\n  )\n\n  // ===== Complex types =====\n\n  // Option[List[String]]\n  val optionListStringType: TypeRepr =\n    Applied(Ref(optionId), List(Applied(Ref(listId), List(stringType))))\n\n  // Map[Email, List[Age]]\n  val emailToAgesType: TypeRepr =\n    Applied(\n      Ref(mapId),\n      List(\n        Ref(emailId),\n        Applied(Ref(listId), List(Ref(ageId)))\n      )\n    )\n\n  // (Int, String) => Boolean\n  val intStringToBoolType: TypeRepr =\n    Function(List(intType, stringType), booleanType)\n\n  // String & { def length: Int }\n  val stringWithLengthType: TypeRepr =\n    Intersection(\n      stringType,\n      Structural(Nil, List(Def(\"length\", Nil, intType)))\n    )\n\n  // ===== Utility: substitute type parameters =====\n\n  def substitute(\n    repr: TypeRepr,\n    substitutions: Map[TypeParam, TypeRepr]\n  ): TypeRepr =\n    repr match {\n      case ParamRef(param) =>\n        substitutions.getOrElse(param, repr)\n\n      case Ref(_) =>\n        repr\n\n      case Applied(tycon, args) =>\n        Applied(\n          substitute(tycon, substitutions),\n          args.map(substitute(_, substitutions))\n        )\n\n      case Structural(parents, members) =>\n        Structural(\n          parents.map(substitute(_, substitutions)),\n          members.map(substituteMember(_, substitutions))\n        )\n\n      case Intersection(l, r) =>\n        Intersection(\n          substitute(l, substitutions),\n          substitute(r, substitutions)\n        )\n\n      case Union(l, r) =>\n        Union(\n          substitute(l, substitutions),\n          substitute(r, substitutions)\n        )\n\n      case Tuple(elems) =>\n        Tuple(elems.map(substitute(_, substitutions)))\n\n      case Function(params, result) =>\n        Function(\n          params.map(substitute(_, substitutions)),\n          substitute(result, substitutions)\n        )\n\n      case Singleton(_) | Constant(_) | AnyType | NothingType =>\n        repr\n    }\n\n  private def substituteMember(\n    m: Member,\n    substitutions: Map[TypeParam, TypeRepr]\n  ): Member =\n    m match {\n      case Val(name, tpe, isVar) =>\n        Val(name, substitute(tpe, substitutions), isVar)\n\n      case Def(name, paramLists, result) =>\n        Def(\n          name,\n          paramLists.map(_.map { p => Param(p.name, substitute(p.tpe, substitutions)) }),\n          substitute(result, substitutions)\n        )\n\n      case TypeMember(name, typeParams, lower, upper) =>\n        TypeMember(\n          name,\n          typeParams,\n          lower.map(substitute(_, substitutions)),\n          upper.map(substitute(_, substitutions))\n        )\n    }\n\n  // Get underlying type for alias/opaque with substitution\n  def underlyingType(\n    id: TypeId[_],\n    args: List[TypeRepr]\n  ): Option[TypeRepr] = id match {\n    case TypeId.Alias(_, _, typeParams, aliased) =>\n      val subs = typeParams.zip(args).toMap\n      Some(substitute(aliased, subs))\n\n    case TypeId.Opaque(_, _, typeParams, representation) =>\n      val subs = typeParams.zip(args).toMap\n      Some(substitute(representation, subs))\n\n    case _ =>\n      None\n  }\n\n  // Examples:\n  // underlyingType(ageId, Nil)                  => Some(Int)\n  // underlyingType(myListId, List(intType))     => Some(List[Int])\n  // underlyingType(stringMapId, List(intType))  => Some(Map[String, Int])\n  // underlyingType(emailId, Nil)                => Some(String)\n\n  // ===== Type safety via phantom types =====\n\n  def processList(id: TypeId[List]): String =\n    s\"Processing list type constructor: ${id.fullName}\"\n\n  def processScalar[A](id: TypeId[A]): String =\n    s\"Processing scalar type: ${id.fullName}\"\n\n  // These compile:\n  val _x: String = processList(listId)\n  val _y: String = processList(myListId)     // MyList is an alias for List\n  val _z: String = processList(safeListId)   // SafeList is opaque over List\n\n  val _s1: String = processScalar(intId)\n  val _s2: String = processScalar(ageId)     // Age is an alias for Int\n  val _s3: String = processScalar(emailId)   // Email is opaque over String\n\n  // These would NOT compile:\n  // processList(intId)     // Type mismatch\n  // processScalar(listId)  // Type mismatch\n}\n```",
              "url": "https://github.com/zio/zio-blocks/issues/471",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#3697",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-12T11:36:03.917Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:36:03.917Z",
            "created_at": "2026-01-12T11:36:03.917Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#3697",
              "status": "open",
              "type": "issue",
              "number": 3697,
              "title": "Datastar requests from Endpoint",
              "source": {
                "data": {
                  "id": "source-ZIO#3697",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Datastar requests from Endpoint",
                  "body": "Build Datastar expressions for request against an Endpoint from its definition\n",
                  "html_url": "https://github.com/zio/zio-http/issues/3697"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3697",
              "body": "Build Datastar expressions for request against an Endpoint from its definition\n",
              "url": "https://github.com/zio/zio-http/issues/3697",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#709",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-12T11:36:04.063Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:36:04.063Z",
            "created_at": "2026-01-12T11:36:04.063Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#709",
              "status": "open",
              "type": "issue",
              "number": 709,
              "title": "Support Http Range header on request for Files",
              "source": {
                "data": {
                  "id": "source-ZIO#709",
                  "user": {
                    "login": "ashprakasan",
                    "id": 8946971,
                    "node_id": "MDQ6VXNlcjg5NDY5NzE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/8946971?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ashprakasan",
                    "html_url": "https://github.com/ashprakasan",
                    "followers_url": "https://api.github.com/users/ashprakasan/followers",
                    "following_url": "https://api.github.com/users/ashprakasan/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ashprakasan/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ashprakasan/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ashprakasan/subscriptions",
                    "organizations_url": "https://api.github.com/users/ashprakasan/orgs",
                    "repos_url": "https://api.github.com/users/ashprakasan/repos",
                    "events_url": "https://api.github.com/users/ashprakasan/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ashprakasan/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Support Http Range header on request for Files",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe Range HTTP request header indicates the part of a document that the server should return. Several parts can be requested with one Range header at once, and the server may send back these ranges in a multipart document.\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample requesting 3 ranges from files -\r\n`Range: bytes=200-1000, 2000-6576, 19000-`\r\n\r\nSend only those parts of the document in Response.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCurrently, the range is hardcoded as follows - \r\n` ctx.write(new DefaultFileRegion(raf.getChannel, 0, fileLength))`\r\nManipulate the positions as per request headers instead.\r\n\r\n**Additional context**\r\n\r\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Range\r\n",
                  "html_url": "https://github.com/zio/zio-http/issues/709"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#709",
              "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe Range HTTP request header indicates the part of a document that the server should return. Several parts can be requested with one Range header at once, and the server may send back these ranges in a multipart document.\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample requesting 3 ranges from files -\r\n`Range: bytes=200-1000, 2000-6576, 19000-`\r\n\r\nSend only those parts of the document in Response.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCurrently, the range is hardcoded as follows - \r\n` ctx.write(new DefaultFileRegion(raf.getChannel, 0, fileLength))`\r\nManipulate the positions as per request headers instead.\r\n\r\n**Additional context**\r\n\r\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Range\r\n",
              "url": "https://github.com/zio/zio-http/issues/709",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#3472",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-12T11:36:04.191Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:36:04.191Z",
            "created_at": "2026-01-12T11:36:04.191Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#3472",
              "status": "open",
              "type": "issue",
              "number": 3472,
              "title": "Split into multiple modules",
              "source": {
                "data": {
                  "id": "source-ZIO#3472",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Split into multiple modules",
                  "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
                  "html_url": "https://github.com/zio/zio-http/issues/3472"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3472",
              "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
              "url": "https://github.com/zio/zio-http/issues/3472",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9810",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-12T11:36:04.371Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:36:04.371Z",
            "created_at": "2026-01-12T11:36:04.371Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9810",
              "status": "open",
              "type": "issue",
              "number": 9810,
              "title": "ZStreams buffer(1) is buffering 2.",
              "source": {
                "data": {
                  "id": "source-ZIO#9810",
                  "user": {
                    "login": "douglasthomsen",
                    "id": 88000378,
                    "node_id": "MDQ6VXNlcjg4MDAwMzc4",
                    "avatar_url": "https://avatars.githubusercontent.com/u/88000378?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/douglasthomsen",
                    "html_url": "https://github.com/douglasthomsen",
                    "followers_url": "https://api.github.com/users/douglasthomsen/followers",
                    "following_url": "https://api.github.com/users/douglasthomsen/following{/other_user}",
                    "gists_url": "https://api.github.com/users/douglasthomsen/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/douglasthomsen/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/douglasthomsen/subscriptions",
                    "organizations_url": "https://api.github.com/users/douglasthomsen/orgs",
                    "repos_url": "https://api.github.com/users/douglasthomsen/repos",
                    "events_url": "https://api.github.com/users/douglasthomsen/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/douglasthomsen/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZStreams buffer(1) is buffering 2.",
                  "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
                  "html_url": "https://github.com/zio/zio/issues/9810"
                },
                "type": "github"
              },
              "hash": "zio/zio#9810",
              "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
              "url": "https://github.com/zio/zio/issues/9810",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "onyx-dot-app#2281",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "onyx-dot-app",
              "id": "generated-onyx-dot-app",
              "name": "Onyx-dot-app",
              "description": "",
              "members": [],
              "display_name": "Onyx-dot-app",
              "created_at": "2026-01-12T11:36:10.490Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/onyx-dot-app?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "danswer-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-12T11:36:10.490Z",
            "created_at": "2026-01-12T11:36:10.490Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-onyx-dot-app#2281",
              "status": "open",
              "type": "issue",
              "number": 2281,
              "title": "Jira Service Management Connector",
              "source": {
                "data": {
                  "id": "source-onyx-dot-app#2281",
                  "user": {
                    "login": "Weves",
                    "id": 25087905,
                    "node_id": "MDQ6VXNlcjI1MDg3OTA1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25087905?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Weves",
                    "html_url": "https://github.com/Weves",
                    "followers_url": "https://api.github.com/users/Weves/followers",
                    "following_url": "https://api.github.com/users/Weves/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Weves/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Weves/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Weves/subscriptions",
                    "organizations_url": "https://api.github.com/users/Weves/orgs",
                    "repos_url": "https://api.github.com/users/Weves/repos",
                    "events_url": "https://api.github.com/users/Weves/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Weves/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Jira Service Management Connector",
                  "body": "Pull in all tickets from a specified [Jira Service Management](https://www.atlassian.com/software/jira/service-management) project. \r\n\r\nCheckout the connector creation README here for more details on the best way to add new connectors: https://github.com/danswer-ai/danswer/blob/main/backend/danswer/connectors/README.md. ",
                  "html_url": "https://github.com/onyx-dot-app/onyx/issues/2281"
                },
                "type": "github"
              },
              "hash": "danswer-ai/danswer#2281",
              "body": "Pull in all tickets from a specified [Jira Service Management](https://www.atlassian.com/software/jira/service-management) project. \r\n\r\nCheckout the connector creation README here for more details on the best way to add new connectors: https://github.com/danswer-ai/danswer/blob/main/backend/danswer/connectors/README.md. ",
              "url": "https://github.com/onyx-dot-app/onyx/issues/2281",
              "tech": [],
              "repo_name": "danswer",
              "repo_owner": "danswer-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          }
        ],
        "next_cursor": null
      }
    }
  }
}