{
  "result": {
    "data": {
      "json": {
        "items": [
          {
            "id": "GolemCloud#275",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "GolemCloud",
              "id": "generated-GolemCloud",
              "name": "GolemCloud",
              "description": "",
              "members": [],
              "display_name": "GolemCloud",
              "created_at": "2026-02-02T08:08:13.099Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/GolemCloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-02T08:08:13.099Z",
            "created_at": "2026-02-02T08:08:13.099Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-GolemCloud#275",
              "status": "open",
              "type": "issue",
              "number": 275,
              "title": "Incorporate MCP Server into Golem CLI",
              "source": {
                "data": {
                  "id": "source-GolemCloud#275",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Incorporate MCP Server into Golem CLI",
                  "body": "With a new command, Golem CLI enters serve mode:\n\n```bash\n%> golem-cli --serve --serve-port 1232\n%> golem-cli running MCP Server at port 1232\n```\n\nIn this mode, Golem CLI creates an MCP Server that exposes different commands as different tools, and exposes relevant resources (the manifest file in the current, ancestor, and children directories) as resources.\n\nWhen this ticket is completed, it should be possible to use an agent such as Claude Code to perform anything that Golem CLI can do. Moreover, all individual tools and resources must be end-to-end tested with an MCP Client that interacts with the MCP Server.\n\n[This library](https://github.com/rust-mcp-stack/rust-mcp-sdk) looks like the one to use for Rust, but perhaps there are better options available.",
                  "html_url": "https://github.com/golemcloud/golem/issues/1926"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem-cli#275",
              "body": "With a new command, Golem CLI enters serve mode:\n\n```bash\n%> golem-cli --serve --serve-port 1232\n%> golem-cli running MCP Server at port 1232\n```\n\nIn this mode, Golem CLI creates an MCP Server that exposes different commands as different tools, and exposes relevant resources (the manifest file in the current, ancestor, and children directories) as resources.\n\nWhen this ticket is completed, it should be possible to use an agent such as Claude Code to perform anything that Golem CLI can do. Moreover, all individual tools and resources must be end-to-end tested with an MCP Client that interacts with the MCP Server.\n\n[This library](https://github.com/rust-mcp-stack/rust-mcp-sdk) looks like the one to use for Rust, but perhaps there are better options available.",
              "url": "https://github.com/golemcloud/golem/issues/1926",
              "tech": [
                "go"
              ],
              "repo_name": "golem-cli",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "GolemCloud#23",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "GolemCloud",
              "id": "generated-GolemCloud",
              "name": "GolemCloud",
              "description": "",
              "members": [],
              "display_name": "GolemCloud",
              "created_at": "2026-02-02T08:08:13.276Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/GolemCloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-02T08:08:13.276Z",
            "created_at": "2026-02-02T08:08:13.276Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-GolemCloud#23",
              "status": "open",
              "type": "issue",
              "number": 23,
              "title": "Implement Durable Text-to-Speech Provider Components for golem:tts WIT Interface",
              "source": {
                "data": {
                  "id": "source-GolemCloud#23",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Implement Durable Text-to-Speech Provider Components for golem:tts WIT Interface",
                  "body": "I have attached to this ticket a WIT file that describes a generic interface for text-to-speech operations. This interface can be implemented by various providers, either by emulating features not present in a given provider, utilizing the provider's native support for a feature, or indicating an error if a particular combination is not natively supported by a provider.\n\nThe intent of this WIT specification is to allow developers of WASM components (on wasmCloud, Spin, or Golem) to leverage text-to-speech capabilities to build voice-powered applications, accessibility services, and audio content generation systems in a portable and provider-agnostic fashion.\n\nThis ticket involves constructing implementations of this WIT interface for the following providers:\n\n- **ElevenLabs**: The leading AI voice synthesis platform with comprehensive voice cloning, real-time streaming, voice conversion, and sound effects generation capabilities.\n- **AWS Polly**: Amazon's enterprise text-to-speech service with extensive language support, custom lexicons, speech marks, and asynchronous synthesis for long-form content.\n- **Google Cloud Text-to-Speech**: Google's neural voice synthesis service with WaveNet and Neural2 voices, device optimization profiles, and streaming synthesis capabilities.\n- **Deepgram Aura**: High-performance real-time TTS with session-based streaming, low-latency neural voices, and conversational AI optimization.\n\nThese implementations must be written in Rust and compilable to WASM Components (WASI 0.23 only, since Golem does not yet support WASI 0.3). The standard Rust toolchain for WASM component development can be employed (see cargo component and the Rust examples of components in this and other Golem repositories).\n\nAdditionally, these implementations should incorporate custom durability semantics using the Golem durability API and the Golem host API. This approach ensures that durability is managed at the level of individual TTS operations (voice synthesis, streaming session creation, voice cloning, batch processing), providing a higher-level and clearer operation log, which aids in debugging and monitoring. See golem:llm and golem:embed for more details and durable implementations in this same repository.\n\nThe final deliverables associated with this ticket are:\n\n- **ElevenLabs implementation**: A WASM Component (WASI 0.23), named `tts-elevenlabs.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **AWS Polly implementation**: A WASM Component (WASI 0.23), named `tts-polly.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Google Cloud TTS implementation**: A WASM Component (WASI 0.23), named `tts-google.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Deepgram Aura implementation**: A WASM Component (WASI 0.23), named `tts-deepgram.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n\n**Note**: If you have a strong recommendation to swap out one or two of these with other popular / common TTS providers (such as Azure Cognitive Services Speech, IBM Watson Text to Speech, or OpenAI TTS), then as long as you get permission beforehand, that's okay with me. However, we definitely need ElevenLabs and AWS Polly.\n\nThese components will require runtime configuration, notably API keys, endpoint URLs, authentication credentials, and provider-specific settings. For configuring this information, the components can use environment variables for now (in the future, they will use wasi-runtime-config, but Golem does not support this yet, whereas Golem has good support for environment variables).\n\nMoreover, the Rust components need to be tested within Golem to ensure compatibility with Golem 1.2.x.\n\nThis WIT has been designed by examining and comparing the APIs of ElevenLabs, AWS Polly, Google Cloud TTS, Azure Speech Services, OpenAI TTS, and Deepgram Aura. However, given there are no implementations, it is possible the provided WIT is not the optimal abstraction across all these providers. Therefore, deviations from the proposed design can be made. However, to be accepted, any deviation must be fully justified and deemed by Golem core contributors to be an improvement from the original specification.\n\n## Implementation Guidelines\n\nEach provider implementation should handle the following key mapping considerations:\n\n- **Voice Management**: Map the unified voice resource to provider-specific voice identifiers, handle voice discovery and metadata appropriately for each provider's voice catalog structure\n- **Audio Format Conversion**: Implement native audio format support where available, or provide format conversion for unsupported output formats using audio processing libraries\n- **Streaming Implementation**: Utilize native streaming APIs where supported (ElevenLabs, Deepgram), or implement chunk-based synthesis for providers without native streaming support\n- **Authentication Handling**: Implement appropriate authentication mechanisms (API keys, OAuth, service accounts) per provider requirements\n- **Feature Availability**: Route advanced features (voice cloning, sound effects, speech marks) through provider-native APIs where supported, or return `unsupported-operation` errors for unavailable features\n- **Error Mapping**: Map provider-specific HTTP errors and API responses to the unified `tts-error` enumeration with appropriate context preservation\n- **Rate Limiting**: Handle provider-specific rate limits and quota management, implementing appropriate retry logic and error reporting\n- **Long-form Content**: Implement efficient handling of long-form synthesis using provider-native async operations (AWS Polly) or intelligent chunking strategies\n\n## Testing Requirements\n\nEach implementation must include comprehensive test suites covering:\n- Basic synthesis operations (text-to-speech with various voices and configurations)\n- Voice discovery and metadata retrieval\n- Streaming synthesis lifecycle (session creation, chunk processing, cleanup)\n- Advanced feature testing (voice cloning, sound effects, custom pronunciations where supported)\n- Audio format validation and quality verification\n- Authentication and authorization scenarios\n- Error handling for unsupported operations and malformed inputs\n- Rate limiting and quota management behavior\n- Connection management and retry logic\n- Long-form content synthesis (>5000 characters)\n- Durability semantics verification across operation boundaries\n- Provider-specific feature utilization (lexicons for Polly, voice settings for ElevenLabs, etc.)\n\n## Configuration Requirements\n\nEach implementation should support the following environment variables:\n\n### Common Configuration\n- `TTS_PROVIDER_ENDPOINT`: Custom endpoint URL (for enterprise/regional deployments)\n- `TTS_PROVIDER_TIMEOUT`: Request timeout in seconds (default: 30)\n- `TTS_PROVIDER_MAX_RETRIES`: Maximum retry attempts (default: 3)\n- `TTS_PROVIDER_LOG_LEVEL`: Logging verbosity (debug, info, warn, error)\n\n### Provider-Specific Configuration\n- **ElevenLabs**: `ELEVENLABS_API_KEY`, `ELEVENLABS_MODEL_VERSION`\n- **AWS Polly**: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `AWS_SESSION_TOKEN`\n- **Google Cloud**: `GOOGLE_APPLICATION_CREDENTIALS`, `GOOGLE_CLOUD_PROJECT`\n- **Deepgram**: `DEEPGRAM_API_KEY`, `DEEPGRAM_API_VERSION`\n\n```wit\npackage golem:tts@1.0.0;\n\n/// Core types and error handling for universal text-to-speech\ninterface types {\n    /// Comprehensive error types covering all TTS operations\n    variant tts-error {\n        /// Input validation errors\n        invalid-text(string),\n        text-too-long(u32),\n        invalid-ssml(string),\n        unsupported-language(string),\n        \n        /// Voice and model errors\n        voice-not-found(string),\n        model-not-found(string),\n        voice-unavailable(string),\n        \n        /// Authentication and authorization\n        unauthorized(string),\n        access-denied(string),\n        \n        /// Resource and quota limits\n        quota-exceeded(quota-info),\n        rate-limited(u32),\n        insufficient-credits,\n        \n        /// Operation errors\n        synthesis-failed(string),\n        unsupported-operation(string),\n        invalid-configuration(string),\n        \n        /// Service errors\n        service-unavailable(string),\n        network-error(string),\n        internal-error(string),\n        \n        /// Storage errors (for async operations)\n        invalid-storage-location(string),\n        storage-access-denied(string),\n    }\n\n    record quota-info {\n        used: u32,\n        limit: u32,\n        reset-time: u64,\n        unit: quota-unit,\n    }\n\n    enum quota-unit {\n        characters,\n        requests,\n        seconds,\n        credits,\n    }\n\n    /// Language identification using BCP 47 codes\n    type language-code = string;\n\n    /// Voice gender classification\n    enum voice-gender {\n        male,\n        female,\n        neutral,\n    }\n\n    /// Voice quality tiers\n    enum voice-quality {\n        standard,\n        premium,\n        neural,\n        studio,\n    }\n\n    /// Text input types\n    enum text-type {\n        plain,\n        ssml,\n    }\n\n    /// Audio output formats\n    enum audio-format {\n        mp3,\n        wav,\n        pcm,\n        ogg-opus,\n        aac,\n        flac,\n        mulaw,\n        alaw,\n    }\n\n    /// Audio quality settings\n    record audio-config {\n        format: audio-format,\n        sample-rate: option<u32>,\n        bit-rate: option<u32>,\n        channels: option<u8>,\n    }\n\n    /// Voice synthesis parameters\n    record voice-settings {\n        /// Speaking rate (0.25 to 4.0, default 1.0)\n        speed: option<f32>,\n        /// Pitch adjustment in semitones (-20.0 to 20.0, default 0.0)\n        pitch: option<f32>,\n        /// Volume gain in dB (-96.0 to 16.0, default 0.0)\n        volume: option<f32>,\n        /// Voice stability (0.0 to 1.0, provider-specific)\n        stability: option<f32>,\n        /// Similarity to original (0.0 to 1.0, provider-specific)\n        similarity: option<f32>,\n        /// Style exaggeration (0.0 to 1.0, provider-specific)\n        style: option<f32>,\n    }\n\n    /// Audio effects and device optimization\n    flags audio-effects {\n        telephone-quality,\n        headphone-optimized,\n        speaker-optimized,\n        car-audio-optimized,\n        noise-reduction,\n        bass-boost,\n        treble-boost,\n    }\n\n    /// Input text with metadata\n    record text-input {\n        content: string,\n        text-type: text-type,\n        language: option<language-code>,\n    }\n\n    /// Complete synthesis result\n    record synthesis-result {\n        audio-data: list<u8>,\n        metadata: synthesis-metadata,\n    }\n\n    /// Metadata about synthesized audio\n    record synthesis-metadata {\n        duration-seconds: f32,\n        character-count: u32,\n        word-count: u32,\n        audio-size-bytes: u32,\n        request-id: string,\n        provider-info: option<string>,\n    }\n\n    /// Streaming audio chunk\n    record audio-chunk {\n        data: list<u8>,\n        sequence-number: u32,\n        is-final: bool,\n        timing-info: option<timing-info>,\n    }\n\n    /// Timing and synchronization information\n    record timing-info {\n        start-time-seconds: f32,\n        end-time-seconds: option<f32>,\n        text-offset: option<u32>,\n        mark-type: option<timing-mark-type>,\n    }\n\n    enum timing-mark-type {\n        word,\n        sentence,\n        paragraph,\n        ssml-mark,\n        viseme,\n    }\n\n\n}\n\n/// Voice discovery and management\ninterface voices {\n    use types.{tts-error, language-code, voice-gender, voice-quality};\n\n    /// Represents a voice that can be used for speech synthesis\n    resource voice {\n        /// Get voice identification\n        get-id: func() -> string;\n        get-name: func() -> string;\n        get-provider-id: func() -> option<string>;\n        \n        /// Get voice characteristics\n        get-language: func() -> language-code;\n        get-additional-languages: func() -> list<language-code>;\n        get-gender: func() -> voice-gender;\n        get-quality: func() -> voice-quality;\n        get-description: func() -> option<string>;\n        \n        /// Voice capabilities\n        supports-ssml: func() -> bool;\n        get-sample-rates: func() -> list<u32>;\n        get-supported-formats: func() -> list<types.audio-format>;\n        \n        /// Voice management (may return unsupported-operation)\n        update-settings: func(settings: types.voice-settings) -> result<_, tts-error>;\n        delete: func() -> result<_, tts-error>;\n        clone: func() -> result<voice, tts-error>;\n        \n        /// Preview voice with sample text\n        preview: func(text: string) -> result<list<u8>, tts-error>;\n    }\n\n    /// Voice search and filtering\n    record voice-filter {\n        language: option<language-code>,\n        gender: option<voice-gender>,\n        quality: option<voice-quality>,\n        supports-ssml: option<bool>,\n        provider: option<string>,\n        search-query: option<string>,\n    }\n\n    /// Detailed voice information\n    record voice-info {\n        id: string,\n        name: string,\n        language: language-code,\n        additional-languages: list<language-code>,\n        gender: voice-gender,\n        quality: voice-quality,\n        description: option<string>,\n        provider: string,\n        sample-rate: u32,\n        is-custom: bool,\n        is-cloned: bool,\n        preview-url: option<string>,\n        use-cases: list<string>,\n    }\n\n    /// Resource-based iterator for voice results\n    resource voice-results {\n        /// Check if more voices are available\n        has-more: func() -> bool;\n        \n        /// Get next batch of voices\n        get-next: func() -> result<list<voice-info>, tts-error>;\n        \n        /// Get total count if available\n        get-total-count: func() -> option<u32>;\n    }\n\n    /// List available voices with filtering and pagination\n    list-voices: func(\n        filter: option<voice-filter>\n    ) -> result<voice-results, tts-error>;\n\n    /// Get specific voice by ID\n    get-voice: func(voice-id: string) -> result<voice, tts-error>;\n\n    /// Search voices by characteristics\n    search-voices: func(\n        query: string,\n        filter: option<voice-filter>\n    ) -> result<list<voice-info>, tts-error>;\n\n    /// Get supported languages\n    list-languages: func() -> result<list<language-info>, tts-error>;\n\n    record language-info {\n        code: language-code,\n        name: string,\n        native-name: string,\n        voice-count: u32,\n    }\n}\n\n/// Core text-to-speech synthesis operations\ninterface synthesis {\n    use types.{\n        text-input, audio-config, voice-settings, audio-effects,\n        synthesis-result, tts-error, timing-info\n    };\n    use voices.{voice};\n\n    /// Synthesis configuration options\n    record synthesis-options {\n        audio-config: option<audio-config>,\n        voice-settings: option<voice-settings>,\n        audio-effects: option<audio-effects>,\n        enable-timing: option<bool>,\n        enable-word-timing: option<bool>,\n        seed: option<u32>,\n        model-version: option<string>,\n        context: option<synthesis-context>,\n    }\n\n    /// Context for better synthesis quality\n    record synthesis-context {\n        previous-text: option<string>,\n        next-text: option<string>,\n        topic: option<string>,\n        emotion: option<string>,\n        speaking-style: option<string>,\n    }\n\n    /// Convert text to speech (removed async)\n    synthesize: func(\n        input: text-input,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-result, tts-error>;\n\n    /// Batch synthesis for multiple inputs (removed async)\n    synthesize-batch: func(\n        inputs: list<text-input>,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<list<synthesis-result>, tts-error>;\n\n    /// Get timing information without audio synthesis\n    get-timing-marks: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<list<timing-info>, tts-error>;\n\n    /// Validate text before synthesis\n    validate-input: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<validation-result, tts-error>;\n\n    record validation-result {\n        is-valid: bool,\n        character-count: u32,\n        estimated-duration: option<f32>,\n        warnings: list<string>,\n        errors: list<string>,\n    }\n}\n\n/// Real-time streaming synthesis\ninterface streaming {\n    use types.{\n        text-input, audio-config, voice-settings, audio-chunk,\n        tts-error, timing-info\n    };\n    use voices.{voice};\n    use synthesis.{synthesis-options};\n\n    /// Streaming synthesis session\n    resource synthesis-stream {\n        /// Send text for synthesis (can be called multiple times)\n        send-text: func(input: text-input) -> result<_, tts-error>;\n        \n        /// Signal end of input and flush remaining audio\n        finish: func() -> result<_, tts-error>;\n        \n        /// Receive next audio chunk (non-blocking)\n        receive-chunk: func() -> result<option<audio-chunk>, tts-error>;\n        \n        /// Check if more chunks are available\n        has-pending-audio: func() -> bool;\n        \n        /// Get current stream status\n        get-status: func() -> stream-status;\n        \n        /// Close stream and clean up resources\n        close: func();\n    }\n\n    enum stream-status {\n        ready,\n        processing,\n        finished,\n        error,\n        closed,\n    }\n\n    /// Create streaming synthesis session\n    create-stream: func(\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-stream, tts-error>;\n\n    /// Real-time voice conversion streaming\n    create-voice-conversion-stream: func(\n        target-voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<voice-conversion-stream, tts-error>;\n\n    resource voice-conversion-stream {\n        /// Send input audio chunks\n        send-audio: func(audio-data: list<u8>) -> result<_, tts-error>;\n        \n        /// Receive converted audio chunks\n        receive-converted: func() -> result<option<audio-chunk>, tts-error>;\n        \n        finish: func() -> result<_, tts-error>;\n        close: func();\n    }\n}\n\n/// Advanced TTS features and voice manipulation\ninterface advanced {\n    use types.{tts-error, audio-config, language-code};\n    use voices.{voice};\n\n    /// Voice cloning and creation (removed async)\n    create-voice-clone: func(\n        name: string,\n        audio-samples: list<audio-sample>,\n        description: option<string>\n    ) -> result<voice, tts-error>;\n\n    record audio-sample {\n        data: list<u8>,\n        transcript: option<string>,\n        quality-rating: option<u8>,\n    }\n\n    /// Design synthetic voice (removed async)\n    design-voice: func(\n        name: string,\n        characteristics: voice-design-params\n    ) -> result<voice, tts-error>;\n\n    record voice-design-params {\n        gender: types.voice-gender,\n        age-category: age-category,\n        accent: string,\n        personality-traits: list<string>,\n        reference-voice: option<string>,\n    }\n\n    enum age-category {\n        child,\n        young-adult,\n        middle-aged,\n        elderly,\n    }\n\n    /// Voice-to-voice conversion (removed async)\n    convert-voice: func(\n        input-audio: list<u8>,\n        target-voice: borrow<voice>,\n        preserve-timing: option<bool>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Generate sound effects from text description (removed async)\n    generate-sound-effect: func(\n        description: string,\n        duration-seconds: option<f32>,\n        style-influence: option<f32>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Custom pronunciation management\n    resource pronunciation-lexicon {\n        get-name: func() -> string;\n        get-language: func() -> language-code;\n        get-entry-count: func() -> u32;\n        \n        /// Add pronunciation rule\n        add-entry: func(word: string, pronunciation: string) -> result<_, tts-error>;\n        \n        /// Remove pronunciation rule\n        remove-entry: func(word: string) -> result<_, tts-error>;\n        \n        /// Export lexicon content\n        export-content: func() -> result<string, tts-error>;\n    }\n\n    /// Create custom pronunciation lexicon\n    create-lexicon: func(\n        name: string,\n        language: language-code,\n        entries: option<list<pronunciation-entry>>\n    ) -> result<pronunciation-lexicon, tts-error>;\n\n    record pronunciation-entry {\n        word: string,\n        pronunciation: string,\n        part-of-speech: option<string>,\n    }\n\n    /// Long-form content synthesis with optimization (removed async)\n    synthesize-long-form: func(\n        content: string,\n        voice: borrow<voice>,\n        output-location: string,\n        chapter-breaks: option<list<u32>>\n    ) -> result<long-form-operation, tts-error>;\n\n    resource long-form-operation {\n        get-status: func() -> operation-status;\n        get-progress: func() -> f32;\n        cancel: func() -> result<_, tts-error>;\n        get-result: func() -> result<long-form-result, tts-error>;\n    }\n\n    enum operation-status {\n        pending,\n        processing,\n        completed,\n        failed,\n        cancelled,\n    }\n\n    record long-form-result {\n        output-location: string,\n        total-duration: f32,\n        chapter-durations: option<list<f32>>,\n        metadata: types.synthesis-metadata,\n    }\n}\n```",
                  "html_url": "https://github.com/golemcloud/golem-ai/issues/23"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem-ai#23",
              "body": "I have attached to this ticket a WIT file that describes a generic interface for text-to-speech operations. This interface can be implemented by various providers, either by emulating features not present in a given provider, utilizing the provider's native support for a feature, or indicating an error if a particular combination is not natively supported by a provider.\n\nThe intent of this WIT specification is to allow developers of WASM components (on wasmCloud, Spin, or Golem) to leverage text-to-speech capabilities to build voice-powered applications, accessibility services, and audio content generation systems in a portable and provider-agnostic fashion.\n\nThis ticket involves constructing implementations of this WIT interface for the following providers:\n\n- **ElevenLabs**: The leading AI voice synthesis platform with comprehensive voice cloning, real-time streaming, voice conversion, and sound effects generation capabilities.\n- **AWS Polly**: Amazon's enterprise text-to-speech service with extensive language support, custom lexicons, speech marks, and asynchronous synthesis for long-form content.\n- **Google Cloud Text-to-Speech**: Google's neural voice synthesis service with WaveNet and Neural2 voices, device optimization profiles, and streaming synthesis capabilities.\n- **Deepgram Aura**: High-performance real-time TTS with session-based streaming, low-latency neural voices, and conversational AI optimization.\n\nThese implementations must be written in Rust and compilable to WASM Components (WASI 0.23 only, since Golem does not yet support WASI 0.3). The standard Rust toolchain for WASM component development can be employed (see cargo component and the Rust examples of components in this and other Golem repositories).\n\nAdditionally, these implementations should incorporate custom durability semantics using the Golem durability API and the Golem host API. This approach ensures that durability is managed at the level of individual TTS operations (voice synthesis, streaming session creation, voice cloning, batch processing), providing a higher-level and clearer operation log, which aids in debugging and monitoring. See golem:llm and golem:embed for more details and durable implementations in this same repository.\n\nThe final deliverables associated with this ticket are:\n\n- **ElevenLabs implementation**: A WASM Component (WASI 0.23), named `tts-elevenlabs.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **AWS Polly implementation**: A WASM Component (WASI 0.23), named `tts-polly.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Google Cloud TTS implementation**: A WASM Component (WASI 0.23), named `tts-google.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Deepgram Aura implementation**: A WASM Component (WASI 0.23), named `tts-deepgram.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n\n**Note**: If you have a strong recommendation to swap out one or two of these with other popular / common TTS providers (such as Azure Cognitive Services Speech, IBM Watson Text to Speech, or OpenAI TTS), then as long as you get permission beforehand, that's okay with me. However, we definitely need ElevenLabs and AWS Polly.\n\nThese components will require runtime configuration, notably API keys, endpoint URLs, authentication credentials, and provider-specific settings. For configuring this information, the components can use environment variables for now (in the future, they will use wasi-runtime-config, but Golem does not support this yet, whereas Golem has good support for environment variables).\n\nMoreover, the Rust components need to be tested within Golem to ensure compatibility with Golem 1.2.x.\n\nThis WIT has been designed by examining and comparing the APIs of ElevenLabs, AWS Polly, Google Cloud TTS, Azure Speech Services, OpenAI TTS, and Deepgram Aura. However, given there are no implementations, it is possible the provided WIT is not the optimal abstraction across all these providers. Therefore, deviations from the proposed design can be made. However, to be accepted, any deviation must be fully justified and deemed by Golem core contributors to be an improvement from the original specification.\n\n## Implementation Guidelines\n\nEach provider implementation should handle the following key mapping considerations:\n\n- **Voice Management**: Map the unified voice resource to provider-specific voice identifiers, handle voice discovery and metadata appropriately for each provider's voice catalog structure\n- **Audio Format Conversion**: Implement native audio format support where available, or provide format conversion for unsupported output formats using audio processing libraries\n- **Streaming Implementation**: Utilize native streaming APIs where supported (ElevenLabs, Deepgram), or implement chunk-based synthesis for providers without native streaming support\n- **Authentication Handling**: Implement appropriate authentication mechanisms (API keys, OAuth, service accounts) per provider requirements\n- **Feature Availability**: Route advanced features (voice cloning, sound effects, speech marks) through provider-native APIs where supported, or return `unsupported-operation` errors for unavailable features\n- **Error Mapping**: Map provider-specific HTTP errors and API responses to the unified `tts-error` enumeration with appropriate context preservation\n- **Rate Limiting**: Handle provider-specific rate limits and quota management, implementing appropriate retry logic and error reporting\n- **Long-form Content**: Implement efficient handling of long-form synthesis using provider-native async operations (AWS Polly) or intelligent chunking strategies\n\n## Testing Requirements\n\nEach implementation must include comprehensive test suites covering:\n- Basic synthesis operations (text-to-speech with various voices and configurations)\n- Voice discovery and metadata retrieval\n- Streaming synthesis lifecycle (session creation, chunk processing, cleanup)\n- Advanced feature testing (voice cloning, sound effects, custom pronunciations where supported)\n- Audio format validation and quality verification\n- Authentication and authorization scenarios\n- Error handling for unsupported operations and malformed inputs\n- Rate limiting and quota management behavior\n- Connection management and retry logic\n- Long-form content synthesis (>5000 characters)\n- Durability semantics verification across operation boundaries\n- Provider-specific feature utilization (lexicons for Polly, voice settings for ElevenLabs, etc.)\n\n## Configuration Requirements\n\nEach implementation should support the following environment variables:\n\n### Common Configuration\n- `TTS_PROVIDER_ENDPOINT`: Custom endpoint URL (for enterprise/regional deployments)\n- `TTS_PROVIDER_TIMEOUT`: Request timeout in seconds (default: 30)\n- `TTS_PROVIDER_MAX_RETRIES`: Maximum retry attempts (default: 3)\n- `TTS_PROVIDER_LOG_LEVEL`: Logging verbosity (debug, info, warn, error)\n\n### Provider-Specific Configuration\n- **ElevenLabs**: `ELEVENLABS_API_KEY`, `ELEVENLABS_MODEL_VERSION`\n- **AWS Polly**: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `AWS_SESSION_TOKEN`\n- **Google Cloud**: `GOOGLE_APPLICATION_CREDENTIALS`, `GOOGLE_CLOUD_PROJECT`\n- **Deepgram**: `DEEPGRAM_API_KEY`, `DEEPGRAM_API_VERSION`\n\n```wit\npackage golem:tts@1.0.0;\n\n/// Core types and error handling for universal text-to-speech\ninterface types {\n    /// Comprehensive error types covering all TTS operations\n    variant tts-error {\n        /// Input validation errors\n        invalid-text(string),\n        text-too-long(u32),\n        invalid-ssml(string),\n        unsupported-language(string),\n        \n        /// Voice and model errors\n        voice-not-found(string),\n        model-not-found(string),\n        voice-unavailable(string),\n        \n        /// Authentication and authorization\n        unauthorized(string),\n        access-denied(string),\n        \n        /// Resource and quota limits\n        quota-exceeded(quota-info),\n        rate-limited(u32),\n        insufficient-credits,\n        \n        /// Operation errors\n        synthesis-failed(string),\n        unsupported-operation(string),\n        invalid-configuration(string),\n        \n        /// Service errors\n        service-unavailable(string),\n        network-error(string),\n        internal-error(string),\n        \n        /// Storage errors (for async operations)\n        invalid-storage-location(string),\n        storage-access-denied(string),\n    }\n\n    record quota-info {\n        used: u32,\n        limit: u32,\n        reset-time: u64,\n        unit: quota-unit,\n    }\n\n    enum quota-unit {\n        characters,\n        requests,\n        seconds,\n        credits,\n    }\n\n    /// Language identification using BCP 47 codes\n    type language-code = string;\n\n    /// Voice gender classification\n    enum voice-gender {\n        male,\n        female,\n        neutral,\n    }\n\n    /// Voice quality tiers\n    enum voice-quality {\n        standard,\n        premium,\n        neural,\n        studio,\n    }\n\n    /// Text input types\n    enum text-type {\n        plain,\n        ssml,\n    }\n\n    /// Audio output formats\n    enum audio-format {\n        mp3,\n        wav,\n        pcm,\n        ogg-opus,\n        aac,\n        flac,\n        mulaw,\n        alaw,\n    }\n\n    /// Audio quality settings\n    record audio-config {\n        format: audio-format,\n        sample-rate: option<u32>,\n        bit-rate: option<u32>,\n        channels: option<u8>,\n    }\n\n    /// Voice synthesis parameters\n    record voice-settings {\n        /// Speaking rate (0.25 to 4.0, default 1.0)\n        speed: option<f32>,\n        /// Pitch adjustment in semitones (-20.0 to 20.0, default 0.0)\n        pitch: option<f32>,\n        /// Volume gain in dB (-96.0 to 16.0, default 0.0)\n        volume: option<f32>,\n        /// Voice stability (0.0 to 1.0, provider-specific)\n        stability: option<f32>,\n        /// Similarity to original (0.0 to 1.0, provider-specific)\n        similarity: option<f32>,\n        /// Style exaggeration (0.0 to 1.0, provider-specific)\n        style: option<f32>,\n    }\n\n    /// Audio effects and device optimization\n    flags audio-effects {\n        telephone-quality,\n        headphone-optimized,\n        speaker-optimized,\n        car-audio-optimized,\n        noise-reduction,\n        bass-boost,\n        treble-boost,\n    }\n\n    /// Input text with metadata\n    record text-input {\n        content: string,\n        text-type: text-type,\n        language: option<language-code>,\n    }\n\n    /// Complete synthesis result\n    record synthesis-result {\n        audio-data: list<u8>,\n        metadata: synthesis-metadata,\n    }\n\n    /// Metadata about synthesized audio\n    record synthesis-metadata {\n        duration-seconds: f32,\n        character-count: u32,\n        word-count: u32,\n        audio-size-bytes: u32,\n        request-id: string,\n        provider-info: option<string>,\n    }\n\n    /// Streaming audio chunk\n    record audio-chunk {\n        data: list<u8>,\n        sequence-number: u32,\n        is-final: bool,\n        timing-info: option<timing-info>,\n    }\n\n    /// Timing and synchronization information\n    record timing-info {\n        start-time-seconds: f32,\n        end-time-seconds: option<f32>,\n        text-offset: option<u32>,\n        mark-type: option<timing-mark-type>,\n    }\n\n    enum timing-mark-type {\n        word,\n        sentence,\n        paragraph,\n        ssml-mark,\n        viseme,\n    }\n\n\n}\n\n/// Voice discovery and management\ninterface voices {\n    use types.{tts-error, language-code, voice-gender, voice-quality};\n\n    /// Represents a voice that can be used for speech synthesis\n    resource voice {\n        /// Get voice identification\n        get-id: func() -> string;\n        get-name: func() -> string;\n        get-provider-id: func() -> option<string>;\n        \n        /// Get voice characteristics\n        get-language: func() -> language-code;\n        get-additional-languages: func() -> list<language-code>;\n        get-gender: func() -> voice-gender;\n        get-quality: func() -> voice-quality;\n        get-description: func() -> option<string>;\n        \n        /// Voice capabilities\n        supports-ssml: func() -> bool;\n        get-sample-rates: func() -> list<u32>;\n        get-supported-formats: func() -> list<types.audio-format>;\n        \n        /// Voice management (may return unsupported-operation)\n        update-settings: func(settings: types.voice-settings) -> result<_, tts-error>;\n        delete: func() -> result<_, tts-error>;\n        clone: func() -> result<voice, tts-error>;\n        \n        /// Preview voice with sample text\n        preview: func(text: string) -> result<list<u8>, tts-error>;\n    }\n\n    /// Voice search and filtering\n    record voice-filter {\n        language: option<language-code>,\n        gender: option<voice-gender>,\n        quality: option<voice-quality>,\n        supports-ssml: option<bool>,\n        provider: option<string>,\n        search-query: option<string>,\n    }\n\n    /// Detailed voice information\n    record voice-info {\n        id: string,\n        name: string,\n        language: language-code,\n        additional-languages: list<language-code>,\n        gender: voice-gender,\n        quality: voice-quality,\n        description: option<string>,\n        provider: string,\n        sample-rate: u32,\n        is-custom: bool,\n        is-cloned: bool,\n        preview-url: option<string>,\n        use-cases: list<string>,\n    }\n\n    /// Resource-based iterator for voice results\n    resource voice-results {\n        /// Check if more voices are available\n        has-more: func() -> bool;\n        \n        /// Get next batch of voices\n        get-next: func() -> result<list<voice-info>, tts-error>;\n        \n        /// Get total count if available\n        get-total-count: func() -> option<u32>;\n    }\n\n    /// List available voices with filtering and pagination\n    list-voices: func(\n        filter: option<voice-filter>\n    ) -> result<voice-results, tts-error>;\n\n    /// Get specific voice by ID\n    get-voice: func(voice-id: string) -> result<voice, tts-error>;\n\n    /// Search voices by characteristics\n    search-voices: func(\n        query: string,\n        filter: option<voice-filter>\n    ) -> result<list<voice-info>, tts-error>;\n\n    /// Get supported languages\n    list-languages: func() -> result<list<language-info>, tts-error>;\n\n    record language-info {\n        code: language-code,\n        name: string,\n        native-name: string,\n        voice-count: u32,\n    }\n}\n\n/// Core text-to-speech synthesis operations\ninterface synthesis {\n    use types.{\n        text-input, audio-config, voice-settings, audio-effects,\n        synthesis-result, tts-error, timing-info\n    };\n    use voices.{voice};\n\n    /// Synthesis configuration options\n    record synthesis-options {\n        audio-config: option<audio-config>,\n        voice-settings: option<voice-settings>,\n        audio-effects: option<audio-effects>,\n        enable-timing: option<bool>,\n        enable-word-timing: option<bool>,\n        seed: option<u32>,\n        model-version: option<string>,\n        context: option<synthesis-context>,\n    }\n\n    /// Context for better synthesis quality\n    record synthesis-context {\n        previous-text: option<string>,\n        next-text: option<string>,\n        topic: option<string>,\n        emotion: option<string>,\n        speaking-style: option<string>,\n    }\n\n    /// Convert text to speech (removed async)\n    synthesize: func(\n        input: text-input,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-result, tts-error>;\n\n    /// Batch synthesis for multiple inputs (removed async)\n    synthesize-batch: func(\n        inputs: list<text-input>,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<list<synthesis-result>, tts-error>;\n\n    /// Get timing information without audio synthesis\n    get-timing-marks: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<list<timing-info>, tts-error>;\n\n    /// Validate text before synthesis\n    validate-input: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<validation-result, tts-error>;\n\n    record validation-result {\n        is-valid: bool,\n        character-count: u32,\n        estimated-duration: option<f32>,\n        warnings: list<string>,\n        errors: list<string>,\n    }\n}\n\n/// Real-time streaming synthesis\ninterface streaming {\n    use types.{\n        text-input, audio-config, voice-settings, audio-chunk,\n        tts-error, timing-info\n    };\n    use voices.{voice};\n    use synthesis.{synthesis-options};\n\n    /// Streaming synthesis session\n    resource synthesis-stream {\n        /// Send text for synthesis (can be called multiple times)\n        send-text: func(input: text-input) -> result<_, tts-error>;\n        \n        /// Signal end of input and flush remaining audio\n        finish: func() -> result<_, tts-error>;\n        \n        /// Receive next audio chunk (non-blocking)\n        receive-chunk: func() -> result<option<audio-chunk>, tts-error>;\n        \n        /// Check if more chunks are available\n        has-pending-audio: func() -> bool;\n        \n        /// Get current stream status\n        get-status: func() -> stream-status;\n        \n        /// Close stream and clean up resources\n        close: func();\n    }\n\n    enum stream-status {\n        ready,\n        processing,\n        finished,\n        error,\n        closed,\n    }\n\n    /// Create streaming synthesis session\n    create-stream: func(\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-stream, tts-error>;\n\n    /// Real-time voice conversion streaming\n    create-voice-conversion-stream: func(\n        target-voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<voice-conversion-stream, tts-error>;\n\n    resource voice-conversion-stream {\n        /// Send input audio chunks\n        send-audio: func(audio-data: list<u8>) -> result<_, tts-error>;\n        \n        /// Receive converted audio chunks\n        receive-converted: func() -> result<option<audio-chunk>, tts-error>;\n        \n        finish: func() -> result<_, tts-error>;\n        close: func();\n    }\n}\n\n/// Advanced TTS features and voice manipulation\ninterface advanced {\n    use types.{tts-error, audio-config, language-code};\n    use voices.{voice};\n\n    /// Voice cloning and creation (removed async)\n    create-voice-clone: func(\n        name: string,\n        audio-samples: list<audio-sample>,\n        description: option<string>\n    ) -> result<voice, tts-error>;\n\n    record audio-sample {\n        data: list<u8>,\n        transcript: option<string>,\n        quality-rating: option<u8>,\n    }\n\n    /// Design synthetic voice (removed async)\n    design-voice: func(\n        name: string,\n        characteristics: voice-design-params\n    ) -> result<voice, tts-error>;\n\n    record voice-design-params {\n        gender: types.voice-gender,\n        age-category: age-category,\n        accent: string,\n        personality-traits: list<string>,\n        reference-voice: option<string>,\n    }\n\n    enum age-category {\n        child,\n        young-adult,\n        middle-aged,\n        elderly,\n    }\n\n    /// Voice-to-voice conversion (removed async)\n    convert-voice: func(\n        input-audio: list<u8>,\n        target-voice: borrow<voice>,\n        preserve-timing: option<bool>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Generate sound effects from text description (removed async)\n    generate-sound-effect: func(\n        description: string,\n        duration-seconds: option<f32>,\n        style-influence: option<f32>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Custom pronunciation management\n    resource pronunciation-lexicon {\n        get-name: func() -> string;\n        get-language: func() -> language-code;\n        get-entry-count: func() -> u32;\n        \n        /// Add pronunciation rule\n        add-entry: func(word: string, pronunciation: string) -> result<_, tts-error>;\n        \n        /// Remove pronunciation rule\n        remove-entry: func(word: string) -> result<_, tts-error>;\n        \n        /// Export lexicon content\n        export-content: func() -> result<string, tts-error>;\n    }\n\n    /// Create custom pronunciation lexicon\n    create-lexicon: func(\n        name: string,\n        language: language-code,\n        entries: option<list<pronunciation-entry>>\n    ) -> result<pronunciation-lexicon, tts-error>;\n\n    record pronunciation-entry {\n        word: string,\n        pronunciation: string,\n        part-of-speech: option<string>,\n    }\n\n    /// Long-form content synthesis with optimization (removed async)\n    synthesize-long-form: func(\n        content: string,\n        voice: borrow<voice>,\n        output-location: string,\n        chapter-breaks: option<list<u32>>\n    ) -> result<long-form-operation, tts-error>;\n\n    resource long-form-operation {\n        get-status: func() -> operation-status;\n        get-progress: func() -> f32;\n        cancel: func() -> result<_, tts-error>;\n        get-result: func() -> result<long-form-result, tts-error>;\n    }\n\n    enum operation-status {\n        pending,\n        processing,\n        completed,\n        failed,\n        cancelled,\n    }\n\n    record long-form-result {\n        output-location: string,\n        total-duration: f32,\n        chapter-durations: option<list<f32>>,\n        metadata: types.synthesis-metadata,\n    }\n}\n```",
              "url": "https://github.com/golemcloud/golem-ai/issues/23",
              "tech": [
                "go"
              ],
              "repo_name": "golem-ai",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "triggerdotdev#2654",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "triggerdotdev",
              "id": "generated-triggerdotdev",
              "name": "Triggerdotdev",
              "description": "",
              "members": [],
              "display_name": "Triggerdotdev",
              "created_at": "2026-02-02T08:08:23.690Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/triggerdotdev?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "colinhacks",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-02T08:08:23.690Z",
            "created_at": "2026-02-02T08:08:23.690Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-triggerdotdev#2654",
              "status": "open",
              "type": "issue",
              "number": 2654,
              "title": "Schema in object being inferred differently (and weirdly)",
              "source": {
                "data": {
                  "id": "source-triggerdotdev#2654",
                  "user": {
                    "login": "ericallam",
                    "id": 534,
                    "node_id": "MDQ6VXNlcjUzNA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/534?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ericallam",
                    "html_url": "https://github.com/ericallam",
                    "followers_url": "https://api.github.com/users/ericallam/followers",
                    "following_url": "https://api.github.com/users/ericallam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ericallam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ericallam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ericallam/subscriptions",
                    "organizations_url": "https://api.github.com/users/ericallam/orgs",
                    "repos_url": "https://api.github.com/users/ericallam/repos",
                    "events_url": "https://api.github.com/users/ericallam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ericallam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Schema in object being inferred differently (and weirdly)",
                  "body": "See the following TS snippet:\r\n\r\n```ts\r\nimport { z } from \"zod\";\r\n\r\nconst EventNameSchema = z.string().or(z.array(z.string()));\r\n\r\ntype EventName = z.infer<typeof EventNameSchema>;\r\n// EventName is string | string[]\r\n\r\nconst EventSchema = z.object({\r\n  name: z.string().or(z.array(z.string())) // this is the same as the EventNameSchema\r\n});\r\n\r\ntype EventWithName = z.infer<typeof EventSchema>;\r\ntype EventName2 = EventWithName[\"name\"];\r\n// EventName2 is (string | string[]) & (string | string[] | undefined)\r\n```\r\n\r\nAnd the TS playground: [link](https://www.typescriptlang.org/play?#code/JYWwDg9gTgLgBAbzgLzgXzgMyhEcBEyEAJvgNwBQFAxhAHYDO8AogG4CmdMAcgIYjsAytQAW7ELzgBeFADomUYHQDmACgCUs6KuSzeUKLwCeO+TEUqN69ZQowjYdnDace-JzN1LM7KAB57RwhMZw4uPgFhMQkAPkoAenjQ1winYAY4BSVlOAAfTPNsgG0AXSpaRhYwmCjxSU8tACMAK3ZqGFUECjg4OncALjksy01tXX1DE11htWt1CjQbKkCnFy4AdWAYEVTpOW9fAId2YOSuWtjKFbO3AQAmPbWYTe3Uovw+gXwShKSn1Ie6TgqhmeQKFmUpXUcAAZMDQfkZqUwQBXOjEdiYJTsYjqIA)\r\n\r\nI'm not sure if this is intended or a bug or maybe just a user error. Using zod `3.21.4` and TS `4.8.4`",
                  "html_url": "https://github.com/colinhacks/zod/issues/2654"
                },
                "type": "github"
              },
              "hash": "colinhacks/zod#2654",
              "body": "See the following TS snippet:\r\n\r\n```ts\r\nimport { z } from \"zod\";\r\n\r\nconst EventNameSchema = z.string().or(z.array(z.string()));\r\n\r\ntype EventName = z.infer<typeof EventNameSchema>;\r\n// EventName is string | string[]\r\n\r\nconst EventSchema = z.object({\r\n  name: z.string().or(z.array(z.string())) // this is the same as the EventNameSchema\r\n});\r\n\r\ntype EventWithName = z.infer<typeof EventSchema>;\r\ntype EventName2 = EventWithName[\"name\"];\r\n// EventName2 is (string | string[]) & (string | string[] | undefined)\r\n```\r\n\r\nAnd the TS playground: [link](https://www.typescriptlang.org/play?#code/JYWwDg9gTgLgBAbzgLzgXzgMyhEcBEyEAJvgNwBQFAxhAHYDO8AogG4CmdMAcgIYjsAytQAW7ELzgBeFADomUYHQDmACgCUs6KuSzeUKLwCeO+TEUqN69ZQowjYdnDace-JzN1LM7KAB57RwhMZw4uPgFhMQkAPkoAenjQ1winYAY4BSVlOAAfTPNsgG0AXSpaRhYwmCjxSU8tACMAK3ZqGFUECjg4OncALjksy01tXX1DE11htWt1CjQbKkCnFy4AdWAYEVTpOW9fAId2YOSuWtjKFbO3AQAmPbWYTe3Uovw+gXwShKSn1Ie6TgqhmeQKFmUpXUcAAZMDQfkZqUwQBXOjEdiYJTsYjqIA)\r\n\r\nI'm not sure if this is intended or a bug or maybe just a user error. Using zod `3.21.4` and TS `4.8.4`",
              "url": "https://github.com/colinhacks/zod/issues/2654",
              "tech": [],
              "repo_name": "zod",
              "repo_owner": "colinhacks",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "outerbase#59",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2026-02-02T08:08:23.779Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-02T08:08:23.779Z",
            "created_at": "2026-02-02T08:08:23.779Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#59",
              "status": "open",
              "type": "issue",
              "number": 59,
              "title": "Database dumps do not work on large databases",
              "source": {
                "data": {
                  "id": "source-outerbase#59",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Database dumps do not work on large databases",
                  "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/59"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#59",
              "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
              "url": "https://github.com/outerbase/starbasedb/issues/59",
              "tech": [],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "outerbase#72",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2026-02-02T08:08:24.123Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-02T08:08:24.123Z",
            "created_at": "2026-02-02T08:08:24.123Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#72",
              "status": "open",
              "type": "issue",
              "number": 72,
              "title": "Replicate data from external source to internal source with a Plugin",
              "source": {
                "data": {
                  "id": "source-outerbase#72",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Replicate data from external source to internal source with a Plugin",
                  "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/72"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#72",
              "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
              "url": "https://github.com/outerbase/starbasedb/issues/72",
              "tech": [],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "golemcloud#275",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "golemcloud",
              "id": "generated-golemcloud",
              "name": "Golemcloud",
              "description": "",
              "members": [],
              "display_name": "Golemcloud",
              "created_at": "2026-02-02T08:08:24.110Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/golemcloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-02T08:08:24.110Z",
            "created_at": "2026-02-02T08:08:24.110Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-golemcloud#275",
              "status": "open",
              "type": "issue",
              "number": 275,
              "title": "Incorporate MCP Server into Golem CLI",
              "source": {
                "data": {
                  "id": "source-golemcloud#275",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Incorporate MCP Server into Golem CLI",
                  "body": "With a new command, Golem CLI enters serve mode:\n\n```bash\n%> golem-cli --serve --serve-port 1232\n%> golem-cli running MCP Server at port 1232\n```\n\nIn this mode, Golem CLI creates an MCP Server that exposes different commands as different tools, and exposes relevant resources (the manifest file in the current, ancestor, and children directories) as resources.\n\nWhen this ticket is completed, it should be possible to use an agent such as Claude Code to perform anything that Golem CLI can do. Moreover, all individual tools and resources must be end-to-end tested with an MCP Client that interacts with the MCP Server.\n\n[This library](https://github.com/rust-mcp-stack/rust-mcp-sdk) looks like the one to use for Rust, but perhaps there are better options available.",
                  "html_url": "https://github.com/golemcloud/golem/issues/1926"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem-cli#275",
              "body": "With a new command, Golem CLI enters serve mode:\n\n```bash\n%> golem-cli --serve --serve-port 1232\n%> golem-cli running MCP Server at port 1232\n```\n\nIn this mode, Golem CLI creates an MCP Server that exposes different commands as different tools, and exposes relevant resources (the manifest file in the current, ancestor, and children directories) as resources.\n\nWhen this ticket is completed, it should be possible to use an agent such as Claude Code to perform anything that Golem CLI can do. Moreover, all individual tools and resources must be end-to-end tested with an MCP Client that interacts with the MCP Server.\n\n[This library](https://github.com/rust-mcp-stack/rust-mcp-sdk) looks like the one to use for Rust, but perhaps there are better options available.",
              "url": "https://github.com/golemcloud/golem/issues/1926",
              "tech": [
                "go"
              ],
              "repo_name": "golem-cli",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "golemcloud#23",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "golemcloud",
              "id": "generated-golemcloud",
              "name": "Golemcloud",
              "description": "",
              "members": [],
              "display_name": "Golemcloud",
              "created_at": "2026-02-02T08:08:24.206Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/golemcloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-02T08:08:24.206Z",
            "created_at": "2026-02-02T08:08:24.206Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-golemcloud#23",
              "status": "open",
              "type": "issue",
              "number": 23,
              "title": "Implement Durable Text-to-Speech Provider Components for golem:tts WIT Interface",
              "source": {
                "data": {
                  "id": "source-golemcloud#23",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Implement Durable Text-to-Speech Provider Components for golem:tts WIT Interface",
                  "body": "I have attached to this ticket a WIT file that describes a generic interface for text-to-speech operations. This interface can be implemented by various providers, either by emulating features not present in a given provider, utilizing the provider's native support for a feature, or indicating an error if a particular combination is not natively supported by a provider.\n\nThe intent of this WIT specification is to allow developers of WASM components (on wasmCloud, Spin, or Golem) to leverage text-to-speech capabilities to build voice-powered applications, accessibility services, and audio content generation systems in a portable and provider-agnostic fashion.\n\nThis ticket involves constructing implementations of this WIT interface for the following providers:\n\n- **ElevenLabs**: The leading AI voice synthesis platform with comprehensive voice cloning, real-time streaming, voice conversion, and sound effects generation capabilities.\n- **AWS Polly**: Amazon's enterprise text-to-speech service with extensive language support, custom lexicons, speech marks, and asynchronous synthesis for long-form content.\n- **Google Cloud Text-to-Speech**: Google's neural voice synthesis service with WaveNet and Neural2 voices, device optimization profiles, and streaming synthesis capabilities.\n- **Deepgram Aura**: High-performance real-time TTS with session-based streaming, low-latency neural voices, and conversational AI optimization.\n\nThese implementations must be written in Rust and compilable to WASM Components (WASI 0.23 only, since Golem does not yet support WASI 0.3). The standard Rust toolchain for WASM component development can be employed (see cargo component and the Rust examples of components in this and other Golem repositories).\n\nAdditionally, these implementations should incorporate custom durability semantics using the Golem durability API and the Golem host API. This approach ensures that durability is managed at the level of individual TTS operations (voice synthesis, streaming session creation, voice cloning, batch processing), providing a higher-level and clearer operation log, which aids in debugging and monitoring. See golem:llm and golem:embed for more details and durable implementations in this same repository.\n\nThe final deliverables associated with this ticket are:\n\n- **ElevenLabs implementation**: A WASM Component (WASI 0.23), named `tts-elevenlabs.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **AWS Polly implementation**: A WASM Component (WASI 0.23), named `tts-polly.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Google Cloud TTS implementation**: A WASM Component (WASI 0.23), named `tts-google.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Deepgram Aura implementation**: A WASM Component (WASI 0.23), named `tts-deepgram.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n\n**Note**: If you have a strong recommendation to swap out one or two of these with other popular / common TTS providers (such as Azure Cognitive Services Speech, IBM Watson Text to Speech, or OpenAI TTS), then as long as you get permission beforehand, that's okay with me. However, we definitely need ElevenLabs and AWS Polly.\n\nThese components will require runtime configuration, notably API keys, endpoint URLs, authentication credentials, and provider-specific settings. For configuring this information, the components can use environment variables for now (in the future, they will use wasi-runtime-config, but Golem does not support this yet, whereas Golem has good support for environment variables).\n\nMoreover, the Rust components need to be tested within Golem to ensure compatibility with Golem 1.2.x.\n\nThis WIT has been designed by examining and comparing the APIs of ElevenLabs, AWS Polly, Google Cloud TTS, Azure Speech Services, OpenAI TTS, and Deepgram Aura. However, given there are no implementations, it is possible the provided WIT is not the optimal abstraction across all these providers. Therefore, deviations from the proposed design can be made. However, to be accepted, any deviation must be fully justified and deemed by Golem core contributors to be an improvement from the original specification.\n\n## Implementation Guidelines\n\nEach provider implementation should handle the following key mapping considerations:\n\n- **Voice Management**: Map the unified voice resource to provider-specific voice identifiers, handle voice discovery and metadata appropriately for each provider's voice catalog structure\n- **Audio Format Conversion**: Implement native audio format support where available, or provide format conversion for unsupported output formats using audio processing libraries\n- **Streaming Implementation**: Utilize native streaming APIs where supported (ElevenLabs, Deepgram), or implement chunk-based synthesis for providers without native streaming support\n- **Authentication Handling**: Implement appropriate authentication mechanisms (API keys, OAuth, service accounts) per provider requirements\n- **Feature Availability**: Route advanced features (voice cloning, sound effects, speech marks) through provider-native APIs where supported, or return `unsupported-operation` errors for unavailable features\n- **Error Mapping**: Map provider-specific HTTP errors and API responses to the unified `tts-error` enumeration with appropriate context preservation\n- **Rate Limiting**: Handle provider-specific rate limits and quota management, implementing appropriate retry logic and error reporting\n- **Long-form Content**: Implement efficient handling of long-form synthesis using provider-native async operations (AWS Polly) or intelligent chunking strategies\n\n## Testing Requirements\n\nEach implementation must include comprehensive test suites covering:\n- Basic synthesis operations (text-to-speech with various voices and configurations)\n- Voice discovery and metadata retrieval\n- Streaming synthesis lifecycle (session creation, chunk processing, cleanup)\n- Advanced feature testing (voice cloning, sound effects, custom pronunciations where supported)\n- Audio format validation and quality verification\n- Authentication and authorization scenarios\n- Error handling for unsupported operations and malformed inputs\n- Rate limiting and quota management behavior\n- Connection management and retry logic\n- Long-form content synthesis (>5000 characters)\n- Durability semantics verification across operation boundaries\n- Provider-specific feature utilization (lexicons for Polly, voice settings for ElevenLabs, etc.)\n\n## Configuration Requirements\n\nEach implementation should support the following environment variables:\n\n### Common Configuration\n- `TTS_PROVIDER_ENDPOINT`: Custom endpoint URL (for enterprise/regional deployments)\n- `TTS_PROVIDER_TIMEOUT`: Request timeout in seconds (default: 30)\n- `TTS_PROVIDER_MAX_RETRIES`: Maximum retry attempts (default: 3)\n- `TTS_PROVIDER_LOG_LEVEL`: Logging verbosity (debug, info, warn, error)\n\n### Provider-Specific Configuration\n- **ElevenLabs**: `ELEVENLABS_API_KEY`, `ELEVENLABS_MODEL_VERSION`\n- **AWS Polly**: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `AWS_SESSION_TOKEN`\n- **Google Cloud**: `GOOGLE_APPLICATION_CREDENTIALS`, `GOOGLE_CLOUD_PROJECT`\n- **Deepgram**: `DEEPGRAM_API_KEY`, `DEEPGRAM_API_VERSION`\n\n```wit\npackage golem:tts@1.0.0;\n\n/// Core types and error handling for universal text-to-speech\ninterface types {\n    /// Comprehensive error types covering all TTS operations\n    variant tts-error {\n        /// Input validation errors\n        invalid-text(string),\n        text-too-long(u32),\n        invalid-ssml(string),\n        unsupported-language(string),\n        \n        /// Voice and model errors\n        voice-not-found(string),\n        model-not-found(string),\n        voice-unavailable(string),\n        \n        /// Authentication and authorization\n        unauthorized(string),\n        access-denied(string),\n        \n        /// Resource and quota limits\n        quota-exceeded(quota-info),\n        rate-limited(u32),\n        insufficient-credits,\n        \n        /// Operation errors\n        synthesis-failed(string),\n        unsupported-operation(string),\n        invalid-configuration(string),\n        \n        /// Service errors\n        service-unavailable(string),\n        network-error(string),\n        internal-error(string),\n        \n        /// Storage errors (for async operations)\n        invalid-storage-location(string),\n        storage-access-denied(string),\n    }\n\n    record quota-info {\n        used: u32,\n        limit: u32,\n        reset-time: u64,\n        unit: quota-unit,\n    }\n\n    enum quota-unit {\n        characters,\n        requests,\n        seconds,\n        credits,\n    }\n\n    /// Language identification using BCP 47 codes\n    type language-code = string;\n\n    /// Voice gender classification\n    enum voice-gender {\n        male,\n        female,\n        neutral,\n    }\n\n    /// Voice quality tiers\n    enum voice-quality {\n        standard,\n        premium,\n        neural,\n        studio,\n    }\n\n    /// Text input types\n    enum text-type {\n        plain,\n        ssml,\n    }\n\n    /// Audio output formats\n    enum audio-format {\n        mp3,\n        wav,\n        pcm,\n        ogg-opus,\n        aac,\n        flac,\n        mulaw,\n        alaw,\n    }\n\n    /// Audio quality settings\n    record audio-config {\n        format: audio-format,\n        sample-rate: option<u32>,\n        bit-rate: option<u32>,\n        channels: option<u8>,\n    }\n\n    /// Voice synthesis parameters\n    record voice-settings {\n        /// Speaking rate (0.25 to 4.0, default 1.0)\n        speed: option<f32>,\n        /// Pitch adjustment in semitones (-20.0 to 20.0, default 0.0)\n        pitch: option<f32>,\n        /// Volume gain in dB (-96.0 to 16.0, default 0.0)\n        volume: option<f32>,\n        /// Voice stability (0.0 to 1.0, provider-specific)\n        stability: option<f32>,\n        /// Similarity to original (0.0 to 1.0, provider-specific)\n        similarity: option<f32>,\n        /// Style exaggeration (0.0 to 1.0, provider-specific)\n        style: option<f32>,\n    }\n\n    /// Audio effects and device optimization\n    flags audio-effects {\n        telephone-quality,\n        headphone-optimized,\n        speaker-optimized,\n        car-audio-optimized,\n        noise-reduction,\n        bass-boost,\n        treble-boost,\n    }\n\n    /// Input text with metadata\n    record text-input {\n        content: string,\n        text-type: text-type,\n        language: option<language-code>,\n    }\n\n    /// Complete synthesis result\n    record synthesis-result {\n        audio-data: list<u8>,\n        metadata: synthesis-metadata,\n    }\n\n    /// Metadata about synthesized audio\n    record synthesis-metadata {\n        duration-seconds: f32,\n        character-count: u32,\n        word-count: u32,\n        audio-size-bytes: u32,\n        request-id: string,\n        provider-info: option<string>,\n    }\n\n    /// Streaming audio chunk\n    record audio-chunk {\n        data: list<u8>,\n        sequence-number: u32,\n        is-final: bool,\n        timing-info: option<timing-info>,\n    }\n\n    /// Timing and synchronization information\n    record timing-info {\n        start-time-seconds: f32,\n        end-time-seconds: option<f32>,\n        text-offset: option<u32>,\n        mark-type: option<timing-mark-type>,\n    }\n\n    enum timing-mark-type {\n        word,\n        sentence,\n        paragraph,\n        ssml-mark,\n        viseme,\n    }\n\n\n}\n\n/// Voice discovery and management\ninterface voices {\n    use types.{tts-error, language-code, voice-gender, voice-quality};\n\n    /// Represents a voice that can be used for speech synthesis\n    resource voice {\n        /// Get voice identification\n        get-id: func() -> string;\n        get-name: func() -> string;\n        get-provider-id: func() -> option<string>;\n        \n        /// Get voice characteristics\n        get-language: func() -> language-code;\n        get-additional-languages: func() -> list<language-code>;\n        get-gender: func() -> voice-gender;\n        get-quality: func() -> voice-quality;\n        get-description: func() -> option<string>;\n        \n        /// Voice capabilities\n        supports-ssml: func() -> bool;\n        get-sample-rates: func() -> list<u32>;\n        get-supported-formats: func() -> list<types.audio-format>;\n        \n        /// Voice management (may return unsupported-operation)\n        update-settings: func(settings: types.voice-settings) -> result<_, tts-error>;\n        delete: func() -> result<_, tts-error>;\n        clone: func() -> result<voice, tts-error>;\n        \n        /// Preview voice with sample text\n        preview: func(text: string) -> result<list<u8>, tts-error>;\n    }\n\n    /// Voice search and filtering\n    record voice-filter {\n        language: option<language-code>,\n        gender: option<voice-gender>,\n        quality: option<voice-quality>,\n        supports-ssml: option<bool>,\n        provider: option<string>,\n        search-query: option<string>,\n    }\n\n    /// Detailed voice information\n    record voice-info {\n        id: string,\n        name: string,\n        language: language-code,\n        additional-languages: list<language-code>,\n        gender: voice-gender,\n        quality: voice-quality,\n        description: option<string>,\n        provider: string,\n        sample-rate: u32,\n        is-custom: bool,\n        is-cloned: bool,\n        preview-url: option<string>,\n        use-cases: list<string>,\n    }\n\n    /// Resource-based iterator for voice results\n    resource voice-results {\n        /// Check if more voices are available\n        has-more: func() -> bool;\n        \n        /// Get next batch of voices\n        get-next: func() -> result<list<voice-info>, tts-error>;\n        \n        /// Get total count if available\n        get-total-count: func() -> option<u32>;\n    }\n\n    /// List available voices with filtering and pagination\n    list-voices: func(\n        filter: option<voice-filter>\n    ) -> result<voice-results, tts-error>;\n\n    /// Get specific voice by ID\n    get-voice: func(voice-id: string) -> result<voice, tts-error>;\n\n    /// Search voices by characteristics\n    search-voices: func(\n        query: string,\n        filter: option<voice-filter>\n    ) -> result<list<voice-info>, tts-error>;\n\n    /// Get supported languages\n    list-languages: func() -> result<list<language-info>, tts-error>;\n\n    record language-info {\n        code: language-code,\n        name: string,\n        native-name: string,\n        voice-count: u32,\n    }\n}\n\n/// Core text-to-speech synthesis operations\ninterface synthesis {\n    use types.{\n        text-input, audio-config, voice-settings, audio-effects,\n        synthesis-result, tts-error, timing-info\n    };\n    use voices.{voice};\n\n    /// Synthesis configuration options\n    record synthesis-options {\n        audio-config: option<audio-config>,\n        voice-settings: option<voice-settings>,\n        audio-effects: option<audio-effects>,\n        enable-timing: option<bool>,\n        enable-word-timing: option<bool>,\n        seed: option<u32>,\n        model-version: option<string>,\n        context: option<synthesis-context>,\n    }\n\n    /// Context for better synthesis quality\n    record synthesis-context {\n        previous-text: option<string>,\n        next-text: option<string>,\n        topic: option<string>,\n        emotion: option<string>,\n        speaking-style: option<string>,\n    }\n\n    /// Convert text to speech (removed async)\n    synthesize: func(\n        input: text-input,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-result, tts-error>;\n\n    /// Batch synthesis for multiple inputs (removed async)\n    synthesize-batch: func(\n        inputs: list<text-input>,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<list<synthesis-result>, tts-error>;\n\n    /// Get timing information without audio synthesis\n    get-timing-marks: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<list<timing-info>, tts-error>;\n\n    /// Validate text before synthesis\n    validate-input: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<validation-result, tts-error>;\n\n    record validation-result {\n        is-valid: bool,\n        character-count: u32,\n        estimated-duration: option<f32>,\n        warnings: list<string>,\n        errors: list<string>,\n    }\n}\n\n/// Real-time streaming synthesis\ninterface streaming {\n    use types.{\n        text-input, audio-config, voice-settings, audio-chunk,\n        tts-error, timing-info\n    };\n    use voices.{voice};\n    use synthesis.{synthesis-options};\n\n    /// Streaming synthesis session\n    resource synthesis-stream {\n        /// Send text for synthesis (can be called multiple times)\n        send-text: func(input: text-input) -> result<_, tts-error>;\n        \n        /// Signal end of input and flush remaining audio\n        finish: func() -> result<_, tts-error>;\n        \n        /// Receive next audio chunk (non-blocking)\n        receive-chunk: func() -> result<option<audio-chunk>, tts-error>;\n        \n        /// Check if more chunks are available\n        has-pending-audio: func() -> bool;\n        \n        /// Get current stream status\n        get-status: func() -> stream-status;\n        \n        /// Close stream and clean up resources\n        close: func();\n    }\n\n    enum stream-status {\n        ready,\n        processing,\n        finished,\n        error,\n        closed,\n    }\n\n    /// Create streaming synthesis session\n    create-stream: func(\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-stream, tts-error>;\n\n    /// Real-time voice conversion streaming\n    create-voice-conversion-stream: func(\n        target-voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<voice-conversion-stream, tts-error>;\n\n    resource voice-conversion-stream {\n        /// Send input audio chunks\n        send-audio: func(audio-data: list<u8>) -> result<_, tts-error>;\n        \n        /// Receive converted audio chunks\n        receive-converted: func() -> result<option<audio-chunk>, tts-error>;\n        \n        finish: func() -> result<_, tts-error>;\n        close: func();\n    }\n}\n\n/// Advanced TTS features and voice manipulation\ninterface advanced {\n    use types.{tts-error, audio-config, language-code};\n    use voices.{voice};\n\n    /// Voice cloning and creation (removed async)\n    create-voice-clone: func(\n        name: string,\n        audio-samples: list<audio-sample>,\n        description: option<string>\n    ) -> result<voice, tts-error>;\n\n    record audio-sample {\n        data: list<u8>,\n        transcript: option<string>,\n        quality-rating: option<u8>,\n    }\n\n    /// Design synthetic voice (removed async)\n    design-voice: func(\n        name: string,\n        characteristics: voice-design-params\n    ) -> result<voice, tts-error>;\n\n    record voice-design-params {\n        gender: types.voice-gender,\n        age-category: age-category,\n        accent: string,\n        personality-traits: list<string>,\n        reference-voice: option<string>,\n    }\n\n    enum age-category {\n        child,\n        young-adult,\n        middle-aged,\n        elderly,\n    }\n\n    /// Voice-to-voice conversion (removed async)\n    convert-voice: func(\n        input-audio: list<u8>,\n        target-voice: borrow<voice>,\n        preserve-timing: option<bool>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Generate sound effects from text description (removed async)\n    generate-sound-effect: func(\n        description: string,\n        duration-seconds: option<f32>,\n        style-influence: option<f32>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Custom pronunciation management\n    resource pronunciation-lexicon {\n        get-name: func() -> string;\n        get-language: func() -> language-code;\n        get-entry-count: func() -> u32;\n        \n        /// Add pronunciation rule\n        add-entry: func(word: string, pronunciation: string) -> result<_, tts-error>;\n        \n        /// Remove pronunciation rule\n        remove-entry: func(word: string) -> result<_, tts-error>;\n        \n        /// Export lexicon content\n        export-content: func() -> result<string, tts-error>;\n    }\n\n    /// Create custom pronunciation lexicon\n    create-lexicon: func(\n        name: string,\n        language: language-code,\n        entries: option<list<pronunciation-entry>>\n    ) -> result<pronunciation-lexicon, tts-error>;\n\n    record pronunciation-entry {\n        word: string,\n        pronunciation: string,\n        part-of-speech: option<string>,\n    }\n\n    /// Long-form content synthesis with optimization (removed async)\n    synthesize-long-form: func(\n        content: string,\n        voice: borrow<voice>,\n        output-location: string,\n        chapter-breaks: option<list<u32>>\n    ) -> result<long-form-operation, tts-error>;\n\n    resource long-form-operation {\n        get-status: func() -> operation-status;\n        get-progress: func() -> f32;\n        cancel: func() -> result<_, tts-error>;\n        get-result: func() -> result<long-form-result, tts-error>;\n    }\n\n    enum operation-status {\n        pending,\n        processing,\n        completed,\n        failed,\n        cancelled,\n    }\n\n    record long-form-result {\n        output-location: string,\n        total-duration: f32,\n        chapter-durations: option<list<f32>>,\n        metadata: types.synthesis-metadata,\n    }\n}\n```",
                  "html_url": "https://github.com/golemcloud/golem-ai/issues/23"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem-ai#23",
              "body": "I have attached to this ticket a WIT file that describes a generic interface for text-to-speech operations. This interface can be implemented by various providers, either by emulating features not present in a given provider, utilizing the provider's native support for a feature, or indicating an error if a particular combination is not natively supported by a provider.\n\nThe intent of this WIT specification is to allow developers of WASM components (on wasmCloud, Spin, or Golem) to leverage text-to-speech capabilities to build voice-powered applications, accessibility services, and audio content generation systems in a portable and provider-agnostic fashion.\n\nThis ticket involves constructing implementations of this WIT interface for the following providers:\n\n- **ElevenLabs**: The leading AI voice synthesis platform with comprehensive voice cloning, real-time streaming, voice conversion, and sound effects generation capabilities.\n- **AWS Polly**: Amazon's enterprise text-to-speech service with extensive language support, custom lexicons, speech marks, and asynchronous synthesis for long-form content.\n- **Google Cloud Text-to-Speech**: Google's neural voice synthesis service with WaveNet and Neural2 voices, device optimization profiles, and streaming synthesis capabilities.\n- **Deepgram Aura**: High-performance real-time TTS with session-based streaming, low-latency neural voices, and conversational AI optimization.\n\nThese implementations must be written in Rust and compilable to WASM Components (WASI 0.23 only, since Golem does not yet support WASI 0.3). The standard Rust toolchain for WASM component development can be employed (see cargo component and the Rust examples of components in this and other Golem repositories).\n\nAdditionally, these implementations should incorporate custom durability semantics using the Golem durability API and the Golem host API. This approach ensures that durability is managed at the level of individual TTS operations (voice synthesis, streaming session creation, voice cloning, batch processing), providing a higher-level and clearer operation log, which aids in debugging and monitoring. See golem:llm and golem:embed for more details and durable implementations in this same repository.\n\nThe final deliverables associated with this ticket are:\n\n- **ElevenLabs implementation**: A WASM Component (WASI 0.23), named `tts-elevenlabs.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **AWS Polly implementation**: A WASM Component (WASI 0.23), named `tts-polly.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Google Cloud TTS implementation**: A WASM Component (WASI 0.23), named `tts-google.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n- **Deepgram Aura implementation**: A WASM Component (WASI 0.23), named `tts-deepgram.wasm`, with a full test suite and custom durability implementation at the level of TTS operations.\n\n**Note**: If you have a strong recommendation to swap out one or two of these with other popular / common TTS providers (such as Azure Cognitive Services Speech, IBM Watson Text to Speech, or OpenAI TTS), then as long as you get permission beforehand, that's okay with me. However, we definitely need ElevenLabs and AWS Polly.\n\nThese components will require runtime configuration, notably API keys, endpoint URLs, authentication credentials, and provider-specific settings. For configuring this information, the components can use environment variables for now (in the future, they will use wasi-runtime-config, but Golem does not support this yet, whereas Golem has good support for environment variables).\n\nMoreover, the Rust components need to be tested within Golem to ensure compatibility with Golem 1.2.x.\n\nThis WIT has been designed by examining and comparing the APIs of ElevenLabs, AWS Polly, Google Cloud TTS, Azure Speech Services, OpenAI TTS, and Deepgram Aura. However, given there are no implementations, it is possible the provided WIT is not the optimal abstraction across all these providers. Therefore, deviations from the proposed design can be made. However, to be accepted, any deviation must be fully justified and deemed by Golem core contributors to be an improvement from the original specification.\n\n## Implementation Guidelines\n\nEach provider implementation should handle the following key mapping considerations:\n\n- **Voice Management**: Map the unified voice resource to provider-specific voice identifiers, handle voice discovery and metadata appropriately for each provider's voice catalog structure\n- **Audio Format Conversion**: Implement native audio format support where available, or provide format conversion for unsupported output formats using audio processing libraries\n- **Streaming Implementation**: Utilize native streaming APIs where supported (ElevenLabs, Deepgram), or implement chunk-based synthesis for providers without native streaming support\n- **Authentication Handling**: Implement appropriate authentication mechanisms (API keys, OAuth, service accounts) per provider requirements\n- **Feature Availability**: Route advanced features (voice cloning, sound effects, speech marks) through provider-native APIs where supported, or return `unsupported-operation` errors for unavailable features\n- **Error Mapping**: Map provider-specific HTTP errors and API responses to the unified `tts-error` enumeration with appropriate context preservation\n- **Rate Limiting**: Handle provider-specific rate limits and quota management, implementing appropriate retry logic and error reporting\n- **Long-form Content**: Implement efficient handling of long-form synthesis using provider-native async operations (AWS Polly) or intelligent chunking strategies\n\n## Testing Requirements\n\nEach implementation must include comprehensive test suites covering:\n- Basic synthesis operations (text-to-speech with various voices and configurations)\n- Voice discovery and metadata retrieval\n- Streaming synthesis lifecycle (session creation, chunk processing, cleanup)\n- Advanced feature testing (voice cloning, sound effects, custom pronunciations where supported)\n- Audio format validation and quality verification\n- Authentication and authorization scenarios\n- Error handling for unsupported operations and malformed inputs\n- Rate limiting and quota management behavior\n- Connection management and retry logic\n- Long-form content synthesis (>5000 characters)\n- Durability semantics verification across operation boundaries\n- Provider-specific feature utilization (lexicons for Polly, voice settings for ElevenLabs, etc.)\n\n## Configuration Requirements\n\nEach implementation should support the following environment variables:\n\n### Common Configuration\n- `TTS_PROVIDER_ENDPOINT`: Custom endpoint URL (for enterprise/regional deployments)\n- `TTS_PROVIDER_TIMEOUT`: Request timeout in seconds (default: 30)\n- `TTS_PROVIDER_MAX_RETRIES`: Maximum retry attempts (default: 3)\n- `TTS_PROVIDER_LOG_LEVEL`: Logging verbosity (debug, info, warn, error)\n\n### Provider-Specific Configuration\n- **ElevenLabs**: `ELEVENLABS_API_KEY`, `ELEVENLABS_MODEL_VERSION`\n- **AWS Polly**: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `AWS_SESSION_TOKEN`\n- **Google Cloud**: `GOOGLE_APPLICATION_CREDENTIALS`, `GOOGLE_CLOUD_PROJECT`\n- **Deepgram**: `DEEPGRAM_API_KEY`, `DEEPGRAM_API_VERSION`\n\n```wit\npackage golem:tts@1.0.0;\n\n/// Core types and error handling for universal text-to-speech\ninterface types {\n    /// Comprehensive error types covering all TTS operations\n    variant tts-error {\n        /// Input validation errors\n        invalid-text(string),\n        text-too-long(u32),\n        invalid-ssml(string),\n        unsupported-language(string),\n        \n        /// Voice and model errors\n        voice-not-found(string),\n        model-not-found(string),\n        voice-unavailable(string),\n        \n        /// Authentication and authorization\n        unauthorized(string),\n        access-denied(string),\n        \n        /// Resource and quota limits\n        quota-exceeded(quota-info),\n        rate-limited(u32),\n        insufficient-credits,\n        \n        /// Operation errors\n        synthesis-failed(string),\n        unsupported-operation(string),\n        invalid-configuration(string),\n        \n        /// Service errors\n        service-unavailable(string),\n        network-error(string),\n        internal-error(string),\n        \n        /// Storage errors (for async operations)\n        invalid-storage-location(string),\n        storage-access-denied(string),\n    }\n\n    record quota-info {\n        used: u32,\n        limit: u32,\n        reset-time: u64,\n        unit: quota-unit,\n    }\n\n    enum quota-unit {\n        characters,\n        requests,\n        seconds,\n        credits,\n    }\n\n    /// Language identification using BCP 47 codes\n    type language-code = string;\n\n    /// Voice gender classification\n    enum voice-gender {\n        male,\n        female,\n        neutral,\n    }\n\n    /// Voice quality tiers\n    enum voice-quality {\n        standard,\n        premium,\n        neural,\n        studio,\n    }\n\n    /// Text input types\n    enum text-type {\n        plain,\n        ssml,\n    }\n\n    /// Audio output formats\n    enum audio-format {\n        mp3,\n        wav,\n        pcm,\n        ogg-opus,\n        aac,\n        flac,\n        mulaw,\n        alaw,\n    }\n\n    /// Audio quality settings\n    record audio-config {\n        format: audio-format,\n        sample-rate: option<u32>,\n        bit-rate: option<u32>,\n        channels: option<u8>,\n    }\n\n    /// Voice synthesis parameters\n    record voice-settings {\n        /// Speaking rate (0.25 to 4.0, default 1.0)\n        speed: option<f32>,\n        /// Pitch adjustment in semitones (-20.0 to 20.0, default 0.0)\n        pitch: option<f32>,\n        /// Volume gain in dB (-96.0 to 16.0, default 0.0)\n        volume: option<f32>,\n        /// Voice stability (0.0 to 1.0, provider-specific)\n        stability: option<f32>,\n        /// Similarity to original (0.0 to 1.0, provider-specific)\n        similarity: option<f32>,\n        /// Style exaggeration (0.0 to 1.0, provider-specific)\n        style: option<f32>,\n    }\n\n    /// Audio effects and device optimization\n    flags audio-effects {\n        telephone-quality,\n        headphone-optimized,\n        speaker-optimized,\n        car-audio-optimized,\n        noise-reduction,\n        bass-boost,\n        treble-boost,\n    }\n\n    /// Input text with metadata\n    record text-input {\n        content: string,\n        text-type: text-type,\n        language: option<language-code>,\n    }\n\n    /// Complete synthesis result\n    record synthesis-result {\n        audio-data: list<u8>,\n        metadata: synthesis-metadata,\n    }\n\n    /// Metadata about synthesized audio\n    record synthesis-metadata {\n        duration-seconds: f32,\n        character-count: u32,\n        word-count: u32,\n        audio-size-bytes: u32,\n        request-id: string,\n        provider-info: option<string>,\n    }\n\n    /// Streaming audio chunk\n    record audio-chunk {\n        data: list<u8>,\n        sequence-number: u32,\n        is-final: bool,\n        timing-info: option<timing-info>,\n    }\n\n    /// Timing and synchronization information\n    record timing-info {\n        start-time-seconds: f32,\n        end-time-seconds: option<f32>,\n        text-offset: option<u32>,\n        mark-type: option<timing-mark-type>,\n    }\n\n    enum timing-mark-type {\n        word,\n        sentence,\n        paragraph,\n        ssml-mark,\n        viseme,\n    }\n\n\n}\n\n/// Voice discovery and management\ninterface voices {\n    use types.{tts-error, language-code, voice-gender, voice-quality};\n\n    /// Represents a voice that can be used for speech synthesis\n    resource voice {\n        /// Get voice identification\n        get-id: func() -> string;\n        get-name: func() -> string;\n        get-provider-id: func() -> option<string>;\n        \n        /// Get voice characteristics\n        get-language: func() -> language-code;\n        get-additional-languages: func() -> list<language-code>;\n        get-gender: func() -> voice-gender;\n        get-quality: func() -> voice-quality;\n        get-description: func() -> option<string>;\n        \n        /// Voice capabilities\n        supports-ssml: func() -> bool;\n        get-sample-rates: func() -> list<u32>;\n        get-supported-formats: func() -> list<types.audio-format>;\n        \n        /// Voice management (may return unsupported-operation)\n        update-settings: func(settings: types.voice-settings) -> result<_, tts-error>;\n        delete: func() -> result<_, tts-error>;\n        clone: func() -> result<voice, tts-error>;\n        \n        /// Preview voice with sample text\n        preview: func(text: string) -> result<list<u8>, tts-error>;\n    }\n\n    /// Voice search and filtering\n    record voice-filter {\n        language: option<language-code>,\n        gender: option<voice-gender>,\n        quality: option<voice-quality>,\n        supports-ssml: option<bool>,\n        provider: option<string>,\n        search-query: option<string>,\n    }\n\n    /// Detailed voice information\n    record voice-info {\n        id: string,\n        name: string,\n        language: language-code,\n        additional-languages: list<language-code>,\n        gender: voice-gender,\n        quality: voice-quality,\n        description: option<string>,\n        provider: string,\n        sample-rate: u32,\n        is-custom: bool,\n        is-cloned: bool,\n        preview-url: option<string>,\n        use-cases: list<string>,\n    }\n\n    /// Resource-based iterator for voice results\n    resource voice-results {\n        /// Check if more voices are available\n        has-more: func() -> bool;\n        \n        /// Get next batch of voices\n        get-next: func() -> result<list<voice-info>, tts-error>;\n        \n        /// Get total count if available\n        get-total-count: func() -> option<u32>;\n    }\n\n    /// List available voices with filtering and pagination\n    list-voices: func(\n        filter: option<voice-filter>\n    ) -> result<voice-results, tts-error>;\n\n    /// Get specific voice by ID\n    get-voice: func(voice-id: string) -> result<voice, tts-error>;\n\n    /// Search voices by characteristics\n    search-voices: func(\n        query: string,\n        filter: option<voice-filter>\n    ) -> result<list<voice-info>, tts-error>;\n\n    /// Get supported languages\n    list-languages: func() -> result<list<language-info>, tts-error>;\n\n    record language-info {\n        code: language-code,\n        name: string,\n        native-name: string,\n        voice-count: u32,\n    }\n}\n\n/// Core text-to-speech synthesis operations\ninterface synthesis {\n    use types.{\n        text-input, audio-config, voice-settings, audio-effects,\n        synthesis-result, tts-error, timing-info\n    };\n    use voices.{voice};\n\n    /// Synthesis configuration options\n    record synthesis-options {\n        audio-config: option<audio-config>,\n        voice-settings: option<voice-settings>,\n        audio-effects: option<audio-effects>,\n        enable-timing: option<bool>,\n        enable-word-timing: option<bool>,\n        seed: option<u32>,\n        model-version: option<string>,\n        context: option<synthesis-context>,\n    }\n\n    /// Context for better synthesis quality\n    record synthesis-context {\n        previous-text: option<string>,\n        next-text: option<string>,\n        topic: option<string>,\n        emotion: option<string>,\n        speaking-style: option<string>,\n    }\n\n    /// Convert text to speech (removed async)\n    synthesize: func(\n        input: text-input,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-result, tts-error>;\n\n    /// Batch synthesis for multiple inputs (removed async)\n    synthesize-batch: func(\n        inputs: list<text-input>,\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<list<synthesis-result>, tts-error>;\n\n    /// Get timing information without audio synthesis\n    get-timing-marks: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<list<timing-info>, tts-error>;\n\n    /// Validate text before synthesis\n    validate-input: func(\n        input: text-input,\n        voice: borrow<voice>\n    ) -> result<validation-result, tts-error>;\n\n    record validation-result {\n        is-valid: bool,\n        character-count: u32,\n        estimated-duration: option<f32>,\n        warnings: list<string>,\n        errors: list<string>,\n    }\n}\n\n/// Real-time streaming synthesis\ninterface streaming {\n    use types.{\n        text-input, audio-config, voice-settings, audio-chunk,\n        tts-error, timing-info\n    };\n    use voices.{voice};\n    use synthesis.{synthesis-options};\n\n    /// Streaming synthesis session\n    resource synthesis-stream {\n        /// Send text for synthesis (can be called multiple times)\n        send-text: func(input: text-input) -> result<_, tts-error>;\n        \n        /// Signal end of input and flush remaining audio\n        finish: func() -> result<_, tts-error>;\n        \n        /// Receive next audio chunk (non-blocking)\n        receive-chunk: func() -> result<option<audio-chunk>, tts-error>;\n        \n        /// Check if more chunks are available\n        has-pending-audio: func() -> bool;\n        \n        /// Get current stream status\n        get-status: func() -> stream-status;\n        \n        /// Close stream and clean up resources\n        close: func();\n    }\n\n    enum stream-status {\n        ready,\n        processing,\n        finished,\n        error,\n        closed,\n    }\n\n    /// Create streaming synthesis session\n    create-stream: func(\n        voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<synthesis-stream, tts-error>;\n\n    /// Real-time voice conversion streaming\n    create-voice-conversion-stream: func(\n        target-voice: borrow<voice>,\n        options: option<synthesis-options>\n    ) -> result<voice-conversion-stream, tts-error>;\n\n    resource voice-conversion-stream {\n        /// Send input audio chunks\n        send-audio: func(audio-data: list<u8>) -> result<_, tts-error>;\n        \n        /// Receive converted audio chunks\n        receive-converted: func() -> result<option<audio-chunk>, tts-error>;\n        \n        finish: func() -> result<_, tts-error>;\n        close: func();\n    }\n}\n\n/// Advanced TTS features and voice manipulation\ninterface advanced {\n    use types.{tts-error, audio-config, language-code};\n    use voices.{voice};\n\n    /// Voice cloning and creation (removed async)\n    create-voice-clone: func(\n        name: string,\n        audio-samples: list<audio-sample>,\n        description: option<string>\n    ) -> result<voice, tts-error>;\n\n    record audio-sample {\n        data: list<u8>,\n        transcript: option<string>,\n        quality-rating: option<u8>,\n    }\n\n    /// Design synthetic voice (removed async)\n    design-voice: func(\n        name: string,\n        characteristics: voice-design-params\n    ) -> result<voice, tts-error>;\n\n    record voice-design-params {\n        gender: types.voice-gender,\n        age-category: age-category,\n        accent: string,\n        personality-traits: list<string>,\n        reference-voice: option<string>,\n    }\n\n    enum age-category {\n        child,\n        young-adult,\n        middle-aged,\n        elderly,\n    }\n\n    /// Voice-to-voice conversion (removed async)\n    convert-voice: func(\n        input-audio: list<u8>,\n        target-voice: borrow<voice>,\n        preserve-timing: option<bool>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Generate sound effects from text description (removed async)\n    generate-sound-effect: func(\n        description: string,\n        duration-seconds: option<f32>,\n        style-influence: option<f32>\n    ) -> result<list<u8>, tts-error>;\n\n    /// Custom pronunciation management\n    resource pronunciation-lexicon {\n        get-name: func() -> string;\n        get-language: func() -> language-code;\n        get-entry-count: func() -> u32;\n        \n        /// Add pronunciation rule\n        add-entry: func(word: string, pronunciation: string) -> result<_, tts-error>;\n        \n        /// Remove pronunciation rule\n        remove-entry: func(word: string) -> result<_, tts-error>;\n        \n        /// Export lexicon content\n        export-content: func() -> result<string, tts-error>;\n    }\n\n    /// Create custom pronunciation lexicon\n    create-lexicon: func(\n        name: string,\n        language: language-code,\n        entries: option<list<pronunciation-entry>>\n    ) -> result<pronunciation-lexicon, tts-error>;\n\n    record pronunciation-entry {\n        word: string,\n        pronunciation: string,\n        part-of-speech: option<string>,\n    }\n\n    /// Long-form content synthesis with optimization (removed async)\n    synthesize-long-form: func(\n        content: string,\n        voice: borrow<voice>,\n        output-location: string,\n        chapter-breaks: option<list<u32>>\n    ) -> result<long-form-operation, tts-error>;\n\n    resource long-form-operation {\n        get-status: func() -> operation-status;\n        get-progress: func() -> f32;\n        cancel: func() -> result<_, tts-error>;\n        get-result: func() -> result<long-form-result, tts-error>;\n    }\n\n    enum operation-status {\n        pending,\n        processing,\n        completed,\n        failed,\n        cancelled,\n    }\n\n    record long-form-result {\n        output-location: string,\n        total-duration: f32,\n        chapter-durations: option<list<f32>>,\n        metadata: types.synthesis-metadata,\n    }\n}\n```",
              "url": "https://github.com/golemcloud/golem-ai/issues/23",
              "tech": [
                "go"
              ],
              "repo_name": "golem-ai",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#1911",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2026-02-02T08:08:53.194Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-02T08:08:53.194Z",
            "created_at": "2026-02-02T08:08:53.194Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#1911",
              "status": "open",
              "type": "issue",
              "number": 1911,
              "title": "Warn on mismatch between global `prisma` and local `prisma` or `@prisma/client`",
              "source": {
                "data": {
                  "id": "source-prisma#1911",
                  "user": {
                    "login": "janpio",
                    "id": 183673,
                    "node_id": "MDQ6VXNlcjE4MzY3Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/183673?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/janpio",
                    "html_url": "https://github.com/janpio",
                    "followers_url": "https://api.github.com/users/janpio/followers",
                    "following_url": "https://api.github.com/users/janpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/janpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/janpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/janpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/janpio/orgs",
                    "repos_url": "https://api.github.com/users/janpio/repos",
                    "events_url": "https://api.github.com/users/janpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/janpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Warn on mismatch between global `prisma` and local `prisma` or `@prisma/client`",
                  "body": "Using a global `prisma generate` with a different local `prisma` or `@prisma/client` might lead to problems. It might be a good idea to warn users if they are doing that and ask for explicit confirmation.",
                  "html_url": "https://github.com/prisma/prisma/issues/1911"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#1911",
              "body": "Using a global `prisma generate` with a different local `prisma` or `@prisma/client` might lead to problems. It might be a good idea to warn users if they are doing that and ask for explicit confirmation.",
              "url": "https://github.com/prisma/prisma/issues/1911",
              "tech": [],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#8548",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2026-02-02T08:08:53.334Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-02T08:08:53.334Z",
            "created_at": "2026-02-02T08:08:53.334Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#8548",
              "status": "open",
              "type": "issue",
              "number": 8548,
              "title": "`prisma format` ends the file with a single CRLF on windows",
              "source": {
                "data": {
                  "id": "source-prisma#8548",
                  "user": {
                    "login": "binary64",
                    "id": 1680627,
                    "node_id": "MDQ6VXNlcjE2ODA2Mjc=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1680627?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/binary64",
                    "html_url": "https://github.com/binary64",
                    "followers_url": "https://api.github.com/users/binary64/followers",
                    "following_url": "https://api.github.com/users/binary64/following{/other_user}",
                    "gists_url": "https://api.github.com/users/binary64/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/binary64/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/binary64/subscriptions",
                    "organizations_url": "https://api.github.com/users/binary64/orgs",
                    "repos_url": "https://api.github.com/users/binary64/repos",
                    "events_url": "https://api.github.com/users/binary64/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/binary64/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "`prisma format` ends the file with a single CRLF on windows",
                  "body": "### Bug description\n\nOn windows, I run `prisma format` and note the unusual file ending. The lines are all LF, but the very last line is CRLF.\r\n\r\nThis causes issue on my Linux CI where it formats it ending in LF's only, causing a diff to occur and the build to fail.\n\n### How to reproduce\n\n1. On windows do prisma format\r\n2. Open in HxD or similar\r\n3. See attached:\r\n \r\n![image](https://user-images.githubusercontent.com/1680627/127931864-fcd66391-9b31-4914-8553-f6c71b3a6fad.png)\r\n\n\n### Expected behavior\n\nLF's only - no CR's to exist at all\n\n### Prisma information\n\n<!-- Do not include your database credentials when sharing your Prisma schema! -->\r\n\n\n### Environment & setup\n\nNode 16\r\nWindows/Linux\n\n### Prisma Version\n\n```\r\n$ C:\\p\\pab\\monorepo\\node_modules\\.bin\\prisma -v\r\nprisma               : 2.26.0\r\n@prisma/client       : 2.28.0\r\nCurrent platform     : windows\r\nQuery Engine         : query-engine 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\query-engine-windows.exe)\r\nMigration Engine     : migration-engine-cli 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\migration-engine-windows.exe)\r\nIntrospection Engine : introspection-core 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\introspection-engine-windows.exe)\r\nFormat Binary        : prisma-fmt 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\prisma-fmt-windows.exe)\r\nDefault Engines Hash : 9b816b3aa13cc270074f172f30d6eda8a8ce867d\r\nStudio               : 0.408.0\r\n```",
                  "html_url": "https://github.com/prisma/prisma/issues/8548"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#8548",
              "body": "### Bug description\n\nOn windows, I run `prisma format` and note the unusual file ending. The lines are all LF, but the very last line is CRLF.\r\n\r\nThis causes issue on my Linux CI where it formats it ending in LF's only, causing a diff to occur and the build to fail.\n\n### How to reproduce\n\n1. On windows do prisma format\r\n2. Open in HxD or similar\r\n3. See attached:\r\n \r\n![image](https://user-images.githubusercontent.com/1680627/127931864-fcd66391-9b31-4914-8553-f6c71b3a6fad.png)\r\n\n\n### Expected behavior\n\nLF's only - no CR's to exist at all\n\n### Prisma information\n\n<!-- Do not include your database credentials when sharing your Prisma schema! -->\r\n\n\n### Environment & setup\n\nNode 16\r\nWindows/Linux\n\n### Prisma Version\n\n```\r\n$ C:\\p\\pab\\monorepo\\node_modules\\.bin\\prisma -v\r\nprisma               : 2.26.0\r\n@prisma/client       : 2.28.0\r\nCurrent platform     : windows\r\nQuery Engine         : query-engine 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\query-engine-windows.exe)\r\nMigration Engine     : migration-engine-cli 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\migration-engine-windows.exe)\r\nIntrospection Engine : introspection-core 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\introspection-engine-windows.exe)\r\nFormat Binary        : prisma-fmt 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\prisma-fmt-windows.exe)\r\nDefault Engines Hash : 9b816b3aa13cc270074f172f30d6eda8a8ce867d\r\nStudio               : 0.408.0\r\n```",
              "url": "https://github.com/prisma/prisma/issues/8548",
              "tech": [],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#7771",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2026-02-02T08:08:53.460Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-02T08:08:53.460Z",
            "created_at": "2026-02-02T08:08:53.460Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#7771",
              "status": "open",
              "type": "issue",
              "number": 7771,
              "title": "Output path of current Prisma in `-v` ",
              "source": {
                "data": {
                  "id": "source-prisma#7771",
                  "user": {
                    "login": "janpio",
                    "id": 183673,
                    "node_id": "MDQ6VXNlcjE4MzY3Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/183673?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/janpio",
                    "html_url": "https://github.com/janpio",
                    "followers_url": "https://api.github.com/users/janpio/followers",
                    "following_url": "https://api.github.com/users/janpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/janpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/janpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/janpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/janpio/orgs",
                    "repos_url": "https://api.github.com/users/janpio/repos",
                    "events_url": "https://api.github.com/users/janpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/janpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Output path of current Prisma in `-v` ",
                  "body": "## Problem\r\n\r\nThis is a situation that can happen:\r\n```\r\n--- yarn prisma -v ---\r\nwarning package.json: No license field\r\nprisma               : 2.26.0-dev.7\r\n@prisma/client       : 2.26.0-dev.7\r\nCurrent platform     : debian-openssl-1.1.x\r\nQuery Engine         : query-engine c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/query-engine-debian-openssl-1.1.x)\r\nMigration Engine     : migration-engine-cli c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/migration-engine-debian-openssl-1.1.x)\r\nIntrospection Engine : introspection-core c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/introspection-engine-debian-openssl-1.1.x)\r\nFormat Binary        : prisma-fmt c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/prisma-fmt-debian-openssl-1.1.x)\r\nDefault Engines Hash : c838e79f39885bc8e1611849b1eb28b5bb5bc922\r\nStudio               : 0.402.0\r\n--- ls node_modules/@prisma/engines/ ---\r\nls: cannot access 'node_modules/@prisma/engines/': No such file or directory\r\n```\r\n\r\nAs you can see `yarn prisma -v` tells us the engines comes from `node_modules/@prisma/engines`, but when you try to list that directory, it is actually not present.\r\n\r\nWhat is happening here is that `yarn prisma` is actually from a few folders _above_ our project. This is kinda visible when you look to not run `yarn -s` but just `yarn`:\r\n```\r\ncodespace  /workspaces/e2e-tests/platforms-serverless/firebase-functions (janpio-patch-5 ) $ yarn prisma -v\r\nyarn run v1.22.10\r\nwarning package.json: No license field\r\n$ /workspaces/e2e-tests/node_modules/.bin/prisma -v\r\nprisma               : 2.25.0-dev.36\r\n@prisma/client       : 2.25.0-dev.36\r\n...\r\n```\r\n\r\n## Suggested solution\r\n\r\nOutput the directory of where the executed `prisma` is from, either similar to Yarn the absolute path to the binary in `node_modules`, or the folder where the `package.json` that is responsible for the installation of Prisma comes from.\r\n\r\n## Alternatives\r\n\r\nRely on `yarn` itself to give that information. Will not work with `npx` unfortunately for example.",
                  "html_url": "https://github.com/prisma/prisma/issues/7771"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#7771",
              "body": "## Problem\r\n\r\nThis is a situation that can happen:\r\n```\r\n--- yarn prisma -v ---\r\nwarning package.json: No license field\r\nprisma               : 2.26.0-dev.7\r\n@prisma/client       : 2.26.0-dev.7\r\nCurrent platform     : debian-openssl-1.1.x\r\nQuery Engine         : query-engine c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/query-engine-debian-openssl-1.1.x)\r\nMigration Engine     : migration-engine-cli c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/migration-engine-debian-openssl-1.1.x)\r\nIntrospection Engine : introspection-core c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/introspection-engine-debian-openssl-1.1.x)\r\nFormat Binary        : prisma-fmt c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/prisma-fmt-debian-openssl-1.1.x)\r\nDefault Engines Hash : c838e79f39885bc8e1611849b1eb28b5bb5bc922\r\nStudio               : 0.402.0\r\n--- ls node_modules/@prisma/engines/ ---\r\nls: cannot access 'node_modules/@prisma/engines/': No such file or directory\r\n```\r\n\r\nAs you can see `yarn prisma -v` tells us the engines comes from `node_modules/@prisma/engines`, but when you try to list that directory, it is actually not present.\r\n\r\nWhat is happening here is that `yarn prisma` is actually from a few folders _above_ our project. This is kinda visible when you look to not run `yarn -s` but just `yarn`:\r\n```\r\ncodespace  /workspaces/e2e-tests/platforms-serverless/firebase-functions (janpio-patch-5 ) $ yarn prisma -v\r\nyarn run v1.22.10\r\nwarning package.json: No license field\r\n$ /workspaces/e2e-tests/node_modules/.bin/prisma -v\r\nprisma               : 2.25.0-dev.36\r\n@prisma/client       : 2.25.0-dev.36\r\n...\r\n```\r\n\r\n## Suggested solution\r\n\r\nOutput the directory of where the executed `prisma` is from, either similar to Yarn the absolute path to the binary in `node_modules`, or the folder where the `package.json` that is responsible for the installation of Prisma comes from.\r\n\r\n## Alternatives\r\n\r\nRely on `yarn` itself to give that information. Will not work with `npx` unfortunately for example.",
              "url": "https://github.com/prisma/prisma/issues/7771",
              "tech": [],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mudlet#8030",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mudlet",
              "id": "generated-mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2026-02-02T08:08:53.205Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-02T08:08:53.205Z",
            "created_at": "2026-02-02T08:08:53.205Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mudlet#8030",
              "status": "open",
              "type": "issue",
              "number": 8030,
              "title": "Split Mudlet up into `libmudlet` and a Qt front-end",
              "source": {
                "data": {
                  "id": "source-mudlet#8030",
                  "user": {
                    "login": "vadi2",
                    "id": 110988,
                    "node_id": "MDQ6VXNlcjExMDk4OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/110988?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vadi2",
                    "html_url": "https://github.com/vadi2",
                    "followers_url": "https://api.github.com/users/vadi2/followers",
                    "following_url": "https://api.github.com/users/vadi2/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vadi2/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vadi2/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vadi2/subscriptions",
                    "organizations_url": "https://api.github.com/users/vadi2/orgs",
                    "repos_url": "https://api.github.com/users/vadi2/repos",
                    "events_url": "https://api.github.com/users/vadi2/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vadi2/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Split Mudlet up into `libmudlet` and a Qt front-end",
                  "body": "#### Description of requested feature:\nMudlet is a Qt Widgets based application, which works great for Linux/macOS/Windows, but not so great for running natively on Android or iPhone, which are popular feature requests.\n\nAkin to how VLC is split into libVLC and various front-ends, split Mudlet out into libmudlet (providing all of core functionality) and a Qt Widget frontend that makes use of all of the core functionality.\n\n**Prior to taking this issue up**, open a new github issue here and in there, provide (1) plan for how the library/frontend split will work on an architectural level, and (2) a plan for the migration strategy, since once mega PR will not work for this.\n\n#### Reasons for adding feature:\n\n1. allowing Mudlet to eventually have a mobile-native version\n\n#### Expected result of feature\nlibmudlet may use Qt Core classes (QObject, QTimer, QThread, QSettings, etc.) but must not depend on Qt Widgets, Qt GUI, or any UI-related Qt modules.\n\n Mudlet's functionality pre and post-split should be 100% the same, nothing should be lost in the transition:\n -  All existing automated tests must pass, plus:\n  - All menu items and dialogs function identically\n  - All Lua API functions return identical results\n  - All protocol features work (GMCP, MXP, etc.)\n  - All file formats (profiles, packages) remain compatible\n\nPerformance of the network/text display stack as well as the trigger engine should be comparable as well (no more than 10% lost). Measured in:\n\n  - Text display: X lines/second in main console (can be measured using [stressinator](https://packages.mudlet.org/packages#pkg-Stressinator))\n  - Network: Y MB/s processing throughput (needs to be measured)\n  - Memory: no more than 10% increase in base memory usage\n\n####\n\n",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/8030"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#8030",
              "body": "#### Description of requested feature:\nMudlet is a Qt Widgets based application, which works great for Linux/macOS/Windows, but not so great for running natively on Android or iPhone, which are popular feature requests.\n\nAkin to how VLC is split into libVLC and various front-ends, split Mudlet out into libmudlet (providing all of core functionality) and a Qt Widget frontend that makes use of all of the core functionality.\n\n**Prior to taking this issue up**, open a new github issue here and in there, provide (1) plan for how the library/frontend split will work on an architectural level, and (2) a plan for the migration strategy, since once mega PR will not work for this.\n\n#### Reasons for adding feature:\n\n1. allowing Mudlet to eventually have a mobile-native version\n\n#### Expected result of feature\nlibmudlet may use Qt Core classes (QObject, QTimer, QThread, QSettings, etc.) but must not depend on Qt Widgets, Qt GUI, or any UI-related Qt modules.\n\n Mudlet's functionality pre and post-split should be 100% the same, nothing should be lost in the transition:\n -  All existing automated tests must pass, plus:\n  - All menu items and dialogs function identically\n  - All Lua API functions return identical results\n  - All protocol features work (GMCP, MXP, etc.)\n  - All file formats (profiles, packages) remain compatible\n\nPerformance of the network/text display stack as well as the trigger engine should be comparable as well (no more than 10% lost). Measured in:\n\n  - Text display: X lines/second in main console (can be measured using [stressinator](https://packages.mudlet.org/packages#pkg-Stressinator))\n  - Network: Y MB/s processing throughput (needs to be measured)\n  - Memory: no more than 10% increase in base memory usage\n\n####\n\n",
              "url": "https://github.com/Mudlet/Mudlet/issues/8030",
              "tech": [],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mudlet#3172",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mudlet",
              "id": "generated-mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2026-02-02T08:08:53.340Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-02T08:08:53.340Z",
            "created_at": "2026-02-02T08:08:53.340Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mudlet#3172",
              "status": "open",
              "type": "issue",
              "number": 3172,
              "title": "generic mapper: add video walkthrough on how to set it up",
              "source": {
                "data": {
                  "id": "source-mudlet#3172",
                  "user": {
                    "login": "vadi2",
                    "id": 110988,
                    "node_id": "MDQ6VXNlcjExMDk4OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/110988?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vadi2",
                    "html_url": "https://github.com/vadi2",
                    "followers_url": "https://api.github.com/users/vadi2/followers",
                    "following_url": "https://api.github.com/users/vadi2/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vadi2/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vadi2/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vadi2/subscriptions",
                    "organizations_url": "https://api.github.com/users/vadi2/orgs",
                    "repos_url": "https://api.github.com/users/vadi2/repos",
                    "events_url": "https://api.github.com/users/vadi2/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vadi2/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "generic mapper: add video walkthrough on how to set it up",
                  "body": "#### Brief summary of issue / Description of requested feature:\r\nIt's been requested a few times, and it would be really handy to link people to a video explanation of how the generic mapper script should be setup.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1. \r\n2. \r\n3. \r\n\r\n#### Error output / Expected result of feature\r\n\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/3172"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#3172",
              "body": "#### Brief summary of issue / Description of requested feature:\r\nIt's been requested a few times, and it would be really handy to link people to a video explanation of how the generic mapper script should be setup.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1. \r\n2. \r\n3. \r\n\r\n#### Error output / Expected result of feature\r\n\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n",
              "url": "https://github.com/Mudlet/Mudlet/issues/3172",
              "tech": [],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mudlet#689",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mudlet",
              "id": "generated-mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2026-02-02T08:08:53.466Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-02T08:08:53.466Z",
            "created_at": "2026-02-02T08:08:53.466Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mudlet#689",
              "status": "open",
              "type": "issue",
              "number": 689,
              "title": "Support telnet:// links",
              "source": {
                "data": {
                  "id": "source-mudlet#689",
                  "user": {
                    "login": "vadi2",
                    "id": 110988,
                    "node_id": "MDQ6VXNlcjExMDk4OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/110988?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vadi2",
                    "html_url": "https://github.com/vadi2",
                    "followers_url": "https://api.github.com/users/vadi2/followers",
                    "following_url": "https://api.github.com/users/vadi2/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vadi2/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vadi2/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vadi2/subscriptions",
                    "organizations_url": "https://api.github.com/users/vadi2/orgs",
                    "repos_url": "https://api.github.com/users/vadi2/repos",
                    "events_url": "https://api.github.com/users/vadi2/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vadi2/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Support telnet:// links",
                  "body": "Idea: MUDs should be able to provide an easy to use link with their connection info to spawn Mudlet and get it to connect to their game. Similar to apt://, steam:// and so forth links.\r\n\r\nI think Mudlet should support those types of links - it'd be a lot more convenient for players to try out new MUDs if they only have to click on a link, instead of copying the server and port, going to Mudlet, making a new profile and so on.\r\n\r\nAs for the naming of the link, we could either go with a custom one: mudlet:// or - use an already standard one (telnet://), which would be much better as some websites use it already (http://dmud.thebbs.org/lotflink.htm) and it would be compatible with other MUDs clients.\r\n\r\nI believe the latter option is better.\r\n\r\nTelnet links seem to work in the format of: telnet://<server>[:<optional port #>], see https://tools.ietf.org/html/rfc4248 for the actual spec.\r\n\r\nThe logic for this could be the following:\r\n\r\nWhen Mudlet is spawned via the telnet link, check to see if any profile(s) server matches server field of the link. If multiple profiles do, auto-load the latest profile used. If one matches, load that profile. If not profiles match...\r\n\r\nCreate a new profile with the given server and port data, and the profiles name will be the servers name as well. Auto-load this newly created profile.\r\n\r\n\r\nI think these cases sound plausible. There'll an issue with peoples already made profile using the server name vs IP address directly as webmasters might, but that's not something that could be easily avoided.\r\n\r\nLaunchpad Details: [#LP1187243](https://bugs.launchpad.net/bugs/1187243) Vadim Peretokin - 2013-06-04 04:47:05 +0000",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/689"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#689",
              "body": "Idea: MUDs should be able to provide an easy to use link with their connection info to spawn Mudlet and get it to connect to their game. Similar to apt://, steam:// and so forth links.\r\n\r\nI think Mudlet should support those types of links - it'd be a lot more convenient for players to try out new MUDs if they only have to click on a link, instead of copying the server and port, going to Mudlet, making a new profile and so on.\r\n\r\nAs for the naming of the link, we could either go with a custom one: mudlet:// or - use an already standard one (telnet://), which would be much better as some websites use it already (http://dmud.thebbs.org/lotflink.htm) and it would be compatible with other MUDs clients.\r\n\r\nI believe the latter option is better.\r\n\r\nTelnet links seem to work in the format of: telnet://<server>[:<optional port #>], see https://tools.ietf.org/html/rfc4248 for the actual spec.\r\n\r\nThe logic for this could be the following:\r\n\r\nWhen Mudlet is spawned via the telnet link, check to see if any profile(s) server matches server field of the link. If multiple profiles do, auto-load the latest profile used. If one matches, load that profile. If not profiles match...\r\n\r\nCreate a new profile with the given server and port data, and the profiles name will be the servers name as well. Auto-load this newly created profile.\r\n\r\n\r\nI think these cases sound plausible. There'll an issue with peoples already made profile using the server name vs IP address directly as webmasters might, but that's not something that could be easily avoided.\r\n\r\nLaunchpad Details: [#LP1187243](https://bugs.launchpad.net/bugs/1187243) Vadim Peretokin - 2013-06-04 04:47:05 +0000",
              "url": "https://github.com/Mudlet/Mudlet/issues/689",
              "tech": [],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "mudlet#5310",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "mudlet",
              "id": "generated-mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2026-02-02T08:08:53.584Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-02T08:08:53.584Z",
            "created_at": "2026-02-02T08:08:53.584Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-mudlet#5310",
              "status": "open",
              "type": "issue",
              "number": 5310,
              "title": "Autocomplete steals window focus, prevents further typing",
              "source": {
                "data": {
                  "id": "source-mudlet#5310",
                  "user": {
                    "login": "Matthew-Marsh",
                    "id": 79426017,
                    "node_id": "MDQ6VXNlcjc5NDI2MDE3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/79426017?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Matthew-Marsh",
                    "html_url": "https://github.com/Matthew-Marsh",
                    "followers_url": "https://api.github.com/users/Matthew-Marsh/followers",
                    "following_url": "https://api.github.com/users/Matthew-Marsh/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Matthew-Marsh/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Matthew-Marsh/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Matthew-Marsh/subscriptions",
                    "organizations_url": "https://api.github.com/users/Matthew-Marsh/orgs",
                    "repos_url": "https://api.github.com/users/Matthew-Marsh/repos",
                    "events_url": "https://api.github.com/users/Matthew-Marsh/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Matthew-Marsh/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Autocomplete steals window focus, prevents further typing",
                  "body": "#### Brief summary of issue / Description of requested feature:\r\n\r\nOccasionally encountering an issue where autocomplete pops up and prevents typing. Need to esc to remove the autocomplete, but will pop up again with another relevant letter.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1.  Unknown to why it begins.\r\n2.  Typing a letter that has a corresponding lua command in the autocomplete. \r\n\r\n#### Error output / Expected result of feature\r\n\r\nExpected result: Being able to continue typing outside of autocomplete.\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n\r\nMudlet version: 4.11.2\r\nWindows 10 Home\r\nVideo recording: https://youtu.be/qJF0h2MDWzg\r\n",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/5310"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#5310",
              "body": "#### Brief summary of issue / Description of requested feature:\r\n\r\nOccasionally encountering an issue where autocomplete pops up and prevents typing. Need to esc to remove the autocomplete, but will pop up again with another relevant letter.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1.  Unknown to why it begins.\r\n2.  Typing a letter that has a corresponding lua command in the autocomplete. \r\n\r\n#### Error output / Expected result of feature\r\n\r\nExpected result: Being able to continue typing outside of autocomplete.\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n\r\nMudlet version: 4.11.2\r\nWindows 10 Home\r\nVideo recording: https://youtu.be/qJF0h2MDWzg\r\n",
              "url": "https://github.com/Mudlet/Mudlet/issues/5310",
              "tech": [],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          }
        ],
        "next_cursor": null
      }
    }
  }
}