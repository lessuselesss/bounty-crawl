{
  "result": {
    "data": {
      "json": {
        "items": [
          {
            "id": "onyx-dot-app#2281",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "onyx-dot-app",
              "id": "generated-onyx-dot-app",
              "name": "Onyx-dot-app",
              "description": "",
              "members": [],
              "display_name": "Onyx-dot-app",
              "created_at": "2026-02-27T22:49:45.777Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/onyx-dot-app?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "danswer-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:49:45.777Z",
            "created_at": "2026-02-27T22:49:45.777Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-onyx-dot-app#2281",
              "status": "open",
              "type": "issue",
              "number": 2281,
              "title": "Jira Service Management Connector",
              "source": {
                "data": {
                  "id": "source-onyx-dot-app#2281",
                  "user": {
                    "login": "Weves",
                    "id": 25087905,
                    "node_id": "MDQ6VXNlcjI1MDg3OTA1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25087905?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Weves",
                    "html_url": "https://github.com/Weves",
                    "followers_url": "https://api.github.com/users/Weves/followers",
                    "following_url": "https://api.github.com/users/Weves/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Weves/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Weves/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Weves/subscriptions",
                    "organizations_url": "https://api.github.com/users/Weves/orgs",
                    "repos_url": "https://api.github.com/users/Weves/repos",
                    "events_url": "https://api.github.com/users/Weves/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Weves/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Jira Service Management Connector",
                  "body": "Pull in all tickets from a specified [Jira Service Management](https://www.atlassian.com/software/jira/service-management) project. \r\n\r\nCheckout the connector creation README here for more details on the best way to add new connectors: https://github.com/danswer-ai/danswer/blob/main/backend/danswer/connectors/README.md. ",
                  "html_url": "https://github.com/onyx-dot-app/onyx/issues/2281"
                },
                "type": "github"
              },
              "hash": "danswer-ai/danswer#2281",
              "body": "Pull in all tickets from a specified [Jira Service Management](https://www.atlassian.com/software/jira/service-management) project. \r\n\r\nCheckout the connector creation README here for more details on the best way to add new connectors: https://github.com/danswer-ai/danswer/blob/main/backend/danswer/connectors/README.md. ",
              "url": "https://github.com/onyx-dot-app/onyx/issues/2281",
              "tech": [],
              "repo_name": "danswer",
              "repo_owner": "danswer-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "golemcloud#275",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "golemcloud",
              "id": "generated-golemcloud",
              "name": "Golemcloud",
              "description": "",
              "members": [],
              "display_name": "Golemcloud",
              "created_at": "2026-02-27T22:50:05.141Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/golemcloud?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "golemcloud",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:05.141Z",
            "created_at": "2026-02-27T22:50:05.141Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-golemcloud#275",
              "status": "open",
              "type": "issue",
              "number": 275,
              "title": "Incorporate MCP Server into Golem CLI",
              "source": {
                "data": {
                  "id": "source-golemcloud#275",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Incorporate MCP Server into Golem CLI",
                  "body": "With a new command, Golem CLI enters serve mode:\n\n```bash\n%> golem-cli --serve --serve-port 1232\n%> golem-cli running MCP Server at port 1232\n```\n\nIn this mode, Golem CLI creates an MCP Server that exposes different commands as different tools, and exposes relevant resources (the manifest file in the current, ancestor, and children directories) as resources.\n\nWhen this ticket is completed, it should be possible to use an agent such as Claude Code to perform anything that Golem CLI can do. Moreover, all individual tools and resources must be end-to-end tested with an MCP Client that interacts with the MCP Server.\n\n[This library](https://github.com/rust-mcp-stack/rust-mcp-sdk) looks like the one to use for Rust, but perhaps there are better options available.",
                  "html_url": "https://github.com/golemcloud/golem/issues/1926"
                },
                "type": "github"
              },
              "hash": "golemcloud/golem-cli#275",
              "body": "With a new command, Golem CLI enters serve mode:\n\n```bash\n%> golem-cli --serve --serve-port 1232\n%> golem-cli running MCP Server at port 1232\n```\n\nIn this mode, Golem CLI creates an MCP Server that exposes different commands as different tools, and exposes relevant resources (the manifest file in the current, ancestor, and children directories) as resources.\n\nWhen this ticket is completed, it should be possible to use an agent such as Claude Code to perform anything that Golem CLI can do. Moreover, all individual tools and resources must be end-to-end tested with an MCP Client that interacts with the MCP Server.\n\n[This library](https://github.com/rust-mcp-stack/rust-mcp-sdk) looks like the one to use for Rust, but perhaps there are better options available.",
              "url": "https://github.com/golemcloud/golem/issues/1926",
              "tech": [
                "go"
              ],
              "repo_name": "golem-cli",
              "repo_owner": "golemcloud",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#519",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2026-02-27T22:50:22.253Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:22.253Z",
            "created_at": "2026-02-27T22:50:22.253Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#519",
              "status": "open",
              "type": "issue",
              "number": 519,
              "title": "Schema Migration System for ZIO Schema 2",
              "source": {
                "data": {
                  "id": "source-zio#519",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Schema Migration System for ZIO Schema 2",
                  "body": "## Overview\n\nImplement a **pure, algebraic migration system** for ZIO Schema 2 that represents **structural transformations between schema versions** as first-class, serializable data.\n\nA migration describes how to transform data from one schema version to another, enabling:\n\n* schema evolution\n* backward / forward compatibility\n* data versioning\n* offline migrations (JSON, SQL, data lakes, registries, etc.)\n\nThe system provides a **typed, macro-validated user API** (`Migration[A, B]`) built on a **pure, serializable core** (`DynamicMigration`) that operates on `DynamicValue`. \n\nThe ADT is fully introspectable and can be used to generate DDL, etc.\n\n## Motivation & Big Picture\n\n### Why structural types?\n\nWhen evolving schemas over time, **older versions of data types should not require runtime representations**.\n\nIn this design:\n\n* **Current versions** are represented by real case classes / enums\n* **Past versions** are represented using:\n\n  * **structural types** for records\n  * **abstract types + intersection types** for sum types\n\nThese types:\n\n* exist **only at compile time**\n* have **no runtime representation**\n* introduce **zero runtime overhead**\n* do **not require optics or instances to be kept around**\n\nThis allows you to describe arbitrarily old versions of data *without polluting your runtime or codebase*.\n\n#### Typical Workflow\n\nA typical workflow looks like:\n\n1. You have a current type:\n\n   ```scala\n   @schema\n   case class Person(name: String, age: Int)\n   ```\n\n2. You derive and copy its structural shape:\n\n   ```scala\n   type PersonV1 = { def name: String; def age: Int }\n   ```\n\n3. You evolve the real type:\n\n   ```scala\n   @schema\n   case class Person(fullName: String, age: Int, country: String)\n   ```\n\n4. You keep only:\n\n   * the **current** runtime type\n   * the **structural type** for the old version\n   * a **pure migration** between them\n\nNo old case classes. No old optics. No runtime baggage.\n\nNote there is no requirement that the \"current\" type actually be a real case class, enum, etc.--so you can work purely with structural types, allowing you to define migrations for data types that are never materialized as runtime structures.\n\n---\n\n### Why pure data migrations?\n\nMigrations are represented entirely as **pure data**:\n\n* no user functions\n* no closures\n* no reflection\n* no runtime code generation\n\nAs a result:\n\n* migrations can be **serialized**\n* stored in **registries**\n* applied **dynamically**\n* inspected and transformed\n* used to generate:\n\n  * upgraders\n  * downgraders\n  * SQL DDL / DML\n  * offline data transforms\n\nWhile code generation is **out of scope for this ticket**, this explains many design decisions (invertibility, path-based actions, no functions).\n\n---\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed migration (user-facing API)\ncase class Migration[A, B](\n  dynamicMigration: DynamicMigration,\n  sourceSchema: Schema[A], // These are structural schemas!!!\n  targetSchema: Schema[B] // These are structural schemas!!!\n) {\n  /** Apply migration to transform A to B */\n  def apply(value: A): Either[MigrationError, B]\n\n  /** Compose migrations sequentially */\n  def ++[C](that: Migration[B, C]): Migration[A, C]\n\n  /** Alias for ++ */\n  def andThen[C](that: Migration[B, C]): Migration[A, C] = this ++ that\n\n  /** Reverse migration (structural inverse; runtime is best-effort) */\n  def reverse: Migration[B, A]\n}\n```\n\n```scala\n// Untyped migration (pure data, fully serializable)\ncase class DynamicMigration(\n  actions: Vector[MigrationAction]\n) {\n  def apply(value: DynamicValue): Either[MigrationError, DynamicValue]\n  def ++(that: DynamicMigration): DynamicMigration\n  def reverse: DynamicMigration\n}\n```\n\n* `Migration[A, B]` is introspectable, but not pure data due to bindings inside schemas\n* `DynamicMigration` is **fully serializable**\n\n---\n\n## User-Facing API: Selector Expressions\n\n### Selectors, not optics\n\nThe user-facing API **does not expose optics**.\n\nInstead, all locations are specified using **selector expressions**:\n\n```scala\nS => A\n```\n\nExamples:\n\n```scala\n_.name\n_.address.street\n_.addresses.each.streetNumber\n_.country.when[UK]\n```\n\nTo see the syntax, one can look at the `optic` macro, which utilizes the same selector syntax for optic creation (e.g. `optic(_.address.street)`, etc.).\n\n### Macro extraction\n\nAll builder methods that accept selectors are **implemented via macros** (or via a macro-generated type class such as `ToDynamicOptic`).\n\nThe macro:\n\n1. Inspects the selector expression\n2. Validates it is a supported projection\n3. Converts it into a `DynamicOptic`\n4. Stores that optic in the migration action\n\nSupported projections include:\n\n* field access (`_.foo.bar`)\n* case selection (`_.country.when[UK]`)\n* collection traversal (`_.items.each`)\n* (future) key access, wrappers, etc.\n\n`DynamicOptic` is **never exposed publicly**.\n\n---\n\n## Migration Builder\n\nAll selector-accepting methods are implemented via macros. For simplicity, these are shown as functions (e.g. `A => Any`), but this is NOT the way to implement them. Either all these functions need to be macros, or a macro needs to be used to generate an implicit / given at each call site. Macros may do additional validation to constrain the validity of these different types of transformations.\n\n```scala\nclass MigrationBuilder[A, B](\n  sourceSchema: Schema[A],\n  targetSchema: Schema[B],\n  actions: Vector[MigrationAction]\n) {\n\n  // ----- Record operations -----\n\n  def addField(\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def dropField(\n    source: A => Any,\n    defaultForReverse: SchemaExpr[B, ?] = SchemaExpr.DefaultValue\n  ): MigrationBuilder[A, B]\n\n  def renameField(\n    from: A => Any,\n    to: B => Any\n  ): MigrationBuilder[A, B]\n\n  def transformField(\n    from: A => Any,\n    to: B => Any,\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def mandateField(\n    source: A => Option[?],\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def optionalizeField(\n    source: A => Any,\n    target: B => Option[?]\n  ): MigrationBuilder[A, B]\n\n  def changeFieldType(\n    source: A => Any,\n    target: B => Any,\n    converter: SchemaExpr[A, ?]  // primitive-to-primitive only\n  ): MigrationBuilder[A, B]\n\n  // ----- Enum operations (limited) -----\n\n  def renameCase[SumA, SumB](\n    from: String,\n    to: String\n  ): MigrationBuilder[A, B]\n\n  def transformCase[SumA, CaseA, SumB, CaseB](\n    caseMigration: MigrationBuilder[CaseA, CaseB] => MigrationBuilder[CaseA, CaseB]\n  ): MigrationBuilder[A, B]\n\n  // ----- Collections -----\n\n  def transformElements(\n    at: A => Vector[?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  // ----- Maps -----\n\n  def transformKeys(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def transformValues(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  /** Build migration with full macro validation */\n  def build: Migration[A, B]\n\n  /** Build migration without full validation */\n  def buildPartial: Migration[A, B]\n}\n```\n\n---\n\n## Migration Actions (Untyped Core)\n\nAll actions operate at a **path**, represented by `DynamicOptic`.\n\n```scala\nsealed trait MigrationAction {\n  def at: DynamicOptic\n  def reverse: MigrationAction\n}\n```\n\n### Record Actions\n\n```scala\ncase class AddField(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class DropField(\n  at: DynamicOptic,\n  defaultForReverse: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Rename(\n  at: DynamicOptic,\n  to: String\n) extends MigrationAction\n\ncase class TransformValue(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Mandate(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Optionalize(\n  at: DynamicOptic\n) extends MigrationAction\n\ncase class Join(\n  at: DynamicOptic,\n  sourcePaths: Vector[DynamicOptic],\n  combiner: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Split(\n  at: DynamicOptic,\n  targetPaths: Vector[DynamicOptic],\n  splitter: SchemaExpr[?]\n) extends MigrationAction\n\ncase class ChangeType(\n  at: DynamicOptic,\n  converter: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n### Enum Actions (Supported)\n\n```scala\ncase class RenameCase(\n  at: DynamicOptic,\n  from: String,\n  to: String\n) extends MigrationAction\n\ncase class TransformCase(\n  at: DynamicOptic,\n  actions: Vector[MigrationAction]\n) extends MigrationAction\n```\n\n> Enum case addition / removal is **out of scope** for this ticket\n> (requires composite value construction).\n\n---\n\n### Collection / Map Actions\n\n```scala\ncase class TransformElements(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformKeys(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformValues(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n## SchemaExpr Integration\n\n* Used for all value-level transformations\n* **Constraints for this ticket**:\n\n  * primitive → primitive only\n  * joins / splits must produce primitives\n  * no record / enum construction\n\n### `SchemaExpr.DefaultValue`\n\nA special expression that:\n\n1. uses the macro-captured field schema\n2. calls `schema.defaultValue`\n3. converts the value to `DynamicValue`\n4. is stored for reverse migrations\n\n---\n\n## Type Modeling\n\n### Records (Structural Types)\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\ntype PersonV1 = { val fullName: String; val age: Int }\n\nimplicit val v0Schema: Schema[PersonV0] = Schema.structural[PersonV0]\nimplicit val v1Schema: Schema[PersonV1] = Schema.structural[PersonV1]\n```\n\n---\n\n### Enums (Union of Structural Types with Tags)\n\nEnums are encoded into structural types by using union types, together with singleton types (string literals, which represent the name of the case of the enum).\n\nIn structural types, the names of the type aliases shown below are not relevant, nor are they used.\n\n```scala\ntype OldCreditCard =\n  { type Tag = \"CreditCard\"; def number: String; def exp: String }\ntype OldWireTransfer =\n  { type Tag = \"WireTransfer\"; def account: String; def routing: String }\ntype OldPaymentMethod = OldCreditCard | OldWireTransfer\n```\n\nMacros extract:\n\n* refinement type → structure of the case\n* type `Tag` with singleton type → case tag\n\n---\n\n## Laws\n\n### Identity\n\n```scala\nMigration.identity[A].apply(a) == Right(a)\n```\n\n### Associativity\n\n```scala\n(m1 ++ m2) ++ m3 == m1 ++ (m2 ++ m3)\n```\n\n### Structural Reverse\n\n```scala\nm.reverse.reverse == m\n```\n\n### Best-Effort Semantic Inverse\n\n```scala\nm.apply(a) == Right(b) ⇒ m.reverse.apply(b) == Right(a)\n```\n\n(when sufficient information exists)\n\n---\n\n## Error Handling\n\n* All runtime errors return `MigrationError`\n* Errors must capture **path information** (`DynamicOptic`)\n* Enables diagnostics such as:\n\n> “Failed to apply TransformValue at `.addresses.each.streetNumber`”\n\n---\n\n## Example\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\n\n@schema\ncase class Person(fullName: String, age: Int)\n\nval migration =\n  Migration.newBuilder[PersonV0, Person]\n    .addField(_.age, 0)\n    .build\n\nval old =\n  new { val firstName = \"John\"; val lastName = \"Doe\" }\n\nmigration(old)\n// Right(Person(\"John Doe\", 0))\n```\n\n---\n\n## Success Criteria\n\n* [ ] `DynamicMigration` fully serializable\n* [ ] `Migration[A, B]` wraps schemas and actions\n* [ ] All actions path-based via `DynamicOptic`\n* [ ] User API uses selector functions (`S => A`) for \"optics\" on old and new types\n* [ ] Macro validation in `.build` to confirm \"old\" has been migrated to \"new\"\n* [ ] `.buildPartial` supported\n* [ ] Structural reverse implemented\n* [ ] Identity & associativity laws hold\n* [ ] Enum rename / transform supported\n* [ ] Errors include path information\n* [ ] Comprehensive tests\n* [ ] Scala 2.13 and Scala 3.5+ supported\n",
                  "html_url": "https://github.com/zio/zio-blocks/issues/519"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#519",
              "body": "## Overview\n\nImplement a **pure, algebraic migration system** for ZIO Schema 2 that represents **structural transformations between schema versions** as first-class, serializable data.\n\nA migration describes how to transform data from one schema version to another, enabling:\n\n* schema evolution\n* backward / forward compatibility\n* data versioning\n* offline migrations (JSON, SQL, data lakes, registries, etc.)\n\nThe system provides a **typed, macro-validated user API** (`Migration[A, B]`) built on a **pure, serializable core** (`DynamicMigration`) that operates on `DynamicValue`. \n\nThe ADT is fully introspectable and can be used to generate DDL, etc.\n\n## Motivation & Big Picture\n\n### Why structural types?\n\nWhen evolving schemas over time, **older versions of data types should not require runtime representations**.\n\nIn this design:\n\n* **Current versions** are represented by real case classes / enums\n* **Past versions** are represented using:\n\n  * **structural types** for records\n  * **abstract types + intersection types** for sum types\n\nThese types:\n\n* exist **only at compile time**\n* have **no runtime representation**\n* introduce **zero runtime overhead**\n* do **not require optics or instances to be kept around**\n\nThis allows you to describe arbitrarily old versions of data *without polluting your runtime or codebase*.\n\n#### Typical Workflow\n\nA typical workflow looks like:\n\n1. You have a current type:\n\n   ```scala\n   @schema\n   case class Person(name: String, age: Int)\n   ```\n\n2. You derive and copy its structural shape:\n\n   ```scala\n   type PersonV1 = { def name: String; def age: Int }\n   ```\n\n3. You evolve the real type:\n\n   ```scala\n   @schema\n   case class Person(fullName: String, age: Int, country: String)\n   ```\n\n4. You keep only:\n\n   * the **current** runtime type\n   * the **structural type** for the old version\n   * a **pure migration** between them\n\nNo old case classes. No old optics. No runtime baggage.\n\nNote there is no requirement that the \"current\" type actually be a real case class, enum, etc.--so you can work purely with structural types, allowing you to define migrations for data types that are never materialized as runtime structures.\n\n---\n\n### Why pure data migrations?\n\nMigrations are represented entirely as **pure data**:\n\n* no user functions\n* no closures\n* no reflection\n* no runtime code generation\n\nAs a result:\n\n* migrations can be **serialized**\n* stored in **registries**\n* applied **dynamically**\n* inspected and transformed\n* used to generate:\n\n  * upgraders\n  * downgraders\n  * SQL DDL / DML\n  * offline data transforms\n\nWhile code generation is **out of scope for this ticket**, this explains many design decisions (invertibility, path-based actions, no functions).\n\n---\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed migration (user-facing API)\ncase class Migration[A, B](\n  dynamicMigration: DynamicMigration,\n  sourceSchema: Schema[A], // These are structural schemas!!!\n  targetSchema: Schema[B] // These are structural schemas!!!\n) {\n  /** Apply migration to transform A to B */\n  def apply(value: A): Either[MigrationError, B]\n\n  /** Compose migrations sequentially */\n  def ++[C](that: Migration[B, C]): Migration[A, C]\n\n  /** Alias for ++ */\n  def andThen[C](that: Migration[B, C]): Migration[A, C] = this ++ that\n\n  /** Reverse migration (structural inverse; runtime is best-effort) */\n  def reverse: Migration[B, A]\n}\n```\n\n```scala\n// Untyped migration (pure data, fully serializable)\ncase class DynamicMigration(\n  actions: Vector[MigrationAction]\n) {\n  def apply(value: DynamicValue): Either[MigrationError, DynamicValue]\n  def ++(that: DynamicMigration): DynamicMigration\n  def reverse: DynamicMigration\n}\n```\n\n* `Migration[A, B]` is introspectable, but not pure data due to bindings inside schemas\n* `DynamicMigration` is **fully serializable**\n\n---\n\n## User-Facing API: Selector Expressions\n\n### Selectors, not optics\n\nThe user-facing API **does not expose optics**.\n\nInstead, all locations are specified using **selector expressions**:\n\n```scala\nS => A\n```\n\nExamples:\n\n```scala\n_.name\n_.address.street\n_.addresses.each.streetNumber\n_.country.when[UK]\n```\n\nTo see the syntax, one can look at the `optic` macro, which utilizes the same selector syntax for optic creation (e.g. `optic(_.address.street)`, etc.).\n\n### Macro extraction\n\nAll builder methods that accept selectors are **implemented via macros** (or via a macro-generated type class such as `ToDynamicOptic`).\n\nThe macro:\n\n1. Inspects the selector expression\n2. Validates it is a supported projection\n3. Converts it into a `DynamicOptic`\n4. Stores that optic in the migration action\n\nSupported projections include:\n\n* field access (`_.foo.bar`)\n* case selection (`_.country.when[UK]`)\n* collection traversal (`_.items.each`)\n* (future) key access, wrappers, etc.\n\n`DynamicOptic` is **never exposed publicly**.\n\n---\n\n## Migration Builder\n\nAll selector-accepting methods are implemented via macros. For simplicity, these are shown as functions (e.g. `A => Any`), but this is NOT the way to implement them. Either all these functions need to be macros, or a macro needs to be used to generate an implicit / given at each call site. Macros may do additional validation to constrain the validity of these different types of transformations.\n\n```scala\nclass MigrationBuilder[A, B](\n  sourceSchema: Schema[A],\n  targetSchema: Schema[B],\n  actions: Vector[MigrationAction]\n) {\n\n  // ----- Record operations -----\n\n  def addField(\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def dropField(\n    source: A => Any,\n    defaultForReverse: SchemaExpr[B, ?] = SchemaExpr.DefaultValue\n  ): MigrationBuilder[A, B]\n\n  def renameField(\n    from: A => Any,\n    to: B => Any\n  ): MigrationBuilder[A, B]\n\n  def transformField(\n    from: A => Any,\n    to: B => Any,\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def mandateField(\n    source: A => Option[?],\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def optionalizeField(\n    source: A => Any,\n    target: B => Option[?]\n  ): MigrationBuilder[A, B]\n\n  def changeFieldType(\n    source: A => Any,\n    target: B => Any,\n    converter: SchemaExpr[A, ?]  // primitive-to-primitive only\n  ): MigrationBuilder[A, B]\n\n  // ----- Enum operations (limited) -----\n\n  def renameCase[SumA, SumB](\n    from: String,\n    to: String\n  ): MigrationBuilder[A, B]\n\n  def transformCase[SumA, CaseA, SumB, CaseB](\n    caseMigration: MigrationBuilder[CaseA, CaseB] => MigrationBuilder[CaseA, CaseB]\n  ): MigrationBuilder[A, B]\n\n  // ----- Collections -----\n\n  def transformElements(\n    at: A => Vector[?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  // ----- Maps -----\n\n  def transformKeys(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def transformValues(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  /** Build migration with full macro validation */\n  def build: Migration[A, B]\n\n  /** Build migration without full validation */\n  def buildPartial: Migration[A, B]\n}\n```\n\n---\n\n## Migration Actions (Untyped Core)\n\nAll actions operate at a **path**, represented by `DynamicOptic`.\n\n```scala\nsealed trait MigrationAction {\n  def at: DynamicOptic\n  def reverse: MigrationAction\n}\n```\n\n### Record Actions\n\n```scala\ncase class AddField(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class DropField(\n  at: DynamicOptic,\n  defaultForReverse: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Rename(\n  at: DynamicOptic,\n  to: String\n) extends MigrationAction\n\ncase class TransformValue(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Mandate(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Optionalize(\n  at: DynamicOptic\n) extends MigrationAction\n\ncase class Join(\n  at: DynamicOptic,\n  sourcePaths: Vector[DynamicOptic],\n  combiner: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Split(\n  at: DynamicOptic,\n  targetPaths: Vector[DynamicOptic],\n  splitter: SchemaExpr[?]\n) extends MigrationAction\n\ncase class ChangeType(\n  at: DynamicOptic,\n  converter: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n### Enum Actions (Supported)\n\n```scala\ncase class RenameCase(\n  at: DynamicOptic,\n  from: String,\n  to: String\n) extends MigrationAction\n\ncase class TransformCase(\n  at: DynamicOptic,\n  actions: Vector[MigrationAction]\n) extends MigrationAction\n```\n\n> Enum case addition / removal is **out of scope** for this ticket\n> (requires composite value construction).\n\n---\n\n### Collection / Map Actions\n\n```scala\ncase class TransformElements(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformKeys(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformValues(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n## SchemaExpr Integration\n\n* Used for all value-level transformations\n* **Constraints for this ticket**:\n\n  * primitive → primitive only\n  * joins / splits must produce primitives\n  * no record / enum construction\n\n### `SchemaExpr.DefaultValue`\n\nA special expression that:\n\n1. uses the macro-captured field schema\n2. calls `schema.defaultValue`\n3. converts the value to `DynamicValue`\n4. is stored for reverse migrations\n\n---\n\n## Type Modeling\n\n### Records (Structural Types)\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\ntype PersonV1 = { val fullName: String; val age: Int }\n\nimplicit val v0Schema: Schema[PersonV0] = Schema.structural[PersonV0]\nimplicit val v1Schema: Schema[PersonV1] = Schema.structural[PersonV1]\n```\n\n---\n\n### Enums (Union of Structural Types with Tags)\n\nEnums are encoded into structural types by using union types, together with singleton types (string literals, which represent the name of the case of the enum).\n\nIn structural types, the names of the type aliases shown below are not relevant, nor are they used.\n\n```scala\ntype OldCreditCard =\n  { type Tag = \"CreditCard\"; def number: String; def exp: String }\ntype OldWireTransfer =\n  { type Tag = \"WireTransfer\"; def account: String; def routing: String }\ntype OldPaymentMethod = OldCreditCard | OldWireTransfer\n```\n\nMacros extract:\n\n* refinement type → structure of the case\n* type `Tag` with singleton type → case tag\n\n---\n\n## Laws\n\n### Identity\n\n```scala\nMigration.identity[A].apply(a) == Right(a)\n```\n\n### Associativity\n\n```scala\n(m1 ++ m2) ++ m3 == m1 ++ (m2 ++ m3)\n```\n\n### Structural Reverse\n\n```scala\nm.reverse.reverse == m\n```\n\n### Best-Effort Semantic Inverse\n\n```scala\nm.apply(a) == Right(b) ⇒ m.reverse.apply(b) == Right(a)\n```\n\n(when sufficient information exists)\n\n---\n\n## Error Handling\n\n* All runtime errors return `MigrationError`\n* Errors must capture **path information** (`DynamicOptic`)\n* Enables diagnostics such as:\n\n> “Failed to apply TransformValue at `.addresses.each.streetNumber`”\n\n---\n\n## Example\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\n\n@schema\ncase class Person(fullName: String, age: Int)\n\nval migration =\n  Migration.newBuilder[PersonV0, Person]\n    .addField(_.age, 0)\n    .build\n\nval old =\n  new { val firstName = \"John\"; val lastName = \"Doe\" }\n\nmigration(old)\n// Right(Person(\"John Doe\", 0))\n```\n\n---\n\n## Success Criteria\n\n* [ ] `DynamicMigration` fully serializable\n* [ ] `Migration[A, B]` wraps schemas and actions\n* [ ] All actions path-based via `DynamicOptic`\n* [ ] User API uses selector functions (`S => A`) for \"optics\" on old and new types\n* [ ] Macro validation in `.build` to confirm \"old\" has been migrated to \"new\"\n* [ ] `.buildPartial` supported\n* [ ] Structural reverse implemented\n* [ ] Identity & associativity laws hold\n* [ ] Enum rename / transform supported\n* [ ] Errors include path information\n* [ ] Comprehensive tests\n* [ ] Scala 2.13 and Scala 3.5+ supported\n",
              "url": "https://github.com/zio/zio-blocks/issues/519",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#519",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2026-02-27T22:50:22.259Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:22.259Z",
            "created_at": "2026-02-27T22:50:22.259Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#519",
              "status": "open",
              "type": "issue",
              "number": 519,
              "title": "Schema Migration System for ZIO Schema 2",
              "source": {
                "data": {
                  "id": "source-zio#519",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Schema Migration System for ZIO Schema 2",
                  "body": "## Overview\n\nImplement a **pure, algebraic migration system** for ZIO Schema 2 that represents **structural transformations between schema versions** as first-class, serializable data.\n\nA migration describes how to transform data from one schema version to another, enabling:\n\n* schema evolution\n* backward / forward compatibility\n* data versioning\n* offline migrations (JSON, SQL, data lakes, registries, etc.)\n\nThe system provides a **typed, macro-validated user API** (`Migration[A, B]`) built on a **pure, serializable core** (`DynamicMigration`) that operates on `DynamicValue`. \n\nThe ADT is fully introspectable and can be used to generate DDL, etc.\n\n## Motivation & Big Picture\n\n### Why structural types?\n\nWhen evolving schemas over time, **older versions of data types should not require runtime representations**.\n\nIn this design:\n\n* **Current versions** are represented by real case classes / enums\n* **Past versions** are represented using:\n\n  * **structural types** for records\n  * **abstract types + intersection types** for sum types\n\nThese types:\n\n* exist **only at compile time**\n* have **no runtime representation**\n* introduce **zero runtime overhead**\n* do **not require optics or instances to be kept around**\n\nThis allows you to describe arbitrarily old versions of data *without polluting your runtime or codebase*.\n\n#### Typical Workflow\n\nA typical workflow looks like:\n\n1. You have a current type:\n\n   ```scala\n   @schema\n   case class Person(name: String, age: Int)\n   ```\n\n2. You derive and copy its structural shape:\n\n   ```scala\n   type PersonV1 = { def name: String; def age: Int }\n   ```\n\n3. You evolve the real type:\n\n   ```scala\n   @schema\n   case class Person(fullName: String, age: Int, country: String)\n   ```\n\n4. You keep only:\n\n   * the **current** runtime type\n   * the **structural type** for the old version\n   * a **pure migration** between them\n\nNo old case classes. No old optics. No runtime baggage.\n\nNote there is no requirement that the \"current\" type actually be a real case class, enum, etc.--so you can work purely with structural types, allowing you to define migrations for data types that are never materialized as runtime structures.\n\n---\n\n### Why pure data migrations?\n\nMigrations are represented entirely as **pure data**:\n\n* no user functions\n* no closures\n* no reflection\n* no runtime code generation\n\nAs a result:\n\n* migrations can be **serialized**\n* stored in **registries**\n* applied **dynamically**\n* inspected and transformed\n* used to generate:\n\n  * upgraders\n  * downgraders\n  * SQL DDL / DML\n  * offline data transforms\n\nWhile code generation is **out of scope for this ticket**, this explains many design decisions (invertibility, path-based actions, no functions).\n\n---\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed migration (user-facing API)\ncase class Migration[A, B](\n  dynamicMigration: DynamicMigration,\n  sourceSchema: Schema[A], // These are structural schemas!!!\n  targetSchema: Schema[B] // These are structural schemas!!!\n) {\n  /** Apply migration to transform A to B */\n  def apply(value: A): Either[MigrationError, B]\n\n  /** Compose migrations sequentially */\n  def ++[C](that: Migration[B, C]): Migration[A, C]\n\n  /** Alias for ++ */\n  def andThen[C](that: Migration[B, C]): Migration[A, C] = this ++ that\n\n  /** Reverse migration (structural inverse; runtime is best-effort) */\n  def reverse: Migration[B, A]\n}\n```\n\n```scala\n// Untyped migration (pure data, fully serializable)\ncase class DynamicMigration(\n  actions: Vector[MigrationAction]\n) {\n  def apply(value: DynamicValue): Either[MigrationError, DynamicValue]\n  def ++(that: DynamicMigration): DynamicMigration\n  def reverse: DynamicMigration\n}\n```\n\n* `Migration[A, B]` is introspectable, but not pure data due to bindings inside schemas\n* `DynamicMigration` is **fully serializable**\n\n---\n\n## User-Facing API: Selector Expressions\n\n### Selectors, not optics\n\nThe user-facing API **does not expose optics**.\n\nInstead, all locations are specified using **selector expressions**:\n\n```scala\nS => A\n```\n\nExamples:\n\n```scala\n_.name\n_.address.street\n_.addresses.each.streetNumber\n_.country.when[UK]\n```\n\nTo see the syntax, one can look at the `optic` macro, which utilizes the same selector syntax for optic creation (e.g. `optic(_.address.street)`, etc.).\n\n### Macro extraction\n\nAll builder methods that accept selectors are **implemented via macros** (or via a macro-generated type class such as `ToDynamicOptic`).\n\nThe macro:\n\n1. Inspects the selector expression\n2. Validates it is a supported projection\n3. Converts it into a `DynamicOptic`\n4. Stores that optic in the migration action\n\nSupported projections include:\n\n* field access (`_.foo.bar`)\n* case selection (`_.country.when[UK]`)\n* collection traversal (`_.items.each`)\n* (future) key access, wrappers, etc.\n\n`DynamicOptic` is **never exposed publicly**.\n\n---\n\n## Migration Builder\n\nAll selector-accepting methods are implemented via macros. For simplicity, these are shown as functions (e.g. `A => Any`), but this is NOT the way to implement them. Either all these functions need to be macros, or a macro needs to be used to generate an implicit / given at each call site. Macros may do additional validation to constrain the validity of these different types of transformations.\n\n```scala\nclass MigrationBuilder[A, B](\n  sourceSchema: Schema[A],\n  targetSchema: Schema[B],\n  actions: Vector[MigrationAction]\n) {\n\n  // ----- Record operations -----\n\n  def addField(\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def dropField(\n    source: A => Any,\n    defaultForReverse: SchemaExpr[B, ?] = SchemaExpr.DefaultValue\n  ): MigrationBuilder[A, B]\n\n  def renameField(\n    from: A => Any,\n    to: B => Any\n  ): MigrationBuilder[A, B]\n\n  def transformField(\n    from: A => Any,\n    to: B => Any,\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def mandateField(\n    source: A => Option[?],\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def optionalizeField(\n    source: A => Any,\n    target: B => Option[?]\n  ): MigrationBuilder[A, B]\n\n  def changeFieldType(\n    source: A => Any,\n    target: B => Any,\n    converter: SchemaExpr[A, ?]  // primitive-to-primitive only\n  ): MigrationBuilder[A, B]\n\n  // ----- Enum operations (limited) -----\n\n  def renameCase[SumA, SumB](\n    from: String,\n    to: String\n  ): MigrationBuilder[A, B]\n\n  def transformCase[SumA, CaseA, SumB, CaseB](\n    caseMigration: MigrationBuilder[CaseA, CaseB] => MigrationBuilder[CaseA, CaseB]\n  ): MigrationBuilder[A, B]\n\n  // ----- Collections -----\n\n  def transformElements(\n    at: A => Vector[?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  // ----- Maps -----\n\n  def transformKeys(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def transformValues(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  /** Build migration with full macro validation */\n  def build: Migration[A, B]\n\n  /** Build migration without full validation */\n  def buildPartial: Migration[A, B]\n}\n```\n\n---\n\n## Migration Actions (Untyped Core)\n\nAll actions operate at a **path**, represented by `DynamicOptic`.\n\n```scala\nsealed trait MigrationAction {\n  def at: DynamicOptic\n  def reverse: MigrationAction\n}\n```\n\n### Record Actions\n\n```scala\ncase class AddField(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class DropField(\n  at: DynamicOptic,\n  defaultForReverse: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Rename(\n  at: DynamicOptic,\n  to: String\n) extends MigrationAction\n\ncase class TransformValue(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Mandate(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Optionalize(\n  at: DynamicOptic\n) extends MigrationAction\n\ncase class Join(\n  at: DynamicOptic,\n  sourcePaths: Vector[DynamicOptic],\n  combiner: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Split(\n  at: DynamicOptic,\n  targetPaths: Vector[DynamicOptic],\n  splitter: SchemaExpr[?]\n) extends MigrationAction\n\ncase class ChangeType(\n  at: DynamicOptic,\n  converter: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n### Enum Actions (Supported)\n\n```scala\ncase class RenameCase(\n  at: DynamicOptic,\n  from: String,\n  to: String\n) extends MigrationAction\n\ncase class TransformCase(\n  at: DynamicOptic,\n  actions: Vector[MigrationAction]\n) extends MigrationAction\n```\n\n> Enum case addition / removal is **out of scope** for this ticket\n> (requires composite value construction).\n\n---\n\n### Collection / Map Actions\n\n```scala\ncase class TransformElements(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformKeys(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformValues(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n## SchemaExpr Integration\n\n* Used for all value-level transformations\n* **Constraints for this ticket**:\n\n  * primitive → primitive only\n  * joins / splits must produce primitives\n  * no record / enum construction\n\n### `SchemaExpr.DefaultValue`\n\nA special expression that:\n\n1. uses the macro-captured field schema\n2. calls `schema.defaultValue`\n3. converts the value to `DynamicValue`\n4. is stored for reverse migrations\n\n---\n\n## Type Modeling\n\n### Records (Structural Types)\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\ntype PersonV1 = { val fullName: String; val age: Int }\n\nimplicit val v0Schema: Schema[PersonV0] = Schema.structural[PersonV0]\nimplicit val v1Schema: Schema[PersonV1] = Schema.structural[PersonV1]\n```\n\n---\n\n### Enums (Union of Structural Types with Tags)\n\nEnums are encoded into structural types by using union types, together with singleton types (string literals, which represent the name of the case of the enum).\n\nIn structural types, the names of the type aliases shown below are not relevant, nor are they used.\n\n```scala\ntype OldCreditCard =\n  { type Tag = \"CreditCard\"; def number: String; def exp: String }\ntype OldWireTransfer =\n  { type Tag = \"WireTransfer\"; def account: String; def routing: String }\ntype OldPaymentMethod = OldCreditCard | OldWireTransfer\n```\n\nMacros extract:\n\n* refinement type → structure of the case\n* type `Tag` with singleton type → case tag\n\n---\n\n## Laws\n\n### Identity\n\n```scala\nMigration.identity[A].apply(a) == Right(a)\n```\n\n### Associativity\n\n```scala\n(m1 ++ m2) ++ m3 == m1 ++ (m2 ++ m3)\n```\n\n### Structural Reverse\n\n```scala\nm.reverse.reverse == m\n```\n\n### Best-Effort Semantic Inverse\n\n```scala\nm.apply(a) == Right(b) ⇒ m.reverse.apply(b) == Right(a)\n```\n\n(when sufficient information exists)\n\n---\n\n## Error Handling\n\n* All runtime errors return `MigrationError`\n* Errors must capture **path information** (`DynamicOptic`)\n* Enables diagnostics such as:\n\n> “Failed to apply TransformValue at `.addresses.each.streetNumber`”\n\n---\n\n## Example\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\n\n@schema\ncase class Person(fullName: String, age: Int)\n\nval migration =\n  Migration.newBuilder[PersonV0, Person]\n    .addField(_.age, 0)\n    .build\n\nval old =\n  new { val firstName = \"John\"; val lastName = \"Doe\" }\n\nmigration(old)\n// Right(Person(\"John Doe\", 0))\n```\n\n---\n\n## Success Criteria\n\n* [ ] `DynamicMigration` fully serializable\n* [ ] `Migration[A, B]` wraps schemas and actions\n* [ ] All actions path-based via `DynamicOptic`\n* [ ] User API uses selector functions (`S => A`) for \"optics\" on old and new types\n* [ ] Macro validation in `.build` to confirm \"old\" has been migrated to \"new\"\n* [ ] `.buildPartial` supported\n* [ ] Structural reverse implemented\n* [ ] Identity & associativity laws hold\n* [ ] Enum rename / transform supported\n* [ ] Errors include path information\n* [ ] Comprehensive tests\n* [ ] Scala 2.13 and Scala 3.5+ supported\n",
                  "html_url": "https://github.com/zio/zio-blocks/issues/519"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#519",
              "body": "## Overview\n\nImplement a **pure, algebraic migration system** for ZIO Schema 2 that represents **structural transformations between schema versions** as first-class, serializable data.\n\nA migration describes how to transform data from one schema version to another, enabling:\n\n* schema evolution\n* backward / forward compatibility\n* data versioning\n* offline migrations (JSON, SQL, data lakes, registries, etc.)\n\nThe system provides a **typed, macro-validated user API** (`Migration[A, B]`) built on a **pure, serializable core** (`DynamicMigration`) that operates on `DynamicValue`. \n\nThe ADT is fully introspectable and can be used to generate DDL, etc.\n\n## Motivation & Big Picture\n\n### Why structural types?\n\nWhen evolving schemas over time, **older versions of data types should not require runtime representations**.\n\nIn this design:\n\n* **Current versions** are represented by real case classes / enums\n* **Past versions** are represented using:\n\n  * **structural types** for records\n  * **abstract types + intersection types** for sum types\n\nThese types:\n\n* exist **only at compile time**\n* have **no runtime representation**\n* introduce **zero runtime overhead**\n* do **not require optics or instances to be kept around**\n\nThis allows you to describe arbitrarily old versions of data *without polluting your runtime or codebase*.\n\n#### Typical Workflow\n\nA typical workflow looks like:\n\n1. You have a current type:\n\n   ```scala\n   @schema\n   case class Person(name: String, age: Int)\n   ```\n\n2. You derive and copy its structural shape:\n\n   ```scala\n   type PersonV1 = { def name: String; def age: Int }\n   ```\n\n3. You evolve the real type:\n\n   ```scala\n   @schema\n   case class Person(fullName: String, age: Int, country: String)\n   ```\n\n4. You keep only:\n\n   * the **current** runtime type\n   * the **structural type** for the old version\n   * a **pure migration** between them\n\nNo old case classes. No old optics. No runtime baggage.\n\nNote there is no requirement that the \"current\" type actually be a real case class, enum, etc.--so you can work purely with structural types, allowing you to define migrations for data types that are never materialized as runtime structures.\n\n---\n\n### Why pure data migrations?\n\nMigrations are represented entirely as **pure data**:\n\n* no user functions\n* no closures\n* no reflection\n* no runtime code generation\n\nAs a result:\n\n* migrations can be **serialized**\n* stored in **registries**\n* applied **dynamically**\n* inspected and transformed\n* used to generate:\n\n  * upgraders\n  * downgraders\n  * SQL DDL / DML\n  * offline data transforms\n\nWhile code generation is **out of scope for this ticket**, this explains many design decisions (invertibility, path-based actions, no functions).\n\n---\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed migration (user-facing API)\ncase class Migration[A, B](\n  dynamicMigration: DynamicMigration,\n  sourceSchema: Schema[A], // These are structural schemas!!!\n  targetSchema: Schema[B] // These are structural schemas!!!\n) {\n  /** Apply migration to transform A to B */\n  def apply(value: A): Either[MigrationError, B]\n\n  /** Compose migrations sequentially */\n  def ++[C](that: Migration[B, C]): Migration[A, C]\n\n  /** Alias for ++ */\n  def andThen[C](that: Migration[B, C]): Migration[A, C] = this ++ that\n\n  /** Reverse migration (structural inverse; runtime is best-effort) */\n  def reverse: Migration[B, A]\n}\n```\n\n```scala\n// Untyped migration (pure data, fully serializable)\ncase class DynamicMigration(\n  actions: Vector[MigrationAction]\n) {\n  def apply(value: DynamicValue): Either[MigrationError, DynamicValue]\n  def ++(that: DynamicMigration): DynamicMigration\n  def reverse: DynamicMigration\n}\n```\n\n* `Migration[A, B]` is introspectable, but not pure data due to bindings inside schemas\n* `DynamicMigration` is **fully serializable**\n\n---\n\n## User-Facing API: Selector Expressions\n\n### Selectors, not optics\n\nThe user-facing API **does not expose optics**.\n\nInstead, all locations are specified using **selector expressions**:\n\n```scala\nS => A\n```\n\nExamples:\n\n```scala\n_.name\n_.address.street\n_.addresses.each.streetNumber\n_.country.when[UK]\n```\n\nTo see the syntax, one can look at the `optic` macro, which utilizes the same selector syntax for optic creation (e.g. `optic(_.address.street)`, etc.).\n\n### Macro extraction\n\nAll builder methods that accept selectors are **implemented via macros** (or via a macro-generated type class such as `ToDynamicOptic`).\n\nThe macro:\n\n1. Inspects the selector expression\n2. Validates it is a supported projection\n3. Converts it into a `DynamicOptic`\n4. Stores that optic in the migration action\n\nSupported projections include:\n\n* field access (`_.foo.bar`)\n* case selection (`_.country.when[UK]`)\n* collection traversal (`_.items.each`)\n* (future) key access, wrappers, etc.\n\n`DynamicOptic` is **never exposed publicly**.\n\n---\n\n## Migration Builder\n\nAll selector-accepting methods are implemented via macros. For simplicity, these are shown as functions (e.g. `A => Any`), but this is NOT the way to implement them. Either all these functions need to be macros, or a macro needs to be used to generate an implicit / given at each call site. Macros may do additional validation to constrain the validity of these different types of transformations.\n\n```scala\nclass MigrationBuilder[A, B](\n  sourceSchema: Schema[A],\n  targetSchema: Schema[B],\n  actions: Vector[MigrationAction]\n) {\n\n  // ----- Record operations -----\n\n  def addField(\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def dropField(\n    source: A => Any,\n    defaultForReverse: SchemaExpr[B, ?] = SchemaExpr.DefaultValue\n  ): MigrationBuilder[A, B]\n\n  def renameField(\n    from: A => Any,\n    to: B => Any\n  ): MigrationBuilder[A, B]\n\n  def transformField(\n    from: A => Any,\n    to: B => Any,\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def mandateField(\n    source: A => Option[?],\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def optionalizeField(\n    source: A => Any,\n    target: B => Option[?]\n  ): MigrationBuilder[A, B]\n\n  def changeFieldType(\n    source: A => Any,\n    target: B => Any,\n    converter: SchemaExpr[A, ?]  // primitive-to-primitive only\n  ): MigrationBuilder[A, B]\n\n  // ----- Enum operations (limited) -----\n\n  def renameCase[SumA, SumB](\n    from: String,\n    to: String\n  ): MigrationBuilder[A, B]\n\n  def transformCase[SumA, CaseA, SumB, CaseB](\n    caseMigration: MigrationBuilder[CaseA, CaseB] => MigrationBuilder[CaseA, CaseB]\n  ): MigrationBuilder[A, B]\n\n  // ----- Collections -----\n\n  def transformElements(\n    at: A => Vector[?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  // ----- Maps -----\n\n  def transformKeys(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def transformValues(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  /** Build migration with full macro validation */\n  def build: Migration[A, B]\n\n  /** Build migration without full validation */\n  def buildPartial: Migration[A, B]\n}\n```\n\n---\n\n## Migration Actions (Untyped Core)\n\nAll actions operate at a **path**, represented by `DynamicOptic`.\n\n```scala\nsealed trait MigrationAction {\n  def at: DynamicOptic\n  def reverse: MigrationAction\n}\n```\n\n### Record Actions\n\n```scala\ncase class AddField(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class DropField(\n  at: DynamicOptic,\n  defaultForReverse: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Rename(\n  at: DynamicOptic,\n  to: String\n) extends MigrationAction\n\ncase class TransformValue(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Mandate(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Optionalize(\n  at: DynamicOptic\n) extends MigrationAction\n\ncase class Join(\n  at: DynamicOptic,\n  sourcePaths: Vector[DynamicOptic],\n  combiner: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Split(\n  at: DynamicOptic,\n  targetPaths: Vector[DynamicOptic],\n  splitter: SchemaExpr[?]\n) extends MigrationAction\n\ncase class ChangeType(\n  at: DynamicOptic,\n  converter: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n### Enum Actions (Supported)\n\n```scala\ncase class RenameCase(\n  at: DynamicOptic,\n  from: String,\n  to: String\n) extends MigrationAction\n\ncase class TransformCase(\n  at: DynamicOptic,\n  actions: Vector[MigrationAction]\n) extends MigrationAction\n```\n\n> Enum case addition / removal is **out of scope** for this ticket\n> (requires composite value construction).\n\n---\n\n### Collection / Map Actions\n\n```scala\ncase class TransformElements(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformKeys(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformValues(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n## SchemaExpr Integration\n\n* Used for all value-level transformations\n* **Constraints for this ticket**:\n\n  * primitive → primitive only\n  * joins / splits must produce primitives\n  * no record / enum construction\n\n### `SchemaExpr.DefaultValue`\n\nA special expression that:\n\n1. uses the macro-captured field schema\n2. calls `schema.defaultValue`\n3. converts the value to `DynamicValue`\n4. is stored for reverse migrations\n\n---\n\n## Type Modeling\n\n### Records (Structural Types)\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\ntype PersonV1 = { val fullName: String; val age: Int }\n\nimplicit val v0Schema: Schema[PersonV0] = Schema.structural[PersonV0]\nimplicit val v1Schema: Schema[PersonV1] = Schema.structural[PersonV1]\n```\n\n---\n\n### Enums (Union of Structural Types with Tags)\n\nEnums are encoded into structural types by using union types, together with singleton types (string literals, which represent the name of the case of the enum).\n\nIn structural types, the names of the type aliases shown below are not relevant, nor are they used.\n\n```scala\ntype OldCreditCard =\n  { type Tag = \"CreditCard\"; def number: String; def exp: String }\ntype OldWireTransfer =\n  { type Tag = \"WireTransfer\"; def account: String; def routing: String }\ntype OldPaymentMethod = OldCreditCard | OldWireTransfer\n```\n\nMacros extract:\n\n* refinement type → structure of the case\n* type `Tag` with singleton type → case tag\n\n---\n\n## Laws\n\n### Identity\n\n```scala\nMigration.identity[A].apply(a) == Right(a)\n```\n\n### Associativity\n\n```scala\n(m1 ++ m2) ++ m3 == m1 ++ (m2 ++ m3)\n```\n\n### Structural Reverse\n\n```scala\nm.reverse.reverse == m\n```\n\n### Best-Effort Semantic Inverse\n\n```scala\nm.apply(a) == Right(b) ⇒ m.reverse.apply(b) == Right(a)\n```\n\n(when sufficient information exists)\n\n---\n\n## Error Handling\n\n* All runtime errors return `MigrationError`\n* Errors must capture **path information** (`DynamicOptic`)\n* Enables diagnostics such as:\n\n> “Failed to apply TransformValue at `.addresses.each.streetNumber`”\n\n---\n\n## Example\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\n\n@schema\ncase class Person(fullName: String, age: Int)\n\nval migration =\n  Migration.newBuilder[PersonV0, Person]\n    .addField(_.age, 0)\n    .build\n\nval old =\n  new { val firstName = \"John\"; val lastName = \"Doe\" }\n\nmigration(old)\n// Right(Person(\"John Doe\", 0))\n```\n\n---\n\n## Success Criteria\n\n* [ ] `DynamicMigration` fully serializable\n* [ ] `Migration[A, B]` wraps schemas and actions\n* [ ] All actions path-based via `DynamicOptic`\n* [ ] User API uses selector functions (`S => A`) for \"optics\" on old and new types\n* [ ] Macro validation in `.build` to confirm \"old\" has been migrated to \"new\"\n* [ ] `.buildPartial` supported\n* [ ] Structural reverse implemented\n* [ ] Identity & associativity laws hold\n* [ ] Enum rename / transform supported\n* [ ] Errors include path information\n* [ ] Comprehensive tests\n* [ ] Scala 2.13 and Scala 3.5+ supported\n",
              "url": "https://github.com/zio/zio-blocks/issues/519",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#3472",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2026-02-27T22:50:22.368Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:22.368Z",
            "created_at": "2026-02-27T22:50:22.368Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#3472",
              "status": "open",
              "type": "issue",
              "number": 3472,
              "title": "Split into multiple modules",
              "source": {
                "data": {
                  "id": "source-zio#3472",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Split into multiple modules",
                  "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
                  "html_url": "https://github.com/zio/zio-http/issues/3472"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3472",
              "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
              "url": "https://github.com/zio/zio-http/issues/3472",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#9810",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2026-02-27T22:50:22.499Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:22.499Z",
            "created_at": "2026-02-27T22:50:22.499Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#9810",
              "status": "open",
              "type": "issue",
              "number": 9810,
              "title": "ZStreams buffer(1) is buffering 2.",
              "source": {
                "data": {
                  "id": "source-zio#9810",
                  "user": {
                    "login": "douglasthomsen",
                    "id": 88000378,
                    "node_id": "MDQ6VXNlcjg4MDAwMzc4",
                    "avatar_url": "https://avatars.githubusercontent.com/u/88000378?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/douglasthomsen",
                    "html_url": "https://github.com/douglasthomsen",
                    "followers_url": "https://api.github.com/users/douglasthomsen/followers",
                    "following_url": "https://api.github.com/users/douglasthomsen/following{/other_user}",
                    "gists_url": "https://api.github.com/users/douglasthomsen/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/douglasthomsen/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/douglasthomsen/subscriptions",
                    "organizations_url": "https://api.github.com/users/douglasthomsen/orgs",
                    "repos_url": "https://api.github.com/users/douglasthomsen/repos",
                    "events_url": "https://api.github.com/users/douglasthomsen/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/douglasthomsen/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZStreams buffer(1) is buffering 2.",
                  "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
                  "html_url": "https://github.com/zio/zio/issues/9810"
                },
                "type": "github"
              },
              "hash": "zio/zio#9810",
              "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
              "url": "https://github.com/zio/zio/issues/9810",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#9844",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2026-02-27T22:50:22.638Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:22.638Z",
            "created_at": "2026-02-27T22:50:22.638Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#9844",
              "status": "open",
              "type": "issue",
              "number": 9844,
              "title": "improved `Queue` shutdown functionality",
              "source": {
                "data": {
                  "id": "source-zio#9844",
                  "user": {
                    "login": "mberndt123",
                    "id": 11650737,
                    "node_id": "MDQ6VXNlcjExNjUwNzM3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/11650737?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/mberndt123",
                    "html_url": "https://github.com/mberndt123",
                    "followers_url": "https://api.github.com/users/mberndt123/followers",
                    "following_url": "https://api.github.com/users/mberndt123/following{/other_user}",
                    "gists_url": "https://api.github.com/users/mberndt123/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/mberndt123/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/mberndt123/subscriptions",
                    "organizations_url": "https://api.github.com/users/mberndt123/orgs",
                    "repos_url": "https://api.github.com/users/mberndt123/repos",
                    "events_url": "https://api.github.com/users/mberndt123/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/mberndt123/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "improved `Queue` shutdown functionality",
                  "body": "Hey, I've recently proposed something on Discord, and since feedback has been rather positive, I'm making a ticket to track the idea.\n\nI've been working with Queues recently, and I've been having some issues around `shutdown` that I would like to address.\n\nSpecifically, I find it a common pattern that I send some kind of request object through a queue because I want another fiber to perform some action on my behalf. Along with the request, I send a `Promise` to have that fiber communicate the outcome of that action to me. By and large this works fine. The issue arises when the fiber that I'm sending requests to fails. In that case, I would like it to communicate the cause of the failure back to the other fibers. This is easy enough for the requests that I've already pulled out of the queue: I simply fail those promises.\nBut I also need to deal with other cases: fibers currently blocked in an `offer` call, future attempts to `offer` to the queue, and I also need to deal with requests that have been submitted to the queue but not yet retrieved.\n\nSo my idea is as follows:\n - add an `E` type parameter to `Queue`\n - add a `shutdownCause` method that takes a type parameter of type `Cause[E]`\n - `shutdownCause` would also return the items currently buffered in the queue in order to dispose of them\n - after `shutdownCause` has been called, any attempt to interact with the queue will fail with the cause\n - methods like `take, offer` etc. should indicate errors of type `E`\n - streams created with `ZStream.fromQueue` would also fail with this cause\n - `shutdownCause` should be atomic: when multiple fibers call it at the same time, one of them wins and the others fail with the cause supplied by the winner\n\nAfaik, adding a new method is a binary compatible change, as is adding a new type parameter. Hence I think this is a source incompatible but binary compatible change. @ghostdogpr therefore suggested it could be added in a ZIO 2.2 release.\n",
                  "html_url": "https://github.com/zio/zio/issues/9844"
                },
                "type": "github"
              },
              "hash": "zio/zio#9844",
              "body": "Hey, I've recently proposed something on Discord, and since feedback has been rather positive, I'm making a ticket to track the idea.\n\nI've been working with Queues recently, and I've been having some issues around `shutdown` that I would like to address.\n\nSpecifically, I find it a common pattern that I send some kind of request object through a queue because I want another fiber to perform some action on my behalf. Along with the request, I send a `Promise` to have that fiber communicate the outcome of that action to me. By and large this works fine. The issue arises when the fiber that I'm sending requests to fails. In that case, I would like it to communicate the cause of the failure back to the other fibers. This is easy enough for the requests that I've already pulled out of the queue: I simply fail those promises.\nBut I also need to deal with other cases: fibers currently blocked in an `offer` call, future attempts to `offer` to the queue, and I also need to deal with requests that have been submitted to the queue but not yet retrieved.\n\nSo my idea is as follows:\n - add an `E` type parameter to `Queue`\n - add a `shutdownCause` method that takes a type parameter of type `Cause[E]`\n - `shutdownCause` would also return the items currently buffered in the queue in order to dispose of them\n - after `shutdownCause` has been called, any attempt to interact with the queue will fail with the cause\n - methods like `take, offer` etc. should indicate errors of type `E`\n - streams created with `ZStream.fromQueue` would also fail with this cause\n - `shutdownCause` should be atomic: when multiple fibers call it at the same time, one of them wins and the others fail with the cause supplied by the winner\n\nAfaik, adding a new method is a binary compatible change, as is adding a new type parameter. Hence I think this is a source incompatible but binary compatible change. @ghostdogpr therefore suggested it could be added in a ZIO 2.2 release.\n",
              "url": "https://github.com/zio/zio/issues/9844",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#9878",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2026-02-27T22:50:22.749Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:22.749Z",
            "created_at": "2026-02-27T22:50:22.749Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#9878",
              "status": "open",
              "type": "issue",
              "number": 9878,
              "title": "ZScheduler parks+unparks workers too frequently",
              "source": {
                "data": {
                  "id": "source-zio#9878",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZScheduler parks+unparks workers too frequently",
                  "body": "Unparking workers is slow and invoked in the hotpath too often. I think we may need to trade some fairness for aggression to avoid excessive cycling.\n\n`maybeUnparkWorker` (obviously `LockSupport.unpark(worker)`) is very expensive: https://github.com/zio/zio/blob/series/2.x/core/jvm-native/src/main/scala/zio/internal/ZScheduler.scala#L443-L454",
                  "html_url": "https://github.com/zio/zio/issues/9878"
                },
                "type": "github"
              },
              "hash": "zio/zio#9878",
              "body": "Unparking workers is slow and invoked in the hotpath too often. I think we may need to trade some fairness for aggression to avoid excessive cycling.\n\n`maybeUnparkWorker` (obviously `LockSupport.unpark(worker)`) is very expensive: https://github.com/zio/zio/blob/series/2.x/core/jvm-native/src/main/scala/zio/internal/ZScheduler.scala#L443-L454",
              "url": "https://github.com/zio/zio/issues/9878",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#9877",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2026-02-27T22:50:22.873Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:22.873Z",
            "created_at": "2026-02-27T22:50:22.873Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#9877",
              "status": "open",
              "type": "issue",
              "number": 9877,
              "title": "Can Fiber(Runtime) and Promise be merged?",
              "source": {
                "data": {
                  "id": "source-zio#9877",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Can Fiber(Runtime) and Promise be merged?",
                  "body": "A Promise awaiting completion is essentially a Fiber parked awaiting an async callback. When a Fiber is forking work (which will eventually complete a promise), then awaiting a Promise, we end up with unnecessary allocations + indirection.\n\nit would be useful to have `Promise.become` or similar to link fibers/promises.",
                  "html_url": "https://github.com/zio/zio/issues/9877"
                },
                "type": "github"
              },
              "hash": "zio/zio#9877",
              "body": "A Promise awaiting completion is essentially a Fiber parked awaiting an async callback. When a Fiber is forking work (which will eventually complete a promise), then awaiting a Promise, we end up with unnecessary allocations + indirection.\n\nit would be useful to have `Promise.become` or similar to link fibers/promises.",
              "url": "https://github.com/zio/zio/issues/9877",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#9874",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2026-02-27T22:50:23.005Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:23.005Z",
            "created_at": "2026-02-27T22:50:23.005Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#9874",
              "status": "open",
              "type": "issue",
              "number": 9874,
              "title": "Handling errors allows recovering from defects",
              "source": {
                "data": {
                  "id": "source-zio#9874",
                  "user": {
                    "login": "kyri-petrou",
                    "id": 67301607,
                    "node_id": "MDQ6VXNlcjY3MzAxNjA3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/67301607?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kyri-petrou",
                    "html_url": "https://github.com/kyri-petrou",
                    "followers_url": "https://api.github.com/users/kyri-petrou/followers",
                    "following_url": "https://api.github.com/users/kyri-petrou/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kyri-petrou/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kyri-petrou/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kyri-petrou/subscriptions",
                    "organizations_url": "https://api.github.com/users/kyri-petrou/orgs",
                    "repos_url": "https://api.github.com/users/kyri-petrou/repos",
                    "events_url": "https://api.github.com/users/kyri-petrou/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kyri-petrou/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Handling errors allows recovering from defects",
                  "body": "Sigh... Well, this is annoying. When a Cause contains both a failure and a defect (i.e., Fail & Die), failure handling assumes that the Cause does not contain any defects and therefor silently ignores them.\n\nRepro:\n\n```scala\nimport zio.*\n\nobject Foo extends ZIOAppDefault {\n  val dieCause: Cause[String] = Cause.die(new RuntimeException(\"boom\"))\n  val combinedCause = dieCause && Cause.fail(\"boom\")\n\n  def run = ZIO.failCause(combinedCause).catchAll { e =>\n    ZIO.debug(e)\n  } *> ZIO.debug(\"Success\")\n}\n```\nprints:\n```\nhandled: boom\nSuccess\n```\n\nHowever if we substituted `ZIO.failCause(combinedCause)` with `ZIO.failCause(dieCause)`:\n\n```\ntimestamp=2025-05-20T16:31:09.291104Z level=ERROR thread=#zio-fiber-1707930317 message=\"\" cause=\"java.lang.RuntimeException: boom\n\tat Foo$.<clinit>(Foo.scala:4)\n\tat Foo.main(Foo.scala)\n\tat <empty>.Foo.run(Foo.scala:7)\n\tat <empty>.Foo.run(Foo.scala:9)\n\"\n```\n\nWith both of these causes, the outcome should be the same as defects should always be prioritised over failures. This gets even worse when interruption is involved, because the failure handling will be prioritised over it.\n\nHaving said that, this has the potential to massively alter applications so I'm too scared to fix it.\n@ghostdogpr @jdegoes  @hearnadam @guizmaii I summon you all for some wisdom",
                  "html_url": "https://github.com/zio/zio/issues/9874"
                },
                "type": "github"
              },
              "hash": "zio/zio#9874",
              "body": "Sigh... Well, this is annoying. When a Cause contains both a failure and a defect (i.e., Fail & Die), failure handling assumes that the Cause does not contain any defects and therefor silently ignores them.\n\nRepro:\n\n```scala\nimport zio.*\n\nobject Foo extends ZIOAppDefault {\n  val dieCause: Cause[String] = Cause.die(new RuntimeException(\"boom\"))\n  val combinedCause = dieCause && Cause.fail(\"boom\")\n\n  def run = ZIO.failCause(combinedCause).catchAll { e =>\n    ZIO.debug(e)\n  } *> ZIO.debug(\"Success\")\n}\n```\nprints:\n```\nhandled: boom\nSuccess\n```\n\nHowever if we substituted `ZIO.failCause(combinedCause)` with `ZIO.failCause(dieCause)`:\n\n```\ntimestamp=2025-05-20T16:31:09.291104Z level=ERROR thread=#zio-fiber-1707930317 message=\"\" cause=\"java.lang.RuntimeException: boom\n\tat Foo$.<clinit>(Foo.scala:4)\n\tat Foo.main(Foo.scala)\n\tat <empty>.Foo.run(Foo.scala:7)\n\tat <empty>.Foo.run(Foo.scala:9)\n\"\n```\n\nWith both of these causes, the outcome should be the same as defects should always be prioritised over failures. This gets even worse when interruption is involved, because the failure handling will be prioritised over it.\n\nHaving said that, this has the potential to massively alter applications so I'm too scared to fix it.\n@ghostdogpr @jdegoes  @hearnadam @guizmaii I summon you all for some wisdom",
              "url": "https://github.com/zio/zio/issues/9874",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#9681",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2026-02-27T22:50:23.151Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:23.151Z",
            "created_at": "2026-02-27T22:50:23.151Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#9681",
              "status": "open",
              "type": "issue",
              "number": 9681,
              "title": "Scala Native `WeakConcurrentBag` NPE when forking 10K fibers",
              "source": {
                "data": {
                  "id": "source-zio#9681",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Scala Native `WeakConcurrentBag` NPE when forking 10K fibers",
                  "body": "```\n[info]   - PromiseSpec - waiter stack safety\n[info]     Exception in thread \"zio-fiber-931\" java.lang.NullPointerException: null\n[info]     \tat scala.scalanative.runtime.package$.throwNullPointer(Unknown Source)\n[info]     \tat <none>.(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.treeifyBin(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.putVal(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap$KeySetView.add(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.addToLongTermStorage(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.add(Unknown Source)\n[info]     \tat zio.internal.FiberScope$global$.add(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.makeChildFiber(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.fork(Unknown Source)\n[info]     \tat zio.ZIO.$anonfun$forkWithScopeOverride$2(Unknown Source)\n[info]     \tat zio.ZIO$$Lambda$280.apply(Unknown Source)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:127)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:124)\n```\nI introduced a new test in #9569 which resulted in this strange failure on Native.",
                  "html_url": "https://github.com/zio/zio/issues/9681"
                },
                "type": "github"
              },
              "hash": "zio/zio#9681",
              "body": "```\n[info]   - PromiseSpec - waiter stack safety\n[info]     Exception in thread \"zio-fiber-931\" java.lang.NullPointerException: null\n[info]     \tat scala.scalanative.runtime.package$.throwNullPointer(Unknown Source)\n[info]     \tat <none>.(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.treeifyBin(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.putVal(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap$KeySetView.add(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.addToLongTermStorage(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.add(Unknown Source)\n[info]     \tat zio.internal.FiberScope$global$.add(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.makeChildFiber(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.fork(Unknown Source)\n[info]     \tat zio.ZIO.$anonfun$forkWithScopeOverride$2(Unknown Source)\n[info]     \tat zio.ZIO$$Lambda$280.apply(Unknown Source)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:127)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:124)\n```\nI introduced a new test in #9569 which resulted in this strange failure on Native.",
              "url": "https://github.com/zio/zio/issues/9681",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "zio#9909",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "zio",
              "id": "generated-zio",
              "name": "Zio",
              "description": "",
              "members": [],
              "display_name": "Zio",
              "created_at": "2026-02-27T22:50:23.307Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/zio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:23.307Z",
            "created_at": "2026-02-27T22:50:23.307Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-zio#9909",
              "status": "open",
              "type": "issue",
              "number": 9909,
              "title": "Create test suite that tests the correct behaviour of `ZIOApp`",
              "source": {
                "data": {
                  "id": "source-zio#9909",
                  "user": {
                    "login": "kyri-petrou",
                    "id": 67301607,
                    "node_id": "MDQ6VXNlcjY3MzAxNjA3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/67301607?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kyri-petrou",
                    "html_url": "https://github.com/kyri-petrou",
                    "followers_url": "https://api.github.com/users/kyri-petrou/followers",
                    "following_url": "https://api.github.com/users/kyri-petrou/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kyri-petrou/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kyri-petrou/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kyri-petrou/subscriptions",
                    "organizations_url": "https://api.github.com/users/kyri-petrou/orgs",
                    "repos_url": "https://api.github.com/users/kyri-petrou/repos",
                    "events_url": "https://api.github.com/users/kyri-petrou/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kyri-petrou/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Create test suite that tests the correct behaviour of `ZIOApp`",
                  "body": "The test suite needs to run during CI and test the behaviour of `ZIOApp` when:\n1. The app completes on its own (either via failure or success)\n2. The app completes due to an external signal (e.g., SIGINT)\n\nWhat needs to be tested:\n1. Correct error code is emitted\n2. Application finalizers are run (except for catastrophic failures)\n3. Shutdown sequence doesn't hang\n4. `gracefulShutdownTimeout` is respected\n5. A lot of use-cases from past issues:\ni. #9901 \nii. #9807\niii. #9240\niv. (I'll add others as I find them)",
                  "html_url": "https://github.com/zio/zio/issues/9909"
                },
                "type": "github"
              },
              "hash": "zio/zio#9909",
              "body": "The test suite needs to run during CI and test the behaviour of `ZIOApp` when:\n1. The app completes on its own (either via failure or success)\n2. The app completes due to an external signal (e.g., SIGINT)\n\nWhat needs to be tested:\n1. Correct error code is emitted\n2. Application finalizers are run (except for catastrophic failures)\n3. Shutdown sequence doesn't hang\n4. `gracefulShutdownTimeout` is respected\n5. A lot of use-cases from past issues:\ni. #9901 \nii. #9807\niii. #9240\niv. (I'll add others as I find them)",
              "url": "https://github.com/zio/zio/issues/9909",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#3960",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2026-02-27T22:50:25.362Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:25.362Z",
            "created_at": "2026-02-27T22:50:25.362Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3960",
              "status": "open",
              "type": "issue",
              "number": 3960,
              "title": "[🔌 Provider]: Nagios Provider",
              "source": {
                "data": {
                  "id": "source-keephq#3960",
                  "user": {
                    "login": "talboren",
                    "id": 68807791,
                    "node_id": "MDQ6VXNlcjY4ODA3Nzkx",
                    "avatar_url": "https://avatars.githubusercontent.com/u/68807791?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/talboren",
                    "html_url": "https://github.com/talboren",
                    "followers_url": "https://api.github.com/users/talboren/followers",
                    "following_url": "https://api.github.com/users/talboren/following{/other_user}",
                    "gists_url": "https://api.github.com/users/talboren/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/talboren/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/talboren/subscriptions",
                    "organizations_url": "https://api.github.com/users/talboren/orgs",
                    "repos_url": "https://api.github.com/users/talboren/repos",
                    "events_url": "https://api.github.com/users/talboren/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/talboren/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[🔌 Provider]: Nagios Provider",
                  "body": "https://www.nagios.org/",
                  "html_url": "https://github.com/keephq/keep/issues/3960"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3960",
              "body": "https://www.nagios.org/",
              "url": "https://github.com/keephq/keep/issues/3960",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#3526",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2026-02-27T22:50:25.460Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:25.460Z",
            "created_at": "2026-02-27T22:50:25.460Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3526",
              "status": "open",
              "type": "issue",
              "number": 3526,
              "title": "[🔌 Provider]: Solarwinds",
              "source": {
                "data": {
                  "id": "source-keephq#3526",
                  "user": {
                    "login": "Matvey-Kuk",
                    "id": 3284841,
                    "node_id": "MDQ6VXNlcjMyODQ4NDE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/3284841?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Matvey-Kuk",
                    "html_url": "https://github.com/Matvey-Kuk",
                    "followers_url": "https://api.github.com/users/Matvey-Kuk/followers",
                    "following_url": "https://api.github.com/users/Matvey-Kuk/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Matvey-Kuk/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Matvey-Kuk/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Matvey-Kuk/subscriptions",
                    "organizations_url": "https://api.github.com/users/Matvey-Kuk/orgs",
                    "repos_url": "https://api.github.com/users/Matvey-Kuk/repos",
                    "events_url": "https://api.github.com/users/Matvey-Kuk/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Matvey-Kuk/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[🔌 Provider]: Solarwinds",
                  "body": "We're looking for a https://www.solarwinds.com/ provider for Keep.",
                  "html_url": "https://github.com/keephq/keep/issues/3526"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3526",
              "body": "We're looking for a https://www.solarwinds.com/ provider for Keep.",
              "url": "https://github.com/keephq/keep/issues/3526",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#3376",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2026-02-27T22:50:25.560Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:25.560Z",
            "created_at": "2026-02-27T22:50:25.560Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3376",
              "status": "open",
              "type": "issue",
              "number": 3376,
              "title": "[➕ Feature]: Add a way to validate Keep workflows from CI",
              "source": {
                "data": {
                  "id": "source-keephq#3376",
                  "user": {
                    "login": "shahargl",
                    "id": 12069200,
                    "node_id": "MDQ6VXNlcjEyMDY5MjAw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/12069200?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/shahargl",
                    "html_url": "https://github.com/shahargl",
                    "followers_url": "https://api.github.com/users/shahargl/followers",
                    "following_url": "https://api.github.com/users/shahargl/following{/other_user}",
                    "gists_url": "https://api.github.com/users/shahargl/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/shahargl/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/shahargl/subscriptions",
                    "organizations_url": "https://api.github.com/users/shahargl/orgs",
                    "repos_url": "https://api.github.com/users/shahargl/repos",
                    "events_url": "https://api.github.com/users/shahargl/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/shahargl/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[➕ Feature]: Add a way to validate Keep workflows from CI",
                  "body": "https://github.com/keephq/keep/pull/5665 https://github.com/keephq/keep/pull/5673 https://github.com/keephq/keep/pull/5642 https://github.com/keephq/keep/pull/5678 https://github.com/keephq/keep/pull/",
                  "html_url": "https://github.com/keephq/keep/issues/3376"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3376",
              "body": "https://github.com/keephq/keep/pull/5665 https://github.com/keephq/keep/pull/5673 https://github.com/keephq/keep/pull/5642 https://github.com/keephq/keep/pull/5678 https://github.com/keephq/keep/pull/",
              "url": "https://github.com/keephq/keep/issues/3376",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#2112",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2026-02-27T22:50:25.666Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:25.666Z",
            "created_at": "2026-02-27T22:50:25.666Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#2112",
              "status": "open",
              "type": "issue",
              "number": 2112,
              "title": "[🔌 Provider]: SNMP provider",
              "source": {
                "data": {
                  "id": "source-keephq#2112",
                  "user": {
                    "login": "shahargl",
                    "id": 12069200,
                    "node_id": "MDQ6VXNlcjEyMDY5MjAw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/12069200?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/shahargl",
                    "html_url": "https://github.com/shahargl",
                    "followers_url": "https://api.github.com/users/shahargl/followers",
                    "following_url": "https://api.github.com/users/shahargl/following{/other_user}",
                    "gists_url": "https://api.github.com/users/shahargl/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/shahargl/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/shahargl/subscriptions",
                    "organizations_url": "https://api.github.com/users/shahargl/orgs",
                    "repos_url": "https://api.github.com/users/shahargl/repos",
                    "events_url": "https://api.github.com/users/shahargl/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/shahargl/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[🔌 Provider]: SNMP provider",
                  "body": "Send SNMP traps/events into Keep as alerts",
                  "html_url": "https://github.com/keephq/keep/issues/2112"
                },
                "type": "github"
              },
              "hash": "keephq/keep#2112",
              "body": "Send SNMP traps/events into Keep as alerts",
              "url": "https://github.com/keephq/keep/issues/2112",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#3322",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2026-02-27T22:50:26.027Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:26.027Z",
            "created_at": "2026-02-27T22:50:26.027Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3322",
              "status": "open",
              "type": "issue",
              "number": 3322,
              "title": "Per-collection metrics for Prometheus",
              "source": {
                "data": {
                  "id": "source-qdrant#3322",
                  "user": {
                    "login": "generall",
                    "id": 1935623,
                    "node_id": "MDQ6VXNlcjE5MzU2MjM=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1935623?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/generall",
                    "html_url": "https://github.com/generall",
                    "followers_url": "https://api.github.com/users/generall/followers",
                    "following_url": "https://api.github.com/users/generall/following{/other_user}",
                    "gists_url": "https://api.github.com/users/generall/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/generall/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/generall/subscriptions",
                    "organizations_url": "https://api.github.com/users/generall/orgs",
                    "repos_url": "https://api.github.com/users/generall/repos",
                    "events_url": "https://api.github.com/users/generall/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/generall/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Per-collection metrics for Prometheus",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, all metrics in `/metrics` are global, meaning that it’s impossible to see differences per collection.\r\n\r\nIn addition to that, all our metrics should have per-collection granularity to allow better aggregation in Prometheus, including:\r\n\r\n- point/vector counts\r\n- REST/gRPC requests\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample:\r\n```\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\"} 0.000046\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection\"} 0.000049\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection-2\"} 0.000046\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreate dedicated endpoint for each collection `/collections/my-collecton/metrics`\r\nbut feedback from DevOps on this idea was negative.\r\n\r\n**Additional context**\r\n\r\nIt might be beneficial to allow users to disable per-collection output. It is especially relevant if there are a lot of collections and metric response could become huge. But this is a nice-to-have requirement.\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently\r\n\r\n",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3322"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3322",
              "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, all metrics in `/metrics` are global, meaning that it’s impossible to see differences per collection.\r\n\r\nIn addition to that, all our metrics should have per-collection granularity to allow better aggregation in Prometheus, including:\r\n\r\n- point/vector counts\r\n- REST/gRPC requests\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample:\r\n```\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\"} 0.000046\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection\"} 0.000049\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection-2\"} 0.000046\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreate dedicated endpoint for each collection `/collections/my-collecton/metrics`\r\nbut feedback from DevOps on this idea was negative.\r\n\r\n**Additional context**\r\n\r\nIt might be beneficial to allow users to disable per-collection output. It is especially relevant if there are a lot of collections and metric response could become huge. But this is a nice-to-have requirement.\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently\r\n\r\n",
              "url": "https://github.com/qdrant/qdrant/issues/3322",
              "tech": [],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#8264",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-02-27T22:50:40.054Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:40.054Z",
            "created_at": "2026-02-27T22:50:40.054Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#8264",
              "status": "open",
              "type": "issue",
              "number": 8264,
              "title": "[Enhancement]: WordPress + OpenLiteSpeed service template",
              "source": {
                "data": {
                  "id": "source-coollabsio#8264",
                  "user": {
                    "login": "enricoangelon",
                    "id": 34418030,
                    "node_id": "MDQ6VXNlcjM0NDE4MDMw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/34418030?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/enricoangelon",
                    "html_url": "https://github.com/enricoangelon",
                    "followers_url": "https://api.github.com/users/enricoangelon/followers",
                    "following_url": "https://api.github.com/users/enricoangelon/following{/other_user}",
                    "gists_url": "https://api.github.com/users/enricoangelon/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/enricoangelon/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/enricoangelon/subscriptions",
                    "organizations_url": "https://api.github.com/users/enricoangelon/orgs",
                    "repos_url": "https://api.github.com/users/enricoangelon/repos",
                    "events_url": "https://api.github.com/users/enricoangelon/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/enricoangelon/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: WordPress + OpenLiteSpeed service template",
                  "body": "### Request Type\n\nImprovement\n\n### Description\n\nFollowing up on the discussion in #8255 (which was closed to split the scope into two dedicated issues).\nAs a web agency (Mediastar Web), we manage multiple WordPress sites for clients and we're evaluating Coolify as our central hosting platform. One area where we're missing structured support is a production-ready reference setup for running WordPress on OpenLiteSpeed.\nWhat we'd like to see:\n- A reusable service template or stack for WordPress + OpenLiteSpeed, following the existing Coolify template patterns\n- Persistent volumes for WordPress files and database data\n- Compatibility with Coolify's built-in proxy",
                  "html_url": "https://github.com/coollabsio/coolify/issues/8264"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#8264",
              "body": "### Request Type\n\nImprovement\n\n### Description\n\nFollowing up on the discussion in #8255 (which was closed to split the scope into two dedicated issues).\nAs a web agency (Mediastar Web), we manage multiple WordPress sites for clients and we're evaluating Coolify as our central hosting platform. One area where we're missing structured support is a production-ready reference setup for running WordPress on OpenLiteSpeed.\nWhat we'd like to see:\n- A reusable service template or stack for WordPress + OpenLiteSpeed, following the existing Coolify template patterns\n- Persistent volumes for WordPress files and database data\n- Compatibility with Coolify's built-in proxy",
              "url": "https://github.com/coollabsio/coolify/issues/8264",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#8266",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-02-27T22:50:40.160Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:40.160Z",
            "created_at": "2026-02-27T22:50:40.160Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#8266",
              "status": "open",
              "type": "issue",
              "number": 8266,
              "title": "[Enhancement]: Add a reusable email server stack/template for managing client email domains",
              "source": {
                "data": {
                  "id": "source-coollabsio#8266",
                  "user": {
                    "login": "enricoangelon",
                    "id": 34418030,
                    "node_id": "MDQ6VXNlcjM0NDE4MDMw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/34418030?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/enricoangelon",
                    "html_url": "https://github.com/enricoangelon",
                    "followers_url": "https://api.github.com/users/enricoangelon/followers",
                    "following_url": "https://api.github.com/users/enricoangelon/following{/other_user}",
                    "gists_url": "https://api.github.com/users/enricoangelon/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/enricoangelon/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/enricoangelon/subscriptions",
                    "organizations_url": "https://api.github.com/users/enricoangelon/orgs",
                    "repos_url": "https://api.github.com/users/enricoangelon/repos",
                    "events_url": "https://api.github.com/users/enricoangelon/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/enricoangelon/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Add a reusable email server stack/template for managing client email domains",
                  "body": "### Request Type\n\nImprovement\n\n### Description\n\nFollowing up on the discussion in #8255 (which was closed to split the scope into two dedicated issues).\nAs a web agency (Mediastar Web), we manage email services for multiple client domains and we're evaluating Coolify as our central hosting platform. One area where we're missing structured support is a straightforward way to host and manage client email domains through a reusable template or stack.\nWhat we'd like to see:\n- A reusable service template/stack for a self-hosted email server (e.g., based on Docker Mailserver, Mailu, or a similar well-maintained project)\n- Persistent volumes for mailboxes, configuration, and certificates\n- Compatibility with Coolify's proxy and certificate management",
                  "html_url": "https://github.com/coollabsio/coolify/issues/8266"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#8266",
              "body": "### Request Type\n\nImprovement\n\n### Description\n\nFollowing up on the discussion in #8255 (which was closed to split the scope into two dedicated issues).\nAs a web agency (Mediastar Web), we manage email services for multiple client domains and we're evaluating Coolify as our central hosting platform. One area where we're missing structured support is a straightforward way to host and manage client email domains through a reusable template or stack.\nWhat we'd like to see:\n- A reusable service template/stack for a self-hosted email server (e.g., based on Docker Mailserver, Mailu, or a similar well-maintained project)\n- Persistent volumes for mailboxes, configuration, and certificates\n- Compatibility with Coolify's proxy and certificate management",
              "url": "https://github.com/coollabsio/coolify/issues/8266",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#8232",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-02-27T22:50:40.252Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:40.252Z",
            "created_at": "2026-02-27T22:50:40.252Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#8232",
              "status": "open",
              "type": "issue",
              "number": 8232,
              "title": "[Enhancement]: Add Open Replay",
              "source": {
                "data": {
                  "id": "source-coollabsio#8232",
                  "user": {
                    "login": "gltched-usr",
                    "id": 126079750,
                    "node_id": "U_kgDOB4PTBg",
                    "avatar_url": "https://avatars.githubusercontent.com/u/126079750?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/gltched-usr",
                    "html_url": "https://github.com/gltched-usr",
                    "followers_url": "https://api.github.com/users/gltched-usr/followers",
                    "following_url": "https://api.github.com/users/gltched-usr/following{/other_user}",
                    "gists_url": "https://api.github.com/users/gltched-usr/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/gltched-usr/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/gltched-usr/subscriptions",
                    "organizations_url": "https://api.github.com/users/gltched-usr/orgs",
                    "repos_url": "https://api.github.com/users/gltched-usr/repos",
                    "events_url": "https://api.github.com/users/gltched-usr/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/gltched-usr/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Add Open Replay",
                  "body": "### Request Type\n\nNew Service\n\n### Description\n\n[Open Replay](https://openreplay.com/) requires [running a installing script](https://docs.openreplay.com/en/deployment/deploy-docker/#deploy-openreplay) that will \"create\" the final docker compose file. It would be cool to have open replay as a \"one click\" (coolify service template) service in coolify.",
                  "html_url": "https://github.com/coollabsio/coolify/issues/8232"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#8232",
              "body": "### Request Type\n\nNew Service\n\n### Description\n\n[Open Replay](https://openreplay.com/) requires [running a installing script](https://docs.openreplay.com/en/deployment/deploy-docker/#deploy-openreplay) that will \"create\" the final docker compose file. It would be cool to have open replay as a \"one click\" (coolify service template) service in coolify.",
              "url": "https://github.com/coollabsio/coolify/issues/8232",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#8042",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-02-27T22:50:40.351Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:40.351Z",
            "created_at": "2026-02-27T22:50:40.351Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#8042",
              "status": "open",
              "type": "issue",
              "number": 8042,
              "title": "[Enhancement]: OAUTH only self registering.",
              "source": {
                "data": {
                  "id": "source-coollabsio#8042",
                  "user": {
                    "login": "kewynf",
                    "id": 47131740,
                    "node_id": "MDQ6VXNlcjQ3MTMxNzQw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/47131740?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kewynf",
                    "html_url": "https://github.com/kewynf",
                    "followers_url": "https://api.github.com/users/kewynf/followers",
                    "following_url": "https://api.github.com/users/kewynf/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kewynf/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kewynf/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kewynf/subscriptions",
                    "organizations_url": "https://api.github.com/users/kewynf/orgs",
                    "repos_url": "https://api.github.com/users/kewynf/repos",
                    "events_url": "https://api.github.com/users/kewynf/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kewynf/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: OAUTH only self registering.",
                  "body": "### Request Type\n\nImprovement\n\n### Description\n\nHi, there!\n\nToday users are only able to self-register with OAUTH2 when general self-register is enabled.\n\nThe improvement would be:\n- Allow users logging in with OAUTH2 accounts to self-register even when general self-registering is disabled;\n- Allow admins to restrict users to OAUTH2 only, blocking users from creating and using passwords if they are coming from an OAUTH2 provider (this would allow a single action to suspend users in multiple Coolify instances);\n\nThis would allow us to, for example, control who can and cannot login into a Coolify instance using a tool like Authentik (ex: only users within a certain organization).\n\nThe ideal world would be SCIM 2.0 or something like LDAP, but this is a good start to block access whenever someone leaves the team.\n\nThanks in advance.",
                  "html_url": "https://github.com/coollabsio/coolify/issues/8042"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#8042",
              "body": "### Request Type\n\nImprovement\n\n### Description\n\nHi, there!\n\nToday users are only able to self-register with OAUTH2 when general self-register is enabled.\n\nThe improvement would be:\n- Allow users logging in with OAUTH2 accounts to self-register even when general self-registering is disabled;\n- Allow admins to restrict users to OAUTH2 only, blocking users from creating and using passwords if they are coming from an OAUTH2 provider (this would allow a single action to suspend users in multiple Coolify instances);\n\nThis would allow us to, for example, control who can and cannot login into a Coolify instance using a tool like Authentik (ex: only users within a certain organization).\n\nThe ideal world would be SCIM 2.0 or something like LDAP, but this is a good start to block access whenever someone leaves the team.\n\nThanks in advance.",
              "url": "https://github.com/coollabsio/coolify/issues/8042",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7655",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-02-27T22:50:40.481Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:40.481Z",
            "created_at": "2026-02-27T22:50:40.481Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7655",
              "status": "open",
              "type": "issue",
              "number": 7655,
              "title": "[Improvement]: Do not share all environment variables across all containers in a Compose project",
              "source": {
                "data": {
                  "id": "source-coollabsio#7655",
                  "user": {
                    "login": "tadamcz",
                    "id": 43300673,
                    "node_id": "MDQ6VXNlcjQzMzAwNjcz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/43300673?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/tadamcz",
                    "html_url": "https://github.com/tadamcz",
                    "followers_url": "https://api.github.com/users/tadamcz/followers",
                    "following_url": "https://api.github.com/users/tadamcz/following{/other_user}",
                    "gists_url": "https://api.github.com/users/tadamcz/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/tadamcz/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/tadamcz/subscriptions",
                    "organizations_url": "https://api.github.com/users/tadamcz/orgs",
                    "repos_url": "https://api.github.com/users/tadamcz/repos",
                    "events_url": "https://api.github.com/users/tadamcz/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/tadamcz/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Improvement]: Do not share all environment variables across all containers in a Compose project",
                  "body": "### Problem Description\n\nWhen deploying a Docker Compose project, Coolify injects all environment variables into every container, regardless of which container they were defined for.\n\nFrom inspecting the \"Raw Docker compose\" in the UI, I believe this happens like this:\n  1. A single `.env` file is created containing ALL environment variables from the entire Docker Compose project\n  2. This `.env` file is automatically added to every container's `env_file:` directive\n\n### Security Implications\n\nThis seems to be a serious security issue. \n\nAny container in a multi-container Docker Compose project can read the secrets/credentials of every other container.\n\nExamples:\n  - In a Next.js + PostgreSQL + Redis stack, the Redis container has access to POSTGRES_PASSWORD and the PostgreSQL container can see OPENAI_API_KEY meant only for the app\n  - In any multi-database setup, each database container can see the credentials of other databases\n  - If one container is compromised, an attacker gains credentials for all containers in the project\n\n###  Expected Behavior\n\n  Each container should only have access to:\n  - Variables explicitly defined in its `environment: ` section\n  - Variables from env files explicitly declared in its `env_file:` section\n  - Coolify metadata variables (`COOLIFY_*`, `SERVICE_URL_*`, etc.) as needed\n\nVariables specific to other containers (especially credentials) should NOT be accessible to unrelated containers.\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7655"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7655",
              "body": "### Problem Description\n\nWhen deploying a Docker Compose project, Coolify injects all environment variables into every container, regardless of which container they were defined for.\n\nFrom inspecting the \"Raw Docker compose\" in the UI, I believe this happens like this:\n  1. A single `.env` file is created containing ALL environment variables from the entire Docker Compose project\n  2. This `.env` file is automatically added to every container's `env_file:` directive\n\n### Security Implications\n\nThis seems to be a serious security issue. \n\nAny container in a multi-container Docker Compose project can read the secrets/credentials of every other container.\n\nExamples:\n  - In a Next.js + PostgreSQL + Redis stack, the Redis container has access to POSTGRES_PASSWORD and the PostgreSQL container can see OPENAI_API_KEY meant only for the app\n  - In any multi-database setup, each database container can see the credentials of other databases\n  - If one container is compromised, an attacker gains credentials for all containers in the project\n\n###  Expected Behavior\n\n  Each container should only have access to:\n  - Variables explicitly defined in its `environment: ` section\n  - Variables from env files explicitly declared in its `env_file:` section\n  - Coolify metadata variables (`COOLIFY_*`, `SERVICE_URL_*`, etc.) as needed\n\nVariables specific to other containers (especially credentials) should NOT be accessible to unrelated containers.\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n",
              "url": "https://github.com/coollabsio/coolify/issues/7655",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7743",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-02-27T22:50:40.571Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:40.571Z",
            "created_at": "2026-02-27T22:50:40.571Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7743",
              "status": "open",
              "type": "issue",
              "number": 7743,
              "title": "[Enhancement]: Don't timeout public database proxies after 10 min",
              "source": {
                "data": {
                  "id": "source-coollabsio#7743",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Don't timeout public database proxies after 10 min",
                  "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the TCP proxy in front of Postgres when you mark \"Expose publicly\" times out after about 10m. Switch this to have no timeout or to have a configurable timeout in the GUI.\n\nUse case: I sometimes have `SELECT *` statements that take a very long time (30m+) to download the results for. The connection timing out prevents that from being successful\n\nBounty: $100 USD once merged and live on Coolify Cloud.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com), a charity that supports teenagers who love coding and electronics! We previously funded database SSL support, backups API, and pgBackRest support for Postgres backups (in progress).",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7743"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7743",
              "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the TCP proxy in front of Postgres when you mark \"Expose publicly\" times out after about 10m. Switch this to have no timeout or to have a configurable timeout in the GUI.\n\nUse case: I sometimes have `SELECT *` statements that take a very long time (30m+) to download the results for. The connection timing out prevents that from being successful\n\nBounty: $100 USD once merged and live on Coolify Cloud.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com), a charity that supports teenagers who love coding and electronics! We previously funded database SSL support, backups API, and pgBackRest support for Postgres backups (in progress).",
              "url": "https://github.com/coollabsio/coolify/issues/7743",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7738",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-02-27T22:50:40.656Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:40.656Z",
            "created_at": "2026-02-27T22:50:40.656Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7738",
              "status": "open",
              "type": "issue",
              "number": 7738,
              "title": "[Enhancement]: Environment variables for each server that can be made available to each application deployed on it",
              "source": {
                "data": {
                  "id": "source-coollabsio#7738",
                  "user": {
                    "login": "pkpio",
                    "id": 816666,
                    "node_id": "MDQ6VXNlcjgxNjY2Ng==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/816666?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/pkpio",
                    "html_url": "https://github.com/pkpio",
                    "followers_url": "https://api.github.com/users/pkpio/followers",
                    "following_url": "https://api.github.com/users/pkpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/pkpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/pkpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/pkpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/pkpio/orgs",
                    "repos_url": "https://api.github.com/users/pkpio/repos",
                    "events_url": "https://api.github.com/users/pkpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/pkpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Environment variables for each server that can be made available to each application deployed on it",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\nWhen deploying a resource using the \"Multiple Servers\" option, currently there is no way to distinguish between the servers from within the application - because the container running on both servers get identical setup. \n\nThis makes debugging harder as application logs cannot identify which server deployment an issue happened - take for instance a failure due to network errors happening specifically on one server (randomly). \n\nA way to define Environment variables for each server and making them available for each application deployed on that server, will fix this limitation (and also generalised in a way for use cases beyond what I described here).",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7738"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7738",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\nWhen deploying a resource using the \"Multiple Servers\" option, currently there is no way to distinguish between the servers from within the application - because the container running on both servers get identical setup. \n\nThis makes debugging harder as application logs cannot identify which server deployment an issue happened - take for instance a failure due to network errors happening specifically on one server (randomly). \n\nA way to define Environment variables for each server and making them available for each application deployed on that server, will fix this limitation (and also generalised in a way for use cases beyond what I described here).",
              "url": "https://github.com/coollabsio/coolify/issues/7738",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7724",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-02-27T22:50:40.747Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:40.747Z",
            "created_at": "2026-02-27T22:50:40.747Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7724",
              "status": "open",
              "type": "issue",
              "number": 7724,
              "title": "[Bug]: Sporadic Permission denied (publickey,password).",
              "source": {
                "data": {
                  "id": "source-coollabsio#7724",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Sporadic Permission denied (publickey,password).",
                  "body": "### Error Message and Logs\n\n<img width=\"380\" height=\"129\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a615ea52-e26d-435d-8121-e01cd7d7f656\" />\n\nStarting maybe ~2 weeks ago we started getting this error constantly. Generating a new private SSH key and setting it up seems to stop it for a bit, then it starts happening again. I'm 99% sure something is causing Coolify to send the wrong SSH key. When I check server logs, it shows that logins are indeed failing. They are not being blocked by fail2ban or anything like that.\n\nI will pay $250 to anyone who can diagnose and fix this issue. It's causing major issues for us. Acceptance criteria: Fix is merged into Coolify Cloud.\n\n### Steps to Reproduce\n\nI'm sorry, I don't have good reproduction steps. It sporadically seems to happen.\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7724"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7724",
              "body": "### Error Message and Logs\n\n<img width=\"380\" height=\"129\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a615ea52-e26d-435d-8121-e01cd7d7f656\" />\n\nStarting maybe ~2 weeks ago we started getting this error constantly. Generating a new private SSH key and setting it up seems to stop it for a bit, then it starts happening again. I'm 99% sure something is causing Coolify to send the wrong SSH key. When I check server logs, it shows that logins are indeed failing. They are not being blocked by fail2ban or anything like that.\n\nI will pay $250 to anyone who can diagnose and fix this issue. It's causing major issues for us. Acceptance criteria: Fix is merged into Coolify Cloud.\n\n### Steps to Reproduce\n\nI'm sorry, I don't have good reproduction steps. It sporadically seems to happen.\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/7724",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7642",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-02-27T22:50:40.854Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:40.854Z",
            "created_at": "2026-02-27T22:50:40.854Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7642",
              "status": "open",
              "type": "issue",
              "number": 7642,
              "title": "[Enhancement]: Add surrealDB with and without TIKV",
              "source": {
                "data": {
                  "id": "source-coollabsio#7642",
                  "user": {
                    "login": "Jordan-Hall",
                    "id": 2092344,
                    "node_id": "MDQ6VXNlcjIwOTIzNDQ=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/2092344?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Jordan-Hall",
                    "html_url": "https://github.com/Jordan-Hall",
                    "followers_url": "https://api.github.com/users/Jordan-Hall/followers",
                    "following_url": "https://api.github.com/users/Jordan-Hall/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Jordan-Hall/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Jordan-Hall/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Jordan-Hall/subscriptions",
                    "organizations_url": "https://api.github.com/users/Jordan-Hall/orgs",
                    "repos_url": "https://api.github.com/users/Jordan-Hall/repos",
                    "events_url": "https://api.github.com/users/Jordan-Hall/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Jordan-Hall/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Add surrealDB with and without TIKV",
                  "body": "### Request Type\n\nNew Service\n\n### Description\n\nThey a couple of decussion around surrealdb as a database option but it be nice if it was bulit in with both TIKV and rockdb as an option\n\nhttps://github.com/coollabsio/coolify/discussions/3587\nhttps://github.com/coollabsio/coolify/discussions/4013 ",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7642"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7642",
              "body": "### Request Type\n\nNew Service\n\n### Description\n\nThey a couple of decussion around surrealdb as a database option but it be nice if it was bulit in with both TIKV and rockdb as an option\n\nhttps://github.com/coollabsio/coolify/discussions/3587\nhttps://github.com/coollabsio/coolify/discussions/4013 ",
              "url": "https://github.com/coollabsio/coolify/issues/7642",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7596",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-02-27T22:50:40.950Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:40.950Z",
            "created_at": "2026-02-27T22:50:40.950Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7596",
              "status": "open",
              "type": "issue",
              "number": 7596,
              "title": "[Enhancement]: new deployment page",
              "source": {
                "data": {
                  "id": "source-coollabsio#7596",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: new deployment page",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n- Add deployments to sidebar\n- Show past deployments (all of them)\n- Add a filter on the top:\n  - Filter by project\n  - Filter by server\n  - Filter by sources\n  - Filter by status (queued, pending, done)\n- Show live updates / refresh?\n- Hide filters if only 1 server / 1 source\n\n## Design inspiration\n\nVercel example:\n\n<img width=\"1362\" height=\"967\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e46d7470-fff1-46c5-8011-63ba82119db2\" />\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7596"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7596",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n- Add deployments to sidebar\n- Show past deployments (all of them)\n- Add a filter on the top:\n  - Filter by project\n  - Filter by server\n  - Filter by sources\n  - Filter by status (queued, pending, done)\n- Show live updates / refresh?\n- Hide filters if only 1 server / 1 source\n\n## Design inspiration\n\nVercel example:\n\n<img width=\"1362\" height=\"967\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e46d7470-fff1-46c5-8011-63ba82119db2\" />\n",
              "url": "https://github.com/coollabsio/coolify/issues/7596",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#519",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-02-27T22:50:41.593Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:41.593Z",
            "created_at": "2026-02-27T22:50:41.593Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#519",
              "status": "open",
              "type": "issue",
              "number": 519,
              "title": "Schema Migration System for ZIO Schema 2",
              "source": {
                "data": {
                  "id": "source-ZIO#519",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Schema Migration System for ZIO Schema 2",
                  "body": "## Overview\n\nImplement a **pure, algebraic migration system** for ZIO Schema 2 that represents **structural transformations between schema versions** as first-class, serializable data.\n\nA migration describes how to transform data from one schema version to another, enabling:\n\n* schema evolution\n* backward / forward compatibility\n* data versioning\n* offline migrations (JSON, SQL, data lakes, registries, etc.)\n\nThe system provides a **typed, macro-validated user API** (`Migration[A, B]`) built on a **pure, serializable core** (`DynamicMigration`) that operates on `DynamicValue`. \n\nThe ADT is fully introspectable and can be used to generate DDL, etc.\n\n## Motivation & Big Picture\n\n### Why structural types?\n\nWhen evolving schemas over time, **older versions of data types should not require runtime representations**.\n\nIn this design:\n\n* **Current versions** are represented by real case classes / enums\n* **Past versions** are represented using:\n\n  * **structural types** for records\n  * **abstract types + intersection types** for sum types\n\nThese types:\n\n* exist **only at compile time**\n* have **no runtime representation**\n* introduce **zero runtime overhead**\n* do **not require optics or instances to be kept around**\n\nThis allows you to describe arbitrarily old versions of data *without polluting your runtime or codebase*.\n\n#### Typical Workflow\n\nA typical workflow looks like:\n\n1. You have a current type:\n\n   ```scala\n   @schema\n   case class Person(name: String, age: Int)\n   ```\n\n2. You derive and copy its structural shape:\n\n   ```scala\n   type PersonV1 = { def name: String; def age: Int }\n   ```\n\n3. You evolve the real type:\n\n   ```scala\n   @schema\n   case class Person(fullName: String, age: Int, country: String)\n   ```\n\n4. You keep only:\n\n   * the **current** runtime type\n   * the **structural type** for the old version\n   * a **pure migration** between them\n\nNo old case classes. No old optics. No runtime baggage.\n\nNote there is no requirement that the \"current\" type actually be a real case class, enum, etc.--so you can work purely with structural types, allowing you to define migrations for data types that are never materialized as runtime structures.\n\n---\n\n### Why pure data migrations?\n\nMigrations are represented entirely as **pure data**:\n\n* no user functions\n* no closures\n* no reflection\n* no runtime code generation\n\nAs a result:\n\n* migrations can be **serialized**\n* stored in **registries**\n* applied **dynamically**\n* inspected and transformed\n* used to generate:\n\n  * upgraders\n  * downgraders\n  * SQL DDL / DML\n  * offline data transforms\n\nWhile code generation is **out of scope for this ticket**, this explains many design decisions (invertibility, path-based actions, no functions).\n\n---\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed migration (user-facing API)\ncase class Migration[A, B](\n  dynamicMigration: DynamicMigration,\n  sourceSchema: Schema[A], // These are structural schemas!!!\n  targetSchema: Schema[B] // These are structural schemas!!!\n) {\n  /** Apply migration to transform A to B */\n  def apply(value: A): Either[MigrationError, B]\n\n  /** Compose migrations sequentially */\n  def ++[C](that: Migration[B, C]): Migration[A, C]\n\n  /** Alias for ++ */\n  def andThen[C](that: Migration[B, C]): Migration[A, C] = this ++ that\n\n  /** Reverse migration (structural inverse; runtime is best-effort) */\n  def reverse: Migration[B, A]\n}\n```\n\n```scala\n// Untyped migration (pure data, fully serializable)\ncase class DynamicMigration(\n  actions: Vector[MigrationAction]\n) {\n  def apply(value: DynamicValue): Either[MigrationError, DynamicValue]\n  def ++(that: DynamicMigration): DynamicMigration\n  def reverse: DynamicMigration\n}\n```\n\n* `Migration[A, B]` is introspectable, but not pure data due to bindings inside schemas\n* `DynamicMigration` is **fully serializable**\n\n---\n\n## User-Facing API: Selector Expressions\n\n### Selectors, not optics\n\nThe user-facing API **does not expose optics**.\n\nInstead, all locations are specified using **selector expressions**:\n\n```scala\nS => A\n```\n\nExamples:\n\n```scala\n_.name\n_.address.street\n_.addresses.each.streetNumber\n_.country.when[UK]\n```\n\nTo see the syntax, one can look at the `optic` macro, which utilizes the same selector syntax for optic creation (e.g. `optic(_.address.street)`, etc.).\n\n### Macro extraction\n\nAll builder methods that accept selectors are **implemented via macros** (or via a macro-generated type class such as `ToDynamicOptic`).\n\nThe macro:\n\n1. Inspects the selector expression\n2. Validates it is a supported projection\n3. Converts it into a `DynamicOptic`\n4. Stores that optic in the migration action\n\nSupported projections include:\n\n* field access (`_.foo.bar`)\n* case selection (`_.country.when[UK]`)\n* collection traversal (`_.items.each`)\n* (future) key access, wrappers, etc.\n\n`DynamicOptic` is **never exposed publicly**.\n\n---\n\n## Migration Builder\n\nAll selector-accepting methods are implemented via macros. For simplicity, these are shown as functions (e.g. `A => Any`), but this is NOT the way to implement them. Either all these functions need to be macros, or a macro needs to be used to generate an implicit / given at each call site. Macros may do additional validation to constrain the validity of these different types of transformations.\n\n```scala\nclass MigrationBuilder[A, B](\n  sourceSchema: Schema[A],\n  targetSchema: Schema[B],\n  actions: Vector[MigrationAction]\n) {\n\n  // ----- Record operations -----\n\n  def addField(\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def dropField(\n    source: A => Any,\n    defaultForReverse: SchemaExpr[B, ?] = SchemaExpr.DefaultValue\n  ): MigrationBuilder[A, B]\n\n  def renameField(\n    from: A => Any,\n    to: B => Any\n  ): MigrationBuilder[A, B]\n\n  def transformField(\n    from: A => Any,\n    to: B => Any,\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def mandateField(\n    source: A => Option[?],\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def optionalizeField(\n    source: A => Any,\n    target: B => Option[?]\n  ): MigrationBuilder[A, B]\n\n  def changeFieldType(\n    source: A => Any,\n    target: B => Any,\n    converter: SchemaExpr[A, ?]  // primitive-to-primitive only\n  ): MigrationBuilder[A, B]\n\n  // ----- Enum operations (limited) -----\n\n  def renameCase[SumA, SumB](\n    from: String,\n    to: String\n  ): MigrationBuilder[A, B]\n\n  def transformCase[SumA, CaseA, SumB, CaseB](\n    caseMigration: MigrationBuilder[CaseA, CaseB] => MigrationBuilder[CaseA, CaseB]\n  ): MigrationBuilder[A, B]\n\n  // ----- Collections -----\n\n  def transformElements(\n    at: A => Vector[?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  // ----- Maps -----\n\n  def transformKeys(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def transformValues(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  /** Build migration with full macro validation */\n  def build: Migration[A, B]\n\n  /** Build migration without full validation */\n  def buildPartial: Migration[A, B]\n}\n```\n\n---\n\n## Migration Actions (Untyped Core)\n\nAll actions operate at a **path**, represented by `DynamicOptic`.\n\n```scala\nsealed trait MigrationAction {\n  def at: DynamicOptic\n  def reverse: MigrationAction\n}\n```\n\n### Record Actions\n\n```scala\ncase class AddField(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class DropField(\n  at: DynamicOptic,\n  defaultForReverse: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Rename(\n  at: DynamicOptic,\n  to: String\n) extends MigrationAction\n\ncase class TransformValue(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Mandate(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Optionalize(\n  at: DynamicOptic\n) extends MigrationAction\n\ncase class Join(\n  at: DynamicOptic,\n  sourcePaths: Vector[DynamicOptic],\n  combiner: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Split(\n  at: DynamicOptic,\n  targetPaths: Vector[DynamicOptic],\n  splitter: SchemaExpr[?]\n) extends MigrationAction\n\ncase class ChangeType(\n  at: DynamicOptic,\n  converter: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n### Enum Actions (Supported)\n\n```scala\ncase class RenameCase(\n  at: DynamicOptic,\n  from: String,\n  to: String\n) extends MigrationAction\n\ncase class TransformCase(\n  at: DynamicOptic,\n  actions: Vector[MigrationAction]\n) extends MigrationAction\n```\n\n> Enum case addition / removal is **out of scope** for this ticket\n> (requires composite value construction).\n\n---\n\n### Collection / Map Actions\n\n```scala\ncase class TransformElements(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformKeys(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformValues(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n## SchemaExpr Integration\n\n* Used for all value-level transformations\n* **Constraints for this ticket**:\n\n  * primitive → primitive only\n  * joins / splits must produce primitives\n  * no record / enum construction\n\n### `SchemaExpr.DefaultValue`\n\nA special expression that:\n\n1. uses the macro-captured field schema\n2. calls `schema.defaultValue`\n3. converts the value to `DynamicValue`\n4. is stored for reverse migrations\n\n---\n\n## Type Modeling\n\n### Records (Structural Types)\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\ntype PersonV1 = { val fullName: String; val age: Int }\n\nimplicit val v0Schema: Schema[PersonV0] = Schema.structural[PersonV0]\nimplicit val v1Schema: Schema[PersonV1] = Schema.structural[PersonV1]\n```\n\n---\n\n### Enums (Union of Structural Types with Tags)\n\nEnums are encoded into structural types by using union types, together with singleton types (string literals, which represent the name of the case of the enum).\n\nIn structural types, the names of the type aliases shown below are not relevant, nor are they used.\n\n```scala\ntype OldCreditCard =\n  { type Tag = \"CreditCard\"; def number: String; def exp: String }\ntype OldWireTransfer =\n  { type Tag = \"WireTransfer\"; def account: String; def routing: String }\ntype OldPaymentMethod = OldCreditCard | OldWireTransfer\n```\n\nMacros extract:\n\n* refinement type → structure of the case\n* type `Tag` with singleton type → case tag\n\n---\n\n## Laws\n\n### Identity\n\n```scala\nMigration.identity[A].apply(a) == Right(a)\n```\n\n### Associativity\n\n```scala\n(m1 ++ m2) ++ m3 == m1 ++ (m2 ++ m3)\n```\n\n### Structural Reverse\n\n```scala\nm.reverse.reverse == m\n```\n\n### Best-Effort Semantic Inverse\n\n```scala\nm.apply(a) == Right(b) ⇒ m.reverse.apply(b) == Right(a)\n```\n\n(when sufficient information exists)\n\n---\n\n## Error Handling\n\n* All runtime errors return `MigrationError`\n* Errors must capture **path information** (`DynamicOptic`)\n* Enables diagnostics such as:\n\n> “Failed to apply TransformValue at `.addresses.each.streetNumber`”\n\n---\n\n## Example\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\n\n@schema\ncase class Person(fullName: String, age: Int)\n\nval migration =\n  Migration.newBuilder[PersonV0, Person]\n    .addField(_.age, 0)\n    .build\n\nval old =\n  new { val firstName = \"John\"; val lastName = \"Doe\" }\n\nmigration(old)\n// Right(Person(\"John Doe\", 0))\n```\n\n---\n\n## Success Criteria\n\n* [ ] `DynamicMigration` fully serializable\n* [ ] `Migration[A, B]` wraps schemas and actions\n* [ ] All actions path-based via `DynamicOptic`\n* [ ] User API uses selector functions (`S => A`) for \"optics\" on old and new types\n* [ ] Macro validation in `.build` to confirm \"old\" has been migrated to \"new\"\n* [ ] `.buildPartial` supported\n* [ ] Structural reverse implemented\n* [ ] Identity & associativity laws hold\n* [ ] Enum rename / transform supported\n* [ ] Errors include path information\n* [ ] Comprehensive tests\n* [ ] Scala 2.13 and Scala 3.5+ supported\n",
                  "html_url": "https://github.com/zio/zio-blocks/issues/519"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#519",
              "body": "## Overview\n\nImplement a **pure, algebraic migration system** for ZIO Schema 2 that represents **structural transformations between schema versions** as first-class, serializable data.\n\nA migration describes how to transform data from one schema version to another, enabling:\n\n* schema evolution\n* backward / forward compatibility\n* data versioning\n* offline migrations (JSON, SQL, data lakes, registries, etc.)\n\nThe system provides a **typed, macro-validated user API** (`Migration[A, B]`) built on a **pure, serializable core** (`DynamicMigration`) that operates on `DynamicValue`. \n\nThe ADT is fully introspectable and can be used to generate DDL, etc.\n\n## Motivation & Big Picture\n\n### Why structural types?\n\nWhen evolving schemas over time, **older versions of data types should not require runtime representations**.\n\nIn this design:\n\n* **Current versions** are represented by real case classes / enums\n* **Past versions** are represented using:\n\n  * **structural types** for records\n  * **abstract types + intersection types** for sum types\n\nThese types:\n\n* exist **only at compile time**\n* have **no runtime representation**\n* introduce **zero runtime overhead**\n* do **not require optics or instances to be kept around**\n\nThis allows you to describe arbitrarily old versions of data *without polluting your runtime or codebase*.\n\n#### Typical Workflow\n\nA typical workflow looks like:\n\n1. You have a current type:\n\n   ```scala\n   @schema\n   case class Person(name: String, age: Int)\n   ```\n\n2. You derive and copy its structural shape:\n\n   ```scala\n   type PersonV1 = { def name: String; def age: Int }\n   ```\n\n3. You evolve the real type:\n\n   ```scala\n   @schema\n   case class Person(fullName: String, age: Int, country: String)\n   ```\n\n4. You keep only:\n\n   * the **current** runtime type\n   * the **structural type** for the old version\n   * a **pure migration** between them\n\nNo old case classes. No old optics. No runtime baggage.\n\nNote there is no requirement that the \"current\" type actually be a real case class, enum, etc.--so you can work purely with structural types, allowing you to define migrations for data types that are never materialized as runtime structures.\n\n---\n\n### Why pure data migrations?\n\nMigrations are represented entirely as **pure data**:\n\n* no user functions\n* no closures\n* no reflection\n* no runtime code generation\n\nAs a result:\n\n* migrations can be **serialized**\n* stored in **registries**\n* applied **dynamically**\n* inspected and transformed\n* used to generate:\n\n  * upgraders\n  * downgraders\n  * SQL DDL / DML\n  * offline data transforms\n\nWhile code generation is **out of scope for this ticket**, this explains many design decisions (invertibility, path-based actions, no functions).\n\n---\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed migration (user-facing API)\ncase class Migration[A, B](\n  dynamicMigration: DynamicMigration,\n  sourceSchema: Schema[A], // These are structural schemas!!!\n  targetSchema: Schema[B] // These are structural schemas!!!\n) {\n  /** Apply migration to transform A to B */\n  def apply(value: A): Either[MigrationError, B]\n\n  /** Compose migrations sequentially */\n  def ++[C](that: Migration[B, C]): Migration[A, C]\n\n  /** Alias for ++ */\n  def andThen[C](that: Migration[B, C]): Migration[A, C] = this ++ that\n\n  /** Reverse migration (structural inverse; runtime is best-effort) */\n  def reverse: Migration[B, A]\n}\n```\n\n```scala\n// Untyped migration (pure data, fully serializable)\ncase class DynamicMigration(\n  actions: Vector[MigrationAction]\n) {\n  def apply(value: DynamicValue): Either[MigrationError, DynamicValue]\n  def ++(that: DynamicMigration): DynamicMigration\n  def reverse: DynamicMigration\n}\n```\n\n* `Migration[A, B]` is introspectable, but not pure data due to bindings inside schemas\n* `DynamicMigration` is **fully serializable**\n\n---\n\n## User-Facing API: Selector Expressions\n\n### Selectors, not optics\n\nThe user-facing API **does not expose optics**.\n\nInstead, all locations are specified using **selector expressions**:\n\n```scala\nS => A\n```\n\nExamples:\n\n```scala\n_.name\n_.address.street\n_.addresses.each.streetNumber\n_.country.when[UK]\n```\n\nTo see the syntax, one can look at the `optic` macro, which utilizes the same selector syntax for optic creation (e.g. `optic(_.address.street)`, etc.).\n\n### Macro extraction\n\nAll builder methods that accept selectors are **implemented via macros** (or via a macro-generated type class such as `ToDynamicOptic`).\n\nThe macro:\n\n1. Inspects the selector expression\n2. Validates it is a supported projection\n3. Converts it into a `DynamicOptic`\n4. Stores that optic in the migration action\n\nSupported projections include:\n\n* field access (`_.foo.bar`)\n* case selection (`_.country.when[UK]`)\n* collection traversal (`_.items.each`)\n* (future) key access, wrappers, etc.\n\n`DynamicOptic` is **never exposed publicly**.\n\n---\n\n## Migration Builder\n\nAll selector-accepting methods are implemented via macros. For simplicity, these are shown as functions (e.g. `A => Any`), but this is NOT the way to implement them. Either all these functions need to be macros, or a macro needs to be used to generate an implicit / given at each call site. Macros may do additional validation to constrain the validity of these different types of transformations.\n\n```scala\nclass MigrationBuilder[A, B](\n  sourceSchema: Schema[A],\n  targetSchema: Schema[B],\n  actions: Vector[MigrationAction]\n) {\n\n  // ----- Record operations -----\n\n  def addField(\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def dropField(\n    source: A => Any,\n    defaultForReverse: SchemaExpr[B, ?] = SchemaExpr.DefaultValue\n  ): MigrationBuilder[A, B]\n\n  def renameField(\n    from: A => Any,\n    to: B => Any\n  ): MigrationBuilder[A, B]\n\n  def transformField(\n    from: A => Any,\n    to: B => Any,\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def mandateField(\n    source: A => Option[?],\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def optionalizeField(\n    source: A => Any,\n    target: B => Option[?]\n  ): MigrationBuilder[A, B]\n\n  def changeFieldType(\n    source: A => Any,\n    target: B => Any,\n    converter: SchemaExpr[A, ?]  // primitive-to-primitive only\n  ): MigrationBuilder[A, B]\n\n  // ----- Enum operations (limited) -----\n\n  def renameCase[SumA, SumB](\n    from: String,\n    to: String\n  ): MigrationBuilder[A, B]\n\n  def transformCase[SumA, CaseA, SumB, CaseB](\n    caseMigration: MigrationBuilder[CaseA, CaseB] => MigrationBuilder[CaseA, CaseB]\n  ): MigrationBuilder[A, B]\n\n  // ----- Collections -----\n\n  def transformElements(\n    at: A => Vector[?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  // ----- Maps -----\n\n  def transformKeys(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def transformValues(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  /** Build migration with full macro validation */\n  def build: Migration[A, B]\n\n  /** Build migration without full validation */\n  def buildPartial: Migration[A, B]\n}\n```\n\n---\n\n## Migration Actions (Untyped Core)\n\nAll actions operate at a **path**, represented by `DynamicOptic`.\n\n```scala\nsealed trait MigrationAction {\n  def at: DynamicOptic\n  def reverse: MigrationAction\n}\n```\n\n### Record Actions\n\n```scala\ncase class AddField(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class DropField(\n  at: DynamicOptic,\n  defaultForReverse: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Rename(\n  at: DynamicOptic,\n  to: String\n) extends MigrationAction\n\ncase class TransformValue(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Mandate(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Optionalize(\n  at: DynamicOptic\n) extends MigrationAction\n\ncase class Join(\n  at: DynamicOptic,\n  sourcePaths: Vector[DynamicOptic],\n  combiner: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Split(\n  at: DynamicOptic,\n  targetPaths: Vector[DynamicOptic],\n  splitter: SchemaExpr[?]\n) extends MigrationAction\n\ncase class ChangeType(\n  at: DynamicOptic,\n  converter: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n### Enum Actions (Supported)\n\n```scala\ncase class RenameCase(\n  at: DynamicOptic,\n  from: String,\n  to: String\n) extends MigrationAction\n\ncase class TransformCase(\n  at: DynamicOptic,\n  actions: Vector[MigrationAction]\n) extends MigrationAction\n```\n\n> Enum case addition / removal is **out of scope** for this ticket\n> (requires composite value construction).\n\n---\n\n### Collection / Map Actions\n\n```scala\ncase class TransformElements(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformKeys(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformValues(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n## SchemaExpr Integration\n\n* Used for all value-level transformations\n* **Constraints for this ticket**:\n\n  * primitive → primitive only\n  * joins / splits must produce primitives\n  * no record / enum construction\n\n### `SchemaExpr.DefaultValue`\n\nA special expression that:\n\n1. uses the macro-captured field schema\n2. calls `schema.defaultValue`\n3. converts the value to `DynamicValue`\n4. is stored for reverse migrations\n\n---\n\n## Type Modeling\n\n### Records (Structural Types)\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\ntype PersonV1 = { val fullName: String; val age: Int }\n\nimplicit val v0Schema: Schema[PersonV0] = Schema.structural[PersonV0]\nimplicit val v1Schema: Schema[PersonV1] = Schema.structural[PersonV1]\n```\n\n---\n\n### Enums (Union of Structural Types with Tags)\n\nEnums are encoded into structural types by using union types, together with singleton types (string literals, which represent the name of the case of the enum).\n\nIn structural types, the names of the type aliases shown below are not relevant, nor are they used.\n\n```scala\ntype OldCreditCard =\n  { type Tag = \"CreditCard\"; def number: String; def exp: String }\ntype OldWireTransfer =\n  { type Tag = \"WireTransfer\"; def account: String; def routing: String }\ntype OldPaymentMethod = OldCreditCard | OldWireTransfer\n```\n\nMacros extract:\n\n* refinement type → structure of the case\n* type `Tag` with singleton type → case tag\n\n---\n\n## Laws\n\n### Identity\n\n```scala\nMigration.identity[A].apply(a) == Right(a)\n```\n\n### Associativity\n\n```scala\n(m1 ++ m2) ++ m3 == m1 ++ (m2 ++ m3)\n```\n\n### Structural Reverse\n\n```scala\nm.reverse.reverse == m\n```\n\n### Best-Effort Semantic Inverse\n\n```scala\nm.apply(a) == Right(b) ⇒ m.reverse.apply(b) == Right(a)\n```\n\n(when sufficient information exists)\n\n---\n\n## Error Handling\n\n* All runtime errors return `MigrationError`\n* Errors must capture **path information** (`DynamicOptic`)\n* Enables diagnostics such as:\n\n> “Failed to apply TransformValue at `.addresses.each.streetNumber`”\n\n---\n\n## Example\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\n\n@schema\ncase class Person(fullName: String, age: Int)\n\nval migration =\n  Migration.newBuilder[PersonV0, Person]\n    .addField(_.age, 0)\n    .build\n\nval old =\n  new { val firstName = \"John\"; val lastName = \"Doe\" }\n\nmigration(old)\n// Right(Person(\"John Doe\", 0))\n```\n\n---\n\n## Success Criteria\n\n* [ ] `DynamicMigration` fully serializable\n* [ ] `Migration[A, B]` wraps schemas and actions\n* [ ] All actions path-based via `DynamicOptic`\n* [ ] User API uses selector functions (`S => A`) for \"optics\" on old and new types\n* [ ] Macro validation in `.build` to confirm \"old\" has been migrated to \"new\"\n* [ ] `.buildPartial` supported\n* [ ] Structural reverse implemented\n* [ ] Identity & associativity laws hold\n* [ ] Enum rename / transform supported\n* [ ] Errors include path information\n* [ ] Comprehensive tests\n* [ ] Scala 2.13 and Scala 3.5+ supported\n",
              "url": "https://github.com/zio/zio-blocks/issues/519",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#519",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-02-27T22:50:41.597Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:41.597Z",
            "created_at": "2026-02-27T22:50:41.597Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#519",
              "status": "open",
              "type": "issue",
              "number": 519,
              "title": "Schema Migration System for ZIO Schema 2",
              "source": {
                "data": {
                  "id": "source-ZIO#519",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Schema Migration System for ZIO Schema 2",
                  "body": "## Overview\n\nImplement a **pure, algebraic migration system** for ZIO Schema 2 that represents **structural transformations between schema versions** as first-class, serializable data.\n\nA migration describes how to transform data from one schema version to another, enabling:\n\n* schema evolution\n* backward / forward compatibility\n* data versioning\n* offline migrations (JSON, SQL, data lakes, registries, etc.)\n\nThe system provides a **typed, macro-validated user API** (`Migration[A, B]`) built on a **pure, serializable core** (`DynamicMigration`) that operates on `DynamicValue`. \n\nThe ADT is fully introspectable and can be used to generate DDL, etc.\n\n## Motivation & Big Picture\n\n### Why structural types?\n\nWhen evolving schemas over time, **older versions of data types should not require runtime representations**.\n\nIn this design:\n\n* **Current versions** are represented by real case classes / enums\n* **Past versions** are represented using:\n\n  * **structural types** for records\n  * **abstract types + intersection types** for sum types\n\nThese types:\n\n* exist **only at compile time**\n* have **no runtime representation**\n* introduce **zero runtime overhead**\n* do **not require optics or instances to be kept around**\n\nThis allows you to describe arbitrarily old versions of data *without polluting your runtime or codebase*.\n\n#### Typical Workflow\n\nA typical workflow looks like:\n\n1. You have a current type:\n\n   ```scala\n   @schema\n   case class Person(name: String, age: Int)\n   ```\n\n2. You derive and copy its structural shape:\n\n   ```scala\n   type PersonV1 = { def name: String; def age: Int }\n   ```\n\n3. You evolve the real type:\n\n   ```scala\n   @schema\n   case class Person(fullName: String, age: Int, country: String)\n   ```\n\n4. You keep only:\n\n   * the **current** runtime type\n   * the **structural type** for the old version\n   * a **pure migration** between them\n\nNo old case classes. No old optics. No runtime baggage.\n\nNote there is no requirement that the \"current\" type actually be a real case class, enum, etc.--so you can work purely with structural types, allowing you to define migrations for data types that are never materialized as runtime structures.\n\n---\n\n### Why pure data migrations?\n\nMigrations are represented entirely as **pure data**:\n\n* no user functions\n* no closures\n* no reflection\n* no runtime code generation\n\nAs a result:\n\n* migrations can be **serialized**\n* stored in **registries**\n* applied **dynamically**\n* inspected and transformed\n* used to generate:\n\n  * upgraders\n  * downgraders\n  * SQL DDL / DML\n  * offline data transforms\n\nWhile code generation is **out of scope for this ticket**, this explains many design decisions (invertibility, path-based actions, no functions).\n\n---\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed migration (user-facing API)\ncase class Migration[A, B](\n  dynamicMigration: DynamicMigration,\n  sourceSchema: Schema[A], // These are structural schemas!!!\n  targetSchema: Schema[B] // These are structural schemas!!!\n) {\n  /** Apply migration to transform A to B */\n  def apply(value: A): Either[MigrationError, B]\n\n  /** Compose migrations sequentially */\n  def ++[C](that: Migration[B, C]): Migration[A, C]\n\n  /** Alias for ++ */\n  def andThen[C](that: Migration[B, C]): Migration[A, C] = this ++ that\n\n  /** Reverse migration (structural inverse; runtime is best-effort) */\n  def reverse: Migration[B, A]\n}\n```\n\n```scala\n// Untyped migration (pure data, fully serializable)\ncase class DynamicMigration(\n  actions: Vector[MigrationAction]\n) {\n  def apply(value: DynamicValue): Either[MigrationError, DynamicValue]\n  def ++(that: DynamicMigration): DynamicMigration\n  def reverse: DynamicMigration\n}\n```\n\n* `Migration[A, B]` is introspectable, but not pure data due to bindings inside schemas\n* `DynamicMigration` is **fully serializable**\n\n---\n\n## User-Facing API: Selector Expressions\n\n### Selectors, not optics\n\nThe user-facing API **does not expose optics**.\n\nInstead, all locations are specified using **selector expressions**:\n\n```scala\nS => A\n```\n\nExamples:\n\n```scala\n_.name\n_.address.street\n_.addresses.each.streetNumber\n_.country.when[UK]\n```\n\nTo see the syntax, one can look at the `optic` macro, which utilizes the same selector syntax for optic creation (e.g. `optic(_.address.street)`, etc.).\n\n### Macro extraction\n\nAll builder methods that accept selectors are **implemented via macros** (or via a macro-generated type class such as `ToDynamicOptic`).\n\nThe macro:\n\n1. Inspects the selector expression\n2. Validates it is a supported projection\n3. Converts it into a `DynamicOptic`\n4. Stores that optic in the migration action\n\nSupported projections include:\n\n* field access (`_.foo.bar`)\n* case selection (`_.country.when[UK]`)\n* collection traversal (`_.items.each`)\n* (future) key access, wrappers, etc.\n\n`DynamicOptic` is **never exposed publicly**.\n\n---\n\n## Migration Builder\n\nAll selector-accepting methods are implemented via macros. For simplicity, these are shown as functions (e.g. `A => Any`), but this is NOT the way to implement them. Either all these functions need to be macros, or a macro needs to be used to generate an implicit / given at each call site. Macros may do additional validation to constrain the validity of these different types of transformations.\n\n```scala\nclass MigrationBuilder[A, B](\n  sourceSchema: Schema[A],\n  targetSchema: Schema[B],\n  actions: Vector[MigrationAction]\n) {\n\n  // ----- Record operations -----\n\n  def addField(\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def dropField(\n    source: A => Any,\n    defaultForReverse: SchemaExpr[B, ?] = SchemaExpr.DefaultValue\n  ): MigrationBuilder[A, B]\n\n  def renameField(\n    from: A => Any,\n    to: B => Any\n  ): MigrationBuilder[A, B]\n\n  def transformField(\n    from: A => Any,\n    to: B => Any,\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def mandateField(\n    source: A => Option[?],\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def optionalizeField(\n    source: A => Any,\n    target: B => Option[?]\n  ): MigrationBuilder[A, B]\n\n  def changeFieldType(\n    source: A => Any,\n    target: B => Any,\n    converter: SchemaExpr[A, ?]  // primitive-to-primitive only\n  ): MigrationBuilder[A, B]\n\n  // ----- Enum operations (limited) -----\n\n  def renameCase[SumA, SumB](\n    from: String,\n    to: String\n  ): MigrationBuilder[A, B]\n\n  def transformCase[SumA, CaseA, SumB, CaseB](\n    caseMigration: MigrationBuilder[CaseA, CaseB] => MigrationBuilder[CaseA, CaseB]\n  ): MigrationBuilder[A, B]\n\n  // ----- Collections -----\n\n  def transformElements(\n    at: A => Vector[?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  // ----- Maps -----\n\n  def transformKeys(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def transformValues(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  /** Build migration with full macro validation */\n  def build: Migration[A, B]\n\n  /** Build migration without full validation */\n  def buildPartial: Migration[A, B]\n}\n```\n\n---\n\n## Migration Actions (Untyped Core)\n\nAll actions operate at a **path**, represented by `DynamicOptic`.\n\n```scala\nsealed trait MigrationAction {\n  def at: DynamicOptic\n  def reverse: MigrationAction\n}\n```\n\n### Record Actions\n\n```scala\ncase class AddField(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class DropField(\n  at: DynamicOptic,\n  defaultForReverse: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Rename(\n  at: DynamicOptic,\n  to: String\n) extends MigrationAction\n\ncase class TransformValue(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Mandate(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Optionalize(\n  at: DynamicOptic\n) extends MigrationAction\n\ncase class Join(\n  at: DynamicOptic,\n  sourcePaths: Vector[DynamicOptic],\n  combiner: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Split(\n  at: DynamicOptic,\n  targetPaths: Vector[DynamicOptic],\n  splitter: SchemaExpr[?]\n) extends MigrationAction\n\ncase class ChangeType(\n  at: DynamicOptic,\n  converter: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n### Enum Actions (Supported)\n\n```scala\ncase class RenameCase(\n  at: DynamicOptic,\n  from: String,\n  to: String\n) extends MigrationAction\n\ncase class TransformCase(\n  at: DynamicOptic,\n  actions: Vector[MigrationAction]\n) extends MigrationAction\n```\n\n> Enum case addition / removal is **out of scope** for this ticket\n> (requires composite value construction).\n\n---\n\n### Collection / Map Actions\n\n```scala\ncase class TransformElements(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformKeys(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformValues(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n## SchemaExpr Integration\n\n* Used for all value-level transformations\n* **Constraints for this ticket**:\n\n  * primitive → primitive only\n  * joins / splits must produce primitives\n  * no record / enum construction\n\n### `SchemaExpr.DefaultValue`\n\nA special expression that:\n\n1. uses the macro-captured field schema\n2. calls `schema.defaultValue`\n3. converts the value to `DynamicValue`\n4. is stored for reverse migrations\n\n---\n\n## Type Modeling\n\n### Records (Structural Types)\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\ntype PersonV1 = { val fullName: String; val age: Int }\n\nimplicit val v0Schema: Schema[PersonV0] = Schema.structural[PersonV0]\nimplicit val v1Schema: Schema[PersonV1] = Schema.structural[PersonV1]\n```\n\n---\n\n### Enums (Union of Structural Types with Tags)\n\nEnums are encoded into structural types by using union types, together with singleton types (string literals, which represent the name of the case of the enum).\n\nIn structural types, the names of the type aliases shown below are not relevant, nor are they used.\n\n```scala\ntype OldCreditCard =\n  { type Tag = \"CreditCard\"; def number: String; def exp: String }\ntype OldWireTransfer =\n  { type Tag = \"WireTransfer\"; def account: String; def routing: String }\ntype OldPaymentMethod = OldCreditCard | OldWireTransfer\n```\n\nMacros extract:\n\n* refinement type → structure of the case\n* type `Tag` with singleton type → case tag\n\n---\n\n## Laws\n\n### Identity\n\n```scala\nMigration.identity[A].apply(a) == Right(a)\n```\n\n### Associativity\n\n```scala\n(m1 ++ m2) ++ m3 == m1 ++ (m2 ++ m3)\n```\n\n### Structural Reverse\n\n```scala\nm.reverse.reverse == m\n```\n\n### Best-Effort Semantic Inverse\n\n```scala\nm.apply(a) == Right(b) ⇒ m.reverse.apply(b) == Right(a)\n```\n\n(when sufficient information exists)\n\n---\n\n## Error Handling\n\n* All runtime errors return `MigrationError`\n* Errors must capture **path information** (`DynamicOptic`)\n* Enables diagnostics such as:\n\n> “Failed to apply TransformValue at `.addresses.each.streetNumber`”\n\n---\n\n## Example\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\n\n@schema\ncase class Person(fullName: String, age: Int)\n\nval migration =\n  Migration.newBuilder[PersonV0, Person]\n    .addField(_.age, 0)\n    .build\n\nval old =\n  new { val firstName = \"John\"; val lastName = \"Doe\" }\n\nmigration(old)\n// Right(Person(\"John Doe\", 0))\n```\n\n---\n\n## Success Criteria\n\n* [ ] `DynamicMigration` fully serializable\n* [ ] `Migration[A, B]` wraps schemas and actions\n* [ ] All actions path-based via `DynamicOptic`\n* [ ] User API uses selector functions (`S => A`) for \"optics\" on old and new types\n* [ ] Macro validation in `.build` to confirm \"old\" has been migrated to \"new\"\n* [ ] `.buildPartial` supported\n* [ ] Structural reverse implemented\n* [ ] Identity & associativity laws hold\n* [ ] Enum rename / transform supported\n* [ ] Errors include path information\n* [ ] Comprehensive tests\n* [ ] Scala 2.13 and Scala 3.5+ supported\n",
                  "html_url": "https://github.com/zio/zio-blocks/issues/519"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#519",
              "body": "## Overview\n\nImplement a **pure, algebraic migration system** for ZIO Schema 2 that represents **structural transformations between schema versions** as first-class, serializable data.\n\nA migration describes how to transform data from one schema version to another, enabling:\n\n* schema evolution\n* backward / forward compatibility\n* data versioning\n* offline migrations (JSON, SQL, data lakes, registries, etc.)\n\nThe system provides a **typed, macro-validated user API** (`Migration[A, B]`) built on a **pure, serializable core** (`DynamicMigration`) that operates on `DynamicValue`. \n\nThe ADT is fully introspectable and can be used to generate DDL, etc.\n\n## Motivation & Big Picture\n\n### Why structural types?\n\nWhen evolving schemas over time, **older versions of data types should not require runtime representations**.\n\nIn this design:\n\n* **Current versions** are represented by real case classes / enums\n* **Past versions** are represented using:\n\n  * **structural types** for records\n  * **abstract types + intersection types** for sum types\n\nThese types:\n\n* exist **only at compile time**\n* have **no runtime representation**\n* introduce **zero runtime overhead**\n* do **not require optics or instances to be kept around**\n\nThis allows you to describe arbitrarily old versions of data *without polluting your runtime or codebase*.\n\n#### Typical Workflow\n\nA typical workflow looks like:\n\n1. You have a current type:\n\n   ```scala\n   @schema\n   case class Person(name: String, age: Int)\n   ```\n\n2. You derive and copy its structural shape:\n\n   ```scala\n   type PersonV1 = { def name: String; def age: Int }\n   ```\n\n3. You evolve the real type:\n\n   ```scala\n   @schema\n   case class Person(fullName: String, age: Int, country: String)\n   ```\n\n4. You keep only:\n\n   * the **current** runtime type\n   * the **structural type** for the old version\n   * a **pure migration** between them\n\nNo old case classes. No old optics. No runtime baggage.\n\nNote there is no requirement that the \"current\" type actually be a real case class, enum, etc.--so you can work purely with structural types, allowing you to define migrations for data types that are never materialized as runtime structures.\n\n---\n\n### Why pure data migrations?\n\nMigrations are represented entirely as **pure data**:\n\n* no user functions\n* no closures\n* no reflection\n* no runtime code generation\n\nAs a result:\n\n* migrations can be **serialized**\n* stored in **registries**\n* applied **dynamically**\n* inspected and transformed\n* used to generate:\n\n  * upgraders\n  * downgraders\n  * SQL DDL / DML\n  * offline data transforms\n\nWhile code generation is **out of scope for this ticket**, this explains many design decisions (invertibility, path-based actions, no functions).\n\n---\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed migration (user-facing API)\ncase class Migration[A, B](\n  dynamicMigration: DynamicMigration,\n  sourceSchema: Schema[A], // These are structural schemas!!!\n  targetSchema: Schema[B] // These are structural schemas!!!\n) {\n  /** Apply migration to transform A to B */\n  def apply(value: A): Either[MigrationError, B]\n\n  /** Compose migrations sequentially */\n  def ++[C](that: Migration[B, C]): Migration[A, C]\n\n  /** Alias for ++ */\n  def andThen[C](that: Migration[B, C]): Migration[A, C] = this ++ that\n\n  /** Reverse migration (structural inverse; runtime is best-effort) */\n  def reverse: Migration[B, A]\n}\n```\n\n```scala\n// Untyped migration (pure data, fully serializable)\ncase class DynamicMigration(\n  actions: Vector[MigrationAction]\n) {\n  def apply(value: DynamicValue): Either[MigrationError, DynamicValue]\n  def ++(that: DynamicMigration): DynamicMigration\n  def reverse: DynamicMigration\n}\n```\n\n* `Migration[A, B]` is introspectable, but not pure data due to bindings inside schemas\n* `DynamicMigration` is **fully serializable**\n\n---\n\n## User-Facing API: Selector Expressions\n\n### Selectors, not optics\n\nThe user-facing API **does not expose optics**.\n\nInstead, all locations are specified using **selector expressions**:\n\n```scala\nS => A\n```\n\nExamples:\n\n```scala\n_.name\n_.address.street\n_.addresses.each.streetNumber\n_.country.when[UK]\n```\n\nTo see the syntax, one can look at the `optic` macro, which utilizes the same selector syntax for optic creation (e.g. `optic(_.address.street)`, etc.).\n\n### Macro extraction\n\nAll builder methods that accept selectors are **implemented via macros** (or via a macro-generated type class such as `ToDynamicOptic`).\n\nThe macro:\n\n1. Inspects the selector expression\n2. Validates it is a supported projection\n3. Converts it into a `DynamicOptic`\n4. Stores that optic in the migration action\n\nSupported projections include:\n\n* field access (`_.foo.bar`)\n* case selection (`_.country.when[UK]`)\n* collection traversal (`_.items.each`)\n* (future) key access, wrappers, etc.\n\n`DynamicOptic` is **never exposed publicly**.\n\n---\n\n## Migration Builder\n\nAll selector-accepting methods are implemented via macros. For simplicity, these are shown as functions (e.g. `A => Any`), but this is NOT the way to implement them. Either all these functions need to be macros, or a macro needs to be used to generate an implicit / given at each call site. Macros may do additional validation to constrain the validity of these different types of transformations.\n\n```scala\nclass MigrationBuilder[A, B](\n  sourceSchema: Schema[A],\n  targetSchema: Schema[B],\n  actions: Vector[MigrationAction]\n) {\n\n  // ----- Record operations -----\n\n  def addField(\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def dropField(\n    source: A => Any,\n    defaultForReverse: SchemaExpr[B, ?] = SchemaExpr.DefaultValue\n  ): MigrationBuilder[A, B]\n\n  def renameField(\n    from: A => Any,\n    to: B => Any\n  ): MigrationBuilder[A, B]\n\n  def transformField(\n    from: A => Any,\n    to: B => Any,\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def mandateField(\n    source: A => Option[?],\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def optionalizeField(\n    source: A => Any,\n    target: B => Option[?]\n  ): MigrationBuilder[A, B]\n\n  def changeFieldType(\n    source: A => Any,\n    target: B => Any,\n    converter: SchemaExpr[A, ?]  // primitive-to-primitive only\n  ): MigrationBuilder[A, B]\n\n  // ----- Enum operations (limited) -----\n\n  def renameCase[SumA, SumB](\n    from: String,\n    to: String\n  ): MigrationBuilder[A, B]\n\n  def transformCase[SumA, CaseA, SumB, CaseB](\n    caseMigration: MigrationBuilder[CaseA, CaseB] => MigrationBuilder[CaseA, CaseB]\n  ): MigrationBuilder[A, B]\n\n  // ----- Collections -----\n\n  def transformElements(\n    at: A => Vector[?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  // ----- Maps -----\n\n  def transformKeys(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def transformValues(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  /** Build migration with full macro validation */\n  def build: Migration[A, B]\n\n  /** Build migration without full validation */\n  def buildPartial: Migration[A, B]\n}\n```\n\n---\n\n## Migration Actions (Untyped Core)\n\nAll actions operate at a **path**, represented by `DynamicOptic`.\n\n```scala\nsealed trait MigrationAction {\n  def at: DynamicOptic\n  def reverse: MigrationAction\n}\n```\n\n### Record Actions\n\n```scala\ncase class AddField(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class DropField(\n  at: DynamicOptic,\n  defaultForReverse: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Rename(\n  at: DynamicOptic,\n  to: String\n) extends MigrationAction\n\ncase class TransformValue(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Mandate(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Optionalize(\n  at: DynamicOptic\n) extends MigrationAction\n\ncase class Join(\n  at: DynamicOptic,\n  sourcePaths: Vector[DynamicOptic],\n  combiner: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Split(\n  at: DynamicOptic,\n  targetPaths: Vector[DynamicOptic],\n  splitter: SchemaExpr[?]\n) extends MigrationAction\n\ncase class ChangeType(\n  at: DynamicOptic,\n  converter: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n### Enum Actions (Supported)\n\n```scala\ncase class RenameCase(\n  at: DynamicOptic,\n  from: String,\n  to: String\n) extends MigrationAction\n\ncase class TransformCase(\n  at: DynamicOptic,\n  actions: Vector[MigrationAction]\n) extends MigrationAction\n```\n\n> Enum case addition / removal is **out of scope** for this ticket\n> (requires composite value construction).\n\n---\n\n### Collection / Map Actions\n\n```scala\ncase class TransformElements(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformKeys(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformValues(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n## SchemaExpr Integration\n\n* Used for all value-level transformations\n* **Constraints for this ticket**:\n\n  * primitive → primitive only\n  * joins / splits must produce primitives\n  * no record / enum construction\n\n### `SchemaExpr.DefaultValue`\n\nA special expression that:\n\n1. uses the macro-captured field schema\n2. calls `schema.defaultValue`\n3. converts the value to `DynamicValue`\n4. is stored for reverse migrations\n\n---\n\n## Type Modeling\n\n### Records (Structural Types)\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\ntype PersonV1 = { val fullName: String; val age: Int }\n\nimplicit val v0Schema: Schema[PersonV0] = Schema.structural[PersonV0]\nimplicit val v1Schema: Schema[PersonV1] = Schema.structural[PersonV1]\n```\n\n---\n\n### Enums (Union of Structural Types with Tags)\n\nEnums are encoded into structural types by using union types, together with singleton types (string literals, which represent the name of the case of the enum).\n\nIn structural types, the names of the type aliases shown below are not relevant, nor are they used.\n\n```scala\ntype OldCreditCard =\n  { type Tag = \"CreditCard\"; def number: String; def exp: String }\ntype OldWireTransfer =\n  { type Tag = \"WireTransfer\"; def account: String; def routing: String }\ntype OldPaymentMethod = OldCreditCard | OldWireTransfer\n```\n\nMacros extract:\n\n* refinement type → structure of the case\n* type `Tag` with singleton type → case tag\n\n---\n\n## Laws\n\n### Identity\n\n```scala\nMigration.identity[A].apply(a) == Right(a)\n```\n\n### Associativity\n\n```scala\n(m1 ++ m2) ++ m3 == m1 ++ (m2 ++ m3)\n```\n\n### Structural Reverse\n\n```scala\nm.reverse.reverse == m\n```\n\n### Best-Effort Semantic Inverse\n\n```scala\nm.apply(a) == Right(b) ⇒ m.reverse.apply(b) == Right(a)\n```\n\n(when sufficient information exists)\n\n---\n\n## Error Handling\n\n* All runtime errors return `MigrationError`\n* Errors must capture **path information** (`DynamicOptic`)\n* Enables diagnostics such as:\n\n> “Failed to apply TransformValue at `.addresses.each.streetNumber`”\n\n---\n\n## Example\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\n\n@schema\ncase class Person(fullName: String, age: Int)\n\nval migration =\n  Migration.newBuilder[PersonV0, Person]\n    .addField(_.age, 0)\n    .build\n\nval old =\n  new { val firstName = \"John\"; val lastName = \"Doe\" }\n\nmigration(old)\n// Right(Person(\"John Doe\", 0))\n```\n\n---\n\n## Success Criteria\n\n* [ ] `DynamicMigration` fully serializable\n* [ ] `Migration[A, B]` wraps schemas and actions\n* [ ] All actions path-based via `DynamicOptic`\n* [ ] User API uses selector functions (`S => A`) for \"optics\" on old and new types\n* [ ] Macro validation in `.build` to confirm \"old\" has been migrated to \"new\"\n* [ ] `.buildPartial` supported\n* [ ] Structural reverse implemented\n* [ ] Identity & associativity laws hold\n* [ ] Enum rename / transform supported\n* [ ] Errors include path information\n* [ ] Comprehensive tests\n* [ ] Scala 2.13 and Scala 3.5+ supported\n",
              "url": "https://github.com/zio/zio-blocks/issues/519",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#3472",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-02-27T22:50:41.600Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:41.600Z",
            "created_at": "2026-02-27T22:50:41.600Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#3472",
              "status": "open",
              "type": "issue",
              "number": 3472,
              "title": "Split into multiple modules",
              "source": {
                "data": {
                  "id": "source-ZIO#3472",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Split into multiple modules",
                  "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
                  "html_url": "https://github.com/zio/zio-http/issues/3472"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3472",
              "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
              "url": "https://github.com/zio/zio-http/issues/3472",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9810",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-02-27T22:50:41.604Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:41.604Z",
            "created_at": "2026-02-27T22:50:41.604Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9810",
              "status": "open",
              "type": "issue",
              "number": 9810,
              "title": "ZStreams buffer(1) is buffering 2.",
              "source": {
                "data": {
                  "id": "source-ZIO#9810",
                  "user": {
                    "login": "douglasthomsen",
                    "id": 88000378,
                    "node_id": "MDQ6VXNlcjg4MDAwMzc4",
                    "avatar_url": "https://avatars.githubusercontent.com/u/88000378?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/douglasthomsen",
                    "html_url": "https://github.com/douglasthomsen",
                    "followers_url": "https://api.github.com/users/douglasthomsen/followers",
                    "following_url": "https://api.github.com/users/douglasthomsen/following{/other_user}",
                    "gists_url": "https://api.github.com/users/douglasthomsen/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/douglasthomsen/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/douglasthomsen/subscriptions",
                    "organizations_url": "https://api.github.com/users/douglasthomsen/orgs",
                    "repos_url": "https://api.github.com/users/douglasthomsen/repos",
                    "events_url": "https://api.github.com/users/douglasthomsen/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/douglasthomsen/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZStreams buffer(1) is buffering 2.",
                  "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
                  "html_url": "https://github.com/zio/zio/issues/9810"
                },
                "type": "github"
              },
              "hash": "zio/zio#9810",
              "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
              "url": "https://github.com/zio/zio/issues/9810",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9844",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-02-27T22:50:41.607Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:41.607Z",
            "created_at": "2026-02-27T22:50:41.607Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9844",
              "status": "open",
              "type": "issue",
              "number": 9844,
              "title": "improved `Queue` shutdown functionality",
              "source": {
                "data": {
                  "id": "source-ZIO#9844",
                  "user": {
                    "login": "mberndt123",
                    "id": 11650737,
                    "node_id": "MDQ6VXNlcjExNjUwNzM3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/11650737?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/mberndt123",
                    "html_url": "https://github.com/mberndt123",
                    "followers_url": "https://api.github.com/users/mberndt123/followers",
                    "following_url": "https://api.github.com/users/mberndt123/following{/other_user}",
                    "gists_url": "https://api.github.com/users/mberndt123/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/mberndt123/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/mberndt123/subscriptions",
                    "organizations_url": "https://api.github.com/users/mberndt123/orgs",
                    "repos_url": "https://api.github.com/users/mberndt123/repos",
                    "events_url": "https://api.github.com/users/mberndt123/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/mberndt123/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "improved `Queue` shutdown functionality",
                  "body": "Hey, I've recently proposed something on Discord, and since feedback has been rather positive, I'm making a ticket to track the idea.\n\nI've been working with Queues recently, and I've been having some issues around `shutdown` that I would like to address.\n\nSpecifically, I find it a common pattern that I send some kind of request object through a queue because I want another fiber to perform some action on my behalf. Along with the request, I send a `Promise` to have that fiber communicate the outcome of that action to me. By and large this works fine. The issue arises when the fiber that I'm sending requests to fails. In that case, I would like it to communicate the cause of the failure back to the other fibers. This is easy enough for the requests that I've already pulled out of the queue: I simply fail those promises.\nBut I also need to deal with other cases: fibers currently blocked in an `offer` call, future attempts to `offer` to the queue, and I also need to deal with requests that have been submitted to the queue but not yet retrieved.\n\nSo my idea is as follows:\n - add an `E` type parameter to `Queue`\n - add a `shutdownCause` method that takes a type parameter of type `Cause[E]`\n - `shutdownCause` would also return the items currently buffered in the queue in order to dispose of them\n - after `shutdownCause` has been called, any attempt to interact with the queue will fail with the cause\n - methods like `take, offer` etc. should indicate errors of type `E`\n - streams created with `ZStream.fromQueue` would also fail with this cause\n - `shutdownCause` should be atomic: when multiple fibers call it at the same time, one of them wins and the others fail with the cause supplied by the winner\n\nAfaik, adding a new method is a binary compatible change, as is adding a new type parameter. Hence I think this is a source incompatible but binary compatible change. @ghostdogpr therefore suggested it could be added in a ZIO 2.2 release.\n",
                  "html_url": "https://github.com/zio/zio/issues/9844"
                },
                "type": "github"
              },
              "hash": "zio/zio#9844",
              "body": "Hey, I've recently proposed something on Discord, and since feedback has been rather positive, I'm making a ticket to track the idea.\n\nI've been working with Queues recently, and I've been having some issues around `shutdown` that I would like to address.\n\nSpecifically, I find it a common pattern that I send some kind of request object through a queue because I want another fiber to perform some action on my behalf. Along with the request, I send a `Promise` to have that fiber communicate the outcome of that action to me. By and large this works fine. The issue arises when the fiber that I'm sending requests to fails. In that case, I would like it to communicate the cause of the failure back to the other fibers. This is easy enough for the requests that I've already pulled out of the queue: I simply fail those promises.\nBut I also need to deal with other cases: fibers currently blocked in an `offer` call, future attempts to `offer` to the queue, and I also need to deal with requests that have been submitted to the queue but not yet retrieved.\n\nSo my idea is as follows:\n - add an `E` type parameter to `Queue`\n - add a `shutdownCause` method that takes a type parameter of type `Cause[E]`\n - `shutdownCause` would also return the items currently buffered in the queue in order to dispose of them\n - after `shutdownCause` has been called, any attempt to interact with the queue will fail with the cause\n - methods like `take, offer` etc. should indicate errors of type `E`\n - streams created with `ZStream.fromQueue` would also fail with this cause\n - `shutdownCause` should be atomic: when multiple fibers call it at the same time, one of them wins and the others fail with the cause supplied by the winner\n\nAfaik, adding a new method is a binary compatible change, as is adding a new type parameter. Hence I think this is a source incompatible but binary compatible change. @ghostdogpr therefore suggested it could be added in a ZIO 2.2 release.\n",
              "url": "https://github.com/zio/zio/issues/9844",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9878",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-02-27T22:50:41.611Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:41.611Z",
            "created_at": "2026-02-27T22:50:41.611Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9878",
              "status": "open",
              "type": "issue",
              "number": 9878,
              "title": "ZScheduler parks+unparks workers too frequently",
              "source": {
                "data": {
                  "id": "source-ZIO#9878",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZScheduler parks+unparks workers too frequently",
                  "body": "Unparking workers is slow and invoked in the hotpath too often. I think we may need to trade some fairness for aggression to avoid excessive cycling.\n\n`maybeUnparkWorker` (obviously `LockSupport.unpark(worker)`) is very expensive: https://github.com/zio/zio/blob/series/2.x/core/jvm-native/src/main/scala/zio/internal/ZScheduler.scala#L443-L454",
                  "html_url": "https://github.com/zio/zio/issues/9878"
                },
                "type": "github"
              },
              "hash": "zio/zio#9878",
              "body": "Unparking workers is slow and invoked in the hotpath too often. I think we may need to trade some fairness for aggression to avoid excessive cycling.\n\n`maybeUnparkWorker` (obviously `LockSupport.unpark(worker)`) is very expensive: https://github.com/zio/zio/blob/series/2.x/core/jvm-native/src/main/scala/zio/internal/ZScheduler.scala#L443-L454",
              "url": "https://github.com/zio/zio/issues/9878",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9877",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-02-27T22:50:41.615Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:41.615Z",
            "created_at": "2026-02-27T22:50:41.615Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9877",
              "status": "open",
              "type": "issue",
              "number": 9877,
              "title": "Can Fiber(Runtime) and Promise be merged?",
              "source": {
                "data": {
                  "id": "source-ZIO#9877",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Can Fiber(Runtime) and Promise be merged?",
                  "body": "A Promise awaiting completion is essentially a Fiber parked awaiting an async callback. When a Fiber is forking work (which will eventually complete a promise), then awaiting a Promise, we end up with unnecessary allocations + indirection.\n\nit would be useful to have `Promise.become` or similar to link fibers/promises.",
                  "html_url": "https://github.com/zio/zio/issues/9877"
                },
                "type": "github"
              },
              "hash": "zio/zio#9877",
              "body": "A Promise awaiting completion is essentially a Fiber parked awaiting an async callback. When a Fiber is forking work (which will eventually complete a promise), then awaiting a Promise, we end up with unnecessary allocations + indirection.\n\nit would be useful to have `Promise.become` or similar to link fibers/promises.",
              "url": "https://github.com/zio/zio/issues/9877",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9874",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-02-27T22:50:41.618Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:41.618Z",
            "created_at": "2026-02-27T22:50:41.618Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9874",
              "status": "open",
              "type": "issue",
              "number": 9874,
              "title": "Handling errors allows recovering from defects",
              "source": {
                "data": {
                  "id": "source-ZIO#9874",
                  "user": {
                    "login": "kyri-petrou",
                    "id": 67301607,
                    "node_id": "MDQ6VXNlcjY3MzAxNjA3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/67301607?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kyri-petrou",
                    "html_url": "https://github.com/kyri-petrou",
                    "followers_url": "https://api.github.com/users/kyri-petrou/followers",
                    "following_url": "https://api.github.com/users/kyri-petrou/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kyri-petrou/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kyri-petrou/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kyri-petrou/subscriptions",
                    "organizations_url": "https://api.github.com/users/kyri-petrou/orgs",
                    "repos_url": "https://api.github.com/users/kyri-petrou/repos",
                    "events_url": "https://api.github.com/users/kyri-petrou/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kyri-petrou/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Handling errors allows recovering from defects",
                  "body": "Sigh... Well, this is annoying. When a Cause contains both a failure and a defect (i.e., Fail & Die), failure handling assumes that the Cause does not contain any defects and therefor silently ignores them.\n\nRepro:\n\n```scala\nimport zio.*\n\nobject Foo extends ZIOAppDefault {\n  val dieCause: Cause[String] = Cause.die(new RuntimeException(\"boom\"))\n  val combinedCause = dieCause && Cause.fail(\"boom\")\n\n  def run = ZIO.failCause(combinedCause).catchAll { e =>\n    ZIO.debug(e)\n  } *> ZIO.debug(\"Success\")\n}\n```\nprints:\n```\nhandled: boom\nSuccess\n```\n\nHowever if we substituted `ZIO.failCause(combinedCause)` with `ZIO.failCause(dieCause)`:\n\n```\ntimestamp=2025-05-20T16:31:09.291104Z level=ERROR thread=#zio-fiber-1707930317 message=\"\" cause=\"java.lang.RuntimeException: boom\n\tat Foo$.<clinit>(Foo.scala:4)\n\tat Foo.main(Foo.scala)\n\tat <empty>.Foo.run(Foo.scala:7)\n\tat <empty>.Foo.run(Foo.scala:9)\n\"\n```\n\nWith both of these causes, the outcome should be the same as defects should always be prioritised over failures. This gets even worse when interruption is involved, because the failure handling will be prioritised over it.\n\nHaving said that, this has the potential to massively alter applications so I'm too scared to fix it.\n@ghostdogpr @jdegoes  @hearnadam @guizmaii I summon you all for some wisdom",
                  "html_url": "https://github.com/zio/zio/issues/9874"
                },
                "type": "github"
              },
              "hash": "zio/zio#9874",
              "body": "Sigh... Well, this is annoying. When a Cause contains both a failure and a defect (i.e., Fail & Die), failure handling assumes that the Cause does not contain any defects and therefor silently ignores them.\n\nRepro:\n\n```scala\nimport zio.*\n\nobject Foo extends ZIOAppDefault {\n  val dieCause: Cause[String] = Cause.die(new RuntimeException(\"boom\"))\n  val combinedCause = dieCause && Cause.fail(\"boom\")\n\n  def run = ZIO.failCause(combinedCause).catchAll { e =>\n    ZIO.debug(e)\n  } *> ZIO.debug(\"Success\")\n}\n```\nprints:\n```\nhandled: boom\nSuccess\n```\n\nHowever if we substituted `ZIO.failCause(combinedCause)` with `ZIO.failCause(dieCause)`:\n\n```\ntimestamp=2025-05-20T16:31:09.291104Z level=ERROR thread=#zio-fiber-1707930317 message=\"\" cause=\"java.lang.RuntimeException: boom\n\tat Foo$.<clinit>(Foo.scala:4)\n\tat Foo.main(Foo.scala)\n\tat <empty>.Foo.run(Foo.scala:7)\n\tat <empty>.Foo.run(Foo.scala:9)\n\"\n```\n\nWith both of these causes, the outcome should be the same as defects should always be prioritised over failures. This gets even worse when interruption is involved, because the failure handling will be prioritised over it.\n\nHaving said that, this has the potential to massively alter applications so I'm too scared to fix it.\n@ghostdogpr @jdegoes  @hearnadam @guizmaii I summon you all for some wisdom",
              "url": "https://github.com/zio/zio/issues/9874",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9681",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-02-27T22:50:41.622Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:41.622Z",
            "created_at": "2026-02-27T22:50:41.622Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9681",
              "status": "open",
              "type": "issue",
              "number": 9681,
              "title": "Scala Native `WeakConcurrentBag` NPE when forking 10K fibers",
              "source": {
                "data": {
                  "id": "source-ZIO#9681",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Scala Native `WeakConcurrentBag` NPE when forking 10K fibers",
                  "body": "```\n[info]   - PromiseSpec - waiter stack safety\n[info]     Exception in thread \"zio-fiber-931\" java.lang.NullPointerException: null\n[info]     \tat scala.scalanative.runtime.package$.throwNullPointer(Unknown Source)\n[info]     \tat <none>.(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.treeifyBin(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.putVal(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap$KeySetView.add(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.addToLongTermStorage(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.add(Unknown Source)\n[info]     \tat zio.internal.FiberScope$global$.add(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.makeChildFiber(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.fork(Unknown Source)\n[info]     \tat zio.ZIO.$anonfun$forkWithScopeOverride$2(Unknown Source)\n[info]     \tat zio.ZIO$$Lambda$280.apply(Unknown Source)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:127)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:124)\n```\nI introduced a new test in #9569 which resulted in this strange failure on Native.",
                  "html_url": "https://github.com/zio/zio/issues/9681"
                },
                "type": "github"
              },
              "hash": "zio/zio#9681",
              "body": "```\n[info]   - PromiseSpec - waiter stack safety\n[info]     Exception in thread \"zio-fiber-931\" java.lang.NullPointerException: null\n[info]     \tat scala.scalanative.runtime.package$.throwNullPointer(Unknown Source)\n[info]     \tat <none>.(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.treeifyBin(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.putVal(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap$KeySetView.add(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.addToLongTermStorage(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.add(Unknown Source)\n[info]     \tat zio.internal.FiberScope$global$.add(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.makeChildFiber(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.fork(Unknown Source)\n[info]     \tat zio.ZIO.$anonfun$forkWithScopeOverride$2(Unknown Source)\n[info]     \tat zio.ZIO$$Lambda$280.apply(Unknown Source)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:127)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:124)\n```\nI introduced a new test in #9569 which resulted in this strange failure on Native.",
              "url": "https://github.com/zio/zio/issues/9681",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9909",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-02-27T22:50:41.625Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:41.625Z",
            "created_at": "2026-02-27T22:50:41.625Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9909",
              "status": "open",
              "type": "issue",
              "number": 9909,
              "title": "Create test suite that tests the correct behaviour of `ZIOApp`",
              "source": {
                "data": {
                  "id": "source-ZIO#9909",
                  "user": {
                    "login": "kyri-petrou",
                    "id": 67301607,
                    "node_id": "MDQ6VXNlcjY3MzAxNjA3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/67301607?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kyri-petrou",
                    "html_url": "https://github.com/kyri-petrou",
                    "followers_url": "https://api.github.com/users/kyri-petrou/followers",
                    "following_url": "https://api.github.com/users/kyri-petrou/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kyri-petrou/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kyri-petrou/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kyri-petrou/subscriptions",
                    "organizations_url": "https://api.github.com/users/kyri-petrou/orgs",
                    "repos_url": "https://api.github.com/users/kyri-petrou/repos",
                    "events_url": "https://api.github.com/users/kyri-petrou/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kyri-petrou/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Create test suite that tests the correct behaviour of `ZIOApp`",
                  "body": "The test suite needs to run during CI and test the behaviour of `ZIOApp` when:\n1. The app completes on its own (either via failure or success)\n2. The app completes due to an external signal (e.g., SIGINT)\n\nWhat needs to be tested:\n1. Correct error code is emitted\n2. Application finalizers are run (except for catastrophic failures)\n3. Shutdown sequence doesn't hang\n4. `gracefulShutdownTimeout` is respected\n5. A lot of use-cases from past issues:\ni. #9901 \nii. #9807\niii. #9240\niv. (I'll add others as I find them)",
                  "html_url": "https://github.com/zio/zio/issues/9909"
                },
                "type": "github"
              },
              "hash": "zio/zio#9909",
              "body": "The test suite needs to run during CI and test the behaviour of `ZIOApp` when:\n1. The app completes on its own (either via failure or success)\n2. The app completes due to an external signal (e.g., SIGINT)\n\nWhat needs to be tested:\n1. Correct error code is emitted\n2. Application finalizers are run (except for catastrophic failures)\n3. Shutdown sequence doesn't hang\n4. `gracefulShutdownTimeout` is respected\n5. A lot of use-cases from past issues:\ni. #9901 \nii. #9807\niii. #9240\niv. (I'll add others as I find them)",
              "url": "https://github.com/zio/zio/issues/9909",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#819",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-02-27T22:50:42.904Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:42.904Z",
            "created_at": "2026-02-27T22:50:42.904Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#819",
              "status": "open",
              "type": "issue",
              "number": 819,
              "title": "tlsx hangs indefinitely for some hosts",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#819",
                  "user": {
                    "login": "msecrfe",
                    "id": 179370796,
                    "node_id": "U_kgDOCrD7LA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/179370796?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/msecrfe",
                    "html_url": "https://github.com/msecrfe",
                    "followers_url": "https://api.github.com/users/msecrfe/followers",
                    "following_url": "https://api.github.com/users/msecrfe/following{/other_user}",
                    "gists_url": "https://api.github.com/users/msecrfe/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/msecrfe/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/msecrfe/subscriptions",
                    "organizations_url": "https://api.github.com/users/msecrfe/orgs",
                    "repos_url": "https://api.github.com/users/msecrfe/repos",
                    "events_url": "https://api.github.com/users/msecrfe/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/msecrfe/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "tlsx hangs indefinitely for some hosts",
                  "body": "### tlsx version:\nv1.1.9\n\n### Current Behavior:\nFor long target lists (in our case: Around 30k host/port combinations), tlsx reliably hangs indefinitely after several hours of execution, usually after around 25k targets have finished. Hanging happens even while writing JSONL output lines, cutting off a JSONL line somewhere in the middle.\n\n### Expected Behavior:\ntlsx should not hang indefinitely.\n\n### Steps To Reproduce:\ntlsx was started as follows:\n\n```\n~/go/bin/tlsx \\\n\t-list /tmp/host_port_combos.txt \\\n\t-scan-mode 'auto' \\\n\t-ip-version '4' \\\n\t-so \\\n\t-tls-version \\\n\t-cipher \\\n\t-hash 'sha256' \\\n\t-wildcard-cert \\\n\t-probe-status \\\n\t-version-enum \\\n\t-cipher-enum \\\n\t-cipher-type 'all' \\\n\t-serial \\\n\t-expired \\\n\t-self-signed \\\n\t-mismatched \\\n\t-revoked \\\n\t-untrusted \\\n\t-resolvers 8.8.8.8,8.8.4.4,1.1.1.1 \\\n\t-certificate \\\n\t-tls-chain \\\n\t-concurrency '300' \\\n\t-cipher-concurrency '10' \\\n\t-timeout '5' \\\n\t-retry '3' \\\n\t-disable-update-check \\\n\t-output /tmp/tlsx_output.jsonl \\\n\t-json \\\n\t-no-color\n```\n\nAt one point, there is no more progress and even output is no longer written. This is the last line of the output file (`/tmp/tlsx_output.jsonl`):\n\n```\n{\"timestamp\":\"2025-04-25T09:59:31.489674682Z\",\"host\":\"xn--<censored>-t6b.<censored>\",\"ip\":\"<censored>\",\"port\":\"443\",\"probe_status\":true,\"tls_version\":\"tls13\",\"cipher\":\"TLS_AES_128_GCM_SHA256\",\"self_signed\":true,\"mismatched\":true,\"not_before\":\"2017-01-16T16:04:01Z\",\"not_after\":\"2027-01-14T16:04:01Z\",\"subject_dn\":\"emailAddress=root@localhost.localdomain, CN=localhost.localdomain, OU=IT, O=MyCompany, L=Seattle, ST=WA, C=US, emailAddress=root@localhost.localdomain\",\"subject_cn\":\n```\nPlease note that the line ends with an open \"subject_cn\" key and the JSON object on that line is never closed. The aforementioned line is line 25737 of the output file, so more than 25k targets have been scanned before.\n\n### Anything else:\nThe issue always appears after a long time of execution. Execution of tlsx for the aforementioned approx. 30k targets (aborted/hanging after about 25k targets) started at `2025-04-24T16:50:47+00:00` and the process started hanging at `2025-04-25T10:47:39+0000`, so about 18 hours later.\n\nThe issue does not seem to depend on the specific target host, as tlsx correctly terminates when only scanning the target host. Also, it always starts hanging indefinitely for a different target, but always after having run for hours and after having already scanned several thousand targets,",
                  "html_url": "https://github.com/projectdiscovery/tlsx/issues/819"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/tlsx#819",
              "body": "### tlsx version:\nv1.1.9\n\n### Current Behavior:\nFor long target lists (in our case: Around 30k host/port combinations), tlsx reliably hangs indefinitely after several hours of execution, usually after around 25k targets have finished. Hanging happens even while writing JSONL output lines, cutting off a JSONL line somewhere in the middle.\n\n### Expected Behavior:\ntlsx should not hang indefinitely.\n\n### Steps To Reproduce:\ntlsx was started as follows:\n\n```\n~/go/bin/tlsx \\\n\t-list /tmp/host_port_combos.txt \\\n\t-scan-mode 'auto' \\\n\t-ip-version '4' \\\n\t-so \\\n\t-tls-version \\\n\t-cipher \\\n\t-hash 'sha256' \\\n\t-wildcard-cert \\\n\t-probe-status \\\n\t-version-enum \\\n\t-cipher-enum \\\n\t-cipher-type 'all' \\\n\t-serial \\\n\t-expired \\\n\t-self-signed \\\n\t-mismatched \\\n\t-revoked \\\n\t-untrusted \\\n\t-resolvers 8.8.8.8,8.8.4.4,1.1.1.1 \\\n\t-certificate \\\n\t-tls-chain \\\n\t-concurrency '300' \\\n\t-cipher-concurrency '10' \\\n\t-timeout '5' \\\n\t-retry '3' \\\n\t-disable-update-check \\\n\t-output /tmp/tlsx_output.jsonl \\\n\t-json \\\n\t-no-color\n```\n\nAt one point, there is no more progress and even output is no longer written. This is the last line of the output file (`/tmp/tlsx_output.jsonl`):\n\n```\n{\"timestamp\":\"2025-04-25T09:59:31.489674682Z\",\"host\":\"xn--<censored>-t6b.<censored>\",\"ip\":\"<censored>\",\"port\":\"443\",\"probe_status\":true,\"tls_version\":\"tls13\",\"cipher\":\"TLS_AES_128_GCM_SHA256\",\"self_signed\":true,\"mismatched\":true,\"not_before\":\"2017-01-16T16:04:01Z\",\"not_after\":\"2027-01-14T16:04:01Z\",\"subject_dn\":\"emailAddress=root@localhost.localdomain, CN=localhost.localdomain, OU=IT, O=MyCompany, L=Seattle, ST=WA, C=US, emailAddress=root@localhost.localdomain\",\"subject_cn\":\n```\nPlease note that the line ends with an open \"subject_cn\" key and the JSON object on that line is never closed. The aforementioned line is line 25737 of the output file, so more than 25k targets have been scanned before.\n\n### Anything else:\nThe issue always appears after a long time of execution. Execution of tlsx for the aforementioned approx. 30k targets (aborted/hanging after about 25k targets) started at `2025-04-24T16:50:47+00:00` and the process started hanging at `2025-04-25T10:47:39+0000`, so about 18 hours later.\n\nThe issue does not seem to depend on the specific target host, as tlsx correctly terminates when only scanning the target host. Also, it always starts hanging indefinitely for a different target, but always after having run for hours and after having already scanned several thousand targets,",
              "url": "https://github.com/projectdiscovery/tlsx/issues/819",
              "tech": [],
              "repo_name": "tlsx",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#6532",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-02-27T22:50:43.032Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:43.032Z",
            "created_at": "2026-02-27T22:50:43.032Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#6532",
              "status": "open",
              "type": "issue",
              "number": 6532,
              "title": "Integrate typos tool into CI",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#6532",
                  "user": {
                    "login": "coderabbitai[bot]",
                    "id": 136622811,
                    "node_id": "BOT_kgDOCCSy2w",
                    "avatar_url": "https://avatars.githubusercontent.com/in/347564?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/coderabbitai%5Bbot%5D",
                    "html_url": "https://github.com/apps/coderabbitai",
                    "followers_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/followers",
                    "following_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/following{/other_user}",
                    "gists_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/subscriptions",
                    "organizations_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/orgs",
                    "repos_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/repos",
                    "events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/received_events",
                    "type": "Bot",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Integrate typos tool into CI",
                  "body": "## Description\n\nWe should integrate the typos tool (https://github.com/crate-ci/typos) into our CI pipeline to automatically catch typos in future PRs and maintain code quality consistently.\n\n## Reference\n\n- GitHub Action documentation: https://github.com/crate-ci/typos/blob/master/docs/github-action.md\n- Related PR: https://github.com/projectdiscovery/nuclei/pull/6521\n- Requested by: @dwisiswant0 in https://github.com/projectdiscovery/nuclei/pull/6521#discussion_r1234567890",
                  "html_url": "https://github.com/projectdiscovery/nuclei/issues/6532"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei#6532",
              "body": "## Description\n\nWe should integrate the typos tool (https://github.com/crate-ci/typos) into our CI pipeline to automatically catch typos in future PRs and maintain code quality consistently.\n\n## Reference\n\n- GitHub Action documentation: https://github.com/crate-ci/typos/blob/master/docs/github-action.md\n- Related PR: https://github.com/projectdiscovery/nuclei/pull/6521\n- Requested by: @dwisiswant0 in https://github.com/projectdiscovery/nuclei/pull/6521#discussion_r1234567890",
              "url": "https://github.com/projectdiscovery/nuclei/issues/6532",
              "tech": [],
              "repo_name": "nuclei",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#1367",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-02-27T22:50:43.142Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:43.142Z",
            "created_at": "2026-02-27T22:50:43.142Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#1367",
              "status": "open",
              "type": "issue",
              "number": 1367,
              "title": "Feature / Question: go-tree-sitter dependency",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#1367",
                  "user": {
                    "login": "aautumn725",
                    "id": 220215965,
                    "node_id": "U_kgDODSA6nQ",
                    "avatar_url": "https://avatars.githubusercontent.com/u/220215965?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/aautumn725",
                    "html_url": "https://github.com/aautumn725",
                    "followers_url": "https://api.github.com/users/aautumn725/followers",
                    "following_url": "https://api.github.com/users/aautumn725/following{/other_user}",
                    "gists_url": "https://api.github.com/users/aautumn725/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/aautumn725/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/aautumn725/subscriptions",
                    "organizations_url": "https://api.github.com/users/aautumn725/orgs",
                    "repos_url": "https://api.github.com/users/aautumn725/repos",
                    "events_url": "https://api.github.com/users/aautumn725/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/aautumn725/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Feature / Question: go-tree-sitter dependency",
                  "body": "### Feature / Question: go-tree-sitter dependency\n\nHi team,  \n\nI noticed that the project currently uses `github.com/smacker/go-tree-sitter` for syntax tree parsing. Since `go-tree-sitter` relies on CGO, cross-platform compilation (especially for darwin/arm64) becomes complicated.  \n\nI have a few questions:  \n1. Is `go-tree-sitter` strictly required for Katana, or only for certain features?  \n2. Are there any alternative pure-Go libraries we could use instead of `go-tree-sitter` to simplify cross-platform builds?  \n\nThis would help in making snapshot builds and CI/CD pipelines simpler, without needing to configure CGO or cross-compilers.  \n\nThanks!\n\n---\n\n### Use Case\n\n- Simplifying cross-platform builds (Windows → macOS/ARM)  \n- Avoiding CGO-related compilation issues  \n- Maintaining full functionality while reducing dependency complexity",
                  "html_url": "https://github.com/projectdiscovery/katana/issues/1367"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/katana#1367",
              "body": "### Feature / Question: go-tree-sitter dependency\n\nHi team,  \n\nI noticed that the project currently uses `github.com/smacker/go-tree-sitter` for syntax tree parsing. Since `go-tree-sitter` relies on CGO, cross-platform compilation (especially for darwin/arm64) becomes complicated.  \n\nI have a few questions:  \n1. Is `go-tree-sitter` strictly required for Katana, or only for certain features?  \n2. Are there any alternative pure-Go libraries we could use instead of `go-tree-sitter` to simplify cross-platform builds?  \n\nThis would help in making snapshot builds and CI/CD pipelines simpler, without needing to configure CGO or cross-compilers.  \n\nThanks!\n\n---\n\n### Use Case\n\n- Simplifying cross-platform builds (Windows → macOS/ARM)  \n- Avoiding CGO-related compilation issues  \n- Maintaining full functionality while reducing dependency complexity",
              "url": "https://github.com/projectdiscovery/katana/issues/1367",
              "tech": [],
              "repo_name": "katana",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#2063",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-02-27T22:50:43.248Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:43.248Z",
            "created_at": "2026-02-27T22:50:43.248Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#2063",
              "status": "open",
              "type": "issue",
              "number": 2063,
              "title": "Add PDF export option",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#2063",
                  "user": {
                    "login": "forgedhallpass",
                    "id": 13679401,
                    "node_id": "MDQ6VXNlcjEzNjc5NDAx",
                    "avatar_url": "https://avatars.githubusercontent.com/u/13679401?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/forgedhallpass",
                    "html_url": "https://github.com/forgedhallpass",
                    "followers_url": "https://api.github.com/users/forgedhallpass/followers",
                    "following_url": "https://api.github.com/users/forgedhallpass/following{/other_user}",
                    "gists_url": "https://api.github.com/users/forgedhallpass/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/forgedhallpass/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/forgedhallpass/subscriptions",
                    "organizations_url": "https://api.github.com/users/forgedhallpass/orgs",
                    "repos_url": "https://api.github.com/users/forgedhallpass/repos",
                    "events_url": "https://api.github.com/users/forgedhallpass/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/forgedhallpass/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add PDF export option",
                  "body": "https://github.com/projectdiscovery/katana/pull/1556 https://github.com/projectdiscovery/katana/pull/1510 https://github.com/projectdiscovery/katana/pull/1521 https://github.com/projectdiscovery/katan",
                  "html_url": "https://github.com/projectdiscovery/nuclei/issues/2063"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei#2063",
              "body": "https://github.com/projectdiscovery/katana/pull/1556 https://github.com/projectdiscovery/katana/pull/1510 https://github.com/projectdiscovery/katana/pull/1521 https://github.com/projectdiscovery/katan",
              "url": "https://github.com/projectdiscovery/nuclei/issues/2063",
              "tech": [],
              "repo_name": "nuclei",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#5838",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-02-27T22:50:43.350Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:43.350Z",
            "created_at": "2026-02-27T22:50:43.350Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#5838",
              "status": "open",
              "type": "issue",
              "number": 5838,
              "title": "XSS Context Analyzer",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#5838",
                  "user": {
                    "login": "ehsandeep",
                    "id": 8293321,
                    "node_id": "MDQ6VXNlcjgyOTMzMjE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/8293321?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ehsandeep",
                    "html_url": "https://github.com/ehsandeep",
                    "followers_url": "https://api.github.com/users/ehsandeep/followers",
                    "following_url": "https://api.github.com/users/ehsandeep/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ehsandeep/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ehsandeep/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ehsandeep/subscriptions",
                    "organizations_url": "https://api.github.com/users/ehsandeep/orgs",
                    "repos_url": "https://api.github.com/users/ehsandeep/repos",
                    "events_url": "https://api.github.com/users/ehsandeep/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ehsandeep/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "XSS Context Analyzer",
                  "body": "https://github.com/projectdiscovery/nuclei/issues/2063 https://github.com/projectdiscovery/nuclei/pull/6806 https://github.com/projectdiscovery/nuclei/pull/6807 https://github.com/projectdiscovery/nuc",
                  "html_url": "https://github.com/projectdiscovery/nuclei/issues/5838"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei#5838",
              "body": "https://github.com/projectdiscovery/nuclei/issues/2063 https://github.com/projectdiscovery/nuclei/pull/6806 https://github.com/projectdiscovery/nuclei/pull/6807 https://github.com/projectdiscovery/nuc",
              "url": "https://github.com/projectdiscovery/nuclei/issues/5838",
              "tech": [],
              "repo_name": "nuclei",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#1367",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-02-27T22:50:43.354Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:43.354Z",
            "created_at": "2026-02-27T22:50:43.354Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#1367",
              "status": "open",
              "type": "issue",
              "number": 1367,
              "title": "Feature / Question: go-tree-sitter dependency",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#1367",
                  "user": {
                    "login": "aautumn725",
                    "id": 220215965,
                    "node_id": "U_kgDODSA6nQ",
                    "avatar_url": "https://avatars.githubusercontent.com/u/220215965?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/aautumn725",
                    "html_url": "https://github.com/aautumn725",
                    "followers_url": "https://api.github.com/users/aautumn725/followers",
                    "following_url": "https://api.github.com/users/aautumn725/following{/other_user}",
                    "gists_url": "https://api.github.com/users/aautumn725/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/aautumn725/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/aautumn725/subscriptions",
                    "organizations_url": "https://api.github.com/users/aautumn725/orgs",
                    "repos_url": "https://api.github.com/users/aautumn725/repos",
                    "events_url": "https://api.github.com/users/aautumn725/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/aautumn725/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Feature / Question: go-tree-sitter dependency",
                  "body": "### Feature / Question: go-tree-sitter dependency\n\nHi team,  \n\nI noticed that the project currently uses `github.com/smacker/go-tree-sitter` for syntax tree parsing. Since `go-tree-sitter` relies on CGO, cross-platform compilation (especially for darwin/arm64) becomes complicated.  \n\nI have a few questions:  \n1. Is `go-tree-sitter` strictly required for Katana, or only for certain features?  \n2. Are there any alternative pure-Go libraries we could use instead of `go-tree-sitter` to simplify cross-platform builds?  \n\nThis would help in making snapshot builds and CI/CD pipelines simpler, without needing to configure CGO or cross-compilers.  \n\nThanks!\n\n---\n\n### Use Case\n\n- Simplifying cross-platform builds (Windows → macOS/ARM)  \n- Avoiding CGO-related compilation issues  \n- Maintaining full functionality while reducing dependency complexity",
                  "html_url": "https://github.com/projectdiscovery/katana/issues/1367"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/katana#1367",
              "body": "### Feature / Question: go-tree-sitter dependency\n\nHi team,  \n\nI noticed that the project currently uses `github.com/smacker/go-tree-sitter` for syntax tree parsing. Since `go-tree-sitter` relies on CGO, cross-platform compilation (especially for darwin/arm64) becomes complicated.  \n\nI have a few questions:  \n1. Is `go-tree-sitter` strictly required for Katana, or only for certain features?  \n2. Are there any alternative pure-Go libraries we could use instead of `go-tree-sitter` to simplify cross-platform builds?  \n\nThis would help in making snapshot builds and CI/CD pipelines simpler, without needing to configure CGO or cross-compilers.  \n\nThanks!\n\n---\n\n### Use Case\n\n- Simplifying cross-platform builds (Windows → macOS/ARM)  \n- Avoiding CGO-related compilation issues  \n- Maintaining full functionality while reducing dependency complexity",
              "url": "https://github.com/projectdiscovery/katana/issues/1367",
              "tech": [],
              "repo_name": "katana",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#5567",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-02-27T22:50:43.447Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:43.447Z",
            "created_at": "2026-02-27T22:50:43.447Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#5567",
              "status": "open",
              "type": "issue",
              "number": 5567,
              "title": "[FEATURE] Template Profile Improvements",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#5567",
                  "user": {
                    "login": "tarunKoyalwar",
                    "id": 45962551,
                    "node_id": "MDQ6VXNlcjQ1OTYyNTUx",
                    "avatar_url": "https://avatars.githubusercontent.com/u/45962551?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/tarunKoyalwar",
                    "html_url": "https://github.com/tarunKoyalwar",
                    "followers_url": "https://api.github.com/users/tarunKoyalwar/followers",
                    "following_url": "https://api.github.com/users/tarunKoyalwar/following{/other_user}",
                    "gists_url": "https://api.github.com/users/tarunKoyalwar/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/tarunKoyalwar/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/tarunKoyalwar/subscriptions",
                    "organizations_url": "https://api.github.com/users/tarunKoyalwar/orgs",
                    "repos_url": "https://api.github.com/users/tarunKoyalwar/repos",
                    "events_url": "https://api.github.com/users/tarunKoyalwar/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/tarunKoyalwar/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[FEATURE] Template Profile Improvements",
                  "body": "### Describe your feature request\n\n- template profiles or config.yaml file contains all flag config in yaml format which can be directly passed to nuclei instead of adding each flag , this way it is easy to maintain and scalable and shareable\r\n- this config file is merged with flags passed to nuclei with priority given to flags that way common / regularly used configs can be maintained and passed via config files\r\n- we should add below new features related to config or template profiles\r\n\r\n- [ ] ignore extra fields ( if we aren't already) that way info can be specified in fields like id , name , purpose yaml keys instead of commenting it out like we do in current template profiles\r\n- [ ] update goflags to allow embedding file content , this way instead of passing auth related data via a file we can embed it in goflags under `secrets` key and goflags can generate a temporary file to handle and pass it internally\n\n### Describe the use case of the feature\n\nthis will allow maintaining a single config file to be used with nuclei and users can maintain a different set of configs  specific to targets thereby keeping all config modular\r\n\r\nexample: a user who intends to vuln scan pd will have their template profile for this scan in this format\r\n\r\n```yaml\r\nname: projectdiscovery-scan\r\npurpose: Config File for Scanning\r\ndescription: single config file that contains every config related to scanning a specific target with specific templates and features\r\n\r\n# targets list file\r\nlist |\r\n  cve.projectdiscovery.io\r\n  chaos.projectdiscovery.io\r\n  ....\r\n  api.projectdiscovery.io\r\n\r\n# templates related config\r\ntype:\r\n  - http\r\n  - tcp\r\n  - javascript\r\n  - dns\r\n  - ssl\r\n\r\nexclude-tags:\r\n  - dos\r\n  - fuzz\r\n  - osint\r\n\r\n# other options\r\ntemplate-concurrency: 5\r\nhost-concurrency: 100\r\nstats: true\r\ntimeout: 30\r\n\r\nsecrets:\r\n  static:\r\n  # 4. Custom Header based auth\r\n  - type: header\r\n    domains:\r\n      - api.projectdiscovery.io\r\n      - cve.projectdiscovery.io\r\n      - chaos.projectdiscovery.io\r\n    headers:\r\n      - key: x-pdcp-key\r\n        value: <api-key-here>\r\n  dynamic:\r\n    - template: custom-oauth-flow.yaml\r\n      variables:\r\n        - name: username\r\n          value: pdteam\r\n        - name: password\r\n          value: nuclei-fuzz\r\n      type: cookie\r\n      domains:\r\n        - .*.projectdiscovery.io\r\n      headers:\r\n        - key: Authorization\r\n          value: Bearer {{token}}\r\n```\n\n### Describe alternatives you've considered\n\n_No response_\n\n### Additional context\n\n_No response_",
                  "html_url": "https://github.com/projectdiscovery/nuclei/issues/5567"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei#5567",
              "body": "### Describe your feature request\n\n- template profiles or config.yaml file contains all flag config in yaml format which can be directly passed to nuclei instead of adding each flag , this way it is easy to maintain and scalable and shareable\r\n- this config file is merged with flags passed to nuclei with priority given to flags that way common / regularly used configs can be maintained and passed via config files\r\n- we should add below new features related to config or template profiles\r\n\r\n- [ ] ignore extra fields ( if we aren't already) that way info can be specified in fields like id , name , purpose yaml keys instead of commenting it out like we do in current template profiles\r\n- [ ] update goflags to allow embedding file content , this way instead of passing auth related data via a file we can embed it in goflags under `secrets` key and goflags can generate a temporary file to handle and pass it internally\n\n### Describe the use case of the feature\n\nthis will allow maintaining a single config file to be used with nuclei and users can maintain a different set of configs  specific to targets thereby keeping all config modular\r\n\r\nexample: a user who intends to vuln scan pd will have their template profile for this scan in this format\r\n\r\n```yaml\r\nname: projectdiscovery-scan\r\npurpose: Config File for Scanning\r\ndescription: single config file that contains every config related to scanning a specific target with specific templates and features\r\n\r\n# targets list file\r\nlist |\r\n  cve.projectdiscovery.io\r\n  chaos.projectdiscovery.io\r\n  ....\r\n  api.projectdiscovery.io\r\n\r\n# templates related config\r\ntype:\r\n  - http\r\n  - tcp\r\n  - javascript\r\n  - dns\r\n  - ssl\r\n\r\nexclude-tags:\r\n  - dos\r\n  - fuzz\r\n  - osint\r\n\r\n# other options\r\ntemplate-concurrency: 5\r\nhost-concurrency: 100\r\nstats: true\r\ntimeout: 30\r\n\r\nsecrets:\r\n  static:\r\n  # 4. Custom Header based auth\r\n  - type: header\r\n    domains:\r\n      - api.projectdiscovery.io\r\n      - cve.projectdiscovery.io\r\n      - chaos.projectdiscovery.io\r\n    headers:\r\n      - key: x-pdcp-key\r\n        value: <api-key-here>\r\n  dynamic:\r\n    - template: custom-oauth-flow.yaml\r\n      variables:\r\n        - name: username\r\n          value: pdteam\r\n        - name: password\r\n          value: nuclei-fuzz\r\n      type: cookie\r\n      domains:\r\n        - .*.projectdiscovery.io\r\n      headers:\r\n        - key: Authorization\r\n          value: Bearer {{token}}\r\n```\n\n### Describe alternatives you've considered\n\n_No response_\n\n### Additional context\n\n_No response_",
              "url": "https://github.com/projectdiscovery/nuclei/issues/5567",
              "tech": [],
              "repo_name": "nuclei",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#6403",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-02-27T22:50:43.557Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:43.557Z",
            "created_at": "2026-02-27T22:50:43.557Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#6403",
              "status": "open",
              "type": "issue",
              "number": 6403,
              "title": "[FEATURE] Add honeypot detection to nuclei",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#6403",
                  "user": {
                    "login": "Ice3man543",
                    "id": 22318055,
                    "node_id": "MDQ6VXNlcjIyMzE4MDU1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22318055?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Ice3man543",
                    "html_url": "https://github.com/Ice3man543",
                    "followers_url": "https://api.github.com/users/Ice3man543/followers",
                    "following_url": "https://api.github.com/users/Ice3man543/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Ice3man543/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Ice3man543/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Ice3man543/subscriptions",
                    "organizations_url": "https://api.github.com/users/Ice3man543/orgs",
                    "repos_url": "https://api.github.com/users/Ice3man543/repos",
                    "events_url": "https://api.github.com/users/Ice3man543/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Ice3man543/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[FEATURE] Add honeypot detection to nuclei",
                  "body": "### Describe your feature request\n\nMany hosts on shodan have all the matchers from nuclei in order to fool scanner (show each vuln as matching). we should have some sort of detection to match such scenarios and ignore their matches (at least inform user)\n\n\n### Describe the use case of the feature\n\nReduce noise while scanning\n\n### Describe alternatives you've considered\n\n_No response_\n\n### Additional context\n\n\n```html\n\n<!--\n--\n<Username Level=\"40/40\" Dispatch=\"account\">admin</Username><User1><Password Level=\"40/40\" Dispatch=\"account\">admin</Password></User1>\n/var/pinglog\n<TITLE>Login</TITLE>\n<a href=\"jpg.html\">LIVE JPEG</a><br>\n<a href=\"liveie.html\">Internet Monitor (Microsoft Internet Explorer 8, 9, 10, 11) </a><br>\n<a href=\"DVRRemoteAP.exe\">Download 32 bits DVR Client (Windows 7, Windows 8, Windows 10)</a><br>\n<a href=\"DVRRemoteAP_X64.exe\">Download 64 bits DVR Client (Windows 7, Windows 8, Windows 10)</a><br>\n<a href=\"DVFPlayer.zip\">Download 32/64 bits File Player (Windows 7, Windows 8, Windows 10)</a><br>\n<\\?xml version=\"1.0\" encoding=\"utf-8\"?><base64Binary xmlns=\"http://micros-hosting.com/EGateway/\">\nLocation: /admin\n<meta name=\"generator\" content=\"vBulletin 5.5.4\" />\nLocation: http://120.26.237.211:80/relogin.htm?_t=3541144909\nLocation: http://120.26.237.211:80/syscmd.htm\"\nLocation: /ui/login\n/cgi-bin/webctrl.cgi?action=index_page\nPDR-M800\nfunction btnPing()\n<HTML><HEAD><TITLE>302 Moved</TITLE></HEAD><BODY><H1>302 Moved</H1>.The document has moved<A HREF=\"http://120.26.237.211:80/relogin.htm?_t=179439949\">here</A></BODY></HTML>\n<link type=\"image/x-icon\" rel=\"shortcut icon\" href=\"/themes/img/icon/cisco_shortcut.png\">\n<link type=\"image/x-icon\" rel=\"shortcut icon\" href=\"/themes/img/icon/cisco_logo.png\">\n<td class=\"Copyright\" colspan=\"2\" style=\"text-align:justify\" height=\"20\" valign=\"bottom\">© 2017 Cisco Systems, Inc. All Rights Reserved.\n<br>Cisco, Cisco Systems, and the Cisco Systems logo are registered\ntrademarks or trademarks of Cisco Systems, Inc. and/or it's affiliates\nin the United States and certain other countries.\n</td>\n:\n#\n>\n$\nSSH key is good\nis not a valid ref and may not be archived\npcPassword2\n'&sessionKey=790148060;'\nname=\"sessionKey\" value=\"790148060\"\nSet-Cookie: loginName=admin\nvar fgt_lang = /dev/cmdb/sslvpn_websession\nphp 8.1.0-dev exit\nspringframework\nTomcat\nDEVICE.ACCOUNT=admin\nAUTHORIZED_GROUP=1\n<uid></uid>\n<name>Admin</name>\n<usrid></usrid>\n<password>admin</password>\n<group></group>\ncpto /tmp/\"root\"\nModel=AC1450\nFirmware=V1.0.0.36_10.0.17\n\"exceptionMessageValue\":\"javax.servlet.ServletException: No valid forensics analysis solrDocIds parameter found.\"\nBIG-IP release 15.0.0\nuser:root\n12345admin123'\nFailed to process image\n \nLocation: http://192.168.0.1:52869/picsdesc.xml\nYou don't have permission to access /vpns/ on this server.\n[global]\nworkgroup = intranet\nencrypt passwords = Yes\nupdate encrypted = Yes\n \nfuncionando\nsystem_sofia\nname resolve order\nInfoOS:Linux node01 uid=0(root) gid=0(root) groups=0(root)OSInfo\n<b>File Uploaded !!!</b><br>\nant=951d11e51392117311602d0c25435d7f\n38ee63071a04dc5e04ed22624c38e648\n6f3249aa304055d63828af3bfab778f6\n<h1> a8748198bf4c454b078f069b109f91af </h1>\n[local]\ntid = OGRjYjc0YTY0ZGM5ODRmYjlhYmUzZTdjMjAxZjgxMGQ5ZWM5MGVkOGU0Y2E3M2M2M2ZiNDliZTFmYmMyM2IwZDIxPT0=\naddr = 120.26.237.211\n\"Powered by vBulletin Version 5.5.4\"\n789551\nLinear eMerge\nSuperSign\nubiq\nYacht\nZeroshell\nFastWeb\nAuthInfo:\nloadingIndicator_bk\nZyxel\nskyrouter\nWAP54\norg.apache.spark.ui\n \nCVE-2024-50379-CONFIRMED HTTP/1.1\nHost: 120.26.237.211:12577\nSec-Ch-Ua-Mobile:\nRESULT=0\n \n\n<br class=\"Apple-interchange-newline\">\n```",
                  "html_url": "https://github.com/projectdiscovery/nuclei/issues/6403"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei#6403",
              "body": "### Describe your feature request\n\nMany hosts on shodan have all the matchers from nuclei in order to fool scanner (show each vuln as matching). we should have some sort of detection to match such scenarios and ignore their matches (at least inform user)\n\n\n### Describe the use case of the feature\n\nReduce noise while scanning\n\n### Describe alternatives you've considered\n\n_No response_\n\n### Additional context\n\n\n```html\n\n<!--\n--\n<Username Level=\"40/40\" Dispatch=\"account\">admin</Username><User1><Password Level=\"40/40\" Dispatch=\"account\">admin</Password></User1>\n/var/pinglog\n<TITLE>Login</TITLE>\n<a href=\"jpg.html\">LIVE JPEG</a><br>\n<a href=\"liveie.html\">Internet Monitor (Microsoft Internet Explorer 8, 9, 10, 11) </a><br>\n<a href=\"DVRRemoteAP.exe\">Download 32 bits DVR Client (Windows 7, Windows 8, Windows 10)</a><br>\n<a href=\"DVRRemoteAP_X64.exe\">Download 64 bits DVR Client (Windows 7, Windows 8, Windows 10)</a><br>\n<a href=\"DVFPlayer.zip\">Download 32/64 bits File Player (Windows 7, Windows 8, Windows 10)</a><br>\n<\\?xml version=\"1.0\" encoding=\"utf-8\"?><base64Binary xmlns=\"http://micros-hosting.com/EGateway/\">\nLocation: /admin\n<meta name=\"generator\" content=\"vBulletin 5.5.4\" />\nLocation: http://120.26.237.211:80/relogin.htm?_t=3541144909\nLocation: http://120.26.237.211:80/syscmd.htm\"\nLocation: /ui/login\n/cgi-bin/webctrl.cgi?action=index_page\nPDR-M800\nfunction btnPing()\n<HTML><HEAD><TITLE>302 Moved</TITLE></HEAD><BODY><H1>302 Moved</H1>.The document has moved<A HREF=\"http://120.26.237.211:80/relogin.htm?_t=179439949\">here</A></BODY></HTML>\n<link type=\"image/x-icon\" rel=\"shortcut icon\" href=\"/themes/img/icon/cisco_shortcut.png\">\n<link type=\"image/x-icon\" rel=\"shortcut icon\" href=\"/themes/img/icon/cisco_logo.png\">\n<td class=\"Copyright\" colspan=\"2\" style=\"text-align:justify\" height=\"20\" valign=\"bottom\">© 2017 Cisco Systems, Inc. All Rights Reserved.\n<br>Cisco, Cisco Systems, and the Cisco Systems logo are registered\ntrademarks or trademarks of Cisco Systems, Inc. and/or it's affiliates\nin the United States and certain other countries.\n</td>\n:\n#\n>\n$\nSSH key is good\nis not a valid ref and may not be archived\npcPassword2\n'&sessionKey=790148060;'\nname=\"sessionKey\" value=\"790148060\"\nSet-Cookie: loginName=admin\nvar fgt_lang = /dev/cmdb/sslvpn_websession\nphp 8.1.0-dev exit\nspringframework\nTomcat\nDEVICE.ACCOUNT=admin\nAUTHORIZED_GROUP=1\n<uid></uid>\n<name>Admin</name>\n<usrid></usrid>\n<password>admin</password>\n<group></group>\ncpto /tmp/\"root\"\nModel=AC1450\nFirmware=V1.0.0.36_10.0.17\n\"exceptionMessageValue\":\"javax.servlet.ServletException: No valid forensics analysis solrDocIds parameter found.\"\nBIG-IP release 15.0.0\nuser:root\n12345admin123'\nFailed to process image\n \nLocation: http://192.168.0.1:52869/picsdesc.xml\nYou don't have permission to access /vpns/ on this server.\n[global]\nworkgroup = intranet\nencrypt passwords = Yes\nupdate encrypted = Yes\n \nfuncionando\nsystem_sofia\nname resolve order\nInfoOS:Linux node01 uid=0(root) gid=0(root) groups=0(root)OSInfo\n<b>File Uploaded !!!</b><br>\nant=951d11e51392117311602d0c25435d7f\n38ee63071a04dc5e04ed22624c38e648\n6f3249aa304055d63828af3bfab778f6\n<h1> a8748198bf4c454b078f069b109f91af </h1>\n[local]\ntid = OGRjYjc0YTY0ZGM5ODRmYjlhYmUzZTdjMjAxZjgxMGQ5ZWM5MGVkOGU0Y2E3M2M2M2ZiNDliZTFmYmMyM2IwZDIxPT0=\naddr = 120.26.237.211\n\"Powered by vBulletin Version 5.5.4\"\n789551\nLinear eMerge\nSuperSign\nubiq\nYacht\nZeroshell\nFastWeb\nAuthInfo:\nloadingIndicator_bk\nZyxel\nskyrouter\nWAP54\norg.apache.spark.ui\n \nCVE-2024-50379-CONFIRMED HTTP/1.1\nHost: 120.26.237.211:12577\nSec-Ch-Ua-Mobile:\nRESULT=0\n \n\n<br class=\"Apple-interchange-newline\">\n```",
              "url": "https://github.com/projectdiscovery/nuclei/issues/6403",
              "tech": [],
              "repo_name": "nuclei",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#924",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-02-27T22:50:43.692Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:43.692Z",
            "created_at": "2026-02-27T22:50:43.692Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#924",
              "status": "open",
              "type": "issue",
              "number": 924,
              "title": "Support auto wildcard detection similar to PureDNS",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#924",
                  "user": {
                    "login": "xhzeem",
                    "id": 34074156,
                    "node_id": "MDQ6VXNlcjM0MDc0MTU2",
                    "avatar_url": "https://avatars.githubusercontent.com/u/34074156?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/xhzeem",
                    "html_url": "https://github.com/xhzeem",
                    "followers_url": "https://api.github.com/users/xhzeem/followers",
                    "following_url": "https://api.github.com/users/xhzeem/following{/other_user}",
                    "gists_url": "https://api.github.com/users/xhzeem/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/xhzeem/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/xhzeem/subscriptions",
                    "organizations_url": "https://api.github.com/users/xhzeem/orgs",
                    "repos_url": "https://api.github.com/users/xhzeem/repos",
                    "events_url": "https://api.github.com/users/xhzeem/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/xhzeem/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Support auto wildcard detection similar to PureDNS",
                  "body": "Hi,\n\nCould you add an **auto wildcard discovery** feature similar to what `puredns` does?\n\nWhat I’m looking for:\n\n* Ability to detect wildcard DNS automatically across **multiple domains** in a single run (no need to specify `-wd` per domain).\n* Filter out wildcard-based results automatically.\n* Expose this via a simple flag, e.g. `--auto-wildcard` (or similar), so existing behaviour doesn’t change.\n\nIdea is basically:\n`puredns` handles wildcard detection automatically can you implement a similar optional mode/flag in `dnsx`?\n\nThanks!\n",
                  "html_url": "https://github.com/projectdiscovery/dnsx/issues/924"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/dnsx#924",
              "body": "Hi,\n\nCould you add an **auto wildcard discovery** feature similar to what `puredns` does?\n\nWhat I’m looking for:\n\n* Ability to detect wildcard DNS automatically across **multiple domains** in a single run (no need to specify `-wd` per domain).\n* Filter out wildcard-based results automatically.\n* Expose this via a simple flag, e.g. `--auto-wildcard` (or similar), so existing behaviour doesn’t change.\n\nIdea is basically:\n`puredns` handles wildcard detection automatically can you implement a similar optional mode/flag in `dnsx`?\n\nThanks!\n",
              "url": "https://github.com/projectdiscovery/dnsx/issues/924",
              "tech": [],
              "repo_name": "dnsx",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#819",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2026-02-27T22:50:43.696Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-02-27T22:50:43.696Z",
            "created_at": "2026-02-27T22:50:43.696Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#819",
              "status": "open",
              "type": "issue",
              "number": 819,
              "title": "tlsx hangs indefinitely for some hosts",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#819",
                  "user": {
                    "login": "msecrfe",
                    "id": 179370796,
                    "node_id": "U_kgDOCrD7LA",
                    "avatar_url": "https://avatars.githubusercontent.com/u/179370796?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/msecrfe",
                    "html_url": "https://github.com/msecrfe",
                    "followers_url": "https://api.github.com/users/msecrfe/followers",
                    "following_url": "https://api.github.com/users/msecrfe/following{/other_user}",
                    "gists_url": "https://api.github.com/users/msecrfe/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/msecrfe/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/msecrfe/subscriptions",
                    "organizations_url": "https://api.github.com/users/msecrfe/orgs",
                    "repos_url": "https://api.github.com/users/msecrfe/repos",
                    "events_url": "https://api.github.com/users/msecrfe/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/msecrfe/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "tlsx hangs indefinitely for some hosts",
                  "body": "### tlsx version:\nv1.1.9\n\n### Current Behavior:\nFor long target lists (in our case: Around 30k host/port combinations), tlsx reliably hangs indefinitely after several hours of execution, usually after around 25k targets have finished. Hanging happens even while writing JSONL output lines, cutting off a JSONL line somewhere in the middle.\n\n### Expected Behavior:\ntlsx should not hang indefinitely.\n\n### Steps To Reproduce:\ntlsx was started as follows:\n\n```\n~/go/bin/tlsx \\\n\t-list /tmp/host_port_combos.txt \\\n\t-scan-mode 'auto' \\\n\t-ip-version '4' \\\n\t-so \\\n\t-tls-version \\\n\t-cipher \\\n\t-hash 'sha256' \\\n\t-wildcard-cert \\\n\t-probe-status \\\n\t-version-enum \\\n\t-cipher-enum \\\n\t-cipher-type 'all' \\\n\t-serial \\\n\t-expired \\\n\t-self-signed \\\n\t-mismatched \\\n\t-revoked \\\n\t-untrusted \\\n\t-resolvers 8.8.8.8,8.8.4.4,1.1.1.1 \\\n\t-certificate \\\n\t-tls-chain \\\n\t-concurrency '300' \\\n\t-cipher-concurrency '10' \\\n\t-timeout '5' \\\n\t-retry '3' \\\n\t-disable-update-check \\\n\t-output /tmp/tlsx_output.jsonl \\\n\t-json \\\n\t-no-color\n```\n\nAt one point, there is no more progress and even output is no longer written. This is the last line of the output file (`/tmp/tlsx_output.jsonl`):\n\n```\n{\"timestamp\":\"2025-04-25T09:59:31.489674682Z\",\"host\":\"xn--<censored>-t6b.<censored>\",\"ip\":\"<censored>\",\"port\":\"443\",\"probe_status\":true,\"tls_version\":\"tls13\",\"cipher\":\"TLS_AES_128_GCM_SHA256\",\"self_signed\":true,\"mismatched\":true,\"not_before\":\"2017-01-16T16:04:01Z\",\"not_after\":\"2027-01-14T16:04:01Z\",\"subject_dn\":\"emailAddress=root@localhost.localdomain, CN=localhost.localdomain, OU=IT, O=MyCompany, L=Seattle, ST=WA, C=US, emailAddress=root@localhost.localdomain\",\"subject_cn\":\n```\nPlease note that the line ends with an open \"subject_cn\" key and the JSON object on that line is never closed. The aforementioned line is line 25737 of the output file, so more than 25k targets have been scanned before.\n\n### Anything else:\nThe issue always appears after a long time of execution. Execution of tlsx for the aforementioned approx. 30k targets (aborted/hanging after about 25k targets) started at `2025-04-24T16:50:47+00:00` and the process started hanging at `2025-04-25T10:47:39+0000`, so about 18 hours later.\n\nThe issue does not seem to depend on the specific target host, as tlsx correctly terminates when only scanning the target host. Also, it always starts hanging indefinitely for a different target, but always after having run for hours and after having already scanned several thousand targets,",
                  "html_url": "https://github.com/projectdiscovery/tlsx/issues/819"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/tlsx#819",
              "body": "### tlsx version:\nv1.1.9\n\n### Current Behavior:\nFor long target lists (in our case: Around 30k host/port combinations), tlsx reliably hangs indefinitely after several hours of execution, usually after around 25k targets have finished. Hanging happens even while writing JSONL output lines, cutting off a JSONL line somewhere in the middle.\n\n### Expected Behavior:\ntlsx should not hang indefinitely.\n\n### Steps To Reproduce:\ntlsx was started as follows:\n\n```\n~/go/bin/tlsx \\\n\t-list /tmp/host_port_combos.txt \\\n\t-scan-mode 'auto' \\\n\t-ip-version '4' \\\n\t-so \\\n\t-tls-version \\\n\t-cipher \\\n\t-hash 'sha256' \\\n\t-wildcard-cert \\\n\t-probe-status \\\n\t-version-enum \\\n\t-cipher-enum \\\n\t-cipher-type 'all' \\\n\t-serial \\\n\t-expired \\\n\t-self-signed \\\n\t-mismatched \\\n\t-revoked \\\n\t-untrusted \\\n\t-resolvers 8.8.8.8,8.8.4.4,1.1.1.1 \\\n\t-certificate \\\n\t-tls-chain \\\n\t-concurrency '300' \\\n\t-cipher-concurrency '10' \\\n\t-timeout '5' \\\n\t-retry '3' \\\n\t-disable-update-check \\\n\t-output /tmp/tlsx_output.jsonl \\\n\t-json \\\n\t-no-color\n```\n\nAt one point, there is no more progress and even output is no longer written. This is the last line of the output file (`/tmp/tlsx_output.jsonl`):\n\n```\n{\"timestamp\":\"2025-04-25T09:59:31.489674682Z\",\"host\":\"xn--<censored>-t6b.<censored>\",\"ip\":\"<censored>\",\"port\":\"443\",\"probe_status\":true,\"tls_version\":\"tls13\",\"cipher\":\"TLS_AES_128_GCM_SHA256\",\"self_signed\":true,\"mismatched\":true,\"not_before\":\"2017-01-16T16:04:01Z\",\"not_after\":\"2027-01-14T16:04:01Z\",\"subject_dn\":\"emailAddress=root@localhost.localdomain, CN=localhost.localdomain, OU=IT, O=MyCompany, L=Seattle, ST=WA, C=US, emailAddress=root@localhost.localdomain\",\"subject_cn\":\n```\nPlease note that the line ends with an open \"subject_cn\" key and the JSON object on that line is never closed. The aforementioned line is line 25737 of the output file, so more than 25k targets have been scanned before.\n\n### Anything else:\nThe issue always appears after a long time of execution. Execution of tlsx for the aforementioned approx. 30k targets (aborted/hanging after about 25k targets) started at `2025-04-24T16:50:47+00:00` and the process started hanging at `2025-04-25T10:47:39+0000`, so about 18 hours later.\n\nThe issue does not seem to depend on the specific target host, as tlsx correctly terminates when only scanning the target host. Also, it always starts hanging indefinitely for a different target, but always after having run for hours and after having already scanned several thousand targets,",
              "url": "https://github.com/projectdiscovery/tlsx/issues/819",
              "tech": [],
              "repo_name": "tlsx",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          }
        ],
        "next_cursor": null
      }
    }
  }
}