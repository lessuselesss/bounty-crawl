{
  "result": {
    "data": {
      "json": {
        "items": [
          {
            "id": "outerbase#59",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2025-11-24T19:50:41.556Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:41.556Z",
            "created_at": "2025-11-24T19:50:41.556Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#59",
              "status": "open",
              "type": "issue",
              "number": 59,
              "title": "Database dumps do not work on large databases",
              "source": {
                "data": {
                  "id": "source-outerbase#59",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Database dumps do not work on large databases",
                  "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/59"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#59",
              "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
              "url": "https://github.com/outerbase/starbasedb/issues/59",
              "tech": [
                "go"
              ],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "outerbase#72",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2025-11-24T19:50:42.100Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:42.100Z",
            "created_at": "2025-11-24T19:50:42.100Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#72",
              "status": "open",
              "type": "issue",
              "number": 72,
              "title": "Replicate data from external source to internal source with a Plugin",
              "source": {
                "data": {
                  "id": "source-outerbase#72",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Replicate data from external source to internal source with a Plugin",
                  "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/72"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#72",
              "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
              "url": "https://github.com/outerbase/starbasedb/issues/72",
              "tech": [],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#1911",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2025-11-24T19:50:42.765Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:42.765Z",
            "created_at": "2025-11-24T19:50:42.765Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#1911",
              "status": "open",
              "type": "issue",
              "number": 1911,
              "title": "Warn on mismatch between global `prisma` and local `prisma` or `@prisma/client`",
              "source": {
                "data": {
                  "id": "source-prisma#1911",
                  "user": {
                    "login": "janpio",
                    "id": 183673,
                    "node_id": "MDQ6VXNlcjE4MzY3Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/183673?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/janpio",
                    "html_url": "https://github.com/janpio",
                    "followers_url": "https://api.github.com/users/janpio/followers",
                    "following_url": "https://api.github.com/users/janpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/janpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/janpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/janpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/janpio/orgs",
                    "repos_url": "https://api.github.com/users/janpio/repos",
                    "events_url": "https://api.github.com/users/janpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/janpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Warn on mismatch between global `prisma` and local `prisma` or `@prisma/client`",
                  "body": "Using a global `prisma generate` with a different local `prisma` or `@prisma/client` might lead to problems. It might be a good idea to warn users if they are doing that and ask for explicit confirmation.",
                  "html_url": "https://github.com/prisma/prisma/issues/1911"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#1911",
              "body": "Using a global `prisma generate` with a different local `prisma` or `@prisma/client` might lead to problems. It might be a good idea to warn users if they are doing that and ask for explicit confirmation.",
              "url": "https://github.com/prisma/prisma/issues/1911",
              "tech": [
                "go"
              ],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#8548",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2025-11-24T19:50:42.991Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:42.991Z",
            "created_at": "2025-11-24T19:50:42.991Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#8548",
              "status": "open",
              "type": "issue",
              "number": 8548,
              "title": "`prisma format` ends the file with a single CRLF on windows",
              "source": {
                "data": {
                  "id": "source-prisma#8548",
                  "user": {
                    "login": "binary64",
                    "id": 1680627,
                    "node_id": "MDQ6VXNlcjE2ODA2Mjc=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1680627?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/binary64",
                    "html_url": "https://github.com/binary64",
                    "followers_url": "https://api.github.com/users/binary64/followers",
                    "following_url": "https://api.github.com/users/binary64/following{/other_user}",
                    "gists_url": "https://api.github.com/users/binary64/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/binary64/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/binary64/subscriptions",
                    "organizations_url": "https://api.github.com/users/binary64/orgs",
                    "repos_url": "https://api.github.com/users/binary64/repos",
                    "events_url": "https://api.github.com/users/binary64/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/binary64/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "`prisma format` ends the file with a single CRLF on windows",
                  "body": "### Bug description\n\nOn windows, I run `prisma format` and note the unusual file ending. The lines are all LF, but the very last line is CRLF.\r\n\r\nThis causes issue on my Linux CI where it formats it ending in LF's only, causing a diff to occur and the build to fail.\n\n### How to reproduce\n\n1. On windows do prisma format\r\n2. Open in HxD or similar\r\n3. See attached:\r\n \r\n![image](https://user-images.githubusercontent.com/1680627/127931864-fcd66391-9b31-4914-8553-f6c71b3a6fad.png)\r\n\n\n### Expected behavior\n\nLF's only - no CR's to exist at all\n\n### Prisma information\n\n<!-- Do not include your database credentials when sharing your Prisma schema! -->\r\n\n\n### Environment & setup\n\nNode 16\r\nWindows/Linux\n\n### Prisma Version\n\n```\r\n$ C:\\p\\pab\\monorepo\\node_modules\\.bin\\prisma -v\r\nprisma               : 2.26.0\r\n@prisma/client       : 2.28.0\r\nCurrent platform     : windows\r\nQuery Engine         : query-engine 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\query-engine-windows.exe)\r\nMigration Engine     : migration-engine-cli 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\migration-engine-windows.exe)\r\nIntrospection Engine : introspection-core 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\introspection-engine-windows.exe)\r\nFormat Binary        : prisma-fmt 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\prisma-fmt-windows.exe)\r\nDefault Engines Hash : 9b816b3aa13cc270074f172f30d6eda8a8ce867d\r\nStudio               : 0.408.0\r\n```",
                  "html_url": "https://github.com/prisma/prisma/issues/8548"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#8548",
              "body": "### Bug description\n\nOn windows, I run `prisma format` and note the unusual file ending. The lines are all LF, but the very last line is CRLF.\r\n\r\nThis causes issue on my Linux CI where it formats it ending in LF's only, causing a diff to occur and the build to fail.\n\n### How to reproduce\n\n1. On windows do prisma format\r\n2. Open in HxD or similar\r\n3. See attached:\r\n \r\n![image](https://user-images.githubusercontent.com/1680627/127931864-fcd66391-9b31-4914-8553-f6c71b3a6fad.png)\r\n\n\n### Expected behavior\n\nLF's only - no CR's to exist at all\n\n### Prisma information\n\n<!-- Do not include your database credentials when sharing your Prisma schema! -->\r\n\n\n### Environment & setup\n\nNode 16\r\nWindows/Linux\n\n### Prisma Version\n\n```\r\n$ C:\\p\\pab\\monorepo\\node_modules\\.bin\\prisma -v\r\nprisma               : 2.26.0\r\n@prisma/client       : 2.28.0\r\nCurrent platform     : windows\r\nQuery Engine         : query-engine 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\query-engine-windows.exe)\r\nMigration Engine     : migration-engine-cli 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\migration-engine-windows.exe)\r\nIntrospection Engine : introspection-core 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\introspection-engine-windows.exe)\r\nFormat Binary        : prisma-fmt 9b816b3aa13cc270074f172f30d6eda8a8ce867d (at node_modules\\@prisma\\engines\\prisma-fmt-windows.exe)\r\nDefault Engines Hash : 9b816b3aa13cc270074f172f30d6eda8a8ce867d\r\nStudio               : 0.408.0\r\n```",
              "url": "https://github.com/prisma/prisma/issues/8548",
              "tech": [],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "prisma#7771",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "prisma",
              "id": "generated-prisma",
              "name": "Prisma",
              "description": "",
              "members": [],
              "display_name": "Prisma",
              "created_at": "2025-11-24T19:50:43.183Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/prisma?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "prisma",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:43.183Z",
            "created_at": "2025-11-24T19:50:43.183Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-prisma#7771",
              "status": "open",
              "type": "issue",
              "number": 7771,
              "title": "Output path of current Prisma in `-v` ",
              "source": {
                "data": {
                  "id": "source-prisma#7771",
                  "user": {
                    "login": "janpio",
                    "id": 183673,
                    "node_id": "MDQ6VXNlcjE4MzY3Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/183673?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/janpio",
                    "html_url": "https://github.com/janpio",
                    "followers_url": "https://api.github.com/users/janpio/followers",
                    "following_url": "https://api.github.com/users/janpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/janpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/janpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/janpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/janpio/orgs",
                    "repos_url": "https://api.github.com/users/janpio/repos",
                    "events_url": "https://api.github.com/users/janpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/janpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Output path of current Prisma in `-v` ",
                  "body": "## Problem\r\n\r\nThis is a situation that can happen:\r\n```\r\n--- yarn prisma -v ---\r\nwarning package.json: No license field\r\nprisma               : 2.26.0-dev.7\r\n@prisma/client       : 2.26.0-dev.7\r\nCurrent platform     : debian-openssl-1.1.x\r\nQuery Engine         : query-engine c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/query-engine-debian-openssl-1.1.x)\r\nMigration Engine     : migration-engine-cli c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/migration-engine-debian-openssl-1.1.x)\r\nIntrospection Engine : introspection-core c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/introspection-engine-debian-openssl-1.1.x)\r\nFormat Binary        : prisma-fmt c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/prisma-fmt-debian-openssl-1.1.x)\r\nDefault Engines Hash : c838e79f39885bc8e1611849b1eb28b5bb5bc922\r\nStudio               : 0.402.0\r\n--- ls node_modules/@prisma/engines/ ---\r\nls: cannot access 'node_modules/@prisma/engines/': No such file or directory\r\n```\r\n\r\nAs you can see `yarn prisma -v` tells us the engines comes from `node_modules/@prisma/engines`, but when you try to list that directory, it is actually not present.\r\n\r\nWhat is happening here is that `yarn prisma` is actually from a few folders _above_ our project. This is kinda visible when you look to not run `yarn -s` but just `yarn`:\r\n```\r\ncodespace ➜ /workspaces/e2e-tests/platforms-serverless/firebase-functions (janpio-patch-5 ✗) $ yarn prisma -v\r\nyarn run v1.22.10\r\nwarning package.json: No license field\r\n$ /workspaces/e2e-tests/node_modules/.bin/prisma -v\r\nprisma               : 2.25.0-dev.36\r\n@prisma/client       : 2.25.0-dev.36\r\n...\r\n```\r\n\r\n## Suggested solution\r\n\r\nOutput the directory of where the executed `prisma` is from, either similar to Yarn the absolute path to the binary in `node_modules`, or the folder where the `package.json` that is responsible for the installation of Prisma comes from.\r\n\r\n## Alternatives\r\n\r\nRely on `yarn` itself to give that information. Will not work with `npx` unfortunately for example.",
                  "html_url": "https://github.com/prisma/prisma/issues/7771"
                },
                "type": "github"
              },
              "hash": "prisma/prisma#7771",
              "body": "## Problem\r\n\r\nThis is a situation that can happen:\r\n```\r\n--- yarn prisma -v ---\r\nwarning package.json: No license field\r\nprisma               : 2.26.0-dev.7\r\n@prisma/client       : 2.26.0-dev.7\r\nCurrent platform     : debian-openssl-1.1.x\r\nQuery Engine         : query-engine c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/query-engine-debian-openssl-1.1.x)\r\nMigration Engine     : migration-engine-cli c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/migration-engine-debian-openssl-1.1.x)\r\nIntrospection Engine : introspection-core c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/introspection-engine-debian-openssl-1.1.x)\r\nFormat Binary        : prisma-fmt c838e79f39885bc8e1611849b1eb28b5bb5bc922 (at node_modules/@prisma/engines/prisma-fmt-debian-openssl-1.1.x)\r\nDefault Engines Hash : c838e79f39885bc8e1611849b1eb28b5bb5bc922\r\nStudio               : 0.402.0\r\n--- ls node_modules/@prisma/engines/ ---\r\nls: cannot access 'node_modules/@prisma/engines/': No such file or directory\r\n```\r\n\r\nAs you can see `yarn prisma -v` tells us the engines comes from `node_modules/@prisma/engines`, but when you try to list that directory, it is actually not present.\r\n\r\nWhat is happening here is that `yarn prisma` is actually from a few folders _above_ our project. This is kinda visible when you look to not run `yarn -s` but just `yarn`:\r\n```\r\ncodespace ➜ /workspaces/e2e-tests/platforms-serverless/firebase-functions (janpio-patch-5 ✗) $ yarn prisma -v\r\nyarn run v1.22.10\r\nwarning package.json: No license field\r\n$ /workspaces/e2e-tests/node_modules/.bin/prisma -v\r\nprisma               : 2.25.0-dev.36\r\n@prisma/client       : 2.25.0-dev.36\r\n...\r\n```\r\n\r\n## Suggested solution\r\n\r\nOutput the directory of where the executed `prisma` is from, either similar to Yarn the absolute path to the binary in `node_modules`, or the folder where the `package.json` that is responsible for the installation of Prisma comes from.\r\n\r\n## Alternatives\r\n\r\nRely on `yarn` itself to give that information. Will not work with `npx` unfortunately for example.",
              "url": "https://github.com/prisma/prisma/issues/7771",
              "tech": [],
              "repo_name": "prisma",
              "repo_owner": "prisma",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "permitio#716",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "permitio",
              "id": "generated-permitio",
              "name": "Permitio",
              "description": "",
              "members": [],
              "display_name": "Permitio",
              "created_at": "2025-11-24T19:50:43.042Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/permitio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "permitio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:43.042Z",
            "created_at": "2025-11-24T19:50:43.042Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-permitio#716",
              "status": "open",
              "type": "issue",
              "number": 716,
              "title": "Error resolving broadcast hostname being swallowed",
              "source": {
                "data": {
                  "id": "source-permitio#716",
                  "user": {
                    "login": "keyz182",
                    "id": 693408,
                    "node_id": "MDQ6VXNlcjY5MzQwOA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/693408?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/keyz182",
                    "html_url": "https://github.com/keyz182",
                    "followers_url": "https://api.github.com/users/keyz182/followers",
                    "following_url": "https://api.github.com/users/keyz182/following{/other_user}",
                    "gists_url": "https://api.github.com/users/keyz182/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/keyz182/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/keyz182/subscriptions",
                    "organizations_url": "https://api.github.com/users/keyz182/orgs",
                    "repos_url": "https://api.github.com/users/keyz182/repos",
                    "events_url": "https://api.github.com/users/keyz182/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/keyz182/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Error resolving broadcast hostname being swallowed",
                  "body": "**Describe the bug**\r\n\r\nWe had a deployment of opal-server that we'd typoed the broadcast URI. We were seeing websockets disconnect errors in the clients, but no errors server side, so no clues it was the broadcast URI. \r\n\r\nAfter turning debug logging on for the server, I spotted the following output:\r\n\r\n```\r\n2024-12-04T15:27:01.018085+0000| fastapi_websocket_rpc.websocket_rpc_e...| INFO  | Client connected\r\n2024-12-04T15:27:01.018500+0000| websockets.legacy.server                | INFO  | connection open\r\n2024-12-04T15:27:01.022749+0000| fastapi_websocket_rpc.rpc_channel       |DEBUG  | Handling RPC request - {'request': RpcRequest(method='_ping_', arguments={}, call_id='5d8d421e3dc94751a035b202644c8e8a'), 'channel': '72c2a547ffc64741bd095079bc778d7d'}\r\n2024-12-04T15:27:01.023420+0000| fastapi_websocket_pubsub.pub_sub_server |DEBUG  | task is done: {<Task finished name='Task-3053' coro=<EventBroadcaster.__read_notifications__() done, defined at /usr/local/lib/python3.10/site-packages/fastapi_websocket_pubsub/event_broadcaster.py:245> exception=gaierror(-2, 'Name or service not known')>}\r\n2024-12-04T15:27:01.023565+0000| fastapi_websocket_pubsub.event_broadc...| INFO  | Cancelling broadcast listen task\r\n2024-12-04T15:27:01.023677+0000| fastapi_websocket_pubsub.event_broadc...|DEBUG  | Unsubscribing from ALL TOPICS\r\n2024-12-04T15:27:01.023790+0000| fastapi_websocket_pubsub.event_notifier |DEBUG  | Removing Subscription of topic='__EventNotifier_ALL_TOPICS__' for subscriber=cc43be7c3ebb41e1b4869ace10d213db\r\n2024-12-04T15:27:01.023948+0000| fastapi_websocket_rpc.websocket_rpc_e...| INFO  | Client connection failed - 42723 :: 72c2a547ffc64741bd095079bc778d7d\r\n2024-12-04T15:27:01.024165+0000| fastapi_websocket_pubsub.pub_sub_server |DEBUG  | Leaving endpoint's main loop\r\n2024-12-04T15:27:01.026785+0000| websockets.legacy.server                | INFO  | connection closed\r\n```\r\n\r\nBased on the 4th line, I went to look at `fastapi_websocket_pubsub/event_broadcaster.py:245` and saw it was referencing the broadcast URI, at which point I double checked ours and saw the typo. \r\n\r\nWhat I believe to be a bug is that the error is being swallowed, and should probably be elevated to an `ERROR` level log for visibility.\r\n\r\n**To Reproduce**\r\nSet the broadcast URI to an invalid value - in our case, a postgres URI with a hostname that didn't resolve.\r\n\r\nLogs: [se616-opal-opal-server-545c454db-hx2nc.log](https://github.com/user-attachments/files/18010731/se616-opal-opal-server-545c454db-hx2nc.log)\r\n\r\n**Expected behavior**\r\nA clear error level log to indicate that the broadcast URI could not be resolved\r\n\r\n**OPAL version**\r\n - Version: Client - 0.7.15, Server - 0.7.8\r\n",
                  "html_url": "https://github.com/permitio/opal/issues/716"
                },
                "type": "github"
              },
              "hash": "permitio/opal#716",
              "body": "**Describe the bug**\r\n\r\nWe had a deployment of opal-server that we'd typoed the broadcast URI. We were seeing websockets disconnect errors in the clients, but no errors server side, so no clues it was the broadcast URI. \r\n\r\nAfter turning debug logging on for the server, I spotted the following output:\r\n\r\n```\r\n2024-12-04T15:27:01.018085+0000| fastapi_websocket_rpc.websocket_rpc_e...| INFO  | Client connected\r\n2024-12-04T15:27:01.018500+0000| websockets.legacy.server                | INFO  | connection open\r\n2024-12-04T15:27:01.022749+0000| fastapi_websocket_rpc.rpc_channel       |DEBUG  | Handling RPC request - {'request': RpcRequest(method='_ping_', arguments={}, call_id='5d8d421e3dc94751a035b202644c8e8a'), 'channel': '72c2a547ffc64741bd095079bc778d7d'}\r\n2024-12-04T15:27:01.023420+0000| fastapi_websocket_pubsub.pub_sub_server |DEBUG  | task is done: {<Task finished name='Task-3053' coro=<EventBroadcaster.__read_notifications__() done, defined at /usr/local/lib/python3.10/site-packages/fastapi_websocket_pubsub/event_broadcaster.py:245> exception=gaierror(-2, 'Name or service not known')>}\r\n2024-12-04T15:27:01.023565+0000| fastapi_websocket_pubsub.event_broadc...| INFO  | Cancelling broadcast listen task\r\n2024-12-04T15:27:01.023677+0000| fastapi_websocket_pubsub.event_broadc...|DEBUG  | Unsubscribing from ALL TOPICS\r\n2024-12-04T15:27:01.023790+0000| fastapi_websocket_pubsub.event_notifier |DEBUG  | Removing Subscription of topic='__EventNotifier_ALL_TOPICS__' for subscriber=cc43be7c3ebb41e1b4869ace10d213db\r\n2024-12-04T15:27:01.023948+0000| fastapi_websocket_rpc.websocket_rpc_e...| INFO  | Client connection failed - 42723 :: 72c2a547ffc64741bd095079bc778d7d\r\n2024-12-04T15:27:01.024165+0000| fastapi_websocket_pubsub.pub_sub_server |DEBUG  | Leaving endpoint's main loop\r\n2024-12-04T15:27:01.026785+0000| websockets.legacy.server                | INFO  | connection closed\r\n```\r\n\r\nBased on the 4th line, I went to look at `fastapi_websocket_pubsub/event_broadcaster.py:245` and saw it was referencing the broadcast URI, at which point I double checked ours and saw the typo. \r\n\r\nWhat I believe to be a bug is that the error is being swallowed, and should probably be elevated to an `ERROR` level log for visibility.\r\n\r\n**To Reproduce**\r\nSet the broadcast URI to an invalid value - in our case, a postgres URI with a hostname that didn't resolve.\r\n\r\nLogs: [se616-opal-opal-server-545c454db-hx2nc.log](https://github.com/user-attachments/files/18010731/se616-opal-opal-server-545c454db-hx2nc.log)\r\n\r\n**Expected behavior**\r\nA clear error level log to indicate that the broadcast URI could not be resolved\r\n\r\n**OPAL version**\r\n - Version: Client - 0.7.15, Server - 0.7.8\r\n",
              "url": "https://github.com/permitio/opal/issues/716",
              "tech": [
                "go"
              ],
              "repo_name": "opal",
              "repo_owner": "permitio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "permitio#677",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "permitio",
              "id": "generated-permitio",
              "name": "Permitio",
              "description": "",
              "members": [],
              "display_name": "Permitio",
              "created_at": "2025-11-24T19:50:43.360Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/permitio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "permitio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:43.360Z",
            "created_at": "2025-11-24T19:50:43.360Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-permitio#677",
              "status": "open",
              "type": "issue",
              "number": 677,
              "title": "Create E2E tests framework using PyTest",
              "source": {
                "data": {
                  "id": "source-permitio#677",
                  "user": {
                    "login": "danyi1212",
                    "id": 12188774,
                    "node_id": "MDQ6VXNlcjEyMTg4Nzc0",
                    "avatar_url": "https://avatars.githubusercontent.com/u/12188774?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/danyi1212",
                    "html_url": "https://github.com/danyi1212",
                    "followers_url": "https://api.github.com/users/danyi1212/followers",
                    "following_url": "https://api.github.com/users/danyi1212/following{/other_user}",
                    "gists_url": "https://api.github.com/users/danyi1212/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/danyi1212/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/danyi1212/subscriptions",
                    "organizations_url": "https://api.github.com/users/danyi1212/orgs",
                    "repos_url": "https://api.github.com/users/danyi1212/repos",
                    "events_url": "https://api.github.com/users/danyi1212/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/danyi1212/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Create E2E tests framework using PyTest",
                  "body": "We want to create a new baseline framework for writing E2E tests for OPAL Client and Server using PyTest\r\n\r\nThe test framework should do the following tasks on its baseline/initial run:\r\n* Run an OPAL Server and Client inside Docker\r\n* Initially test for health check responsivity\r\n* Check logs for errors and critical alerts\r\n* Check the client and server are connected using the [Statistics API](https://opal-v2.permit.io/redoc#tag/Server-Statistics/operation/get_statistics_statistics_get)\r\n\r\nThe acceptance criteria for this issue is the ability to run a single test command that will be based on the framework specified above and run a very basic assertion test on OPAL",
                  "html_url": "https://github.com/permitio/opal/issues/677"
                },
                "type": "github"
              },
              "hash": "permitio/opal#677",
              "body": "We want to create a new baseline framework for writing E2E tests for OPAL Client and Server using PyTest\r\n\r\nThe test framework should do the following tasks on its baseline/initial run:\r\n* Run an OPAL Server and Client inside Docker\r\n* Initially test for health check responsivity\r\n* Check logs for errors and critical alerts\r\n* Check the client and server are connected using the [Statistics API](https://opal-v2.permit.io/redoc#tag/Server-Statistics/operation/get_statistics_statistics_get)\r\n\r\nThe acceptance criteria for this issue is the ability to run a single test command that will be based on the framework specified above and run a very basic assertion test on OPAL",
              "url": "https://github.com/permitio/opal/issues/677",
              "tech": [],
              "repo_name": "opal",
              "repo_owner": "permitio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "permitio#634",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "permitio",
              "id": "generated-permitio",
              "name": "Permitio",
              "description": "",
              "members": [],
              "display_name": "Permitio",
              "created_at": "2025-11-24T19:50:43.745Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/permitio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "permitio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:43.745Z",
            "created_at": "2025-11-24T19:50:43.745Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-permitio#634",
              "status": "open",
              "type": "issue",
              "number": 634,
              "title": "OPAL Server doesn't clean up symbolic links when github is down",
              "source": {
                "data": {
                  "id": "source-permitio#634",
                  "user": {
                    "login": "kreyyser",
                    "id": 8156669,
                    "node_id": "MDQ6VXNlcjgxNTY2Njk=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/8156669?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kreyyser",
                    "html_url": "https://github.com/kreyyser",
                    "followers_url": "https://api.github.com/users/kreyyser/followers",
                    "following_url": "https://api.github.com/users/kreyyser/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kreyyser/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kreyyser/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kreyyser/subscriptions",
                    "organizations_url": "https://api.github.com/users/kreyyser/orgs",
                    "repos_url": "https://api.github.com/users/kreyyser/repos",
                    "events_url": "https://api.github.com/users/kreyyser/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kreyyser/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "OPAL Server doesn't clean up symbolic links when github is down",
                  "body": "When opal server has github policies setup and github is down for some time opal server seems like spawn zombie processes but apparently looks like it is just a list of symbolic links that are not cleaned up.\r\n\r\n**To Reproduce**\r\nrun OPAL with github policies source as a container\r\nmake somehow github return 500\r\nlist processes in opal server container\r\n\r\n**Expected behavior**\r\nNo zombie processes or broken links proc directory\r\n\r\n**Screenshots**\r\n<img width=\"1329\" alt=\"opal-server-proc\" src=\"https://github.com/user-attachments/assets/9f4fa8a5-9867-45d2-a21d-2a7c133ac9c1\">\r\n\r\n**OPAL version**\r\n - Version: 0.7.6\r\n",
                  "html_url": "https://github.com/permitio/opal/issues/634"
                },
                "type": "github"
              },
              "hash": "permitio/opal#634",
              "body": "When opal server has github policies setup and github is down for some time opal server seems like spawn zombie processes but apparently looks like it is just a list of symbolic links that are not cleaned up.\r\n\r\n**To Reproduce**\r\nrun OPAL with github policies source as a container\r\nmake somehow github return 500\r\nlist processes in opal server container\r\n\r\n**Expected behavior**\r\nNo zombie processes or broken links proc directory\r\n\r\n**Screenshots**\r\n<img width=\"1329\" alt=\"opal-server-proc\" src=\"https://github.com/user-attachments/assets/9f4fa8a5-9867-45d2-a21d-2a7c133ac9c1\">\r\n\r\n**OPAL version**\r\n - Version: 0.7.6\r\n",
              "url": "https://github.com/permitio/opal/issues/634",
              "tech": [],
              "repo_name": "opal",
              "repo_owner": "permitio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#14026",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-24T19:50:42.718Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:42.718Z",
            "created_at": "2025-11-24T19:50:42.718Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#14026",
              "status": "open",
              "type": "issue",
              "number": 14026,
              "title": "CVE-2021-45461 - FreePBX RestApps - Remote Code Execution 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#14026",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2021-45461 - FreePBX RestApps - Remote Code Execution 💰",
                  "body": "\n### Description: \n> FreePBX restapps 15.0.19.87, 15.0.19.88, 16.0.18.40, and 16.0.18.41 contain a remote code execution caused by improper input handling, letting remote attackers execute arbitrary code, exploit requires remote network access.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://community.freepbx.org/t/0-day-freepbx-exploit/80092\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/14026"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#14026",
              "body": "\n### Description: \n> FreePBX restapps 15.0.19.87, 15.0.19.88, 16.0.18.40, and 16.0.18.41 contain a remote code execution caused by improper input handling, letting remote attackers execute arbitrary code, exploit requires remote network access.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://community.freepbx.org/t/0-day-freepbx-exploit/80092\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/14026",
              "tech": [
                "go"
              ],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13997",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-24T19:50:43.040Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:43.040Z",
            "created_at": "2025-11-24T19:50:43.040Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13997",
              "status": "open",
              "type": "issue",
              "number": 13997,
              "title": "CVE-2022-21445 - Oracle Fusion Middleware - Remote Code Execution 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13997",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2022-21445 - Oracle Fusion Middleware - Remote Code Execution 💰",
                  "body": "\n### Description: \n> Oracle Fusion Middleware ADF Faces versions 12.2.1.3.0 and 12.2.1.4.0 contain a remote code execution caused by an unauthenticated network access vulnerability in ADF Faces, letting attackers compromise the application, exploit requires network access via HTTP.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/hienkiet/CVE-2022-21445-for-12.2.1.3.0-Weblogic\n- https://vulncheck.com/xdb/df8eb20f5b8e\n- https///github.com:hienkiet/CVE-2022-21445-for-12.2.1.3.0-Weblogic.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13997"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13997",
              "body": "\n### Description: \n> Oracle Fusion Middleware ADF Faces versions 12.2.1.3.0 and 12.2.1.4.0 contain a remote code execution caused by an unauthenticated network access vulnerability in ADF Faces, letting attackers compromise the application, exploit requires network access via HTTP.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/hienkiet/CVE-2022-21445-for-12.2.1.3.0-Weblogic\n- https://vulncheck.com/xdb/df8eb20f5b8e\n- https///github.com:hienkiet/CVE-2022-21445-for-12.2.1.3.0-Weblogic.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13997",
              "tech": [
                "go"
              ],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13942",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-24T19:50:43.361Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:43.361Z",
            "created_at": "2025-11-24T19:50:43.361Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13942",
              "status": "open",
              "type": "issue",
              "number": 13942,
              "title": "CVE-2022-31199 - Netwrix Auditor - Remote Code Execution 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13942",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2022-31199 - Netwrix Auditor - Remote Code Execution 💰",
                  "body": "\n### Description: \n> Netwrix Auditor User Activity Video Recording component contains remote code execution caused by vulnerabilities in the underlying protocol, letting unauthenticated attackers execute arbitrary code as SYSTEM, exploit requires network access.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://bishopfox.com/blog/netwrix-auditor-advisory\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13942"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13942",
              "body": "\n### Description: \n> Netwrix Auditor User Activity Video Recording component contains remote code execution caused by vulnerabilities in the underlying protocol, letting unauthenticated attackers execute arbitrary code as SYSTEM, exploit requires network access.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://bishopfox.com/blog/netwrix-auditor-advisory\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13942",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13942",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-24T19:50:43.667Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:43.667Z",
            "created_at": "2025-11-24T19:50:43.667Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13942",
              "status": "open",
              "type": "issue",
              "number": 13942,
              "title": "CVE-2022-31199 - Netwrix Auditor - Remote Code Execution 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13942",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2022-31199 - Netwrix Auditor - Remote Code Execution 💰",
                  "body": "\n### Description: \n> Netwrix Auditor User Activity Video Recording component contains remote code execution caused by vulnerabilities in the underlying protocol, letting unauthenticated attackers execute arbitrary code as SYSTEM, exploit requires network access.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://bishopfox.com/blog/netwrix-auditor-advisory\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13942"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13942",
              "body": "\n### Description: \n> Netwrix Auditor User Activity Video Recording component contains remote code execution caused by vulnerabilities in the underlying protocol, letting unauthenticated attackers execute arbitrary code as SYSTEM, exploit requires network access.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://bishopfox.com/blog/netwrix-auditor-advisory\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13942",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13933",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-24T19:50:44.047Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:44.047Z",
            "created_at": "2025-11-24T19:50:44.047Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13933",
              "status": "open",
              "type": "issue",
              "number": 13933,
              "title": "CVE-2023-25158 - GeoTools - SQL Injection 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13933",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2023-25158 - GeoTools - SQL Injection 💰",
                  "body": "\n### Description: \n> GeoTools < 27.4, 28.2 contains a sql_injection caused by unsanitized OGC Filter expressions in JDBCDataStore, letting attackers execute arbitrary SQL commands, exploit requires executing malicious filters.\n\n#### Severity: `Critical`\n\n#### POC: \n- https///github.com:murataydemir/CVE-2023-25157-and-CVE-2023-25158.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13933"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13933",
              "body": "\n### Description: \n> GeoTools < 27.4, 28.2 contains a sql_injection caused by unsanitized OGC Filter expressions in JDBCDataStore, letting attackers execute arbitrary SQL commands, exploit requires executing malicious filters.\n\n#### Severity: `Critical`\n\n#### POC: \n- https///github.com:murataydemir/CVE-2023-25157-and-CVE-2023-25158.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13933",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13923",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-24T19:50:44.546Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:44.546Z",
            "created_at": "2025-11-24T19:50:44.546Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13923",
              "status": "open",
              "type": "issue",
              "number": 13923,
              "title": "CVE-2023-27532 - Veeam Backup & Replication - Credential Disclosure 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13923",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2023-27532 - Veeam Backup & Replication - Credential Disclosure 💰",
                  "body": "\n### Description: \n> Veeam Backup & Replication contains a vulnerability that allows encrypted credentials stored in the configuration database to be obtained, letting attackers access backup infrastructure hosts, exploit requires access to the configuration database.\n\n#### Severity: `High`\n\n#### POC: \n- https://vulncheck.com/xdb/a0eedd90601f\n- https://github.com/puckiestyle/CVE-2023-27532-RCE-Only\n- https///github.com:puckiestyle/CVE-2023-27532-RCE-Only.git\n- https://vulncheck.com/xdb/be7830da6e38\n- https://github.com/sfewer-r7/CVE-2023-27532\n- https///github.com:sfewer-r7/CVE-2023-27532.git\n- https://vulncheck.com/xdb/70b9158e5d47\n- https://github.com/horizon3ai/CVE-2023-27532\n- https///github.com:horizon3ai/CVE-2023-27532.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13923"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13923",
              "body": "\n### Description: \n> Veeam Backup & Replication contains a vulnerability that allows encrypted credentials stored in the configuration database to be obtained, letting attackers access backup infrastructure hosts, exploit requires access to the configuration database.\n\n#### Severity: `High`\n\n#### POC: \n- https://vulncheck.com/xdb/a0eedd90601f\n- https://github.com/puckiestyle/CVE-2023-27532-RCE-Only\n- https///github.com:puckiestyle/CVE-2023-27532-RCE-Only.git\n- https://vulncheck.com/xdb/be7830da6e38\n- https://github.com/sfewer-r7/CVE-2023-27532\n- https///github.com:sfewer-r7/CVE-2023-27532.git\n- https://vulncheck.com/xdb/70b9158e5d47\n- https://github.com/horizon3ai/CVE-2023-27532\n- https///github.com:horizon3ai/CVE-2023-27532.git\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13923",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13915",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-24T19:50:45.685Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:45.685Z",
            "created_at": "2025-11-24T19:50:45.685Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13915",
              "status": "open",
              "type": "issue",
              "number": 13915,
              "title": "CVE-2023-28725 - General Bytes CAS - Remote Code Execution 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13915",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2023-28725 - General Bytes CAS - Remote Code Execution 💰",
                  "body": "\n### Description: \n> General Bytes Crypto Application Server (CAS) 20230120 contains a remote code execution caused by uploading a Java application to the /batm/app/admin/standalone/deployments directory, letting remote attackers execute arbitrary Java code, exploit requires upload access to the deployment directory.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://generalbytes.atlassian.net/wiki/spaces/ESD/pages/2885222430/Security+Incident+March+17-18th+2023\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13915"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13915",
              "body": "\n### Description: \n> General Bytes Crypto Application Server (CAS) 20230120 contains a remote code execution caused by uploading a Java application to the /batm/app/admin/standalone/deployments directory, letting remote attackers execute arbitrary Java code, exploit requires upload access to the deployment directory.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://generalbytes.atlassian.net/wiki/spaces/ESD/pages/2885222430/Security+Incident+March+17-18th+2023\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13915",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13724",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-24T19:50:47.086Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:47.086Z",
            "created_at": "2025-11-24T19:50:47.086Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13724",
              "status": "open",
              "type": "issue",
              "number": 13724,
              "title": "CVE-2025-61932 - Lanscope Endpoint Manager - Remote Code Execution 💰",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13724",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2025-61932 - Lanscope Endpoint Manager - Remote Code Execution 💰",
                  "body": "\n### Description: \n> Lanscope Endpoint Manager (On-Premises) contains a remote code execution vulnerability caused by improper verification of the origin of incoming requests, letting attackers execute arbitrary code remotely, exploit requires sending specially crafted packets.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/allinsthon/CVE-2025-61932\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13724"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13724",
              "body": "\n### Description: \n> Lanscope Endpoint Manager (On-Premises) contains a remote code execution vulnerability caused by improper verification of the origin of incoming requests, letting attackers execute arbitrary code remotely, exploit requires sending specially crafted packets.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/allinsthon/CVE-2025-61932\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and won’t produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13724",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#3791",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-11-24T19:50:42.631Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:42.631Z",
            "created_at": "2025-11-24T19:50:42.631Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#3791",
              "status": "open",
              "type": "issue",
              "number": 3791,
              "title": "Read signals from query params to case class",
              "source": {
                "data": {
                  "id": "source-ZIO#3791",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Read signals from query params to case class",
                  "body": "easy way to read query param signals to case class for get requests",
                  "html_url": "https://github.com/zio/zio-http/issues/3791"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3791",
              "body": "easy way to read query param signals to case class for get requests",
              "url": "https://github.com/zio/zio-http/issues/3791",
              "tech": [
                "go"
              ],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#3697",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-11-24T19:50:42.836Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:42.836Z",
            "created_at": "2025-11-24T19:50:42.836Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#3697",
              "status": "open",
              "type": "issue",
              "number": 3697,
              "title": "Datastar requests from Endpoint",
              "source": {
                "data": {
                  "id": "source-ZIO#3697",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Datastar requests from Endpoint",
                  "body": "Build Datastar expressions for request against an Endpoint from its definition\n",
                  "html_url": "https://github.com/zio/zio-http/issues/3697"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3697",
              "body": "Build Datastar expressions for request against an Endpoint from its definition\n",
              "url": "https://github.com/zio/zio-http/issues/3697",
              "tech": [
                "go"
              ],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#709",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-11-24T19:50:43.042Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:43.042Z",
            "created_at": "2025-11-24T19:50:43.042Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#709",
              "status": "open",
              "type": "issue",
              "number": 709,
              "title": "Support Http Range header on request for Files",
              "source": {
                "data": {
                  "id": "source-ZIO#709",
                  "user": {
                    "login": "ashprakasan",
                    "id": 8946971,
                    "node_id": "MDQ6VXNlcjg5NDY5NzE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/8946971?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ashprakasan",
                    "html_url": "https://github.com/ashprakasan",
                    "followers_url": "https://api.github.com/users/ashprakasan/followers",
                    "following_url": "https://api.github.com/users/ashprakasan/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ashprakasan/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ashprakasan/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ashprakasan/subscriptions",
                    "organizations_url": "https://api.github.com/users/ashprakasan/orgs",
                    "repos_url": "https://api.github.com/users/ashprakasan/repos",
                    "events_url": "https://api.github.com/users/ashprakasan/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ashprakasan/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Support Http Range header on request for Files",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe Range HTTP request header indicates the part of a document that the server should return. Several parts can be requested with one Range header at once, and the server may send back these ranges in a multipart document.\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample requesting 3 ranges from files -\r\n`Range: bytes=200-1000, 2000-6576, 19000-`\r\n\r\nSend only those parts of the document in Response.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCurrently, the range is hardcoded as follows - \r\n` ctx.write(new DefaultFileRegion(raf.getChannel, 0, fileLength))`\r\nManipulate the positions as per request headers instead.\r\n\r\n**Additional context**\r\n\r\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Range\r\n",
                  "html_url": "https://github.com/zio/zio-http/issues/709"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#709",
              "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe Range HTTP request header indicates the part of a document that the server should return. Several parts can be requested with one Range header at once, and the server may send back these ranges in a multipart document.\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample requesting 3 ranges from files -\r\n`Range: bytes=200-1000, 2000-6576, 19000-`\r\n\r\nSend only those parts of the document in Response.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCurrently, the range is hardcoded as follows - \r\n` ctx.write(new DefaultFileRegion(raf.getChannel, 0, fileLength))`\r\nManipulate the positions as per request headers instead.\r\n\r\n**Additional context**\r\n\r\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Range\r\n",
              "url": "https://github.com/zio/zio-http/issues/709",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#3472",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-11-24T19:50:43.361Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:43.361Z",
            "created_at": "2025-11-24T19:50:43.361Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#3472",
              "status": "open",
              "type": "issue",
              "number": 3472,
              "title": "Split into multiple modules",
              "source": {
                "data": {
                  "id": "source-ZIO#3472",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Split into multiple modules",
                  "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
                  "html_url": "https://github.com/zio/zio-http/issues/3472"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3472",
              "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
              "url": "https://github.com/zio/zio-http/issues/3472",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9810",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-11-24T19:50:43.821Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:43.821Z",
            "created_at": "2025-11-24T19:50:43.821Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9810",
              "status": "open",
              "type": "issue",
              "number": 9810,
              "title": "ZStreams buffer(1) is buffering 2.",
              "source": {
                "data": {
                  "id": "source-ZIO#9810",
                  "user": {
                    "login": "douglasthomsen",
                    "id": 88000378,
                    "node_id": "MDQ6VXNlcjg4MDAwMzc4",
                    "avatar_url": "https://avatars.githubusercontent.com/u/88000378?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/douglasthomsen",
                    "html_url": "https://github.com/douglasthomsen",
                    "followers_url": "https://api.github.com/users/douglasthomsen/followers",
                    "following_url": "https://api.github.com/users/douglasthomsen/following{/other_user}",
                    "gists_url": "https://api.github.com/users/douglasthomsen/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/douglasthomsen/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/douglasthomsen/subscriptions",
                    "organizations_url": "https://api.github.com/users/douglasthomsen/orgs",
                    "repos_url": "https://api.github.com/users/douglasthomsen/repos",
                    "events_url": "https://api.github.com/users/douglasthomsen/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/douglasthomsen/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZStreams buffer(1) is buffering 2.",
                  "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
                  "html_url": "https://github.com/zio/zio/issues/9810"
                },
                "type": "github"
              },
              "hash": "zio/zio#9810",
              "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
              "url": "https://github.com/zio/zio/issues/9810",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9844",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-11-24T19:50:44.310Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:44.310Z",
            "created_at": "2025-11-24T19:50:44.310Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9844",
              "status": "open",
              "type": "issue",
              "number": 9844,
              "title": "improved `Queue` shutdown functionality",
              "source": {
                "data": {
                  "id": "source-ZIO#9844",
                  "user": {
                    "login": "mberndt123",
                    "id": 11650737,
                    "node_id": "MDQ6VXNlcjExNjUwNzM3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/11650737?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/mberndt123",
                    "html_url": "https://github.com/mberndt123",
                    "followers_url": "https://api.github.com/users/mberndt123/followers",
                    "following_url": "https://api.github.com/users/mberndt123/following{/other_user}",
                    "gists_url": "https://api.github.com/users/mberndt123/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/mberndt123/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/mberndt123/subscriptions",
                    "organizations_url": "https://api.github.com/users/mberndt123/orgs",
                    "repos_url": "https://api.github.com/users/mberndt123/repos",
                    "events_url": "https://api.github.com/users/mberndt123/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/mberndt123/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "improved `Queue` shutdown functionality",
                  "body": "Hey, I've recently proposed something on Discord, and since feedback has been rather positive, I'm making a ticket to track the idea.\n\nI've been working with Queues recently, and I've been having some issues around `shutdown` that I would like to address.\n\nSpecifically, I find it a common pattern that I send some kind of request object through a queue because I want another fiber to perform some action on my behalf. Along with the request, I send a `Promise` to have that fiber communicate the outcome of that action to me. By and large this works fine. The issue arises when the fiber that I'm sending requests to fails. In that case, I would like it to communicate the cause of the failure back to the other fibers. This is easy enough for the requests that I've already pulled out of the queue: I simply fail those promises.\nBut I also need to deal with other cases: fibers currently blocked in an `offer` call, future attempts to `offer` to the queue, and I also need to deal with requests that have been submitted to the queue but not yet retrieved.\n\nSo my idea is as follows:\n - add an `E` type parameter to `Queue`\n - add a `shutdownCause` method that takes a type parameter of type `Cause[E]`\n - `shutdownCause` would also return the items currently buffered in the queue in order to dispose of them\n - after `shutdownCause` has been called, any attempt to interact with the queue will fail with the cause\n - methods like `take, offer` etc. should indicate errors of type `E`\n - streams created with `ZStream.fromQueue` would also fail with this cause\n - `shutdownCause` should be atomic: when multiple fibers call it at the same time, one of them wins and the others fail with the cause supplied by the winner\n\nAfaik, adding a new method is a binary compatible change, as is adding a new type parameter. Hence I think this is a source incompatible but binary compatible change. @ghostdogpr therefore suggested it could be added in a ZIO 2.2 release.\n",
                  "html_url": "https://github.com/zio/zio/issues/9844"
                },
                "type": "github"
              },
              "hash": "zio/zio#9844",
              "body": "Hey, I've recently proposed something on Discord, and since feedback has been rather positive, I'm making a ticket to track the idea.\n\nI've been working with Queues recently, and I've been having some issues around `shutdown` that I would like to address.\n\nSpecifically, I find it a common pattern that I send some kind of request object through a queue because I want another fiber to perform some action on my behalf. Along with the request, I send a `Promise` to have that fiber communicate the outcome of that action to me. By and large this works fine. The issue arises when the fiber that I'm sending requests to fails. In that case, I would like it to communicate the cause of the failure back to the other fibers. This is easy enough for the requests that I've already pulled out of the queue: I simply fail those promises.\nBut I also need to deal with other cases: fibers currently blocked in an `offer` call, future attempts to `offer` to the queue, and I also need to deal with requests that have been submitted to the queue but not yet retrieved.\n\nSo my idea is as follows:\n - add an `E` type parameter to `Queue`\n - add a `shutdownCause` method that takes a type parameter of type `Cause[E]`\n - `shutdownCause` would also return the items currently buffered in the queue in order to dispose of them\n - after `shutdownCause` has been called, any attempt to interact with the queue will fail with the cause\n - methods like `take, offer` etc. should indicate errors of type `E`\n - streams created with `ZStream.fromQueue` would also fail with this cause\n - `shutdownCause` should be atomic: when multiple fibers call it at the same time, one of them wins and the others fail with the cause supplied by the winner\n\nAfaik, adding a new method is a binary compatible change, as is adding a new type parameter. Hence I think this is a source incompatible but binary compatible change. @ghostdogpr therefore suggested it could be added in a ZIO 2.2 release.\n",
              "url": "https://github.com/zio/zio/issues/9844",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9878",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-11-24T19:50:45.012Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:45.012Z",
            "created_at": "2025-11-24T19:50:45.012Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9878",
              "status": "open",
              "type": "issue",
              "number": 9878,
              "title": "ZScheduler parks+unparks workers too frequently",
              "source": {
                "data": {
                  "id": "source-ZIO#9878",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZScheduler parks+unparks workers too frequently",
                  "body": "Unparking workers is slow and invoked in the hotpath too often. I think we may need to trade some fairness for aggression to avoid excessive cycling.\n\n`maybeUnparkWorker` (obviously `LockSupport.unpark(worker)`) is very expensive: https://github.com/zio/zio/blob/series/2.x/core/jvm-native/src/main/scala/zio/internal/ZScheduler.scala#L443-L454",
                  "html_url": "https://github.com/zio/zio/issues/9878"
                },
                "type": "github"
              },
              "hash": "zio/zio#9878",
              "body": "Unparking workers is slow and invoked in the hotpath too often. I think we may need to trade some fairness for aggression to avoid excessive cycling.\n\n`maybeUnparkWorker` (obviously `LockSupport.unpark(worker)`) is very expensive: https://github.com/zio/zio/blob/series/2.x/core/jvm-native/src/main/scala/zio/internal/ZScheduler.scala#L443-L454",
              "url": "https://github.com/zio/zio/issues/9878",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9877",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-11-24T19:50:46.427Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:46.427Z",
            "created_at": "2025-11-24T19:50:46.427Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9877",
              "status": "open",
              "type": "issue",
              "number": 9877,
              "title": "Can Fiber(Runtime) and Promise be merged?",
              "source": {
                "data": {
                  "id": "source-ZIO#9877",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Can Fiber(Runtime) and Promise be merged?",
                  "body": "A Promise awaiting completion is essentially a Fiber parked awaiting an async callback. When a Fiber is forking work (which will eventually complete a promise), then awaiting a Promise, we end up with unnecessary allocations + indirection.\n\nit would be useful to have `Promise.become` or similar to link fibers/promises.",
                  "html_url": "https://github.com/zio/zio/issues/9877"
                },
                "type": "github"
              },
              "hash": "zio/zio#9877",
              "body": "A Promise awaiting completion is essentially a Fiber parked awaiting an async callback. When a Fiber is forking work (which will eventually complete a promise), then awaiting a Promise, we end up with unnecessary allocations + indirection.\n\nit would be useful to have `Promise.become` or similar to link fibers/promises.",
              "url": "https://github.com/zio/zio/issues/9877",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9874",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-11-24T19:50:47.649Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:47.649Z",
            "created_at": "2025-11-24T19:50:47.649Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9874",
              "status": "open",
              "type": "issue",
              "number": 9874,
              "title": "Handling errors allows recovering from defects",
              "source": {
                "data": {
                  "id": "source-ZIO#9874",
                  "user": {
                    "login": "kyri-petrou",
                    "id": 67301607,
                    "node_id": "MDQ6VXNlcjY3MzAxNjA3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/67301607?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kyri-petrou",
                    "html_url": "https://github.com/kyri-petrou",
                    "followers_url": "https://api.github.com/users/kyri-petrou/followers",
                    "following_url": "https://api.github.com/users/kyri-petrou/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kyri-petrou/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kyri-petrou/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kyri-petrou/subscriptions",
                    "organizations_url": "https://api.github.com/users/kyri-petrou/orgs",
                    "repos_url": "https://api.github.com/users/kyri-petrou/repos",
                    "events_url": "https://api.github.com/users/kyri-petrou/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kyri-petrou/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Handling errors allows recovering from defects",
                  "body": "Sigh... Well, this is annoying. When a Cause contains both a failure and a defect (i.e., Fail & Die), failure handling assumes that the Cause does not contain any defects and therefor silently ignores them.\n\nRepro:\n\n```scala\nimport zio.*\n\nobject Foo extends ZIOAppDefault {\n  val dieCause: Cause[String] = Cause.die(new RuntimeException(\"boom\"))\n  val combinedCause = dieCause && Cause.fail(\"boom\")\n\n  def run = ZIO.failCause(combinedCause).catchAll { e =>\n    ZIO.debug(e)\n  } *> ZIO.debug(\"Success\")\n}\n```\nprints:\n```\nhandled: boom\nSuccess\n```\n\nHowever if we substituted `ZIO.failCause(combinedCause)` with `ZIO.failCause(dieCause)`:\n\n```\ntimestamp=2025-05-20T16:31:09.291104Z level=ERROR thread=#zio-fiber-1707930317 message=\"\" cause=\"java.lang.RuntimeException: boom\n\tat Foo$.<clinit>(Foo.scala:4)\n\tat Foo.main(Foo.scala)\n\tat <empty>.Foo.run(Foo.scala:7)\n\tat <empty>.Foo.run(Foo.scala:9)\n\"\n```\n\nWith both of these causes, the outcome should be the same as defects should always be prioritised over failures. This gets even worse when interruption is involved, because the failure handling will be prioritised over it.\n\nHaving said that, this has the potential to massively alter applications so I'm too scared to fix it.\n@ghostdogpr @jdegoes  @hearnadam @guizmaii I summon you all for some wisdom",
                  "html_url": "https://github.com/zio/zio/issues/9874"
                },
                "type": "github"
              },
              "hash": "zio/zio#9874",
              "body": "Sigh... Well, this is annoying. When a Cause contains both a failure and a defect (i.e., Fail & Die), failure handling assumes that the Cause does not contain any defects and therefor silently ignores them.\n\nRepro:\n\n```scala\nimport zio.*\n\nobject Foo extends ZIOAppDefault {\n  val dieCause: Cause[String] = Cause.die(new RuntimeException(\"boom\"))\n  val combinedCause = dieCause && Cause.fail(\"boom\")\n\n  def run = ZIO.failCause(combinedCause).catchAll { e =>\n    ZIO.debug(e)\n  } *> ZIO.debug(\"Success\")\n}\n```\nprints:\n```\nhandled: boom\nSuccess\n```\n\nHowever if we substituted `ZIO.failCause(combinedCause)` with `ZIO.failCause(dieCause)`:\n\n```\ntimestamp=2025-05-20T16:31:09.291104Z level=ERROR thread=#zio-fiber-1707930317 message=\"\" cause=\"java.lang.RuntimeException: boom\n\tat Foo$.<clinit>(Foo.scala:4)\n\tat Foo.main(Foo.scala)\n\tat <empty>.Foo.run(Foo.scala:7)\n\tat <empty>.Foo.run(Foo.scala:9)\n\"\n```\n\nWith both of these causes, the outcome should be the same as defects should always be prioritised over failures. This gets even worse when interruption is involved, because the failure handling will be prioritised over it.\n\nHaving said that, this has the potential to massively alter applications so I'm too scared to fix it.\n@ghostdogpr @jdegoes  @hearnadam @guizmaii I summon you all for some wisdom",
              "url": "https://github.com/zio/zio/issues/9874",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9681",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2025-11-24T19:50:49.814Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-24T19:50:49.814Z",
            "created_at": "2025-11-24T19:50:49.814Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9681",
              "status": "open",
              "type": "issue",
              "number": 9681,
              "title": "Scala Native `WeakConcurrentBag` NPE when forking 10K fibers",
              "source": {
                "data": {
                  "id": "source-ZIO#9681",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Scala Native `WeakConcurrentBag` NPE when forking 10K fibers",
                  "body": "```\n[info]   - PromiseSpec - waiter stack safety\n[info]     Exception in thread \"zio-fiber-931\" java.lang.NullPointerException: null\n[info]     \tat scala.scalanative.runtime.package$.throwNullPointer(Unknown Source)\n[info]     \tat <none>.(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.treeifyBin(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.putVal(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap$KeySetView.add(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.addToLongTermStorage(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.add(Unknown Source)\n[info]     \tat zio.internal.FiberScope$global$.add(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.makeChildFiber(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.fork(Unknown Source)\n[info]     \tat zio.ZIO.$anonfun$forkWithScopeOverride$2(Unknown Source)\n[info]     \tat zio.ZIO$$Lambda$280.apply(Unknown Source)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:127)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:124)\n```\nI introduced a new test in #9569 which resulted in this strange failure on Native.",
                  "html_url": "https://github.com/zio/zio/issues/9681"
                },
                "type": "github"
              },
              "hash": "zio/zio#9681",
              "body": "```\n[info]   - PromiseSpec - waiter stack safety\n[info]     Exception in thread \"zio-fiber-931\" java.lang.NullPointerException: null\n[info]     \tat scala.scalanative.runtime.package$.throwNullPointer(Unknown Source)\n[info]     \tat <none>.(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.treeifyBin(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.putVal(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap$KeySetView.add(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.addToLongTermStorage(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.add(Unknown Source)\n[info]     \tat zio.internal.FiberScope$global$.add(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.makeChildFiber(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.fork(Unknown Source)\n[info]     \tat zio.ZIO.$anonfun$forkWithScopeOverride$2(Unknown Source)\n[info]     \tat zio.ZIO$$Lambda$280.apply(Unknown Source)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:127)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:124)\n```\nI introduced a new test in #9569 which resulted in this strange failure on Native.",
              "url": "https://github.com/zio/zio/issues/9681",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          }
        ],
        "next_cursor": null
      }
    }
  }
}