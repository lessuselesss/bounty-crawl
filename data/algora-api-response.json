{
  "result": {
    "data": {
      "json": {
        "items": [
          {
            "id": "PX4#21902",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "PX4",
              "id": "generated-PX4",
              "name": "PX4",
              "description": "",
              "members": [],
              "display_name": "PX4",
              "created_at": "2025-11-09T04:01:12.253Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/PX4?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "PX4",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:12.253Z",
            "created_at": "2025-11-09T04:01:12.253Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-PX4#21902",
              "status": "open",
              "type": "issue",
              "number": 21902,
              "title": "Support EKF2_GPS_POS_* for Multiple GPS",
              "source": {
                "data": {
                  "id": "source-PX4#21902",
                  "user": {
                    "login": "AlexKlimaj",
                    "id": 2019539,
                    "node_id": "MDQ6VXNlcjIwMTk1Mzk=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/2019539?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/AlexKlimaj",
                    "html_url": "https://github.com/AlexKlimaj",
                    "followers_url": "https://api.github.com/users/AlexKlimaj/followers",
                    "following_url": "https://api.github.com/users/AlexKlimaj/following{/other_user}",
                    "gists_url": "https://api.github.com/users/AlexKlimaj/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/AlexKlimaj/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/AlexKlimaj/subscriptions",
                    "organizations_url": "https://api.github.com/users/AlexKlimaj/orgs",
                    "repos_url": "https://api.github.com/users/AlexKlimaj/repos",
                    "events_url": "https://api.github.com/users/AlexKlimaj/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/AlexKlimaj/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Support EKF2_GPS_POS_* for Multiple GPS",
                  "body": "### Describe problem solved by the proposed feature\n\nCurrently the EKF2_GPS_POS_* params only apply to vehicle_gps when it gets used in the EKF.\n\n### Describe your preferred solution\n\nI propose we move these params to an offset in the GPS driver.\n\n### Describe possible alternatives\n\nDo we need these offsets at all?\n\n### Additional context\n\n_No response_",
                  "html_url": "https://github.com/PX4/PX4-Autopilot/issues/21902"
                },
                "type": "github"
              },
              "hash": "PX4/PX4-Autopilot#21902",
              "body": "### Describe problem solved by the proposed feature\n\nCurrently the EKF2_GPS_POS_* params only apply to vehicle_gps when it gets used in the EKF.\n\n### Describe your preferred solution\n\nI propose we move these params to an offset in the GPS driver.\n\n### Describe possible alternatives\n\nDo we need these offsets at all?\n\n### Additional context\n\n_No response_",
              "url": "https://github.com/PX4/PX4-Autopilot/issues/21902",
              "tech": [
                "go"
              ],
              "repo_name": "PX4-Autopilot",
              "repo_owner": "PX4",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "PX4#19970",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "PX4",
              "id": "generated-PX4",
              "name": "PX4",
              "description": "",
              "members": [],
              "display_name": "PX4",
              "created_at": "2025-11-09T04:01:13.002Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/PX4?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "PX4",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:13.002Z",
            "created_at": "2025-11-09T04:01:13.002Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-PX4#19970",
              "status": "open",
              "type": "issue",
              "number": 19970,
              "title": "[Project Tracker] Sensor configuration display UI",
              "source": {
                "data": {
                  "id": "source-PX4#19970",
                  "user": {
                    "login": "junwoo091400",
                    "id": 23277211,
                    "node_id": "MDQ6VXNlcjIzMjc3MjEx",
                    "avatar_url": "https://avatars.githubusercontent.com/u/23277211?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/junwoo091400",
                    "html_url": "https://github.com/junwoo091400",
                    "followers_url": "https://api.github.com/users/junwoo091400/followers",
                    "following_url": "https://api.github.com/users/junwoo091400/following{/other_user}",
                    "gists_url": "https://api.github.com/users/junwoo091400/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/junwoo091400/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/junwoo091400/subscriptions",
                    "organizations_url": "https://api.github.com/users/junwoo091400/orgs",
                    "repos_url": "https://api.github.com/users/junwoo091400/repos",
                    "events_url": "https://api.github.com/users/junwoo091400/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/junwoo091400/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Project Tracker] Sensor configuration display UI",
                  "body": "## Describe problem solved by the proposed feature\r\nCurrently it is hard to figure out which sensors are connected where, with which configuration and which priority (e.g. `CAL_MAG0_PRIO`) in a single view. For example during my [boat project](https://discuss.px4.io/t/rc-speed-boat-with-px4-episode-1-using-px4-to-control-the-boat/28429#things-that-are-still-ambiguous-to-me-22) build, I wasn't sure if I needed to set the priority of magnetometer manually or not.\r\n\r\nThis is also quite related to the calibration pain addressed in the issue #19459. What can we do to improve user experience for setting up the sensors? If so, which part should be addressed and how?\r\n\r\nWhat could be great (in my opinion) could be something like this in QGC (it won't be a literal text output like this, but just for giving some idea):\r\n\r\n```\r\n<mag-type> | <mag-orientation> | <mag-priority> | <mag-protocol?> # First mag sensor\r\n<mag-type> | <mag-orientation> | <mag-priority> | <mag-protocol?> # One for the second mag\r\n<baro-type> |              | <baro-priority> | <baro-protocol>\r\n<gyro-type> | <gyro-orientation> | <gyro-priority> | <gyro-protocol>\r\n```\r\n\r\nBut I am also not sure what others expectation / needs are, so any feedback would be appreciated!\r\n\r\n## Describe your preferred solution\r\n* @davids5 pointed out that transferring device tree information over to QGC could be a solution. Could you elaborate on that?\r\n* @dagar pointed out that having a unified view in general would be good. Could you let me know if a view I suggested above is similar to what you have imagined?\r\n",
                  "html_url": "https://github.com/PX4/PX4-Autopilot/issues/19970"
                },
                "type": "github"
              },
              "hash": "PX4/PX4-Autopilot#19970",
              "body": "## Describe problem solved by the proposed feature\r\nCurrently it is hard to figure out which sensors are connected where, with which configuration and which priority (e.g. `CAL_MAG0_PRIO`) in a single view. For example during my [boat project](https://discuss.px4.io/t/rc-speed-boat-with-px4-episode-1-using-px4-to-control-the-boat/28429#things-that-are-still-ambiguous-to-me-22) build, I wasn't sure if I needed to set the priority of magnetometer manually or not.\r\n\r\nThis is also quite related to the calibration pain addressed in the issue #19459. What can we do to improve user experience for setting up the sensors? If so, which part should be addressed and how?\r\n\r\nWhat could be great (in my opinion) could be something like this in QGC (it won't be a literal text output like this, but just for giving some idea):\r\n\r\n```\r\n<mag-type> | <mag-orientation> | <mag-priority> | <mag-protocol?> # First mag sensor\r\n<mag-type> | <mag-orientation> | <mag-priority> | <mag-protocol?> # One for the second mag\r\n<baro-type> |              | <baro-priority> | <baro-protocol>\r\n<gyro-type> | <gyro-orientation> | <gyro-priority> | <gyro-protocol>\r\n```\r\n\r\nBut I am also not sure what others expectation / needs are, so any feedback would be appreciated!\r\n\r\n## Describe your preferred solution\r\n* @davids5 pointed out that transferring device tree information over to QGC could be a solution. Could you elaborate on that?\r\n* @dagar pointed out that having a unified view in general would be good. Could you let me know if a view I suggested above is similar to what you have imagined?\r\n",
              "url": "https://github.com/PX4/PX4-Autopilot/issues/19970",
              "tech": [
                "go"
              ],
              "repo_name": "PX4-Autopilot",
              "repo_owner": "PX4",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "Mudlet#8030",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "Mudlet",
              "id": "generated-Mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2025-11-09T04:01:36.490Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/Mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:36.490Z",
            "created_at": "2025-11-09T04:01:36.490Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-Mudlet#8030",
              "status": "open",
              "type": "issue",
              "number": 8030,
              "title": "Split Mudlet up into `libmudlet` and a Qt front-end",
              "source": {
                "data": {
                  "id": "source-Mudlet#8030",
                  "user": {
                    "login": "vadi2",
                    "id": 110988,
                    "node_id": "MDQ6VXNlcjExMDk4OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/110988?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vadi2",
                    "html_url": "https://github.com/vadi2",
                    "followers_url": "https://api.github.com/users/vadi2/followers",
                    "following_url": "https://api.github.com/users/vadi2/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vadi2/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vadi2/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vadi2/subscriptions",
                    "organizations_url": "https://api.github.com/users/vadi2/orgs",
                    "repos_url": "https://api.github.com/users/vadi2/repos",
                    "events_url": "https://api.github.com/users/vadi2/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vadi2/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Split Mudlet up into `libmudlet` and a Qt front-end",
                  "body": "#### Description of requested feature:\nMudlet is a Qt Widgets based application, which works great for Linux/macOS/Windows, but not so great for running natively on Android or iPhone, which are popular feature requests.\n\nAkin to how VLC is split into libVLC and various front-ends, split Mudlet out into libmudlet (providing all of core functionality) and a Qt Widget frontend that makes use of all of the core functionality.\n\n**Prior to taking this issue up**, open a new github issue here and in there, provide (1) plan for how the library/frontend split will work on an architectural level, and (2) a plan for the migration strategy, since once mega PR will not work for this.\n\n#### Reasons for adding feature:\n\n1. allowing Mudlet to eventually have a mobile-native version\n\n#### Expected result of feature\nlibmudlet may use Qt Core classes (QObject, QTimer, QThread, QSettings, etc.) but must not depend on Qt Widgets, Qt GUI, or any UI-related Qt modules.\n\n Mudlet's functionality pre and post-split should be 100% the same, nothing should be lost in the transition:\n -  All existing automated tests must pass, plus:\n  - All menu items and dialogs function identically\n  - All Lua API functions return identical results\n  - All protocol features work (GMCP, MXP, etc.)\n  - All file formats (profiles, packages) remain compatible\n\nPerformance of the network/text display stack as well as the trigger engine should be comparable as well (no more than 10% lost). Measured in:\n\n  - Text display: X lines/second in main console (can be measured using [stressinator](https://packages.mudlet.org/packages#pkg-Stressinator))\n  - Network: Y MB/s processing throughput (needs to be measured)\n  - Memory: no more than 10% increase in base memory usage\n\n####\n\n",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/8030"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#8030",
              "body": "#### Description of requested feature:\nMudlet is a Qt Widgets based application, which works great for Linux/macOS/Windows, but not so great for running natively on Android or iPhone, which are popular feature requests.\n\nAkin to how VLC is split into libVLC and various front-ends, split Mudlet out into libmudlet (providing all of core functionality) and a Qt Widget frontend that makes use of all of the core functionality.\n\n**Prior to taking this issue up**, open a new github issue here and in there, provide (1) plan for how the library/frontend split will work on an architectural level, and (2) a plan for the migration strategy, since once mega PR will not work for this.\n\n#### Reasons for adding feature:\n\n1. allowing Mudlet to eventually have a mobile-native version\n\n#### Expected result of feature\nlibmudlet may use Qt Core classes (QObject, QTimer, QThread, QSettings, etc.) but must not depend on Qt Widgets, Qt GUI, or any UI-related Qt modules.\n\n Mudlet's functionality pre and post-split should be 100% the same, nothing should be lost in the transition:\n -  All existing automated tests must pass, plus:\n  - All menu items and dialogs function identically\n  - All Lua API functions return identical results\n  - All protocol features work (GMCP, MXP, etc.)\n  - All file formats (profiles, packages) remain compatible\n\nPerformance of the network/text display stack as well as the trigger engine should be comparable as well (no more than 10% lost). Measured in:\n\n  - Text display: X lines/second in main console (can be measured using [stressinator](https://packages.mudlet.org/packages#pkg-Stressinator))\n  - Network: Y MB/s processing throughput (needs to be measured)\n  - Memory: no more than 10% increase in base memory usage\n\n####\n\n",
              "url": "https://github.com/Mudlet/Mudlet/issues/8030",
              "tech": [
                "go"
              ],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "Mudlet#3172",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "Mudlet",
              "id": "generated-Mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2025-11-09T04:01:36.598Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/Mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:36.598Z",
            "created_at": "2025-11-09T04:01:36.598Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-Mudlet#3172",
              "status": "open",
              "type": "issue",
              "number": 3172,
              "title": "generic mapper: add video walkthrough on how to set it up",
              "source": {
                "data": {
                  "id": "source-Mudlet#3172",
                  "user": {
                    "login": "vadi2",
                    "id": 110988,
                    "node_id": "MDQ6VXNlcjExMDk4OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/110988?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vadi2",
                    "html_url": "https://github.com/vadi2",
                    "followers_url": "https://api.github.com/users/vadi2/followers",
                    "following_url": "https://api.github.com/users/vadi2/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vadi2/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vadi2/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vadi2/subscriptions",
                    "organizations_url": "https://api.github.com/users/vadi2/orgs",
                    "repos_url": "https://api.github.com/users/vadi2/repos",
                    "events_url": "https://api.github.com/users/vadi2/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vadi2/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "generic mapper: add video walkthrough on how to set it up",
                  "body": "#### Brief summary of issue / Description of requested feature:\r\nIt's been requested a few times, and it would be really handy to link people to a video explanation of how the generic mapper script should be setup.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1. \r\n2. \r\n3. \r\n\r\n#### Error output / Expected result of feature\r\n\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/3172"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#3172",
              "body": "#### Brief summary of issue / Description of requested feature:\r\nIt's been requested a few times, and it would be really handy to link people to a video explanation of how the generic mapper script should be setup.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1. \r\n2. \r\n3. \r\n\r\n#### Error output / Expected result of feature\r\n\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n",
              "url": "https://github.com/Mudlet/Mudlet/issues/3172",
              "tech": [
                "go"
              ],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "Mudlet#7126",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "Mudlet",
              "id": "generated-Mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2025-11-09T04:01:36.689Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/Mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:36.689Z",
            "created_at": "2025-11-09T04:01:36.689Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-Mudlet#7126",
              "status": "open",
              "type": "issue",
              "number": 7126,
              "title": "Implement sentry.io's Qt SDK for crash reporting",
              "source": {
                "data": {
                  "id": "source-Mudlet#7126",
                  "user": {
                    "login": "vadi2",
                    "id": 110988,
                    "node_id": "MDQ6VXNlcjExMDk4OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/110988?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vadi2",
                    "html_url": "https://github.com/vadi2",
                    "followers_url": "https://api.github.com/users/vadi2/followers",
                    "following_url": "https://api.github.com/users/vadi2/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vadi2/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vadi2/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vadi2/subscriptions",
                    "organizations_url": "https://api.github.com/users/vadi2/orgs",
                    "repos_url": "https://api.github.com/users/vadi2/repos",
                    "events_url": "https://api.github.com/users/vadi2/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vadi2/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Implement sentry.io's Qt SDK for crash reporting",
                  "body": "#### Brief summary of issue / Description of requested feature:\r\nImplement sentry.io's [Qt SDK](https://docs.sentry.io/platforms/native/guides/qt/) for crash log reporting on Linux using gcc, macOS using clang, and Windows using mingw.\r\n\r\nIf the task cannot be completed entirely, you will receive 2/3 of the bounty if 2/3 of the platforms are operational.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1. Mudlet crashes are known to Mudlet developers\r\n\r\n#### Error output / Expected result of feature\r\nCrash log reporting working on Linux using gcc, macOS using clang, and Windows using mingw.\r\n\r\n#### Extra information, such as the Mudlet version, operating system and ideas for how to solve / implement:\r\nPlease note that a proof of concept for crash reporting on Linux has already been implemented, so that part should be achievable.",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/7126"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#7126",
              "body": "#### Brief summary of issue / Description of requested feature:\r\nImplement sentry.io's [Qt SDK](https://docs.sentry.io/platforms/native/guides/qt/) for crash log reporting on Linux using gcc, macOS using clang, and Windows using mingw.\r\n\r\nIf the task cannot be completed entirely, you will receive 2/3 of the bounty if 2/3 of the platforms are operational.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1. Mudlet crashes are known to Mudlet developers\r\n\r\n#### Error output / Expected result of feature\r\nCrash log reporting working on Linux using gcc, macOS using clang, and Windows using mingw.\r\n\r\n#### Extra information, such as the Mudlet version, operating system and ideas for how to solve / implement:\r\nPlease note that a proof of concept for crash reporting on Linux has already been implemented, so that part should be achievable.",
              "url": "https://github.com/Mudlet/Mudlet/issues/7126",
              "tech": [],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "Mudlet#689",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "Mudlet",
              "id": "generated-Mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2025-11-09T04:01:36.836Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/Mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:36.836Z",
            "created_at": "2025-11-09T04:01:36.836Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-Mudlet#689",
              "status": "open",
              "type": "issue",
              "number": 689,
              "title": "Support telnet:// links",
              "source": {
                "data": {
                  "id": "source-Mudlet#689",
                  "user": {
                    "login": "vadi2",
                    "id": 110988,
                    "node_id": "MDQ6VXNlcjExMDk4OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/110988?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vadi2",
                    "html_url": "https://github.com/vadi2",
                    "followers_url": "https://api.github.com/users/vadi2/followers",
                    "following_url": "https://api.github.com/users/vadi2/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vadi2/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vadi2/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vadi2/subscriptions",
                    "organizations_url": "https://api.github.com/users/vadi2/orgs",
                    "repos_url": "https://api.github.com/users/vadi2/repos",
                    "events_url": "https://api.github.com/users/vadi2/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vadi2/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Support telnet:// links",
                  "body": "Idea: MUDs should be able to provide an easy to use link with their connection info to spawn Mudlet and get it to connect to their game. Similar to apt://, steam:// and so forth links.\r\n\r\nI think Mudlet should support those types of links - it'd be a lot more convenient for players to try out new MUDs if they only have to click on a link, instead of copying the server and port, going to Mudlet, making a new profile and so on.\r\n\r\nAs for the naming of the link, we could either go with a custom one: mudlet:// or - use an already standard one (telnet://), which would be much better as some websites use it already (http://dmud.thebbs.org/lotflink.htm) and it would be compatible with other MUDs clients.\r\n\r\nI believe the latter option is better.\r\n\r\nTelnet links seem to work in the format of: telnet://<server>[:<optional port #>], see https://tools.ietf.org/html/rfc4248 for the actual spec.\r\n\r\nThe logic for this could be the following:\r\n\r\nWhen Mudlet is spawned via the telnet link, check to see if any profile(s) server matches server field of the link. If multiple profiles do, auto-load the latest profile used. If one matches, load that profile. If not profiles match...\r\n\r\nCreate a new profile with the given server and port data, and the profiles name will be the servers name as well. Auto-load this newly created profile.\r\n\r\n\r\nI think these cases sound plausible. There'll an issue with peoples already made profile using the server name vs IP address directly as webmasters might, but that's not something that could be easily avoided.\r\n\r\nLaunchpad Details: [#LP1187243](https://bugs.launchpad.net/bugs/1187243) Vadim Peretokin - 2013-06-04 04:47:05 +0000",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/689"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#689",
              "body": "Idea: MUDs should be able to provide an easy to use link with their connection info to spawn Mudlet and get it to connect to their game. Similar to apt://, steam:// and so forth links.\r\n\r\nI think Mudlet should support those types of links - it'd be a lot more convenient for players to try out new MUDs if they only have to click on a link, instead of copying the server and port, going to Mudlet, making a new profile and so on.\r\n\r\nAs for the naming of the link, we could either go with a custom one: mudlet:// or - use an already standard one (telnet://), which would be much better as some websites use it already (http://dmud.thebbs.org/lotflink.htm) and it would be compatible with other MUDs clients.\r\n\r\nI believe the latter option is better.\r\n\r\nTelnet links seem to work in the format of: telnet://<server>[:<optional port #>], see https://tools.ietf.org/html/rfc4248 for the actual spec.\r\n\r\nThe logic for this could be the following:\r\n\r\nWhen Mudlet is spawned via the telnet link, check to see if any profile(s) server matches server field of the link. If multiple profiles do, auto-load the latest profile used. If one matches, load that profile. If not profiles match...\r\n\r\nCreate a new profile with the given server and port data, and the profiles name will be the servers name as well. Auto-load this newly created profile.\r\n\r\n\r\nI think these cases sound plausible. There'll an issue with peoples already made profile using the server name vs IP address directly as webmasters might, but that's not something that could be easily avoided.\r\n\r\nLaunchpad Details: [#LP1187243](https://bugs.launchpad.net/bugs/1187243) Vadim Peretokin - 2013-06-04 04:47:05 +0000",
              "url": "https://github.com/Mudlet/Mudlet/issues/689",
              "tech": [],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "Mudlet#707",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "Mudlet",
              "id": "generated-Mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2025-11-09T04:01:36.958Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/Mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:36.958Z",
            "created_at": "2025-11-09T04:01:36.958Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-Mudlet#707",
              "status": "open",
              "type": "issue",
              "number": 707,
              "title": "Undo/redo support in editor",
              "source": {
                "data": {
                  "id": "source-Mudlet#707",
                  "user": {
                    "login": "vadi2",
                    "id": 110988,
                    "node_id": "MDQ6VXNlcjExMDk4OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/110988?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vadi2",
                    "html_url": "https://github.com/vadi2",
                    "followers_url": "https://api.github.com/users/vadi2/followers",
                    "following_url": "https://api.github.com/users/vadi2/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vadi2/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vadi2/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vadi2/subscriptions",
                    "organizations_url": "https://api.github.com/users/vadi2/orgs",
                    "repos_url": "https://api.github.com/users/vadi2/repos",
                    "events_url": "https://api.github.com/users/vadi2/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vadi2/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Undo/redo support in editor",
                  "body": "It would be really good if people could undo all actions in Mudlet's editor:\r\n\r\n![image](https://user-images.githubusercontent.com/110988/235861804-593c6899-a82a-4f02-bf19-72809c90dbcb.png)\r\n\r\nThis would be particularly helpful in case an item is deleted or moved somewhere else by accident.\r\n\r\nLaunchpad Details: [#LP1664710](https://bugs.launchpad.net/bugs/1664710) Vadim Peretokin - 2017-02-14 20:31:12 +0000",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/707"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#707",
              "body": "It would be really good if people could undo all actions in Mudlet's editor:\r\n\r\n![image](https://user-images.githubusercontent.com/110988/235861804-593c6899-a82a-4f02-bf19-72809c90dbcb.png)\r\n\r\nThis would be particularly helpful in case an item is deleted or moved somewhere else by accident.\r\n\r\nLaunchpad Details: [#LP1664710](https://bugs.launchpad.net/bugs/1664710) Vadim Peretokin - 2017-02-14 20:31:12 +0000",
              "url": "https://github.com/Mudlet/Mudlet/issues/707",
              "tech": [],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "Mudlet#5310",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "Mudlet",
              "id": "generated-Mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2025-11-09T04:01:37.054Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/Mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:37.054Z",
            "created_at": "2025-11-09T04:01:37.054Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-Mudlet#5310",
              "status": "open",
              "type": "issue",
              "number": 5310,
              "title": "Autocomplete steals window focus, prevents further typing",
              "source": {
                "data": {
                  "id": "source-Mudlet#5310",
                  "user": {
                    "login": "Matthew-Marsh",
                    "id": 79426017,
                    "node_id": "MDQ6VXNlcjc5NDI2MDE3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/79426017?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Matthew-Marsh",
                    "html_url": "https://github.com/Matthew-Marsh",
                    "followers_url": "https://api.github.com/users/Matthew-Marsh/followers",
                    "following_url": "https://api.github.com/users/Matthew-Marsh/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Matthew-Marsh/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Matthew-Marsh/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Matthew-Marsh/subscriptions",
                    "organizations_url": "https://api.github.com/users/Matthew-Marsh/orgs",
                    "repos_url": "https://api.github.com/users/Matthew-Marsh/repos",
                    "events_url": "https://api.github.com/users/Matthew-Marsh/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Matthew-Marsh/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Autocomplete steals window focus, prevents further typing",
                  "body": "#### Brief summary of issue / Description of requested feature:\r\n\r\nOccasionally encountering an issue where autocomplete pops up and prevents typing. Need to esc to remove the autocomplete, but will pop up again with another relevant letter.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1.  Unknown to why it begins.\r\n2.  Typing a letter that has a corresponding lua command in the autocomplete. \r\n\r\n#### Error output / Expected result of feature\r\n\r\nExpected result: Being able to continue typing outside of autocomplete.\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n\r\nMudlet version: 4.11.2\r\nWindows 10 Home\r\nVideo recording: https://youtu.be/qJF0h2MDWzg\r\n",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/5310"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#5310",
              "body": "#### Brief summary of issue / Description of requested feature:\r\n\r\nOccasionally encountering an issue where autocomplete pops up and prevents typing. Need to esc to remove the autocomplete, but will pop up again with another relevant letter.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1.  Unknown to why it begins.\r\n2.  Typing a letter that has a corresponding lua command in the autocomplete. \r\n\r\n#### Error output / Expected result of feature\r\n\r\nExpected result: Being able to continue typing outside of autocomplete.\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n\r\nMudlet version: 4.11.2\r\nWindows 10 Home\r\nVideo recording: https://youtu.be/qJF0h2MDWzg\r\n",
              "url": "https://github.com/Mudlet/Mudlet/issues/5310",
              "tech": [],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#3957",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2025-11-09T04:01:37.491Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:37.491Z",
            "created_at": "2025-11-09T04:01:37.491Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3957",
              "status": "open",
              "type": "issue",
              "number": 3957,
              "title": "Add properties to a collection",
              "source": {
                "data": {
                  "id": "source-qdrant#3957",
                  "user": {
                    "login": "Waffleboy",
                    "id": 12254813,
                    "node_id": "MDQ6VXNlcjEyMjU0ODEz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/12254813?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Waffleboy",
                    "html_url": "https://github.com/Waffleboy",
                    "followers_url": "https://api.github.com/users/Waffleboy/followers",
                    "following_url": "https://api.github.com/users/Waffleboy/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Waffleboy/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Waffleboy/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Waffleboy/subscriptions",
                    "organizations_url": "https://api.github.com/users/Waffleboy/orgs",
                    "repos_url": "https://api.github.com/users/Waffleboy/repos",
                    "events_url": "https://api.github.com/users/Waffleboy/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Waffleboy/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add properties to a collection",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\nIf theres any information that applies table-wide, theres currently no way to add it in unless we add it as a metadata to every row. This causes space wastage\r\n\r\n**Describe the solution you'd like**\r\nAbility to add any properties to the table. eg,\r\n\r\n```python\r\ncollection = client.get_collection(\"example_tablename\")\r\nprint(collection.properties) # --> gives dictionary of properties. default {}\r\n\r\ncollection.set_property(\"main_column\", \"column a\") --> sets it in property\r\n\r\nprint(collection.properties) # --> {\"main_column\":\"column a\"}\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nCurrently adding as a column metadata instead (so every row has a static value)\r\n\r\n**Additional context**\r\n",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3957"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3957",
              "body": "**Is your feature request related to a problem? Please describe.**\r\nIf theres any information that applies table-wide, theres currently no way to add it in unless we add it as a metadata to every row. This causes space wastage\r\n\r\n**Describe the solution you'd like**\r\nAbility to add any properties to the table. eg,\r\n\r\n```python\r\ncollection = client.get_collection(\"example_tablename\")\r\nprint(collection.properties) # --> gives dictionary of properties. default {}\r\n\r\ncollection.set_property(\"main_column\", \"column a\") --> sets it in property\r\n\r\nprint(collection.properties) # --> {\"main_column\":\"column a\"}\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nCurrently adding as a column metadata instead (so every row has a static value)\r\n\r\n**Additional context**\r\n",
              "url": "https://github.com/qdrant/qdrant/issues/3957",
              "tech": [
                "go"
              ],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#3531",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2025-11-09T04:01:37.605Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:37.605Z",
            "created_at": "2025-11-09T04:01:37.605Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3531",
              "status": "open",
              "type": "issue",
              "number": 3531,
              "title": "Better error response for wrong datetime format in REST filter",
              "source": {
                "data": {
                  "id": "source-qdrant#3531",
                  "user": {
                    "login": "timvisee",
                    "id": 856222,
                    "node_id": "MDQ6VXNlcjg1NjIyMg==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/856222?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/timvisee",
                    "html_url": "https://github.com/timvisee",
                    "followers_url": "https://api.github.com/users/timvisee/followers",
                    "following_url": "https://api.github.com/users/timvisee/following{/other_user}",
                    "gists_url": "https://api.github.com/users/timvisee/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/timvisee/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/timvisee/subscriptions",
                    "organizations_url": "https://api.github.com/users/timvisee/orgs",
                    "repos_url": "https://api.github.com/users/timvisee/repos",
                    "events_url": "https://api.github.com/users/timvisee/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/timvisee/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Better error response for wrong datetime format in REST filter",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\nWe recently merged <https://github.com/qdrant/qdrant/pull/3395> which adds a datetime payload index.\r\n\r\nCurrently, the datetime parser is very strict, only allowing [RFC 3339](https://www.rfc-editor.org/rfc/rfc3339) formats in our REST API. A common format such as `YYYY-MM-DD HH:MM:SS` is currently not accepted.\r\n\r\nIf you'd send the following request:\r\n\r\n```json\r\nPOST collections/test_collection/points/scroll\r\n{\r\n  \"limit\": 10,\r\n  \"filter\": {\r\n    \"must\": [\r\n      {\r\n        \"key\": \"updated\",\r\n        \"datetime_range\": {\r\n          \"gt\": \"2014-01-01T00:00:00\"\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nYou'd receive the following error:\r\n\r\n```\r\nFormat error in JSON body: data did not match any variant of untagged enum Condition at line 1 column 96\r\n```\r\n\r\nThis error is very confusing.\r\n\r\n**Describe the solution you'd like**\r\nWe'd strongly prefer a more descriptive error message instead.\r\n\r\nSomething like this would be a lot better:\r\n\r\n```\r\nFormat error in JSON body: '2014-01-01T00:00:00' does not match any accepted datetime format\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n_None_\r\n\r\n**Additional context**\r\nRelated issue: <https://github.com/qdrant/qdrant/issues/3529>",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3531"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3531",
              "body": "**Is your feature request related to a problem? Please describe.**\r\nWe recently merged <https://github.com/qdrant/qdrant/pull/3395> which adds a datetime payload index.\r\n\r\nCurrently, the datetime parser is very strict, only allowing [RFC 3339](https://www.rfc-editor.org/rfc/rfc3339) formats in our REST API. A common format such as `YYYY-MM-DD HH:MM:SS` is currently not accepted.\r\n\r\nIf you'd send the following request:\r\n\r\n```json\r\nPOST collections/test_collection/points/scroll\r\n{\r\n  \"limit\": 10,\r\n  \"filter\": {\r\n    \"must\": [\r\n      {\r\n        \"key\": \"updated\",\r\n        \"datetime_range\": {\r\n          \"gt\": \"2014-01-01T00:00:00\"\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nYou'd receive the following error:\r\n\r\n```\r\nFormat error in JSON body: data did not match any variant of untagged enum Condition at line 1 column 96\r\n```\r\n\r\nThis error is very confusing.\r\n\r\n**Describe the solution you'd like**\r\nWe'd strongly prefer a more descriptive error message instead.\r\n\r\nSomething like this would be a lot better:\r\n\r\n```\r\nFormat error in JSON body: '2014-01-01T00:00:00' does not match any accepted datetime format\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n_None_\r\n\r\n**Additional context**\r\nRelated issue: <https://github.com/qdrant/qdrant/issues/3529>",
              "url": "https://github.com/qdrant/qdrant/issues/3531",
              "tech": [],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#3322",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2025-11-09T04:01:37.698Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:37.698Z",
            "created_at": "2025-11-09T04:01:37.698Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3322",
              "status": "open",
              "type": "issue",
              "number": 3322,
              "title": "Per-collection metrics for Prometheus",
              "source": {
                "data": {
                  "id": "source-qdrant#3322",
                  "user": {
                    "login": "generall",
                    "id": 1935623,
                    "node_id": "MDQ6VXNlcjE5MzU2MjM=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1935623?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/generall",
                    "html_url": "https://github.com/generall",
                    "followers_url": "https://api.github.com/users/generall/followers",
                    "following_url": "https://api.github.com/users/generall/following{/other_user}",
                    "gists_url": "https://api.github.com/users/generall/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/generall/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/generall/subscriptions",
                    "organizations_url": "https://api.github.com/users/generall/orgs",
                    "repos_url": "https://api.github.com/users/generall/repos",
                    "events_url": "https://api.github.com/users/generall/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/generall/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Per-collection metrics for Prometheus",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, all metrics in `/metrics` are global, meaning that its impossible to see differences per collection.\r\n\r\nIn addition to that, all our metrics should have per-collection granularity to allow better aggregation in Prometheus, including:\r\n\r\n- point/vector counts\r\n- REST/gRPC requests\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample:\r\n```\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\"} 0.000046\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection\"} 0.000049\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection-2\"} 0.000046\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreate dedicated endpoint for each collection `/collections/my-collecton/metrics`\r\nbut feedback from DevOps on this idea was negative.\r\n\r\n**Additional context**\r\n\r\nIt might be beneficial to allow users to disable per-collection output. It is especially relevant if there are a lot of collections and metric response could become huge. But this is a nice-to-have requirement.\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently\r\n\r\n",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3322"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3322",
              "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, all metrics in `/metrics` are global, meaning that its impossible to see differences per collection.\r\n\r\nIn addition to that, all our metrics should have per-collection granularity to allow better aggregation in Prometheus, including:\r\n\r\n- point/vector counts\r\n- REST/gRPC requests\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample:\r\n```\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\"} 0.000046\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection\"} 0.000049\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection-2\"} 0.000046\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreate dedicated endpoint for each collection `/collections/my-collecton/metrics`\r\nbut feedback from DevOps on this idea was negative.\r\n\r\n**Additional context**\r\n\r\nIt might be beneficial to allow users to disable per-collection output. It is especially relevant if there are a lot of collections and metric response could become huge. But this is a nice-to-have requirement.\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently\r\n\r\n",
              "url": "https://github.com/qdrant/qdrant/issues/3322",
              "tech": [],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#3321",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2025-11-09T04:01:37.791Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:37.791Z",
            "created_at": "2025-11-09T04:01:37.791Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3321",
              "status": "open",
              "type": "issue",
              "number": 3321,
              "title": "Allow Qdrant to run on read-only FS",
              "source": {
                "data": {
                  "id": "source-qdrant#3321",
                  "user": {
                    "login": "generall",
                    "id": 1935623,
                    "node_id": "MDQ6VXNlcjE5MzU2MjM=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1935623?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/generall",
                    "html_url": "https://github.com/generall",
                    "followers_url": "https://api.github.com/users/generall/followers",
                    "following_url": "https://api.github.com/users/generall/following{/other_user}",
                    "gists_url": "https://api.github.com/users/generall/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/generall/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/generall/subscriptions",
                    "organizations_url": "https://api.github.com/users/generall/orgs",
                    "repos_url": "https://api.github.com/users/generall/repos",
                    "events_url": "https://api.github.com/users/generall/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/generall/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Allow Qdrant to run on read-only FS",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently qdrant requires write access to storage directory, even if there are no write operations happening in the system.\r\nIt would be interesting in some scenarios to have an ability to run qdrant from read-only FS. For example, from the mounted network FS, so that multiple qdrant instances can serve same data.\r\n\r\n\r\n**Describe the solution you'd like**\r\n\r\nIntroduce a new CLI argument `--read-only` which will enable read only mode in qdrant.\r\n\r\nFor update APIs read-only instance should behave in the same way as for read-only API key - respond with `403 Forbidden` and explanation that the instance is in read-only mode.\r\n\r\nDistributed deployment can't be read-only.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nAutomatic fallback into read-only if the file system doesn't allow writes, but it seems less flexible and error-prone.\r\n\r\n**Additional context**\r\n\r\nread-only mode assumes skipping WAL reading, so all changes should be applied and flushed to the real storage in advance\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently \r\n\r\n",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3321"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3321",
              "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently qdrant requires write access to storage directory, even if there are no write operations happening in the system.\r\nIt would be interesting in some scenarios to have an ability to run qdrant from read-only FS. For example, from the mounted network FS, so that multiple qdrant instances can serve same data.\r\n\r\n\r\n**Describe the solution you'd like**\r\n\r\nIntroduce a new CLI argument `--read-only` which will enable read only mode in qdrant.\r\n\r\nFor update APIs read-only instance should behave in the same way as for read-only API key - respond with `403 Forbidden` and explanation that the instance is in read-only mode.\r\n\r\nDistributed deployment can't be read-only.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nAutomatic fallback into read-only if the file system doesn't allow writes, but it seems less flexible and error-prone.\r\n\r\n**Additional context**\r\n\r\nread-only mode assumes skipping WAL reading, so all changes should be applied and flushed to the real storage in advance\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently \r\n\r\n",
              "url": "https://github.com/qdrant/qdrant/issues/3321",
              "tech": [],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#2620",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2025-11-09T04:01:37.911Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:37.911Z",
            "created_at": "2025-11-09T04:01:37.911Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#2620",
              "status": "open",
              "type": "issue",
              "number": 2620,
              "title": "Local Qdrant Snapshot throwing No such file or directory (OS error 2)",
              "source": {
                "data": {
                  "id": "source-qdrant#2620",
                  "user": {
                    "login": "dkirman-re",
                    "id": 84460102,
                    "node_id": "MDQ6VXNlcjg0NDYwMTAy",
                    "avatar_url": "https://avatars.githubusercontent.com/u/84460102?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/dkirman-re",
                    "html_url": "https://github.com/dkirman-re",
                    "followers_url": "https://api.github.com/users/dkirman-re/followers",
                    "following_url": "https://api.github.com/users/dkirman-re/following{/other_user}",
                    "gists_url": "https://api.github.com/users/dkirman-re/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/dkirman-re/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/dkirman-re/subscriptions",
                    "organizations_url": "https://api.github.com/users/dkirman-re/orgs",
                    "repos_url": "https://api.github.com/users/dkirman-re/repos",
                    "events_url": "https://api.github.com/users/dkirman-re/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/dkirman-re/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Local Qdrant Snapshot throwing No such file or directory (OS error 2)",
                  "body": "## Current Behavior\r\nI have an instance of qdrant running locally on docker using the qdrant/qdrant:latest image. I have 11 collections, all of which are empty except for one named rrdb_matter_2. I haven't experimented with sharding or clusters yet, I am simply trying to test snapshots at scale. When I attempt to make a POST request to create a new snapshot (/collections/rrdb_matter_2/snapshots), I am eventually met with the following error:\r\n```\r\n[2023-09-07T20:37:53.799Z WARN  qdrant::actix::helpers] error processing request: Error while copy WAL \"./storage/snapshots_temp/rrdb_matter_2-1016472092926465-2023-09-07-20-37-31.tmp/0\" No such file or directory (os error 2)\r\n[2023-09-07T20:37:53.799Z INFO  actix_web::middleware::logger] 172.17.0.1 \"POST /collections/rrdb_matter_2/snapshots HTTP/1.1\" 500 195 \"-\" \"Apache-HttpClient/4.5.13 (Java/17.0.2)\" 21.905568\r\n```\r\n## Steps to Reproduce\r\n1. Pull latest docker image (v1.5.0)\r\n2. Run container using `docker run -p 6333:6333 -v $PWD/qdrant_storage:/qdrant/storage:z qdrant/qdrant:latest`\r\n3. After creating a new collection, load ~75,000 points with all 3 vector distances (euclidean, dot, cosine) referencing the same set of embeddings to the collection.\r\n4. Attempt to create a snapshot using the /collections/collection_name/snapshot POST request\r\n\r\nThe collection's stats are as follows:\r\n```\r\n{\r\n\"status\":\"green\",\"optimizer_status\":\"ok\",\"vectors_count\":227400,\"indexed_vectors_count\":162600,\"points_count\":75800,\"segments_count\":4,\"config\":{\"params\":{\"vectors\":{\"cosine\":{\"size\":384,\"distance\":\"Cosine\"},\"dot\":{\"size\":384,\"distance\":\"Dot\"},\"euclidean\":{\"size\":384,\"distance\":\"Euclid\"}},\"shard_number\":1,\"replication_factor\":1,\"write_consistency_factor\":1,\"on_disk_payload\":true},\"hnsw_config\":{\"m\":16,\"ef_construct\":100,\"full_scan_threshold\":10000,\"max_indexing_threads\":0,\"on_disk\":false},\"optimizer_config\":{\"deleted_threshold\":0.2,\"vacuum_min_vector_number\":1000,\"default_segment_number\":0,\"max_segment_size\":null,\"memmap_threshold\":null,\"indexing_threshold\":20000,\"flush_interval_sec\":5,\"max_optimization_threads\":1},\"wal_config\":{\"wal_capacity_mb\":32,\"wal_segments_ahead\":0},\"quantization_config\":null},\"payload_schema\":{}\r\n}\r\n```\r\n\r\n## Expected Behavior\r\nSnapshot should be created, stored, and accessible via the REST API\r\n\r\n## Context (Environment)\r\nAttempted on Windows 10 Pro v10.0.19045\r\nRunning locally in order to establish a docker protocol to append to our existing docker stack. Haven't run into these issues when running on a cloud instance.\r\n",
                  "html_url": "https://github.com/qdrant/qdrant/issues/2620"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#2620",
              "body": "## Current Behavior\r\nI have an instance of qdrant running locally on docker using the qdrant/qdrant:latest image. I have 11 collections, all of which are empty except for one named rrdb_matter_2. I haven't experimented with sharding or clusters yet, I am simply trying to test snapshots at scale. When I attempt to make a POST request to create a new snapshot (/collections/rrdb_matter_2/snapshots), I am eventually met with the following error:\r\n```\r\n[2023-09-07T20:37:53.799Z WARN  qdrant::actix::helpers] error processing request: Error while copy WAL \"./storage/snapshots_temp/rrdb_matter_2-1016472092926465-2023-09-07-20-37-31.tmp/0\" No such file or directory (os error 2)\r\n[2023-09-07T20:37:53.799Z INFO  actix_web::middleware::logger] 172.17.0.1 \"POST /collections/rrdb_matter_2/snapshots HTTP/1.1\" 500 195 \"-\" \"Apache-HttpClient/4.5.13 (Java/17.0.2)\" 21.905568\r\n```\r\n## Steps to Reproduce\r\n1. Pull latest docker image (v1.5.0)\r\n2. Run container using `docker run -p 6333:6333 -v $PWD/qdrant_storage:/qdrant/storage:z qdrant/qdrant:latest`\r\n3. After creating a new collection, load ~75,000 points with all 3 vector distances (euclidean, dot, cosine) referencing the same set of embeddings to the collection.\r\n4. Attempt to create a snapshot using the /collections/collection_name/snapshot POST request\r\n\r\nThe collection's stats are as follows:\r\n```\r\n{\r\n\"status\":\"green\",\"optimizer_status\":\"ok\",\"vectors_count\":227400,\"indexed_vectors_count\":162600,\"points_count\":75800,\"segments_count\":4,\"config\":{\"params\":{\"vectors\":{\"cosine\":{\"size\":384,\"distance\":\"Cosine\"},\"dot\":{\"size\":384,\"distance\":\"Dot\"},\"euclidean\":{\"size\":384,\"distance\":\"Euclid\"}},\"shard_number\":1,\"replication_factor\":1,\"write_consistency_factor\":1,\"on_disk_payload\":true},\"hnsw_config\":{\"m\":16,\"ef_construct\":100,\"full_scan_threshold\":10000,\"max_indexing_threads\":0,\"on_disk\":false},\"optimizer_config\":{\"deleted_threshold\":0.2,\"vacuum_min_vector_number\":1000,\"default_segment_number\":0,\"max_segment_size\":null,\"memmap_threshold\":null,\"indexing_threshold\":20000,\"flush_interval_sec\":5,\"max_optimization_threads\":1},\"wal_config\":{\"wal_capacity_mb\":32,\"wal_segments_ahead\":0},\"quantization_config\":null},\"payload_schema\":{}\r\n}\r\n```\r\n\r\n## Expected Behavior\r\nSnapshot should be created, stored, and accessible via the REST API\r\n\r\n## Context (Environment)\r\nAttempted on Windows 10 Pro v10.0.19045\r\nRunning locally in order to establish a docker protocol to append to our existing docker stack. Haven't run into these issues when running on a cloud instance.\r\n",
              "url": "https://github.com/qdrant/qdrant/issues/2620",
              "tech": [],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "highlight#8635",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "highlight",
              "id": "generated-highlight",
              "name": "Highlight",
              "description": "",
              "members": [],
              "display_name": "Highlight",
              "created_at": "2025-11-09T04:01:38.276Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/highlight?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "highlight",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:38.276Z",
            "created_at": "2025-11-09T04:01:38.276Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-highlight#8635",
              "status": "open",
              "type": "issue",
              "number": 8635,
              "title": "Update workspace and project settings to not use antd components",
              "source": {
                "data": {
                  "id": "source-highlight#8635",
                  "user": {
                    "login": "ccschmitz",
                    "id": 308182,
                    "node_id": "MDQ6VXNlcjMwODE4Mg==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/308182?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ccschmitz",
                    "html_url": "https://github.com/ccschmitz",
                    "followers_url": "https://api.github.com/users/ccschmitz/followers",
                    "following_url": "https://api.github.com/users/ccschmitz/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ccschmitz/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ccschmitz/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ccschmitz/subscriptions",
                    "organizations_url": "https://api.github.com/users/ccschmitz/orgs",
                    "repos_url": "https://api.github.com/users/ccschmitz/repos",
                    "events_url": "https://api.github.com/users/ccschmitz/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ccschmitz/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Update workspace and project settings to not use antd components",
                  "body": "Whoever implements should feel free to break this up into multiple tickets, perhaps one per page.",
                  "html_url": "https://github.com/highlight/highlight/issues/8635"
                },
                "type": "github"
              },
              "hash": "highlight/highlight#8635",
              "body": "Whoever implements should feel free to break this up into multiple tickets, perhaps one per page.",
              "url": "https://github.com/highlight/highlight/issues/8635",
              "tech": [
                "go"
              ],
              "repo_name": "highlight",
              "repo_owner": "highlight",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "highlight#8614",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "highlight",
              "id": "generated-highlight",
              "name": "Highlight",
              "description": "",
              "members": [],
              "display_name": "Highlight",
              "created_at": "2025-11-09T04:01:38.378Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/highlight?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "highlight",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:38.378Z",
            "created_at": "2025-11-09T04:01:38.378Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-highlight#8614",
              "status": "open",
              "type": "issue",
              "number": 8614,
              "title": "update design of integrations page",
              "source": {
                "data": {
                  "id": "source-highlight#8614",
                  "user": {
                    "login": "Vadman97",
                    "id": 1351531,
                    "node_id": "MDQ6VXNlcjEzNTE1MzE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1351531?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Vadman97",
                    "html_url": "https://github.com/Vadman97",
                    "followers_url": "https://api.github.com/users/Vadman97/followers",
                    "following_url": "https://api.github.com/users/Vadman97/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Vadman97/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Vadman97/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Vadman97/subscriptions",
                    "organizations_url": "https://api.github.com/users/Vadman97/orgs",
                    "repos_url": "https://api.github.com/users/Vadman97/repos",
                    "events_url": "https://api.github.com/users/Vadman97/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Vadman97/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "update design of integrations page",
                  "body": "Call us +1 (650) 420-2207  https://github.com/highlight/highlight/issues/8635 https://github.com/highlight/highlight/pull/9716 https://github.com/highlight/highlight/issues/8614 https://github.com/hig",
                  "html_url": "https://github.com/highlight/highlight/issues/8614"
                },
                "type": "github"
              },
              "hash": "highlight/highlight#8614",
              "body": "Call us +1 (650) 420-2207  https://github.com/highlight/highlight/issues/8635 https://github.com/highlight/highlight/pull/9716 https://github.com/highlight/highlight/issues/8614 https://github.com/hig",
              "url": "https://github.com/highlight/highlight/issues/8614",
              "tech": [],
              "repo_name": "highlight",
              "repo_owner": "highlight",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "highlight#8032",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "highlight",
              "id": "generated-highlight",
              "name": "Highlight",
              "description": "",
              "members": [],
              "display_name": "Highlight",
              "created_at": "2025-11-09T04:01:38.498Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/highlight?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "highlight",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:38.498Z",
            "created_at": "2025-11-09T04:01:38.498Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-highlight#8032",
              "status": "open",
              "type": "issue",
              "number": 8032,
              "title": "document sveltekit backend instrumentation",
              "source": {
                "data": {
                  "id": "source-highlight#8032",
                  "user": {
                    "login": "Vadman97",
                    "id": 1351531,
                    "node_id": "MDQ6VXNlcjEzNTE1MzE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1351531?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Vadman97",
                    "html_url": "https://github.com/Vadman97",
                    "followers_url": "https://api.github.com/users/Vadman97/followers",
                    "following_url": "https://api.github.com/users/Vadman97/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Vadman97/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Vadman97/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Vadman97/subscriptions",
                    "organizations_url": "https://api.github.com/users/Vadman97/orgs",
                    "repos_url": "https://api.github.com/users/Vadman97/repos",
                    "events_url": "https://api.github.com/users/Vadman97/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Vadman97/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "document sveltekit backend instrumentation",
                  "body": "see linear thread linked for starting point\n\n[https://discord.com/channels/1026884757667188757/1217184768001839225/1218189516041621524](https://discord.com/channels/1026884757667188757/1217184768001839225/1218189516041621524)",
                  "html_url": "https://github.com/highlight/highlight/issues/8032"
                },
                "type": "github"
              },
              "hash": "highlight/highlight#8032",
              "body": "see linear thread linked for starting point\n\n[https://discord.com/channels/1026884757667188757/1217184768001839225/1218189516041621524](https://discord.com/channels/1026884757667188757/1217184768001839225/1218189516041621524)",
              "url": "https://github.com/highlight/highlight/issues/8032",
              "tech": [],
              "repo_name": "highlight",
              "repo_owner": "highlight",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "highlight#6775",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "highlight",
              "id": "generated-highlight",
              "name": "Highlight",
              "description": "",
              "members": [],
              "display_name": "Highlight",
              "created_at": "2025-11-09T04:01:38.599Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/highlight?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "highlight",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:38.599Z",
            "created_at": "2025-11-09T04:01:38.599Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-highlight#6775",
              "status": "open",
              "type": "issue",
              "number": 6775,
              "title": "Performance of canvas snapshotting on Safari is poor",
              "source": {
                "data": {
                  "id": "source-highlight#6775",
                  "user": {
                    "login": "Pinpickle",
                    "id": 3238878,
                    "node_id": "MDQ6VXNlcjMyMzg4Nzg=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/3238878?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Pinpickle",
                    "html_url": "https://github.com/Pinpickle",
                    "followers_url": "https://api.github.com/users/Pinpickle/followers",
                    "following_url": "https://api.github.com/users/Pinpickle/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Pinpickle/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Pinpickle/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Pinpickle/subscriptions",
                    "organizations_url": "https://api.github.com/users/Pinpickle/orgs",
                    "repos_url": "https://api.github.com/users/Pinpickle/repos",
                    "events_url": "https://api.github.com/users/Pinpickle/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Pinpickle/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Performance of canvas snapshotting on Safari is poor",
                  "body": "**Describe the bug**\r\n\r\nSnapshotting a canvas element in Safari 16.x takes a long time (>20ms). This leads to a frame drop every time the canvas is snapshotted.\r\n\r\n**To Reproduce**\r\n\r\nGo to the Codsandbox full-screen here https://jqgtld.csb.app/ \r\n\r\nLook at the \"Snapshot\" stat in the top right corner (or in the console). On my computer it is ~20ms on Safari 16.5. On Chrome, it is between 0 and 0.3ms.\r\n\r\nThe window size is 1057 x 734 (retina display, so double the dimensions for the canvas)\r\n\r\nHere's the codesandbox with the editor: https://codesandbox.io/s/dazzling-roentgen-jqgtld?file=/src/App.js\r\n\r\n**Expected behavior**\r\n\r\nOverhead for snapshotting to be near 0\r\n\r\n**Screenshots**\r\n\r\n## Safari\r\n\r\n![CleanShot 2023-10-02 at 15 23 03 png](https://github.com/highlight/highlight/assets/3238878/1bc6d193-ea1f-4fda-ae03-7ea9c9cf9143)\r\n\r\n## Chrome\r\n\r\n![CleanShot 2023-10-02 at 15 23 55 png](https://github.com/highlight/highlight/assets/3238878/7a3767f7-94a0-467b-9c23-bac305507d66)\r\n\r\n## iOS\r\n\r\n![CleanShot 2023-10-02 at 15 27 57 png](https://github.com/highlight/highlight/assets/3238878/664fc6c4-27b8-43ce-be71-b35b7553716f)\r\n\r\n\r\n**Additional context**\r\n\r\nEnvironment:\r\n\r\n```\r\nSystem:\r\n    OS: macOS 13.4\r\n    CPU: (8) arm64 Apple M1\r\n    Memory: 51.78 MB / 8.00 GB\r\nBrowsers:\r\n    Chrome: 117.0.5938.92\r\n    Safari: 16.5\r\n```\r\n\r\nProvided this also affects Safari 17 (I don't know if it does), this affects _every_ Safari-based browser (including everything on iOS). This performance drop means we had to disable canvas recording for Safari on our app which really limits its usefulness.\r\n\r\nThe larger the canvas, the longer the snapshot time, from what I can tell. Changing `canvasMaxSnapshotDimension` does not appear to make a difference. Safari doesn't even respect the options parameter for `createBitmapImage`: https://developer.mozilla.org/en-US/docs/Web/API/createImageBitmap\r\n\r\nI'm reasonably confident this comes from the call to `createBitmapImage` here:\r\n\r\nhttps://github.com/highlight/highlight/blob/ed2ea183d0d11781736e2001b01e24e55c33e8cb/frontend/src/__generated/rr/rr.js#L4266-L4269\r\n\r\nIt's supposed to be asynchronous but it looks like it is blocking in Safari. I wonder if there are other ways to get the image data out of a canvas? I understand there are efforts to use WebRTC for canvas recording? I imagine this could help.\r\n",
                  "html_url": "https://github.com/highlight/highlight/issues/6775"
                },
                "type": "github"
              },
              "hash": "highlight/highlight#6775",
              "body": "**Describe the bug**\r\n\r\nSnapshotting a canvas element in Safari 16.x takes a long time (>20ms). This leads to a frame drop every time the canvas is snapshotted.\r\n\r\n**To Reproduce**\r\n\r\nGo to the Codsandbox full-screen here https://jqgtld.csb.app/ \r\n\r\nLook at the \"Snapshot\" stat in the top right corner (or in the console). On my computer it is ~20ms on Safari 16.5. On Chrome, it is between 0 and 0.3ms.\r\n\r\nThe window size is 1057 x 734 (retina display, so double the dimensions for the canvas)\r\n\r\nHere's the codesandbox with the editor: https://codesandbox.io/s/dazzling-roentgen-jqgtld?file=/src/App.js\r\n\r\n**Expected behavior**\r\n\r\nOverhead for snapshotting to be near 0\r\n\r\n**Screenshots**\r\n\r\n## Safari\r\n\r\n![CleanShot 2023-10-02 at 15 23 03 png](https://github.com/highlight/highlight/assets/3238878/1bc6d193-ea1f-4fda-ae03-7ea9c9cf9143)\r\n\r\n## Chrome\r\n\r\n![CleanShot 2023-10-02 at 15 23 55 png](https://github.com/highlight/highlight/assets/3238878/7a3767f7-94a0-467b-9c23-bac305507d66)\r\n\r\n## iOS\r\n\r\n![CleanShot 2023-10-02 at 15 27 57 png](https://github.com/highlight/highlight/assets/3238878/664fc6c4-27b8-43ce-be71-b35b7553716f)\r\n\r\n\r\n**Additional context**\r\n\r\nEnvironment:\r\n\r\n```\r\nSystem:\r\n    OS: macOS 13.4\r\n    CPU: (8) arm64 Apple M1\r\n    Memory: 51.78 MB / 8.00 GB\r\nBrowsers:\r\n    Chrome: 117.0.5938.92\r\n    Safari: 16.5\r\n```\r\n\r\nProvided this also affects Safari 17 (I don't know if it does), this affects _every_ Safari-based browser (including everything on iOS). This performance drop means we had to disable canvas recording for Safari on our app which really limits its usefulness.\r\n\r\nThe larger the canvas, the longer the snapshot time, from what I can tell. Changing `canvasMaxSnapshotDimension` does not appear to make a difference. Safari doesn't even respect the options parameter for `createBitmapImage`: https://developer.mozilla.org/en-US/docs/Web/API/createImageBitmap\r\n\r\nI'm reasonably confident this comes from the call to `createBitmapImage` here:\r\n\r\nhttps://github.com/highlight/highlight/blob/ed2ea183d0d11781736e2001b01e24e55c33e8cb/frontend/src/__generated/rr/rr.js#L4266-L4269\r\n\r\nIt's supposed to be asynchronous but it looks like it is blocking in Safari. I wonder if there are other ways to get the image data out of a canvas? I understand there are efforts to use WebRTC for canvas recording? I imagine this could help.\r\n",
              "url": "https://github.com/highlight/highlight/issues/6775",
              "tech": [],
              "repo_name": "highlight",
              "repo_owner": "highlight",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7113",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-11-09T04:01:37.887Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:37.887Z",
            "created_at": "2025-11-09T04:01:37.887Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7113",
              "status": "open",
              "type": "issue",
              "number": 7113,
              "title": "[Bug]: Deployments failing without clear cause / error",
              "source": {
                "data": {
                  "id": "source-coollabsio#7113",
                  "user": {
                    "login": "suptejas",
                    "id": 63039748,
                    "node_id": "MDQ6VXNlcjYzMDM5NzQ4",
                    "avatar_url": "https://avatars.githubusercontent.com/u/63039748?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/suptejas",
                    "html_url": "https://github.com/suptejas",
                    "followers_url": "https://api.github.com/users/suptejas/followers",
                    "following_url": "https://api.github.com/users/suptejas/following{/other_user}",
                    "gists_url": "https://api.github.com/users/suptejas/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/suptejas/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/suptejas/subscriptions",
                    "organizations_url": "https://api.github.com/users/suptejas/orgs",
                    "repos_url": "https://api.github.com/users/suptejas/repos",
                    "events_url": "https://api.github.com/users/suptejas/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/suptejas/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Deployments failing without clear cause / error",
                  "body": "### Error Message and Logs\n\nOur deployments have been in-deterministically failing with no obvious cause. Here's a few deployment logs on our end that just failed, and would work perfectly with a redeploy.\n\n<details>\n\n```\n2025-Nov-05 10:19:19.363823\nFound a suitable build server (Builder).\n2025-Nov-05 10:19:19.370090\nStarting deployment of dimensionhq/ai:master to Webhooks - 2.\n2025-Nov-05 10:19:19.728111\nPreparing container with helper image: ghcr.io/coollabsio/coolify-helper:1.0.11\n2025-Nov-05 10:19:19.905615\n[CMD]: docker stop --time=30 uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:19.905615\nFlag --time has been deprecated, use --timeout instead\n2025-Nov-05 10:19:19.907955\nError response from daemon: No such container: uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:20.143670\n[CMD]: docker rm -f uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:20.143670\nError response from daemon: No such container: uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:20.365835\n[CMD]: docker run -d --name uw4kosoc84ooc808ww4080ww  --rm -v /root/.docker/config.json:/root/.docker/config.json:ro -v /var/run/docker.sock:/var/run/docker.sock ghcr.io/coollabsio/coolify-helper:1.0.11\n2025-Nov-05 10:19:20.365835\n0b60882c666a468473fc10c4a2350c55587bb7cd4cb62e200bba037838f453e8\n2025-Nov-05 10:19:22.053986\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'GIT_SSH_COMMAND=\"ssh -o ConnectTimeout=30 -p 22 -o Port=22 -o LogLevel=ERROR -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null\" git ls-remote [https://x-access-token:<REDACTED>@github.com/dimensionhq/ai.git](https://x-access-token:%3CREDACTED%3E@github.com/dimensionhq/ai.git) refs/heads/master'\n2025-Nov-05 10:19:22.053986\neb20a0771f925bf19364784030b4df74a55441f5\trefs/heads/master\n2025-Nov-05 10:19:22.188928\n----------------------------------------\n2025-Nov-05 10:19:22.194547\nImporting dimensionhq/ai:master (commit sha eb20a0771f925bf19364784030b4df74a55441f5) to /artifacts/uw4kosoc84ooc808ww4080ww.\n2025-Nov-05 10:19:22.451630\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'git clone --depth=1 --recurse-submodules --shallow-submodules -b 'master' '[https://x-access-token:<REDACTED>@github.com/dimensionhq/ai.git'](https://x-access-token:%3CREDACTED%3E@github.com/dimensionhq/ai.git') '/artifacts/uw4kosoc84ooc808ww4080ww' && cd '/artifacts/uw4kosoc84ooc808ww4080ww' && if [ -f .gitmodules ]; then git submodule sync && GIT_SSH_COMMAND=\"ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null\" git submodule update --init --recursive --depth=1; fi && cd '/artifacts/uw4kosoc84ooc808ww4080ww' && GIT_SSH_COMMAND=\"ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null\" git lfs pull'\n2025-Nov-05 10:19:22.451630\nCloning into '/artifacts/uw4kosoc84ooc808ww4080ww'...\n2025-Nov-05 10:19:24.006780\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'cd /artifacts/uw4kosoc84ooc808ww4080ww && git log -1 eb20a0771f925bf19364784030b4df74a55441f5 --pretty=%B'\n2025-Nov-05 10:19:24.006780\nMerge branch 'master' of https://github.com/dimensionhq/ai\n2025-Nov-05 10:19:24.769603\nImage not found (realmsoftwareinc/webhooks-prod:eb20a0771f925bf19364784030b4df74a55441f5). Building new image.\n2025-Nov-05 10:19:26.046158\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'cat /artifacts/uw4kosoc84ooc808ww4080ww/apps/webhooks/Dockerfile'\n2025-Nov-05 10:19:26.046158\n# Build dependencies and virtualenv in a dedicated stage\n2025-Nov-05 10:19:26.046158\nFROM python:3.11-slim AS builder\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\nWORKDIR /app\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Install build tooling and uv (no recommends to keep layer slim)\n2025-Nov-05 10:19:26.046158\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n2025-Nov-05 10:19:26.046158\ngcc \\\n2025-Nov-05 10:19:26.046158\ng++ \\\n2025-Nov-05 10:19:26.046158\ncurl \\\n2025-Nov-05 10:19:26.046158\n&& rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\nRUN pip install --no-cache-dir uv\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Copy workspace files needed for dependency resolution\n2025-Nov-05 10:19:26.046158\nCOPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:26.046158\nCOPY packages/shared /app/packages/shared\n2025-Nov-05 10:19:26.046158\nCOPY apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Install Python dependencies into .venv\n2025-Nov-05 10:19:26.046158\nRUN uv sync --frozen --package webhooks\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Clean up build artefacts to keep the copied layer trim\n2025-Nov-05 10:19:26.046158\nRUN rm -rf /root/.cache /root/.uv-cache\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Final runtime image\n2025-Nov-05 10:19:26.046158\nFROM python:3.11-slim\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\nWORKDIR /app\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Install curl (for health check) and Infisical CLI with minimal extras\n2025-Nov-05 10:19:26.046158\nRUN apt-get update && apt-get install -y --no-install-recommends curl \\\n2025-Nov-05 10:19:26.046158\n&& curl -1sLf 'https://artifacts-cli.infisical.com/setup.deb.sh' | bash \\\n2025-Nov-05 10:19:26.046158\n&& apt-get install -y --no-install-recommends infisical \\\n2025-Nov-05 10:19:26.046158\n&& rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Copy in the prebuilt virtualenv and application code\n2025-Nov-05 10:19:26.046158\nCOPY --from=builder /app/.venv /app/.venv\n2025-Nov-05 10:19:26.046158\nCOPY --from=builder /app/packages/shared /app/packages/shared\n2025-Nov-05 10:19:26.046158\nCOPY --from=builder /app/apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:26.046158\nCOPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Expose port 8000\n2025-Nov-05 10:19:26.046158\nEXPOSE 8000\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Set environment variables\n2025-Nov-05 10:19:26.046158\nENV PYTHONPATH=/app\n2025-Nov-05 10:19:26.046158\nENV PYTHONUNBUFFERED=1\n2025-Nov-05 10:19:26.046158\nENV PATH=\"/app/.venv/bin:$PATH\"\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Health check\n2025-Nov-05 10:19:26.046158\nHEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\\n2025-Nov-05 10:19:26.046158\nCMD curl -f http://localhost:8000/health || exit 1\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Run the application with Infisical and Gunicorn\n2025-Nov-05 10:19:26.046158\n# Note: Set INFISICAL_TOKEN and INFISICAL_PROJECT_ID environment variables when running the container\n2025-Nov-05 10:19:26.046158\n# Example: docker run --env INFISICAL_TOKEN=$INFISICAL_TOKEN --env INFISICAL_PROJECT_ID=your-project-id your-image\n2025-Nov-05 10:19:26.046158\nCMD [\"sh\", \"-c\", \"infisical run --projectId $INFISICAL_PROJECT_ID --command 'cd /app/apps/webhooks/webhooks && /app/.venv/bin/gunicorn main:app -c gunicorn.conf.py'\"]\n2025-Nov-05 10:19:26.382688\nCreating build-time .env file in /artifacts (outside Docker context).\n2025-Nov-05 10:19:26.930010\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'cat /artifacts/build-time.env'\n2025-Nov-05 10:19:26.930010\nSOURCE_COMMIT='eb20a0771f925bf19364784030b4df74a55441f5'\n2025-Nov-05 10:19:26.930010\nCOOLIFY_URL=''\n2025-Nov-05 10:19:26.930010\nCOOLIFY_FQDN=''\n2025-Nov-05 10:19:26.930010\nCOOLIFY_BRANCH='master'\n2025-Nov-05 10:19:26.930010\nCOOLIFY_RESOURCE_UUID='b0808cwg8c4ko4kk84kkcks0'\n2025-Nov-05 10:19:26.930010\nCOOLIFY_CONTAINER_NAME='b0808cwg8c4ko4kk84kkcks0-101917583267'\n2025-Nov-05 10:19:26.930010\nINFISICAL_PROJECT_ID=\"65a15447c63fc2a03460007d\"\n2025-Nov-05 10:19:26.930010\nINFISICAL_TOKEN=\"st.885a8fa6-7c1c-47bb-8bfb-715555b46050.b9107cb09ef5069f89ac2720ab9c424a.1bd120fcdff9cbbab6c6c0e1f7678875\"\n2025-Nov-05 10:19:27.264299\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'cat /artifacts/uw4kosoc84ooc808ww4080ww/apps/webhooks/Dockerfile'\n2025-Nov-05 10:19:27.264299\n# Build dependencies and virtualenv in a dedicated stage\n2025-Nov-05 10:19:27.264299\nFROM python:3.11-slim AS builder\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\nWORKDIR /app\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Install build tooling and uv (no recommends to keep layer slim)\n2025-Nov-05 10:19:27.264299\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n2025-Nov-05 10:19:27.264299\ngcc \\\n2025-Nov-05 10:19:27.264299\ng++ \\\n2025-Nov-05 10:19:27.264299\ncurl \\\n2025-Nov-05 10:19:27.264299\n&& rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\nRUN pip install --no-cache-dir uv\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Copy workspace files needed for dependency resolution\n2025-Nov-05 10:19:27.264299\nCOPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:27.264299\nCOPY packages/shared /app/packages/shared\n2025-Nov-05 10:19:27.264299\nCOPY apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Install Python dependencies into .venv\n2025-Nov-05 10:19:27.264299\nRUN uv sync --frozen --package webhooks\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Clean up build artefacts to keep the copied layer trim\n2025-Nov-05 10:19:27.264299\nRUN rm -rf /root/.cache /root/.uv-cache\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Final runtime image\n2025-Nov-05 10:19:27.264299\nFROM python:3.11-slim\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\nWORKDIR /app\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Install curl (for health check) and Infisical CLI with minimal extras\n2025-Nov-05 10:19:27.264299\nRUN apt-get update && apt-get install -y --no-install-recommends curl \\\n2025-Nov-05 10:19:27.264299\n&& curl -1sLf 'https://artifacts-cli.infisical.com/setup.deb.sh' | bash \\\n2025-Nov-05 10:19:27.264299\n&& apt-get install -y --no-install-recommends infisical \\\n2025-Nov-05 10:19:27.264299\n&& rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Copy in the prebuilt virtualenv and application code\n2025-Nov-05 10:19:27.264299\nCOPY --from=builder /app/.venv /app/.venv\n2025-Nov-05 10:19:27.264299\nCOPY --from=builder /app/packages/shared /app/packages/shared\n2025-Nov-05 10:19:27.264299\nCOPY --from=builder /app/apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:27.264299\nCOPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Expose port 8000\n2025-Nov-05 10:19:27.264299\nEXPOSE 8000\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Set environment variables\n2025-Nov-05 10:19:27.264299\nENV PYTHONPATH=/app\n2025-Nov-05 10:19:27.264299\nENV PYTHONUNBUFFERED=1\n2025-Nov-05 10:19:27.264299\nENV PATH=\"/app/.venv/bin:$PATH\"\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Health check\n2025-Nov-05 10:19:27.264299\nHEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\\n2025-Nov-05 10:19:27.264299\nCMD curl -f http://localhost:8000/health || exit 1\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Run the application with Infisical and Gunicorn\n2025-Nov-05 10:19:27.264299\n# Note: Set INFISICAL_TOKEN and INFISICAL_PROJECT_ID environment variables when running the container\n2025-Nov-05 10:19:27.264299\n# Example: docker run --env INFISICAL_TOKEN=$INFISICAL_TOKEN --env INFISICAL_PROJECT_ID=your-project-id your-image\n2025-Nov-05 10:19:27.264299\nCMD [\"sh\", \"-c\", \"infisical run --projectId $INFISICAL_PROJECT_ID --command 'cd /app/apps/webhooks/webhooks && /app/.venv/bin/gunicorn main:app -c gunicorn.conf.py'\"]\n2025-Nov-05 10:19:27.306071\nFinal Dockerfile:\n2025-Nov-05 10:19:27.928385\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'cat /artifacts/uw4kosoc84ooc808ww4080ww/apps/webhooks/Dockerfile'\n2025-Nov-05 10:19:27.928385\n# Build dependencies and virtualenv in a dedicated stage\n2025-Nov-05 10:19:27.928385\nARG COOLIFY_BUILD_SECRETS_HASH=4387256370ab25c71c6c7f93ce46e2a426fafb4ba429afe60f75c57a2cc75894\n2025-Nov-05 10:19:27.928385\nARG COOLIFY_CONTAINER_NAME=b0808cwg8c4ko4kk84kkcks0-101917583267\n2025-Nov-05 10:19:27.928385\nARG COOLIFY_RESOURCE_UUID=b0808cwg8c4ko4kk84kkcks0\n2025-Nov-05 10:19:27.928385\nARG COOLIFY_BRANCH=master\n2025-Nov-05 10:19:27.928385\nARG SOURCE_COMMIT=eb20a0771f925bf19364784030b4df74a55441f5\n2025-Nov-05 10:19:27.928385\nARG INFISICAL_TOKEN=st.885a8fa6-7c1c-47bb-8bfb-715555b46050.b9107cb09ef5069f89ac2720ab9c424a.1bd120fcdff9cbbab6c6c0e1f7678875\n2025-Nov-05 10:19:27.928385\nARG INFISICAL_PROJECT_ID=65a15447c63fc2a03460007d\n2025-Nov-05 10:19:27.928385\nFROM python:3.11-slim AS builder\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\nWORKDIR /app\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Install build tooling and uv (no recommends to keep layer slim)\n2025-Nov-05 10:19:27.928385\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n2025-Nov-05 10:19:27.928385\ngcc \\\n2025-Nov-05 10:19:27.928385\ng++ \\\n2025-Nov-05 10:19:27.928385\ncurl \\\n2025-Nov-05 10:19:27.928385\n&& rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\nRUN pip install --no-cache-dir uv\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Copy workspace files needed for dependency resolution\n2025-Nov-05 10:19:27.928385\nCOPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:27.928385\nCOPY packages/shared /app/packages/shared\n2025-Nov-05 10:19:27.928385\nCOPY apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Install Python dependencies into .venv\n2025-Nov-05 10:19:27.928385\nRUN uv sync --frozen --package webhooks\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Clean up build artefacts to keep the copied layer trim\n2025-Nov-05 10:19:27.928385\nRUN rm -rf /root/.cache /root/.uv-cache\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Final runtime image\n2025-Nov-05 10:19:27.928385\nFROM python:3.11-slim\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\nWORKDIR /app\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Install curl (for health check) and Infisical CLI with minimal extras\n2025-Nov-05 10:19:27.928385\nRUN apt-get update && apt-get install -y --no-install-recommends curl \\\n2025-Nov-05 10:19:27.928385\n&& curl -1sLf 'https://artifacts-cli.infisical.com/setup.deb.sh' | bash \\\n2025-Nov-05 10:19:27.928385\n&& apt-get install -y --no-install-recommends infisical \\\n2025-Nov-05 10:19:27.928385\n&& rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Copy in the prebuilt virtualenv and application code\n2025-Nov-05 10:19:27.928385\nCOPY --from=builder /app/.venv /app/.venv\n2025-Nov-05 10:19:27.928385\nCOPY --from=builder /app/packages/shared /app/packages/shared\n2025-Nov-05 10:19:27.928385\nCOPY --from=builder /app/apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:27.928385\nCOPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Expose port 8000\n2025-Nov-05 10:19:27.928385\nEXPOSE 8000\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Set environment variables\n2025-Nov-05 10:19:27.928385\nENV PYTHONPATH=/app\n2025-Nov-05 10:19:27.928385\nENV PYTHONUNBUFFERED=1\n2025-Nov-05 10:19:27.928385\nENV PATH=\"/app/.venv/bin:$PATH\"\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Health check\n2025-Nov-05 10:19:27.928385\nHEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\\n2025-Nov-05 10:19:27.928385\nCMD curl -f http://localhost:8000/health || exit 1\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Run the application with Infisical and Gunicorn\n2025-Nov-05 10:19:27.928385\n# Note: Set INFISICAL_TOKEN and INFISICAL_PROJECT_ID environment variables when running the container\n2025-Nov-05 10:19:27.928385\n# Example: docker run --env INFISICAL_TOKEN=$INFISICAL_TOKEN --env INFISICAL_PROJECT_ID=your-project-id your-image\n2025-Nov-05 10:19:27.928385\nCMD [\"sh\", \"-c\", \"infisical run --projectId $INFISICAL_PROJECT_ID --command 'cd /app/apps/webhooks/webhooks && /app/.venv/bin/gunicorn main:app -c gunicorn.conf.py'\"]\n2025-Nov-05 10:19:27.942703\n----------------------------------------\n2025-Nov-05 10:19:27.949099\nBuilding docker image started.\n2025-Nov-05 10:19:27.957779\nTo check the current progress, click on Show Debug Logs.\n2025-Nov-05 10:19:28.573409\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'cat /artifacts/build.sh'\n2025-Nov-05 10:19:28.573409\ncd /artifacts/uw4kosoc84ooc808ww4080ww && set -a && source /artifacts/build-time.env && set +a && docker build   --network host -f /artifacts/uw4kosoc84ooc808ww4080ww/apps/webhooks/Dockerfile --build-arg SOURCE_COMMIT --build-arg COOLIFY_URL --build-arg COOLIFY_FQDN --build-arg COOLIFY_BRANCH --build-arg COOLIFY_RESOURCE_UUID --build-arg COOLIFY_CONTAINER_NAME --build-arg INFISICAL_PROJECT_ID --build-arg INFISICAL_TOKEN --build-arg COOLIFY_BUILD_SECRETS_HASH=636980d03d37af4b459b987881db690134f9b90ab8d67d21c1fc8e99e0f83d41 --build-arg 'SOURCE_COMMIT' --build-arg 'COOLIFY_URL' --build-arg 'COOLIFY_FQDN' --build-arg 'COOLIFY_BRANCH' --build-arg 'COOLIFY_RESOURCE_UUID' --build-arg 'COOLIFY_CONTAINER_NAME' --progress plain -t realmsoftwareinc/webhooks-prod:eb20a0771f925bf19364784030b4df74a55441f5 /artifacts/uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:29.156678\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'bash /artifacts/build.sh'\n2025-Nov-05 10:19:29.156678\n#0 building with \"default\" instance using docker driver\n2025-Nov-05 10:19:29.156678\n2025-Nov-05 10:19:29.156678\n#1 [internal] load build definition from Dockerfile\n2025-Nov-05 10:19:29.156678\n#1 transferring dockerfile: 2.52kB done\n2025-Nov-05 10:19:29.156678\n#1 DONE 0.0s\n2025-Nov-05 10:19:29.156678\n2025-Nov-05 10:19:29.156678\n#2 [auth] library/python:pull token for registry-1.docker.io\n2025-Nov-05 10:19:29.156678\n#2 DONE 0.0s\n2025-Nov-05 10:19:29.156678\n2025-Nov-05 10:19:29.156678\n#3 [internal] load metadata for docker.io/library/python:3.11-slim\n2025-Nov-05 10:19:29.156678\n#3 DONE 0.1s\n2025-Nov-05 10:19:29.262918\n#4 [builder 1/9] FROM docker.io/library/python:3.11-slim@sha256:fa9b525a0be0c5ae5e6f2209f4be6fdc5a15a36fed0222144d98ac0d08f876d4\n2025-Nov-05 10:19:29.262918\n#4 DONE 0.0s\n2025-Nov-05 10:19:29.262918\n2025-Nov-05 10:19:29.262918\n#5 [internal] load .dockerignore\n2025-Nov-05 10:19:29.262918\n#5 transferring context: 2B done\n2025-Nov-05 10:19:29.262918\n#5 DONE 0.0s\n2025-Nov-05 10:19:29.262918\n2025-Nov-05 10:19:29.262918\n#6 [internal] load build context\n2025-Nov-05 10:19:29.262918\n#6 transferring context: 1.44MB 0.1s done\n2025-Nov-05 10:19:29.510044\n#6 DONE 0.1s\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#7 [builder 6/9] COPY packages/shared /app/packages/shared\n2025-Nov-05 10:19:29.510044\n#7 CACHED\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#8 [builder 2/9] WORKDIR /app\n2025-Nov-05 10:19:29.510044\n#8 CACHED\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#9 [builder 4/9] RUN pip install --no-cache-dir uv\n2025-Nov-05 10:19:29.510044\n#9 CACHED\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#10 [builder 3/9] RUN apt-get update && apt-get install -y --no-install-recommends   gcc   g++   curl   && rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:29.510044\n#10 CACHED\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#11 [builder 5/9] COPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:29.510044\n#11 CACHED\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#12 [builder 6/9] COPY packages/shared /app/packages/shared\n2025-Nov-05 10:19:29.510044\n#12 CACHED\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#13 [builder 7/9] COPY apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:29.510044\n#13 DONE 0.1s\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#14 [builder 8/9] RUN uv sync --frozen --package webhooks\n2025-Nov-05 10:19:29.594969\n#14 0.238 Using CPython 3.11.14 interpreter at: /usr/local/bin/python3\n2025-Nov-05 10:19:29.594969\n#14 0.238 Creating virtual environment at: .venv\n2025-Nov-05 10:19:29.749236\n#14 0.305    Building webhooks @ file:///app/apps/webhooks\n2025-Nov-05 10:19:29.749236\n#14 0.309    Building shared @ file:///app/packages/shared\n2025-Nov-05 10:19:29.749236\n#14 0.392 Downloading aiohttp (1.7MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.392 Downloading psycopg-binary (4.2MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.393 Downloading pynacl (1.3MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.394 Downloading sqlalchemy (3.2MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.396 Downloading asyncpg (3.0MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.397 Downloading pydantic-core (2.0MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.398 Downloading cryptography (4.3MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.399 Downloading virtualenv (5.7MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.400 Downloading ruff (12.8MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.400 Downloading uvloop (3.8MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.400 Downloading pygments (1.2MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.400 Downloading grpcio (6.2MiB)\n2025-Nov-05 10:19:30.555268\n#14 1.199    Building nats-py==2.11.0\n2025-Nov-05 10:19:31.339158\n#14 1.983  Downloading pydantic-core\n2025-Nov-05 10:19:31.491550\n#14 2.034    Building tonyg-rfc3339==0.1\n2025-Nov-05 10:19:31.491550\n#14 2.133    Building nkeys==0.2.1\n2025-Nov-05 10:19:31.598344\n#14 2.147  Downloading pynacl\n2025-Nov-05 10:19:31.602095\n#14 2.241  Downloading aiohttp\n2025-Nov-05 10:19:31.763871\n#14 2.407  Downloading asyncpg\n2025-Nov-05 10:19:31.999697\n#14 2.643  Downloading psycopg-binary\n2025-Nov-05 10:19:32.105619\n#14 2.749  Downloading virtualenv\n2025-Nov-05 10:19:32.252014\n#14 2.755  Downloading ruff\n2025-Nov-05 10:19:32.252014\n#14 2.818  Downloading uvloop\n2025-Nov-05 10:19:32.252014\n#14 2.890  Downloading grpcio\n2025-Nov-05 10:19:32.489971\n#14 2.929  Downloading sqlalchemy\n2025-Nov-05 10:19:32.489971\n#14 2.943  Downloading cryptography\n2025-Nov-05 10:19:32.489971\n#14 2.983  Downloading pygments\n2025-Nov-05 10:19:35.169371\n#14 5.813       Built nkeys==0.2.1\n2025-Nov-05 10:19:35.410078\n#14 6.052       Built nats-py==2.11.0\n2025-Nov-05 10:19:35.576134\n#14 6.084       Built shared @ file:///app/packages/shared\n2025-Nov-05 10:19:35.576134\n#14 6.218       Built webhooks @ file:///app/apps/webhooks\n2025-Nov-05 10:19:35.576134\n#14 6.218       Built tonyg-rfc3339==0.1\n2025-Nov-05 10:19:35.729658\n#14 6.221 Prepared 115 packages in 5.94s\n2025-Nov-05 10:19:35.793532\n#14 6.435 Installed 115 packages in 212ms\n2025-Nov-05 10:19:35.793532\n#14 6.435  + aiofiles==25.1.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + aiogoogle==5.17.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + aiohappyeyeballs==2.6.1\n2025-Nov-05 10:19:35.793532\n#14 6.435  + aiohttp==3.13.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + aiosignal==1.4.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + annotated-types==0.7.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + anyio==4.11.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + apscheduler==3.11.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + async-timeout==5.0.1\n2025-Nov-05 10:19:35.793532\n#14 6.435  + asyncpg==0.30.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + attrs==25.4.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + cachetools==6.2.1\n2025-Nov-05 10:19:35.793532\n#14 6.435  + certifi==2025.10.5\n2025-Nov-05 10:19:35.793532\n#14 6.435  + cffi==2.0.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + cfgv==3.4.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + charset-normalizer==3.4.4\n2025-Nov-05 10:19:35.793532\n#14 6.435  + click==8.3.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + cryptography==46.0.2\n2025-Nov-05 10:19:35.793532\n#14 6.435  + distlib==0.4.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + distro==1.9.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + dnspython==2.8.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + email-validator==2.3.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + fastapi==0.119.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + fastapi-cli==0.0.13\n2025-Nov-05 10:19:35.793532\n#14 6.435  + fastapi-cloud-cli==0.3.1\n2025-Nov-05 10:19:35.793532\n#14 6.435  + filelock==3.20.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + frozenlist==1.8.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + google-api-core==2.26.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + google-auth==2.41.1\n2025-Nov-05 10:19:35.793532\n#14 6.435  + google-cloud-kms==3.6.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + google-cloud-pubsub==2.31.1\n2025-Nov-05 10:19:35.793532\n#14 6.435  + googleapis-common-protos==1.70.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + greenlet\n2025-Nov-05 10:19:35.950300\n==3.2.4\n2025-Nov-05 10:19:35.950300\n#14 6.435  + grpc-google-iam-v1==0.14.2\n2025-Nov-05 10:19:35.950300\n#14 6.435  + grpcio==1.75.1\n2025-Nov-05 10:19:35.950300\n#14 6.435  + grpcio-status==1.75.1\n2025-Nov-05 10:19:35.950300\n#14 6.435  + gunicorn==23.0.0\n2025-Nov-05 10:19:35.950300\n#14 6.435  + h11==0.16.0\n2025-Nov-05 10:19:35.950300\n#14 6.435  + httpcore==1.0.9\n2025-Nov-05 10:19:35.950300\n#14 6.435  + httptools==0.7.1\n2025-Nov-05 10:19:35.950300\n#14 6.435  + httpx==0.28.1\n2025-Nov-05 10:19:35.950300\n#14 6.435  + identify==2.6.15\n2025-Nov-05 10:19:35.950300\n#14 6.435  + idna==3.11\n2025-Nov-05 10:19:35.950300\n#14 6.439  + importlib-metadata==8.7.0\n2025-Nov-05 10:19:35.950300\n#14 6.439  + iniconfig==2.1.0\n2025-Nov-05 10:19:35.950300\n#14 6.439  + jinja2==3.1.6\n2025-Nov-05 10:19:35.950300\n#14 6.439  + jiter==0.11.0\n2025-Nov-05 10:19:35.950300\n#14 6.439  + markdown-it-py==4.0.0\n2025-Nov-05 10:19:35.950300\n#14 6.439  + markupsafe==3.0.3\n2025-Nov-05 10:19:35.950300\n#14 6.439  + mdurl==0.1.2\n2025-Nov-05 10:19:35.950300\n#14 6.440  + multidict==6.7.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + nats-py==2.11.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + nkeys==0.2.1\n2025-Nov-05 10:19:35.950300\n#14 6.440  + nodeenv==1.9.1\n2025-Nov-05 10:19:35.950300\n#14 6.440  + openai==1.109.1\n2025-Nov-05 10:19:35.950300\n#14 6.440  + opentelemetry-api==1.37.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + opentelemetry-sdk==1.37.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + opentelemetry-semantic-conventions==0.58b0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + packaging==25.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + platformdirs==4.5.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + pluggy==1.6.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + pre-commit==4.3.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + propcache==0.4.1\n2025-Nov-05 10:19:35.950300\n#14 6.441  + proto-plus==1.26.1\n2025-Nov-05 10:19:35.950300\n#14 6.441  + protobuf==6.32.1\n2025-Nov-05 10:19:35.950300\n#14 6.441  + psycopg==3.2.10\n2025-Nov-05 10:19:35.950300\n#14 6.441  + psycopg-binary==3.2.10\n2025-Nov-05 10:19:35.950300\n#14 6.441  + psycopg-pool==3.2.6\n2025-Nov-05 10:19:35.950300\n#14 6.441  + pyasn1==0.6.1\n2025-Nov-05 10:19:35.950300\n#14 6.441  + pyasn1-modules==0.4.2\n2025-Nov-05 10:19:35.950300\n#14 6.441  + pybase64==1.4.2\n2025-Nov-05 10:19:35.950300\n#14 6.441  + pycparser==2.23\n2025-Nov-05 10:19:35.950300\n#14 6.442  + pydantic==2.12.1\n2025-Nov-05 10:19:35.950300\n#14 6.442  + pydantic-core==2.41.3\n2025-Nov-05 10:19:35.950300\n#14 6.442  + pydantic-settings==2.11.0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + pygments==2.19.2\n2025-Nov-05 10:19:35.950300\n#14 6.442  + pynacl==1.6.0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + pytest==8.4.2\n2025-Nov-05 10:19:35.950300\n#14 6.442  + python-dateutil==2.9.0.post0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + python-dotenv==1.1.1\n2025-Nov-05 10:19:35.950300\n#14 6.442  + python-multipart==0.0.20\n2025-Nov-05 10:19:35.950300\n#14 6.442  + pyyaml==6.0.3\n2025-Nov-05 10:19:35.950300\n#14 6.442  + redis==6.4.0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + requests==2.32.5\n2025-Nov-05 10:19:35.950300\n#14 6.442  + rich==14.2.0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + rich-toolkit==0.15.1\n2025-Nov-05 10:19:35.950300\n#14 6.442  + rignore==0.7.0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + rsa==4.9.1\n2025-Nov-05 10:19:35.950300\n#14 6.442  + ruff==0.14.0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + sentry-sdk==2.41.0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + shared==0.1.0 (from file:///app/packages/shared)\n2025-Nov-05 10:19:35.950300\n#14 6.443  + shellingham==1.5.4\n2025-Nov-05 10:19:35.950300\n#14 6.443  + six==1.17.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + slack-sdk==3.37.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + sniffio==1.3.1\n2025-Nov-05 10:19:35.950300\n#14 6.443  + sqlalchemy==2.0.44\n2025-Nov-05 10:19:35.950300\n#14 6.443  + starlette==0.48.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + structlog==25.4.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + tonyg-rfc3339==0.1\n2025-Nov-05 10:19:35.950300\n#14 6.443  + tqdm==4.67.1\n2025-Nov-05 10:19:35.950300\n#14 6.443  + turbopuffer==1.3.1\n2025-Nov-05 10:19:35.950300\n#14 6.443  + typer==0.19.2\n2025-Nov-05 10:19:35.950300\n#14 6.443  + typing-extensions==4.15.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + typing-inspection==0.4.2\n2025-Nov-05 10:19:35.950300\n#14 6.443  + tzlocal==5.3.1\n2025-Nov-05 10:19:35.950300\n#14 6.443  + urllib3==2.5.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + uvicorn==0.37.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + uvloop==0.21.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + virtualenv==20.35.3\n2025-Nov-05 10:19:35.950300\n#14 6.443  + watchfiles==1.1.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + webhooks==0.1.0 (from file:///app/apps/webhooks)\n2025-Nov-05 10:19:35.950300\n#14 6.443  + websockets==15.0.1\n2025-Nov-05 10:19:35.950300\n#14 6.443  + yarl==1.22.0\n2025-Nov-05 10:19:35.950300\n#14 6.444  + zep-cloud==3.5.0\n2025-Nov-05 10:19:35.950300\n#14 6.444  + zipp==3.23.0\n2025-Nov-05 10:19:37.586385\n#14 DONE 8.2s\n2025-Nov-05 10:19:37.746014\n#15 [builder 9/9] RUN rm -rf /root/.cache /root/.uv-cache\n2025-Nov-05 10:19:44.770014\n#15 DONE 7.2s\n2025-Nov-05 10:19:50.259887\n#16 [stage-1 3/7] RUN apt-get update && apt-get install -y --no-install-recommends curl   && curl -1sLf 'https://artifacts-cli.infisical.com/setup.deb.sh' | bash   && apt-get install -y --no-install-recommends infisical   && rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:50.412590\n#16 CACHED\n2025-Nov-05 10:19:50.412590\n2025-Nov-05 10:19:50.412590\n#17 [stage-1 4/7] COPY --from=builder /app/.venv /app/.venv\n2025-Nov-05 10:19:54.030020\n#17 DONE 3.8s\n2025-Nov-05 10:19:54.139159\n#18 [stage-1 5/7] COPY --from=builder /app/packages/shared /app/packages/shared\n2025-Nov-05 10:19:54.139159\n#18 DONE 0.1s\n2025-Nov-05 10:19:54.250116\n#19 [stage-1 6/7] COPY --from=builder /app/apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:54.250116\n#19 DONE 0.1s\n2025-Nov-05 10:19:54.405723\n#20 [stage-1 7/7] COPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:54.455673\n#20 DONE 0.2s\n2025-Nov-05 10:19:54.645685\n#21 exporting to image\n2025-Nov-05 10:19:54.645685\n#21 exporting layers\n2025-Nov-05 10:19:56.973033\n#21 exporting layers 2.5s done\n2025-Nov-05 10:19:57.087921\n#21 writing image sha256:d284e7f248539ffb86adae9e166d03cd29425ac74c5bbe5691a0aa3219dfe2eb done\n2025-Nov-05 10:19:57.087921\n#21 naming to docker.io/realmsoftwareinc/webhooks-prod:eb20a0771f925bf19364784030b4df74a55441f5 done\n2025-Nov-05 10:19:57.087921\n#21 DONE 2.5s\n2025-Nov-05 10:19:57.140786\nBuilding docker image completed.\n2025-Nov-05 10:19:57.156075\nCreating .env file with runtime variables for build phase.\n2025-Nov-05 10:19:57.691747\nOops something is not okay, are you okay? \n2025-Nov-05 10:19:57.701848\nDeployment failed. Removing the new version of your application.\n2025-Nov-05 10:19:57.952779\nGracefully shutting down build container: uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:58.199636\n[CMD]: docker stop --time=30 uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:58.199636\nFlag --time has been deprecated, use --timeout instead\n2025-Nov-05 10:19:58.603460\nuw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:58.857150\n[CMD]: docker rm -f uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:58.857150\nError response from daemon: No such container: uw4kosoc84ooc808ww4080ww\n```\n\nOr, another build that failed for no apparent reason, this time on the builder:\n\n```\n2025-Nov-04 21:11:16.151285\nFound a suitable build server (Builder).\n2025-Nov-04 21:11:16.162132\nStarting deployment of dimensionhq/ai:master to Webhooks - 2.\n2025-Nov-04 21:11:16.500066\nPreparing container with helper image: ghcr.io/coollabsio/coolify-helper:1.0.11\n2025-Nov-04 21:11:16.703351\n[CMD]: docker stop --time=30 b0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:16.703351\nFlag --time has been deprecated, use --timeout instead\n2025-Nov-04 21:11:16.705523\nError response from daemon: No such container: b0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:16.890495\n[CMD]: docker rm -f b0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:16.890495\nError response from daemon: No such container: b0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:17.130715\n[CMD]: docker run -d --name b0o844sgkwkow48oc4gc8cgk  --rm -v /root/.docker/config.json:/root/.docker/config.json:ro -v /var/run/docker.sock:/var/run/docker.sock ghcr.io/coollabsio/coolify-helper:1.0.11\n2025-Nov-04 21:11:17.130715\n702832ce4fbd3a6abf2976103a23fec9c9d5642de8d7fbbe920ed7645cc74ea9\n2025-Nov-04 21:11:18.542726\nOops something is not okay, are you okay? \n2025-Nov-04 21:11:18.550276\nDeployment failed. Removing the new version of your application.\n2025-Nov-04 21:11:18.736879\nGracefully shutting down build container: b0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:18.923578\n[CMD]: docker stop --time=30 b0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:18.923578\nFlag --time has been deprecated, use --timeout instead\n2025-Nov-04 21:11:19.088910\nb0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:19.297149\n[CMD]: docker rm -f b0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:19.297149\nError response from daemon: No such container: b0o844sgkwkow48oc4gc8cgk\n```\n\nFinal example:\n```\n2025-Nov-05 02:32:59.297151\nFound a suitable build server (Builder).\n2025-Nov-05 02:32:59.306247\nStarting deployment of dimensionhq/gmail-mcp-server:master to MCP - 2.\n2025-Nov-05 02:32:59.721620\nPreparing container with helper image: ghcr.io/coollabsio/coolify-helper:1.0.11\n2025-Nov-05 02:33:02.138241\n----------------------------------------\n2025-Nov-05 02:33:02.147524\nImporting dimensionhq/gmail-mcp-server:master (commit sha 0062e28d4ef88173db8c0a9e33eca23b8b8c75d6) to /artifacts/i8k04s4scgkcok0wwwswoscs.\n2025-Nov-05 02:33:04.576587\nImage not found (realmsoftwareinc/gmail-mcp-server-production:0062e28d4ef88173db8c0a9e33eca23b8b8c75d6). Building new image.\n2025-Nov-05 02:33:07.614573\n----------------------------------------\n2025-Nov-05 02:33:07.624301\nBuilding docker image started.\n2025-Nov-05 02:33:07.633300\nTo check the current progress, click on Show Debug Logs.\n2025-Nov-05 02:33:51.372999\nBuilding docker image completed.\n2025-Nov-05 02:33:52.638262\n----------------------------------------\n2025-Nov-05 02:33:52.649146\nPushing image to docker registry (realmsoftwareinc/gmail-mcp-server-production:0062e28d4ef88173db8c0a9e33eca23b8b8c75d6).\n2025-Nov-05 02:34:14.362435\nTagging and pushing image with latest tag.\n2025-Nov-05 02:34:17.144804\nFound a suitable build server (Builder).\n2025-Nov-05 02:34:17.155960\nStarting deployment of dimensionhq/gmail-mcp-server:master to MCP - 2.\n2025-Nov-05 02:34:17.526919\nPreparing container with helper image: ghcr.io/coollabsio/coolify-helper:1.0.11\n2025-Nov-05 02:34:18.291348\n----------------------------------------\n2025-Nov-05 02:34:18.300366\nRolling update started.\n2025-Nov-05 02:34:34.775583\n----------------------------------------\n2025-Nov-05 02:34:34.792699\nRolling update started.\n2025-Nov-05 02:34:38.307388\nNew container started.\n2025-Nov-05 02:34:38.318536\nNew container started.\n2025-Nov-05 02:34:38.328167\nCustom healthcheck found in Dockerfile.\n2025-Nov-05 02:34:38.337170\nWaiting for healthcheck to pass on the new container.\n2025-Nov-05 02:34:38.346321\nWaiting for the start period (5 seconds) before starting healthcheck.\n2025-Nov-05 02:34:43.892990\nAttempt 1 of 3 | Healthcheck status: \"healthy\"\n2025-Nov-05 02:34:43.910443\nHealthcheck logs:   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n2025-Nov-05 02:34:43.910443\nDload  Upload   Total   Spent    Left  Speed\n2025-Nov-05 02:34:43.910443\n0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100    64  100    64    0     0   4002      0 --:--:-- --:--:-- --:--:--  4266\n2025-Nov-05 02:34:43.910443\n{\"status\":\"ok\",\"transport\":\"streamable-http\",\"mode\":\"stateless\"} | Return code: 0\n2025-Nov-05 02:34:43.929915\nNew container is healthy.\n2025-Nov-05 02:34:43.945834\nRemoving old containers.\n2025-Nov-05 02:34:46.188552\nRolling update completed.\n2025-Nov-05 02:34:46.260320\nGracefully shutting down build container: i8k04s4scgkcok0wwwswoscs\n2025-Nov-05 02:35:14.238820\nOops something is not okay, are you okay? \n2025-Nov-05 02:35:14.250226\nError: No such object: k00cg8gccos8s888cgo4w804-023024867976\n2025-Nov-05 02:35:14.261788\nDeployment failed. Removing the new version of your application.\n2025-Nov-05 02:35:14.553878\nGracefully shutting down build container: i8k04s4scgkcok0wwwswoscs\n```\n\n</details>\n\n### Steps to Reproduce\n\nI'm not certain how to reproduce this issue, but I would appreciate guidance on how to look deeper into the logs or inside Coolify to see what actually went wrong.\n\nWe setup a Builder instance with 6 vCPU & 16 GB of ram, with a maximum of 2 concurrent deployments. This issue occurs across several different resources and several different Docker images.\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.441\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nUbuntu 24.04\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7113"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7113",
              "body": "### Error Message and Logs\n\nOur deployments have been in-deterministically failing with no obvious cause. Here's a few deployment logs on our end that just failed, and would work perfectly with a redeploy.\n\n<details>\n\n```\n2025-Nov-05 10:19:19.363823\nFound a suitable build server (Builder).\n2025-Nov-05 10:19:19.370090\nStarting deployment of dimensionhq/ai:master to Webhooks - 2.\n2025-Nov-05 10:19:19.728111\nPreparing container with helper image: ghcr.io/coollabsio/coolify-helper:1.0.11\n2025-Nov-05 10:19:19.905615\n[CMD]: docker stop --time=30 uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:19.905615\nFlag --time has been deprecated, use --timeout instead\n2025-Nov-05 10:19:19.907955\nError response from daemon: No such container: uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:20.143670\n[CMD]: docker rm -f uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:20.143670\nError response from daemon: No such container: uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:20.365835\n[CMD]: docker run -d --name uw4kosoc84ooc808ww4080ww  --rm -v /root/.docker/config.json:/root/.docker/config.json:ro -v /var/run/docker.sock:/var/run/docker.sock ghcr.io/coollabsio/coolify-helper:1.0.11\n2025-Nov-05 10:19:20.365835\n0b60882c666a468473fc10c4a2350c55587bb7cd4cb62e200bba037838f453e8\n2025-Nov-05 10:19:22.053986\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'GIT_SSH_COMMAND=\"ssh -o ConnectTimeout=30 -p 22 -o Port=22 -o LogLevel=ERROR -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null\" git ls-remote [https://x-access-token:<REDACTED>@github.com/dimensionhq/ai.git](https://x-access-token:%3CREDACTED%3E@github.com/dimensionhq/ai.git) refs/heads/master'\n2025-Nov-05 10:19:22.053986\neb20a0771f925bf19364784030b4df74a55441f5\trefs/heads/master\n2025-Nov-05 10:19:22.188928\n----------------------------------------\n2025-Nov-05 10:19:22.194547\nImporting dimensionhq/ai:master (commit sha eb20a0771f925bf19364784030b4df74a55441f5) to /artifacts/uw4kosoc84ooc808ww4080ww.\n2025-Nov-05 10:19:22.451630\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'git clone --depth=1 --recurse-submodules --shallow-submodules -b 'master' '[https://x-access-token:<REDACTED>@github.com/dimensionhq/ai.git'](https://x-access-token:%3CREDACTED%3E@github.com/dimensionhq/ai.git') '/artifacts/uw4kosoc84ooc808ww4080ww' && cd '/artifacts/uw4kosoc84ooc808ww4080ww' && if [ -f .gitmodules ]; then git submodule sync && GIT_SSH_COMMAND=\"ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null\" git submodule update --init --recursive --depth=1; fi && cd '/artifacts/uw4kosoc84ooc808ww4080ww' && GIT_SSH_COMMAND=\"ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null\" git lfs pull'\n2025-Nov-05 10:19:22.451630\nCloning into '/artifacts/uw4kosoc84ooc808ww4080ww'...\n2025-Nov-05 10:19:24.006780\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'cd /artifacts/uw4kosoc84ooc808ww4080ww && git log -1 eb20a0771f925bf19364784030b4df74a55441f5 --pretty=%B'\n2025-Nov-05 10:19:24.006780\nMerge branch 'master' of https://github.com/dimensionhq/ai\n2025-Nov-05 10:19:24.769603\nImage not found (realmsoftwareinc/webhooks-prod:eb20a0771f925bf19364784030b4df74a55441f5). Building new image.\n2025-Nov-05 10:19:26.046158\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'cat /artifacts/uw4kosoc84ooc808ww4080ww/apps/webhooks/Dockerfile'\n2025-Nov-05 10:19:26.046158\n# Build dependencies and virtualenv in a dedicated stage\n2025-Nov-05 10:19:26.046158\nFROM python:3.11-slim AS builder\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\nWORKDIR /app\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Install build tooling and uv (no recommends to keep layer slim)\n2025-Nov-05 10:19:26.046158\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n2025-Nov-05 10:19:26.046158\ngcc \\\n2025-Nov-05 10:19:26.046158\ng++ \\\n2025-Nov-05 10:19:26.046158\ncurl \\\n2025-Nov-05 10:19:26.046158\n&& rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\nRUN pip install --no-cache-dir uv\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Copy workspace files needed for dependency resolution\n2025-Nov-05 10:19:26.046158\nCOPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:26.046158\nCOPY packages/shared /app/packages/shared\n2025-Nov-05 10:19:26.046158\nCOPY apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Install Python dependencies into .venv\n2025-Nov-05 10:19:26.046158\nRUN uv sync --frozen --package webhooks\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Clean up build artefacts to keep the copied layer trim\n2025-Nov-05 10:19:26.046158\nRUN rm -rf /root/.cache /root/.uv-cache\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Final runtime image\n2025-Nov-05 10:19:26.046158\nFROM python:3.11-slim\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\nWORKDIR /app\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Install curl (for health check) and Infisical CLI with minimal extras\n2025-Nov-05 10:19:26.046158\nRUN apt-get update && apt-get install -y --no-install-recommends curl \\\n2025-Nov-05 10:19:26.046158\n&& curl -1sLf 'https://artifacts-cli.infisical.com/setup.deb.sh' | bash \\\n2025-Nov-05 10:19:26.046158\n&& apt-get install -y --no-install-recommends infisical \\\n2025-Nov-05 10:19:26.046158\n&& rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Copy in the prebuilt virtualenv and application code\n2025-Nov-05 10:19:26.046158\nCOPY --from=builder /app/.venv /app/.venv\n2025-Nov-05 10:19:26.046158\nCOPY --from=builder /app/packages/shared /app/packages/shared\n2025-Nov-05 10:19:26.046158\nCOPY --from=builder /app/apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:26.046158\nCOPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Expose port 8000\n2025-Nov-05 10:19:26.046158\nEXPOSE 8000\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Set environment variables\n2025-Nov-05 10:19:26.046158\nENV PYTHONPATH=/app\n2025-Nov-05 10:19:26.046158\nENV PYTHONUNBUFFERED=1\n2025-Nov-05 10:19:26.046158\nENV PATH=\"/app/.venv/bin:$PATH\"\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Health check\n2025-Nov-05 10:19:26.046158\nHEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\\n2025-Nov-05 10:19:26.046158\nCMD curl -f http://localhost:8000/health || exit 1\n2025-Nov-05 10:19:26.046158\n2025-Nov-05 10:19:26.046158\n# Run the application with Infisical and Gunicorn\n2025-Nov-05 10:19:26.046158\n# Note: Set INFISICAL_TOKEN and INFISICAL_PROJECT_ID environment variables when running the container\n2025-Nov-05 10:19:26.046158\n# Example: docker run --env INFISICAL_TOKEN=$INFISICAL_TOKEN --env INFISICAL_PROJECT_ID=your-project-id your-image\n2025-Nov-05 10:19:26.046158\nCMD [\"sh\", \"-c\", \"infisical run --projectId $INFISICAL_PROJECT_ID --command 'cd /app/apps/webhooks/webhooks && /app/.venv/bin/gunicorn main:app -c gunicorn.conf.py'\"]\n2025-Nov-05 10:19:26.382688\nCreating build-time .env file in /artifacts (outside Docker context).\n2025-Nov-05 10:19:26.930010\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'cat /artifacts/build-time.env'\n2025-Nov-05 10:19:26.930010\nSOURCE_COMMIT='eb20a0771f925bf19364784030b4df74a55441f5'\n2025-Nov-05 10:19:26.930010\nCOOLIFY_URL=''\n2025-Nov-05 10:19:26.930010\nCOOLIFY_FQDN=''\n2025-Nov-05 10:19:26.930010\nCOOLIFY_BRANCH='master'\n2025-Nov-05 10:19:26.930010\nCOOLIFY_RESOURCE_UUID='b0808cwg8c4ko4kk84kkcks0'\n2025-Nov-05 10:19:26.930010\nCOOLIFY_CONTAINER_NAME='b0808cwg8c4ko4kk84kkcks0-101917583267'\n2025-Nov-05 10:19:26.930010\nINFISICAL_PROJECT_ID=\"65a15447c63fc2a03460007d\"\n2025-Nov-05 10:19:26.930010\nINFISICAL_TOKEN=\"st.885a8fa6-7c1c-47bb-8bfb-715555b46050.b9107cb09ef5069f89ac2720ab9c424a.1bd120fcdff9cbbab6c6c0e1f7678875\"\n2025-Nov-05 10:19:27.264299\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'cat /artifacts/uw4kosoc84ooc808ww4080ww/apps/webhooks/Dockerfile'\n2025-Nov-05 10:19:27.264299\n# Build dependencies and virtualenv in a dedicated stage\n2025-Nov-05 10:19:27.264299\nFROM python:3.11-slim AS builder\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\nWORKDIR /app\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Install build tooling and uv (no recommends to keep layer slim)\n2025-Nov-05 10:19:27.264299\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n2025-Nov-05 10:19:27.264299\ngcc \\\n2025-Nov-05 10:19:27.264299\ng++ \\\n2025-Nov-05 10:19:27.264299\ncurl \\\n2025-Nov-05 10:19:27.264299\n&& rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\nRUN pip install --no-cache-dir uv\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Copy workspace files needed for dependency resolution\n2025-Nov-05 10:19:27.264299\nCOPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:27.264299\nCOPY packages/shared /app/packages/shared\n2025-Nov-05 10:19:27.264299\nCOPY apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Install Python dependencies into .venv\n2025-Nov-05 10:19:27.264299\nRUN uv sync --frozen --package webhooks\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Clean up build artefacts to keep the copied layer trim\n2025-Nov-05 10:19:27.264299\nRUN rm -rf /root/.cache /root/.uv-cache\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Final runtime image\n2025-Nov-05 10:19:27.264299\nFROM python:3.11-slim\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\nWORKDIR /app\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Install curl (for health check) and Infisical CLI with minimal extras\n2025-Nov-05 10:19:27.264299\nRUN apt-get update && apt-get install -y --no-install-recommends curl \\\n2025-Nov-05 10:19:27.264299\n&& curl -1sLf 'https://artifacts-cli.infisical.com/setup.deb.sh' | bash \\\n2025-Nov-05 10:19:27.264299\n&& apt-get install -y --no-install-recommends infisical \\\n2025-Nov-05 10:19:27.264299\n&& rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Copy in the prebuilt virtualenv and application code\n2025-Nov-05 10:19:27.264299\nCOPY --from=builder /app/.venv /app/.venv\n2025-Nov-05 10:19:27.264299\nCOPY --from=builder /app/packages/shared /app/packages/shared\n2025-Nov-05 10:19:27.264299\nCOPY --from=builder /app/apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:27.264299\nCOPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Expose port 8000\n2025-Nov-05 10:19:27.264299\nEXPOSE 8000\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Set environment variables\n2025-Nov-05 10:19:27.264299\nENV PYTHONPATH=/app\n2025-Nov-05 10:19:27.264299\nENV PYTHONUNBUFFERED=1\n2025-Nov-05 10:19:27.264299\nENV PATH=\"/app/.venv/bin:$PATH\"\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Health check\n2025-Nov-05 10:19:27.264299\nHEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\\n2025-Nov-05 10:19:27.264299\nCMD curl -f http://localhost:8000/health || exit 1\n2025-Nov-05 10:19:27.264299\n2025-Nov-05 10:19:27.264299\n# Run the application with Infisical and Gunicorn\n2025-Nov-05 10:19:27.264299\n# Note: Set INFISICAL_TOKEN and INFISICAL_PROJECT_ID environment variables when running the container\n2025-Nov-05 10:19:27.264299\n# Example: docker run --env INFISICAL_TOKEN=$INFISICAL_TOKEN --env INFISICAL_PROJECT_ID=your-project-id your-image\n2025-Nov-05 10:19:27.264299\nCMD [\"sh\", \"-c\", \"infisical run --projectId $INFISICAL_PROJECT_ID --command 'cd /app/apps/webhooks/webhooks && /app/.venv/bin/gunicorn main:app -c gunicorn.conf.py'\"]\n2025-Nov-05 10:19:27.306071\nFinal Dockerfile:\n2025-Nov-05 10:19:27.928385\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'cat /artifacts/uw4kosoc84ooc808ww4080ww/apps/webhooks/Dockerfile'\n2025-Nov-05 10:19:27.928385\n# Build dependencies and virtualenv in a dedicated stage\n2025-Nov-05 10:19:27.928385\nARG COOLIFY_BUILD_SECRETS_HASH=4387256370ab25c71c6c7f93ce46e2a426fafb4ba429afe60f75c57a2cc75894\n2025-Nov-05 10:19:27.928385\nARG COOLIFY_CONTAINER_NAME=b0808cwg8c4ko4kk84kkcks0-101917583267\n2025-Nov-05 10:19:27.928385\nARG COOLIFY_RESOURCE_UUID=b0808cwg8c4ko4kk84kkcks0\n2025-Nov-05 10:19:27.928385\nARG COOLIFY_BRANCH=master\n2025-Nov-05 10:19:27.928385\nARG SOURCE_COMMIT=eb20a0771f925bf19364784030b4df74a55441f5\n2025-Nov-05 10:19:27.928385\nARG INFISICAL_TOKEN=st.885a8fa6-7c1c-47bb-8bfb-715555b46050.b9107cb09ef5069f89ac2720ab9c424a.1bd120fcdff9cbbab6c6c0e1f7678875\n2025-Nov-05 10:19:27.928385\nARG INFISICAL_PROJECT_ID=65a15447c63fc2a03460007d\n2025-Nov-05 10:19:27.928385\nFROM python:3.11-slim AS builder\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\nWORKDIR /app\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Install build tooling and uv (no recommends to keep layer slim)\n2025-Nov-05 10:19:27.928385\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n2025-Nov-05 10:19:27.928385\ngcc \\\n2025-Nov-05 10:19:27.928385\ng++ \\\n2025-Nov-05 10:19:27.928385\ncurl \\\n2025-Nov-05 10:19:27.928385\n&& rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\nRUN pip install --no-cache-dir uv\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Copy workspace files needed for dependency resolution\n2025-Nov-05 10:19:27.928385\nCOPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:27.928385\nCOPY packages/shared /app/packages/shared\n2025-Nov-05 10:19:27.928385\nCOPY apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Install Python dependencies into .venv\n2025-Nov-05 10:19:27.928385\nRUN uv sync --frozen --package webhooks\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Clean up build artefacts to keep the copied layer trim\n2025-Nov-05 10:19:27.928385\nRUN rm -rf /root/.cache /root/.uv-cache\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Final runtime image\n2025-Nov-05 10:19:27.928385\nFROM python:3.11-slim\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\nWORKDIR /app\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Install curl (for health check) and Infisical CLI with minimal extras\n2025-Nov-05 10:19:27.928385\nRUN apt-get update && apt-get install -y --no-install-recommends curl \\\n2025-Nov-05 10:19:27.928385\n&& curl -1sLf 'https://artifacts-cli.infisical.com/setup.deb.sh' | bash \\\n2025-Nov-05 10:19:27.928385\n&& apt-get install -y --no-install-recommends infisical \\\n2025-Nov-05 10:19:27.928385\n&& rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Copy in the prebuilt virtualenv and application code\n2025-Nov-05 10:19:27.928385\nCOPY --from=builder /app/.venv /app/.venv\n2025-Nov-05 10:19:27.928385\nCOPY --from=builder /app/packages/shared /app/packages/shared\n2025-Nov-05 10:19:27.928385\nCOPY --from=builder /app/apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:27.928385\nCOPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Expose port 8000\n2025-Nov-05 10:19:27.928385\nEXPOSE 8000\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Set environment variables\n2025-Nov-05 10:19:27.928385\nENV PYTHONPATH=/app\n2025-Nov-05 10:19:27.928385\nENV PYTHONUNBUFFERED=1\n2025-Nov-05 10:19:27.928385\nENV PATH=\"/app/.venv/bin:$PATH\"\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Health check\n2025-Nov-05 10:19:27.928385\nHEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\\n2025-Nov-05 10:19:27.928385\nCMD curl -f http://localhost:8000/health || exit 1\n2025-Nov-05 10:19:27.928385\n2025-Nov-05 10:19:27.928385\n# Run the application with Infisical and Gunicorn\n2025-Nov-05 10:19:27.928385\n# Note: Set INFISICAL_TOKEN and INFISICAL_PROJECT_ID environment variables when running the container\n2025-Nov-05 10:19:27.928385\n# Example: docker run --env INFISICAL_TOKEN=$INFISICAL_TOKEN --env INFISICAL_PROJECT_ID=your-project-id your-image\n2025-Nov-05 10:19:27.928385\nCMD [\"sh\", \"-c\", \"infisical run --projectId $INFISICAL_PROJECT_ID --command 'cd /app/apps/webhooks/webhooks && /app/.venv/bin/gunicorn main:app -c gunicorn.conf.py'\"]\n2025-Nov-05 10:19:27.942703\n----------------------------------------\n2025-Nov-05 10:19:27.949099\nBuilding docker image started.\n2025-Nov-05 10:19:27.957779\nTo check the current progress, click on Show Debug Logs.\n2025-Nov-05 10:19:28.573409\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'cat /artifacts/build.sh'\n2025-Nov-05 10:19:28.573409\ncd /artifacts/uw4kosoc84ooc808ww4080ww && set -a && source /artifacts/build-time.env && set +a && docker build   --network host -f /artifacts/uw4kosoc84ooc808ww4080ww/apps/webhooks/Dockerfile --build-arg SOURCE_COMMIT --build-arg COOLIFY_URL --build-arg COOLIFY_FQDN --build-arg COOLIFY_BRANCH --build-arg COOLIFY_RESOURCE_UUID --build-arg COOLIFY_CONTAINER_NAME --build-arg INFISICAL_PROJECT_ID --build-arg INFISICAL_TOKEN --build-arg COOLIFY_BUILD_SECRETS_HASH=636980d03d37af4b459b987881db690134f9b90ab8d67d21c1fc8e99e0f83d41 --build-arg 'SOURCE_COMMIT' --build-arg 'COOLIFY_URL' --build-arg 'COOLIFY_FQDN' --build-arg 'COOLIFY_BRANCH' --build-arg 'COOLIFY_RESOURCE_UUID' --build-arg 'COOLIFY_CONTAINER_NAME' --progress plain -t realmsoftwareinc/webhooks-prod:eb20a0771f925bf19364784030b4df74a55441f5 /artifacts/uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:29.156678\n[CMD]: docker exec uw4kosoc84ooc808ww4080ww bash -c 'bash /artifacts/build.sh'\n2025-Nov-05 10:19:29.156678\n#0 building with \"default\" instance using docker driver\n2025-Nov-05 10:19:29.156678\n2025-Nov-05 10:19:29.156678\n#1 [internal] load build definition from Dockerfile\n2025-Nov-05 10:19:29.156678\n#1 transferring dockerfile: 2.52kB done\n2025-Nov-05 10:19:29.156678\n#1 DONE 0.0s\n2025-Nov-05 10:19:29.156678\n2025-Nov-05 10:19:29.156678\n#2 [auth] library/python:pull token for registry-1.docker.io\n2025-Nov-05 10:19:29.156678\n#2 DONE 0.0s\n2025-Nov-05 10:19:29.156678\n2025-Nov-05 10:19:29.156678\n#3 [internal] load metadata for docker.io/library/python:3.11-slim\n2025-Nov-05 10:19:29.156678\n#3 DONE 0.1s\n2025-Nov-05 10:19:29.262918\n#4 [builder 1/9] FROM docker.io/library/python:3.11-slim@sha256:fa9b525a0be0c5ae5e6f2209f4be6fdc5a15a36fed0222144d98ac0d08f876d4\n2025-Nov-05 10:19:29.262918\n#4 DONE 0.0s\n2025-Nov-05 10:19:29.262918\n2025-Nov-05 10:19:29.262918\n#5 [internal] load .dockerignore\n2025-Nov-05 10:19:29.262918\n#5 transferring context: 2B done\n2025-Nov-05 10:19:29.262918\n#5 DONE 0.0s\n2025-Nov-05 10:19:29.262918\n2025-Nov-05 10:19:29.262918\n#6 [internal] load build context\n2025-Nov-05 10:19:29.262918\n#6 transferring context: 1.44MB 0.1s done\n2025-Nov-05 10:19:29.510044\n#6 DONE 0.1s\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#7 [builder 6/9] COPY packages/shared /app/packages/shared\n2025-Nov-05 10:19:29.510044\n#7 CACHED\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#8 [builder 2/9] WORKDIR /app\n2025-Nov-05 10:19:29.510044\n#8 CACHED\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#9 [builder 4/9] RUN pip install --no-cache-dir uv\n2025-Nov-05 10:19:29.510044\n#9 CACHED\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#10 [builder 3/9] RUN apt-get update && apt-get install -y --no-install-recommends   gcc   g++   curl   && rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:29.510044\n#10 CACHED\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#11 [builder 5/9] COPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:29.510044\n#11 CACHED\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#12 [builder 6/9] COPY packages/shared /app/packages/shared\n2025-Nov-05 10:19:29.510044\n#12 CACHED\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#13 [builder 7/9] COPY apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:29.510044\n#13 DONE 0.1s\n2025-Nov-05 10:19:29.510044\n2025-Nov-05 10:19:29.510044\n#14 [builder 8/9] RUN uv sync --frozen --package webhooks\n2025-Nov-05 10:19:29.594969\n#14 0.238 Using CPython 3.11.14 interpreter at: /usr/local/bin/python3\n2025-Nov-05 10:19:29.594969\n#14 0.238 Creating virtual environment at: .venv\n2025-Nov-05 10:19:29.749236\n#14 0.305    Building webhooks @ file:///app/apps/webhooks\n2025-Nov-05 10:19:29.749236\n#14 0.309    Building shared @ file:///app/packages/shared\n2025-Nov-05 10:19:29.749236\n#14 0.392 Downloading aiohttp (1.7MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.392 Downloading psycopg-binary (4.2MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.393 Downloading pynacl (1.3MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.394 Downloading sqlalchemy (3.2MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.396 Downloading asyncpg (3.0MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.397 Downloading pydantic-core (2.0MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.398 Downloading cryptography (4.3MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.399 Downloading virtualenv (5.7MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.400 Downloading ruff (12.8MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.400 Downloading uvloop (3.8MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.400 Downloading pygments (1.2MiB)\n2025-Nov-05 10:19:29.911749\n#14 0.400 Downloading grpcio (6.2MiB)\n2025-Nov-05 10:19:30.555268\n#14 1.199    Building nats-py==2.11.0\n2025-Nov-05 10:19:31.339158\n#14 1.983  Downloading pydantic-core\n2025-Nov-05 10:19:31.491550\n#14 2.034    Building tonyg-rfc3339==0.1\n2025-Nov-05 10:19:31.491550\n#14 2.133    Building nkeys==0.2.1\n2025-Nov-05 10:19:31.598344\n#14 2.147  Downloading pynacl\n2025-Nov-05 10:19:31.602095\n#14 2.241  Downloading aiohttp\n2025-Nov-05 10:19:31.763871\n#14 2.407  Downloading asyncpg\n2025-Nov-05 10:19:31.999697\n#14 2.643  Downloading psycopg-binary\n2025-Nov-05 10:19:32.105619\n#14 2.749  Downloading virtualenv\n2025-Nov-05 10:19:32.252014\n#14 2.755  Downloading ruff\n2025-Nov-05 10:19:32.252014\n#14 2.818  Downloading uvloop\n2025-Nov-05 10:19:32.252014\n#14 2.890  Downloading grpcio\n2025-Nov-05 10:19:32.489971\n#14 2.929  Downloading sqlalchemy\n2025-Nov-05 10:19:32.489971\n#14 2.943  Downloading cryptography\n2025-Nov-05 10:19:32.489971\n#14 2.983  Downloading pygments\n2025-Nov-05 10:19:35.169371\n#14 5.813       Built nkeys==0.2.1\n2025-Nov-05 10:19:35.410078\n#14 6.052       Built nats-py==2.11.0\n2025-Nov-05 10:19:35.576134\n#14 6.084       Built shared @ file:///app/packages/shared\n2025-Nov-05 10:19:35.576134\n#14 6.218       Built webhooks @ file:///app/apps/webhooks\n2025-Nov-05 10:19:35.576134\n#14 6.218       Built tonyg-rfc3339==0.1\n2025-Nov-05 10:19:35.729658\n#14 6.221 Prepared 115 packages in 5.94s\n2025-Nov-05 10:19:35.793532\n#14 6.435 Installed 115 packages in 212ms\n2025-Nov-05 10:19:35.793532\n#14 6.435  + aiofiles==25.1.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + aiogoogle==5.17.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + aiohappyeyeballs==2.6.1\n2025-Nov-05 10:19:35.793532\n#14 6.435  + aiohttp==3.13.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + aiosignal==1.4.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + annotated-types==0.7.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + anyio==4.11.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + apscheduler==3.11.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + async-timeout==5.0.1\n2025-Nov-05 10:19:35.793532\n#14 6.435  + asyncpg==0.30.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + attrs==25.4.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + cachetools==6.2.1\n2025-Nov-05 10:19:35.793532\n#14 6.435  + certifi==2025.10.5\n2025-Nov-05 10:19:35.793532\n#14 6.435  + cffi==2.0.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + cfgv==3.4.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + charset-normalizer==3.4.4\n2025-Nov-05 10:19:35.793532\n#14 6.435  + click==8.3.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + cryptography==46.0.2\n2025-Nov-05 10:19:35.793532\n#14 6.435  + distlib==0.4.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + distro==1.9.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + dnspython==2.8.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + email-validator==2.3.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + fastapi==0.119.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + fastapi-cli==0.0.13\n2025-Nov-05 10:19:35.793532\n#14 6.435  + fastapi-cloud-cli==0.3.1\n2025-Nov-05 10:19:35.793532\n#14 6.435  + filelock==3.20.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + frozenlist==1.8.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + google-api-core==2.26.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + google-auth==2.41.1\n2025-Nov-05 10:19:35.793532\n#14 6.435  + google-cloud-kms==3.6.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + google-cloud-pubsub==2.31.1\n2025-Nov-05 10:19:35.793532\n#14 6.435  + googleapis-common-protos==1.70.0\n2025-Nov-05 10:19:35.793532\n#14 6.435  + greenlet\n2025-Nov-05 10:19:35.950300\n==3.2.4\n2025-Nov-05 10:19:35.950300\n#14 6.435  + grpc-google-iam-v1==0.14.2\n2025-Nov-05 10:19:35.950300\n#14 6.435  + grpcio==1.75.1\n2025-Nov-05 10:19:35.950300\n#14 6.435  + grpcio-status==1.75.1\n2025-Nov-05 10:19:35.950300\n#14 6.435  + gunicorn==23.0.0\n2025-Nov-05 10:19:35.950300\n#14 6.435  + h11==0.16.0\n2025-Nov-05 10:19:35.950300\n#14 6.435  + httpcore==1.0.9\n2025-Nov-05 10:19:35.950300\n#14 6.435  + httptools==0.7.1\n2025-Nov-05 10:19:35.950300\n#14 6.435  + httpx==0.28.1\n2025-Nov-05 10:19:35.950300\n#14 6.435  + identify==2.6.15\n2025-Nov-05 10:19:35.950300\n#14 6.435  + idna==3.11\n2025-Nov-05 10:19:35.950300\n#14 6.439  + importlib-metadata==8.7.0\n2025-Nov-05 10:19:35.950300\n#14 6.439  + iniconfig==2.1.0\n2025-Nov-05 10:19:35.950300\n#14 6.439  + jinja2==3.1.6\n2025-Nov-05 10:19:35.950300\n#14 6.439  + jiter==0.11.0\n2025-Nov-05 10:19:35.950300\n#14 6.439  + markdown-it-py==4.0.0\n2025-Nov-05 10:19:35.950300\n#14 6.439  + markupsafe==3.0.3\n2025-Nov-05 10:19:35.950300\n#14 6.439  + mdurl==0.1.2\n2025-Nov-05 10:19:35.950300\n#14 6.440  + multidict==6.7.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + nats-py==2.11.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + nkeys==0.2.1\n2025-Nov-05 10:19:35.950300\n#14 6.440  + nodeenv==1.9.1\n2025-Nov-05 10:19:35.950300\n#14 6.440  + openai==1.109.1\n2025-Nov-05 10:19:35.950300\n#14 6.440  + opentelemetry-api==1.37.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + opentelemetry-sdk==1.37.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + opentelemetry-semantic-conventions==0.58b0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + packaging==25.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + platformdirs==4.5.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + pluggy==1.6.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + pre-commit==4.3.0\n2025-Nov-05 10:19:35.950300\n#14 6.440  + propcache==0.4.1\n2025-Nov-05 10:19:35.950300\n#14 6.441  + proto-plus==1.26.1\n2025-Nov-05 10:19:35.950300\n#14 6.441  + protobuf==6.32.1\n2025-Nov-05 10:19:35.950300\n#14 6.441  + psycopg==3.2.10\n2025-Nov-05 10:19:35.950300\n#14 6.441  + psycopg-binary==3.2.10\n2025-Nov-05 10:19:35.950300\n#14 6.441  + psycopg-pool==3.2.6\n2025-Nov-05 10:19:35.950300\n#14 6.441  + pyasn1==0.6.1\n2025-Nov-05 10:19:35.950300\n#14 6.441  + pyasn1-modules==0.4.2\n2025-Nov-05 10:19:35.950300\n#14 6.441  + pybase64==1.4.2\n2025-Nov-05 10:19:35.950300\n#14 6.441  + pycparser==2.23\n2025-Nov-05 10:19:35.950300\n#14 6.442  + pydantic==2.12.1\n2025-Nov-05 10:19:35.950300\n#14 6.442  + pydantic-core==2.41.3\n2025-Nov-05 10:19:35.950300\n#14 6.442  + pydantic-settings==2.11.0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + pygments==2.19.2\n2025-Nov-05 10:19:35.950300\n#14 6.442  + pynacl==1.6.0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + pytest==8.4.2\n2025-Nov-05 10:19:35.950300\n#14 6.442  + python-dateutil==2.9.0.post0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + python-dotenv==1.1.1\n2025-Nov-05 10:19:35.950300\n#14 6.442  + python-multipart==0.0.20\n2025-Nov-05 10:19:35.950300\n#14 6.442  + pyyaml==6.0.3\n2025-Nov-05 10:19:35.950300\n#14 6.442  + redis==6.4.0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + requests==2.32.5\n2025-Nov-05 10:19:35.950300\n#14 6.442  + rich==14.2.0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + rich-toolkit==0.15.1\n2025-Nov-05 10:19:35.950300\n#14 6.442  + rignore==0.7.0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + rsa==4.9.1\n2025-Nov-05 10:19:35.950300\n#14 6.442  + ruff==0.14.0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + sentry-sdk==2.41.0\n2025-Nov-05 10:19:35.950300\n#14 6.442  + shared==0.1.0 (from file:///app/packages/shared)\n2025-Nov-05 10:19:35.950300\n#14 6.443  + shellingham==1.5.4\n2025-Nov-05 10:19:35.950300\n#14 6.443  + six==1.17.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + slack-sdk==3.37.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + sniffio==1.3.1\n2025-Nov-05 10:19:35.950300\n#14 6.443  + sqlalchemy==2.0.44\n2025-Nov-05 10:19:35.950300\n#14 6.443  + starlette==0.48.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + structlog==25.4.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + tonyg-rfc3339==0.1\n2025-Nov-05 10:19:35.950300\n#14 6.443  + tqdm==4.67.1\n2025-Nov-05 10:19:35.950300\n#14 6.443  + turbopuffer==1.3.1\n2025-Nov-05 10:19:35.950300\n#14 6.443  + typer==0.19.2\n2025-Nov-05 10:19:35.950300\n#14 6.443  + typing-extensions==4.15.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + typing-inspection==0.4.2\n2025-Nov-05 10:19:35.950300\n#14 6.443  + tzlocal==5.3.1\n2025-Nov-05 10:19:35.950300\n#14 6.443  + urllib3==2.5.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + uvicorn==0.37.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + uvloop==0.21.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + virtualenv==20.35.3\n2025-Nov-05 10:19:35.950300\n#14 6.443  + watchfiles==1.1.0\n2025-Nov-05 10:19:35.950300\n#14 6.443  + webhooks==0.1.0 (from file:///app/apps/webhooks)\n2025-Nov-05 10:19:35.950300\n#14 6.443  + websockets==15.0.1\n2025-Nov-05 10:19:35.950300\n#14 6.443  + yarl==1.22.0\n2025-Nov-05 10:19:35.950300\n#14 6.444  + zep-cloud==3.5.0\n2025-Nov-05 10:19:35.950300\n#14 6.444  + zipp==3.23.0\n2025-Nov-05 10:19:37.586385\n#14 DONE 8.2s\n2025-Nov-05 10:19:37.746014\n#15 [builder 9/9] RUN rm -rf /root/.cache /root/.uv-cache\n2025-Nov-05 10:19:44.770014\n#15 DONE 7.2s\n2025-Nov-05 10:19:50.259887\n#16 [stage-1 3/7] RUN apt-get update && apt-get install -y --no-install-recommends curl   && curl -1sLf 'https://artifacts-cli.infisical.com/setup.deb.sh' | bash   && apt-get install -y --no-install-recommends infisical   && rm -rf /var/lib/apt/lists/*\n2025-Nov-05 10:19:50.412590\n#16 CACHED\n2025-Nov-05 10:19:50.412590\n2025-Nov-05 10:19:50.412590\n#17 [stage-1 4/7] COPY --from=builder /app/.venv /app/.venv\n2025-Nov-05 10:19:54.030020\n#17 DONE 3.8s\n2025-Nov-05 10:19:54.139159\n#18 [stage-1 5/7] COPY --from=builder /app/packages/shared /app/packages/shared\n2025-Nov-05 10:19:54.139159\n#18 DONE 0.1s\n2025-Nov-05 10:19:54.250116\n#19 [stage-1 6/7] COPY --from=builder /app/apps/webhooks /app/apps/webhooks\n2025-Nov-05 10:19:54.250116\n#19 DONE 0.1s\n2025-Nov-05 10:19:54.405723\n#20 [stage-1 7/7] COPY pyproject.toml uv.lock ./\n2025-Nov-05 10:19:54.455673\n#20 DONE 0.2s\n2025-Nov-05 10:19:54.645685\n#21 exporting to image\n2025-Nov-05 10:19:54.645685\n#21 exporting layers\n2025-Nov-05 10:19:56.973033\n#21 exporting layers 2.5s done\n2025-Nov-05 10:19:57.087921\n#21 writing image sha256:d284e7f248539ffb86adae9e166d03cd29425ac74c5bbe5691a0aa3219dfe2eb done\n2025-Nov-05 10:19:57.087921\n#21 naming to docker.io/realmsoftwareinc/webhooks-prod:eb20a0771f925bf19364784030b4df74a55441f5 done\n2025-Nov-05 10:19:57.087921\n#21 DONE 2.5s\n2025-Nov-05 10:19:57.140786\nBuilding docker image completed.\n2025-Nov-05 10:19:57.156075\nCreating .env file with runtime variables for build phase.\n2025-Nov-05 10:19:57.691747\nOops something is not okay, are you okay? \n2025-Nov-05 10:19:57.701848\nDeployment failed. Removing the new version of your application.\n2025-Nov-05 10:19:57.952779\nGracefully shutting down build container: uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:58.199636\n[CMD]: docker stop --time=30 uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:58.199636\nFlag --time has been deprecated, use --timeout instead\n2025-Nov-05 10:19:58.603460\nuw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:58.857150\n[CMD]: docker rm -f uw4kosoc84ooc808ww4080ww\n2025-Nov-05 10:19:58.857150\nError response from daemon: No such container: uw4kosoc84ooc808ww4080ww\n```\n\nOr, another build that failed for no apparent reason, this time on the builder:\n\n```\n2025-Nov-04 21:11:16.151285\nFound a suitable build server (Builder).\n2025-Nov-04 21:11:16.162132\nStarting deployment of dimensionhq/ai:master to Webhooks - 2.\n2025-Nov-04 21:11:16.500066\nPreparing container with helper image: ghcr.io/coollabsio/coolify-helper:1.0.11\n2025-Nov-04 21:11:16.703351\n[CMD]: docker stop --time=30 b0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:16.703351\nFlag --time has been deprecated, use --timeout instead\n2025-Nov-04 21:11:16.705523\nError response from daemon: No such container: b0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:16.890495\n[CMD]: docker rm -f b0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:16.890495\nError response from daemon: No such container: b0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:17.130715\n[CMD]: docker run -d --name b0o844sgkwkow48oc4gc8cgk  --rm -v /root/.docker/config.json:/root/.docker/config.json:ro -v /var/run/docker.sock:/var/run/docker.sock ghcr.io/coollabsio/coolify-helper:1.0.11\n2025-Nov-04 21:11:17.130715\n702832ce4fbd3a6abf2976103a23fec9c9d5642de8d7fbbe920ed7645cc74ea9\n2025-Nov-04 21:11:18.542726\nOops something is not okay, are you okay? \n2025-Nov-04 21:11:18.550276\nDeployment failed. Removing the new version of your application.\n2025-Nov-04 21:11:18.736879\nGracefully shutting down build container: b0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:18.923578\n[CMD]: docker stop --time=30 b0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:18.923578\nFlag --time has been deprecated, use --timeout instead\n2025-Nov-04 21:11:19.088910\nb0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:19.297149\n[CMD]: docker rm -f b0o844sgkwkow48oc4gc8cgk\n2025-Nov-04 21:11:19.297149\nError response from daemon: No such container: b0o844sgkwkow48oc4gc8cgk\n```\n\nFinal example:\n```\n2025-Nov-05 02:32:59.297151\nFound a suitable build server (Builder).\n2025-Nov-05 02:32:59.306247\nStarting deployment of dimensionhq/gmail-mcp-server:master to MCP - 2.\n2025-Nov-05 02:32:59.721620\nPreparing container with helper image: ghcr.io/coollabsio/coolify-helper:1.0.11\n2025-Nov-05 02:33:02.138241\n----------------------------------------\n2025-Nov-05 02:33:02.147524\nImporting dimensionhq/gmail-mcp-server:master (commit sha 0062e28d4ef88173db8c0a9e33eca23b8b8c75d6) to /artifacts/i8k04s4scgkcok0wwwswoscs.\n2025-Nov-05 02:33:04.576587\nImage not found (realmsoftwareinc/gmail-mcp-server-production:0062e28d4ef88173db8c0a9e33eca23b8b8c75d6). Building new image.\n2025-Nov-05 02:33:07.614573\n----------------------------------------\n2025-Nov-05 02:33:07.624301\nBuilding docker image started.\n2025-Nov-05 02:33:07.633300\nTo check the current progress, click on Show Debug Logs.\n2025-Nov-05 02:33:51.372999\nBuilding docker image completed.\n2025-Nov-05 02:33:52.638262\n----------------------------------------\n2025-Nov-05 02:33:52.649146\nPushing image to docker registry (realmsoftwareinc/gmail-mcp-server-production:0062e28d4ef88173db8c0a9e33eca23b8b8c75d6).\n2025-Nov-05 02:34:14.362435\nTagging and pushing image with latest tag.\n2025-Nov-05 02:34:17.144804\nFound a suitable build server (Builder).\n2025-Nov-05 02:34:17.155960\nStarting deployment of dimensionhq/gmail-mcp-server:master to MCP - 2.\n2025-Nov-05 02:34:17.526919\nPreparing container with helper image: ghcr.io/coollabsio/coolify-helper:1.0.11\n2025-Nov-05 02:34:18.291348\n----------------------------------------\n2025-Nov-05 02:34:18.300366\nRolling update started.\n2025-Nov-05 02:34:34.775583\n----------------------------------------\n2025-Nov-05 02:34:34.792699\nRolling update started.\n2025-Nov-05 02:34:38.307388\nNew container started.\n2025-Nov-05 02:34:38.318536\nNew container started.\n2025-Nov-05 02:34:38.328167\nCustom healthcheck found in Dockerfile.\n2025-Nov-05 02:34:38.337170\nWaiting for healthcheck to pass on the new container.\n2025-Nov-05 02:34:38.346321\nWaiting for the start period (5 seconds) before starting healthcheck.\n2025-Nov-05 02:34:43.892990\nAttempt 1 of 3 | Healthcheck status: \"healthy\"\n2025-Nov-05 02:34:43.910443\nHealthcheck logs:   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n2025-Nov-05 02:34:43.910443\nDload  Upload   Total   Spent    Left  Speed\n2025-Nov-05 02:34:43.910443\n0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100    64  100    64    0     0   4002      0 --:--:-- --:--:-- --:--:--  4266\n2025-Nov-05 02:34:43.910443\n{\"status\":\"ok\",\"transport\":\"streamable-http\",\"mode\":\"stateless\"} | Return code: 0\n2025-Nov-05 02:34:43.929915\nNew container is healthy.\n2025-Nov-05 02:34:43.945834\nRemoving old containers.\n2025-Nov-05 02:34:46.188552\nRolling update completed.\n2025-Nov-05 02:34:46.260320\nGracefully shutting down build container: i8k04s4scgkcok0wwwswoscs\n2025-Nov-05 02:35:14.238820\nOops something is not okay, are you okay? \n2025-Nov-05 02:35:14.250226\nError: No such object: k00cg8gccos8s888cgo4w804-023024867976\n2025-Nov-05 02:35:14.261788\nDeployment failed. Removing the new version of your application.\n2025-Nov-05 02:35:14.553878\nGracefully shutting down build container: i8k04s4scgkcok0wwwswoscs\n```\n\n</details>\n\n### Steps to Reproduce\n\nI'm not certain how to reproduce this issue, but I would appreciate guidance on how to look deeper into the logs or inside Coolify to see what actually went wrong.\n\nWe setup a Builder instance with 6 vCPU & 16 GB of ram, with a maximum of 2 concurrent deployments. This issue occurs across several different resources and several different Docker images.\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.441\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nUbuntu 24.04\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/7113",
              "tech": [
                "go"
              ],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7110",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-11-09T04:01:37.977Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:37.977Z",
            "created_at": "2025-11-09T04:01:37.977Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7110",
              "status": "open",
              "type": "issue",
              "number": 7110,
              "title": "[Enhancement]: Update Clickhouse template",
              "source": {
                "data": {
                  "id": "source-coollabsio#7110",
                  "user": {
                    "login": "ronenteva",
                    "id": 2454954,
                    "node_id": "MDQ6VXNlcjI0NTQ5NTQ=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/2454954?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/ronenteva",
                    "html_url": "https://github.com/ronenteva",
                    "followers_url": "https://api.github.com/users/ronenteva/followers",
                    "following_url": "https://api.github.com/users/ronenteva/following{/other_user}",
                    "gists_url": "https://api.github.com/users/ronenteva/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/ronenteva/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/ronenteva/subscriptions",
                    "organizations_url": "https://api.github.com/users/ronenteva/orgs",
                    "repos_url": "https://api.github.com/users/ronenteva/repos",
                    "events_url": "https://api.github.com/users/ronenteva/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/ronenteva/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Update Clickhouse template",
                  "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the Clickhouse template is using `bitnamilegacy/clickhouse` which is not updated anymore.\nI believe the correct image to be used is `clickhouse:lts`.\n\nSimply changing the image doesn't work, probably just different environment variables.\nThere should be a migration path so data won't be lost (written explanation is fine).\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7110"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7110",
              "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the Clickhouse template is using `bitnamilegacy/clickhouse` which is not updated anymore.\nI believe the correct image to be used is `clickhouse:lts`.\n\nSimply changing the image doesn't work, probably just different environment variables.\nThere should be a migration path so data won't be lost (written explanation is fine).\n",
              "url": "https://github.com/coollabsio/coolify/issues/7110",
              "tech": [
                "go"
              ],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#6894",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-11-09T04:01:38.066Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:38.066Z",
            "created_at": "2025-11-09T04:01:38.066Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#6894",
              "status": "open",
              "type": "issue",
              "number": 6894,
              "title": "[Enhancement]: Project-specific members",
              "source": {
                "data": {
                  "id": "source-coollabsio#6894",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Project-specific members",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n$1,000 USD bounty.\n\nAdd support for project-specific team members.\n\nProblem: I have team members I want to add to a project on Coolify, but I dont want to give them access to the full account and to all projects on the server. Instead, I want to invite them to a specific project on Coolify and for them to only have access to that project.\n\nAdditionally, I want to optionally allow the project-specific member to deploy their own apps on the servers on the account. This will just create a new project in the Team with them as a project-specific member.\n\nI should be able to manage all project-specific members from the main team page in addition to on each projects page.\n\nAny APIs that exist for managing team members should also work for project-specific members.\n\nThe purpose of this bounty is to create a secure way to give people limited access to projects on Coolify. They must not be able to break out of their permissions. For example, if I can SSH into a server as a project member using one of the keys - that would allow me to break out of my permissions.\n\nAcceptance criteria: Once your PR is merged and deployed on Coolify Cloud, I will test the features and award the bounty. Thanks!\n\n[Hack Club](https://hackclub.com) previously awarded bounties to implement database SSL and APIs to manage backups. Were a nonprofit for teenage coders!",
                  "html_url": "https://github.com/coollabsio/coolify/issues/6894"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#6894",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n$1,000 USD bounty.\n\nAdd support for project-specific team members.\n\nProblem: I have team members I want to add to a project on Coolify, but I dont want to give them access to the full account and to all projects on the server. Instead, I want to invite them to a specific project on Coolify and for them to only have access to that project.\n\nAdditionally, I want to optionally allow the project-specific member to deploy their own apps on the servers on the account. This will just create a new project in the Team with them as a project-specific member.\n\nI should be able to manage all project-specific members from the main team page in addition to on each projects page.\n\nAny APIs that exist for managing team members should also work for project-specific members.\n\nThe purpose of this bounty is to create a secure way to give people limited access to projects on Coolify. They must not be able to break out of their permissions. For example, if I can SSH into a server as a project member using one of the keys - that would allow me to break out of my permissions.\n\nAcceptance criteria: Once your PR is merged and deployed on Coolify Cloud, I will test the features and award the bounty. Thanks!\n\n[Hack Club](https://hackclub.com) previously awarded bounties to implement database SSL and APIs to manage backups. Were a nonprofit for teenage coders!",
              "url": "https://github.com/coollabsio/coolify/issues/6894",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#4523",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-11-09T04:01:38.180Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:38.180Z",
            "created_at": "2025-11-09T04:01:38.180Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#4523",
              "status": "open",
              "type": "issue",
              "number": 4523,
              "title": "[Bug]: Arch Linux is not handled in InstallDocker.php",
              "source": {
                "data": {
                  "id": "source-coollabsio#4523",
                  "user": {
                    "login": "NeoxyBox",
                    "id": 69315360,
                    "node_id": "MDQ6VXNlcjY5MzE1MzYw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/69315360?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/NeoxyBox",
                    "html_url": "https://github.com/NeoxyBox",
                    "followers_url": "https://api.github.com/users/NeoxyBox/followers",
                    "following_url": "https://api.github.com/users/NeoxyBox/following{/other_user}",
                    "gists_url": "https://api.github.com/users/NeoxyBox/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/NeoxyBox/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/NeoxyBox/subscriptions",
                    "organizations_url": "https://api.github.com/users/NeoxyBox/orgs",
                    "repos_url": "https://api.github.com/users/NeoxyBox/repos",
                    "events_url": "https://api.github.com/users/NeoxyBox/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/NeoxyBox/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Arch Linux is not handled in InstallDocker.php",
                  "body": "### Error Message and Logs\n\nArch Linux is not handled in the `app/Actions/Server/InstallDocker.php` file, which makes it impossible to install an Arch Linux remote server.\n\nError:\n\n500\nWait, this is not cool...\nThere has been an error, we are working on it.\nError: Unsupported OS\n\n### Steps to Reproduce\n\n1. Create an Arch Linux server and install Coolify on it\n2. Try adding an Arch Linux server as a remote server\n\n### Example Repository URL\n\nhttps://github.com/coollabsio/coolify/blob/8d779c88ff4f4709ac0353713533a65fe7d0b86c/app/Actions/Server/InstallDocker.php#L76\n\n### Coolify Version\n\nv4.0.0-beta.376\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nArch Linux\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/4523"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#4523",
              "body": "### Error Message and Logs\n\nArch Linux is not handled in the `app/Actions/Server/InstallDocker.php` file, which makes it impossible to install an Arch Linux remote server.\n\nError:\n\n500\nWait, this is not cool...\nThere has been an error, we are working on it.\nError: Unsupported OS\n\n### Steps to Reproduce\n\n1. Create an Arch Linux server and install Coolify on it\n2. Try adding an Arch Linux server as a remote server\n\n### Example Repository URL\n\nhttps://github.com/coollabsio/coolify/blob/8d779c88ff4f4709ac0353713533a65fe7d0b86c/app/Actions/Server/InstallDocker.php#L76\n\n### Coolify Version\n\nv4.0.0-beta.376\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nArch Linux\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/4523",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#6567",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-11-09T04:01:38.288Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:38.288Z",
            "created_at": "2025-11-09T04:01:38.288Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#6567",
              "status": "open",
              "type": "issue",
              "number": 6567,
              "title": "[Enhancement]: Add Soju IRC bouncer",
              "source": {
                "data": {
                  "id": "source-coollabsio#6567",
                  "user": {
                    "login": "XEJK",
                    "id": 4692876,
                    "node_id": "MDQ6VXNlcjQ2OTI4NzY=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/4692876?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/XEJK",
                    "html_url": "https://github.com/XEJK",
                    "followers_url": "https://api.github.com/users/XEJK/followers",
                    "following_url": "https://api.github.com/users/XEJK/following{/other_user}",
                    "gists_url": "https://api.github.com/users/XEJK/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/XEJK/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/XEJK/subscriptions",
                    "organizations_url": "https://api.github.com/users/XEJK/orgs",
                    "repos_url": "https://api.github.com/users/XEJK/repos",
                    "events_url": "https://api.github.com/users/XEJK/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/XEJK/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Add Soju IRC bouncer",
                  "body": "### Request Type\n\nNew Service\n\n### Description\n\nIt would be nice to add the Soju IRC bouncer to the list of services.\nThe documentation is here: \n1. https://codeberg.org/emersion/soju/src/branch/master/doc/getting-started.md\n2. https://codeberg.org/emersion/soju-containers\n3. https://codeberg.org/emersion/soju/src/branch/master/doc/file-upload.md\n\nIt's based on a docker compose seems to need some extra thought since user creation is done through the command line \n\n\nWhen the template is merged in Coolify and I can spin-up a working instance of soju \nincluding file upload support, secure connections, and full support for the protocols supported by soju wjhich can be tested using an IRCv3 compatible client such as goguma or halloy will the attached bounty be seen as completed.\n\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/6567"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#6567",
              "body": "### Request Type\n\nNew Service\n\n### Description\n\nIt would be nice to add the Soju IRC bouncer to the list of services.\nThe documentation is here: \n1. https://codeberg.org/emersion/soju/src/branch/master/doc/getting-started.md\n2. https://codeberg.org/emersion/soju-containers\n3. https://codeberg.org/emersion/soju/src/branch/master/doc/file-upload.md\n\nIt's based on a docker compose seems to need some extra thought since user creation is done through the command line \n\n\nWhen the template is merged in Coolify and I can spin-up a working instance of soju \nincluding file upload support, secure connections, and full support for the protocols supported by soju wjhich can be tested using an IRCv3 compatible client such as goguma or halloy will the attached bounty be seen as completed.\n\n",
              "url": "https://github.com/coollabsio/coolify/issues/6567",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#6566",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-11-09T04:01:38.378Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:38.378Z",
            "created_at": "2025-11-09T04:01:38.378Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#6566",
              "status": "open",
              "type": "issue",
              "number": 6566,
              "title": "[Bug]: Scheduled tasks fails without logs",
              "source": {
                "data": {
                  "id": "source-coollabsio#6566",
                  "user": {
                    "login": "vlourme",
                    "id": 58728578,
                    "node_id": "MDQ6VXNlcjU4NzI4NTc4",
                    "avatar_url": "https://avatars.githubusercontent.com/u/58728578?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vlourme",
                    "html_url": "https://github.com/vlourme",
                    "followers_url": "https://api.github.com/users/vlourme/followers",
                    "following_url": "https://api.github.com/users/vlourme/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vlourme/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vlourme/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vlourme/subscriptions",
                    "organizations_url": "https://api.github.com/users/vlourme/orgs",
                    "repos_url": "https://api.github.com/users/vlourme/repos",
                    "events_url": "https://api.github.com/users/vlourme/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vlourme/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Scheduled tasks fails without logs",
                  "body": "### Error Message and Logs\n\nHello,\n\nI have a worker container that execute multiple tasks based on cron, around 20 cron with different schedules, hourly or daily mostly.\n\nI have a lot of cron that fails without any logs, without any reason  and, weirdly they work when I launch them manually.\n\nExpending logs just shows: \"Waiting for task output...\"\n\n<img width=\"1371\" height=\"703\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d086e872-4717-4cab-8f33-5398a4675280\" />\n\n### Steps to Reproduce\n\nI don't know\n\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.426\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nDebian 13 (trixie)\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/6566"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#6566",
              "body": "### Error Message and Logs\n\nHello,\n\nI have a worker container that execute multiple tasks based on cron, around 20 cron with different schedules, hourly or daily mostly.\n\nI have a lot of cron that fails without any logs, without any reason  and, weirdly they work when I launch them manually.\n\nExpending logs just shows: \"Waiting for task output...\"\n\n<img width=\"1371\" height=\"703\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d086e872-4717-4cab-8f33-5398a4675280\" />\n\n### Steps to Reproduce\n\nI don't know\n\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.426\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nDebian 13 (trixie)\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/6566",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#6519",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-11-09T04:01:38.474Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:38.474Z",
            "created_at": "2025-11-09T04:01:38.474Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#6519",
              "status": "open",
              "type": "issue",
              "number": 6519,
              "title": "[Enhancement]: Filebrowser for Containerlevel",
              "source": {
                "data": {
                  "id": "source-coollabsio#6519",
                  "user": {
                    "login": "swissbyte",
                    "id": 33572050,
                    "node_id": "MDQ6VXNlcjMzNTcyMDUw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/33572050?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/swissbyte",
                    "html_url": "https://github.com/swissbyte",
                    "followers_url": "https://api.github.com/users/swissbyte/followers",
                    "following_url": "https://api.github.com/users/swissbyte/following{/other_user}",
                    "gists_url": "https://api.github.com/users/swissbyte/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/swissbyte/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/swissbyte/subscriptions",
                    "organizations_url": "https://api.github.com/users/swissbyte/orgs",
                    "repos_url": "https://api.github.com/users/swissbyte/repos",
                    "events_url": "https://api.github.com/users/swissbyte/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/swissbyte/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Filebrowser for Containerlevel",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\nI would like to get the ability to have a filebrowser on containerlevel. The idea is, that, for example, one can download or upload config file or images or any other type of files within the scope of the container. This includes mounts and also the overlay fs. Just a filebrowser for everything that you can see inside the container itself. \n\nPrio 1: mapped folders\nPrio 2: everything \"inside\" the container. \n\nIt should support: \n\n- Browsing like windows explorer or nautilus under linux\n- Upload and download single files\n- Upload and download folders\n- Create folders\n- Delete folders / files\n- Check Filesize\n- Check permissions (optional: set them)\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/6519"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#6519",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\nI would like to get the ability to have a filebrowser on containerlevel. The idea is, that, for example, one can download or upload config file or images or any other type of files within the scope of the container. This includes mounts and also the overlay fs. Just a filebrowser for everything that you can see inside the container itself. \n\nPrio 1: mapped folders\nPrio 2: everything \"inside\" the container. \n\nIt should support: \n\n- Browsing like windows explorer or nautilus under linux\n- Upload and download single files\n- Upload and download folders\n- Create folders\n- Delete folders / files\n- Check Filesize\n- Check permissions (optional: set them)\n",
              "url": "https://github.com/coollabsio/coolify/issues/6519",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#4117",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-11-09T04:01:38.581Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:38.581Z",
            "created_at": "2025-11-09T04:01:38.581Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#4117",
              "status": "open",
              "type": "issue",
              "number": 4117,
              "title": "[Enhancement]: Improve navigation from breadcrumb",
              "source": {
                "data": {
                  "id": "source-coollabsio#4117",
                  "user": {
                    "login": "apperside",
                    "id": 5955338,
                    "node_id": "MDQ6VXNlcjU5NTUzMzg=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/5955338?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/apperside",
                    "html_url": "https://github.com/apperside",
                    "followers_url": "https://api.github.com/users/apperside/followers",
                    "following_url": "https://api.github.com/users/apperside/following{/other_user}",
                    "gists_url": "https://api.github.com/users/apperside/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/apperside/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/apperside/subscriptions",
                    "organizations_url": "https://api.github.com/users/apperside/orgs",
                    "repos_url": "https://api.github.com/users/apperside/repos",
                    "events_url": "https://api.github.com/users/apperside/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/apperside/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Improve navigation from breadcrumb",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\nIt would be a big UX improvement if it would be possible to navigate resources and sections of resources directly from the breadcrumbs.\nBelow you will find a very explicative screenshot\n\n![Image](https://github.com/user-attachments/assets/2566cb0b-6be6-40dc-8448-b640b2d6ebe5)\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/4117"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#4117",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\nIt would be a big UX improvement if it would be possible to navigate resources and sections of resources directly from the breadcrumbs.\nBelow you will find a very explicative screenshot\n\n![Image](https://github.com/user-attachments/assets/2566cb0b-6be6-40dc-8448-b640b2d6ebe5)\n",
              "url": "https://github.com/coollabsio/coolify/issues/4117",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#2495",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-11-09T04:01:38.687Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:38.687Z",
            "created_at": "2025-11-09T04:01:38.687Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#2495",
              "status": "open",
              "type": "issue",
              "number": 2495,
              "title": "[Improvement]: Container Info and Network tab (for each container and service)",
              "source": {
                "data": {
                  "id": "source-coollabsio#2495",
                  "user": {
                    "login": "peaklabs-dev",
                    "id": 122374094,
                    "node_id": "U_kgDOB0tHzg",
                    "avatar_url": "https://avatars.githubusercontent.com/u/122374094?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/peaklabs-dev",
                    "html_url": "https://github.com/peaklabs-dev",
                    "followers_url": "https://api.github.com/users/peaklabs-dev/followers",
                    "following_url": "https://api.github.com/users/peaklabs-dev/following{/other_user}",
                    "gists_url": "https://api.github.com/users/peaklabs-dev/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/peaklabs-dev/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/peaklabs-dev/subscriptions",
                    "organizations_url": "https://api.github.com/users/peaklabs-dev/orgs",
                    "repos_url": "https://api.github.com/users/peaklabs-dev/repos",
                    "events_url": "https://api.github.com/users/peaklabs-dev/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/peaklabs-dev/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Improvement]: Container Info and Network tab (for each container and service)",
                  "body": "### Description\n\nI had a deep look into the coolify containers and found some things I believe could be improved (hope I can help like this as I am at the moment not ready to start code contributing)\n\n### Minimal Reproduction (if possible, example repository)\n\nNetwork page on the individual Container/ services:\n- [ ] Let us select network via dropdown and also see which network the container is in\n- [ ] Make sure we can connect containers to networks from the UI after they are created, especially for databases this would be great as they do not have a predefined network checkbox. The ability to have a UI where we can select networks would also eliminate the connect to predefined network checkbox, as if we select a network when creating or on the Network tab, it will automatically connect to that.\n- [ ] When you select a network when creating a resource, it is automatically connected to the resource without you having to check a checkbox.\n- [ ] Let us remove networks with a click of a button\n- [ ] let us add multiple networks to the container 3-4...\n- [ ] Also enabled Ipv6 on docker networks (all of them should have Ipv4 and Ipv6): https://github.com/coollabsio/coolify/discussions/4048\n\n\nGeneral info tab for the current container:\n- [ ] IPv4 and IPv6 IP addresses displayed for the container with a copy button\n- [ ] Mac Adresse is displayed here in the network tab for the container\n- [ ] let us see the container ID \n- [ ] Let us see the container name -> the name with the uuid\n- [ ] Let us set the container name for databases manually if we want\n- [ ] container Image hash \n- [ ] when was the container create\n- [ ] when was it startet -> especially for services\n- [ ] when was the image last pulled\n- [ ] when was the container updated -> depended on this: https://github.com/coollabsio/coolify/issues/2500\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/2495"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#2495",
              "body": "### Description\n\nI had a deep look into the coolify containers and found some things I believe could be improved (hope I can help like this as I am at the moment not ready to start code contributing)\n\n### Minimal Reproduction (if possible, example repository)\n\nNetwork page on the individual Container/ services:\n- [ ] Let us select network via dropdown and also see which network the container is in\n- [ ] Make sure we can connect containers to networks from the UI after they are created, especially for databases this would be great as they do not have a predefined network checkbox. The ability to have a UI where we can select networks would also eliminate the connect to predefined network checkbox, as if we select a network when creating or on the Network tab, it will automatically connect to that.\n- [ ] When you select a network when creating a resource, it is automatically connected to the resource without you having to check a checkbox.\n- [ ] Let us remove networks with a click of a button\n- [ ] let us add multiple networks to the container 3-4...\n- [ ] Also enabled Ipv6 on docker networks (all of them should have Ipv4 and Ipv6): https://github.com/coollabsio/coolify/discussions/4048\n\n\nGeneral info tab for the current container:\n- [ ] IPv4 and IPv6 IP addresses displayed for the container with a copy button\n- [ ] Mac Adresse is displayed here in the network tab for the container\n- [ ] let us see the container ID \n- [ ] Let us see the container name -> the name with the uuid\n- [ ] Let us set the container name for databases manually if we want\n- [ ] container Image hash \n- [ ] when was the container create\n- [ ] when was it startet -> especially for services\n- [ ] when was the image last pulled\n- [ ] when was the container updated -> depended on this: https://github.com/coollabsio/coolify/issues/2500\n",
              "url": "https://github.com/coollabsio/coolify/issues/2495",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#4458",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2025-11-09T04:01:38.787Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:38.787Z",
            "created_at": "2025-11-09T04:01:38.787Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#4458",
              "status": "open",
              "type": "issue",
              "number": 4458,
              "title": "[Enhancement]: AppFlowy Serice",
              "source": {
                "data": {
                  "id": "source-coollabsio#4458",
                  "user": {
                    "login": "imaron85",
                    "id": 45713863,
                    "node_id": "MDQ6VXNlcjQ1NzEzODYz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/45713863?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/imaron85",
                    "html_url": "https://github.com/imaron85",
                    "followers_url": "https://api.github.com/users/imaron85/followers",
                    "following_url": "https://api.github.com/users/imaron85/following{/other_user}",
                    "gists_url": "https://api.github.com/users/imaron85/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/imaron85/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/imaron85/subscriptions",
                    "organizations_url": "https://api.github.com/users/imaron85/orgs",
                    "repos_url": "https://api.github.com/users/imaron85/repos",
                    "events_url": "https://api.github.com/users/imaron85/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/imaron85/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: AppFlowy Serice",
                  "body": "### Request Type\n\nNew Service\n\n### Description\n\nI would like a Coolify Service for easily deploying AppFlowy.\nI've tried myself, but can't figure out recreating the nginx config in coolify.\nIt might not even be neccessary, all I want is be able to easily deploy AppFlowy for our small team.",
                  "html_url": "https://github.com/coollabsio/coolify/issues/4458"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#4458",
              "body": "### Request Type\n\nNew Service\n\n### Description\n\nI would like a Coolify Service for easily deploying AppFlowy.\nI've tried myself, but can't figure out recreating the nginx config in coolify.\nIt might not even be neccessary, all I want is be able to easily deploy AppFlowy for our small team.",
              "url": "https://github.com/coollabsio/coolify/issues/4458",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13872",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-09T04:01:40.495Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:40.495Z",
            "created_at": "2025-11-09T04:01:40.495Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13872",
              "status": "open",
              "type": "issue",
              "number": 13872,
              "title": "CVE-2021-4374 - WordPress Automatic Plugin - Broken Access Control ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13872",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2021-4374 - WordPress Automatic Plugin - Broken Access Control ",
                  "body": "\n### Description: \n> WordPress Automatic Plugin for WordPress versions up to 3.53.2 contains a broken access control caused by missing authorization and option validation in process_form.php, letting unauthenticated attackers arbitrarily update site settings, exploit requires no authentication.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://blog.nintechnet.com/critical-vulnerability-fixed-in-wordpress-automatic-plugin/\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13872"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13872",
              "body": "\n### Description: \n> WordPress Automatic Plugin for WordPress versions up to 3.53.2 contains a broken access control caused by missing authorization and option validation in process_form.php, letting unauthenticated attackers arbitrarily update site settings, exploit requires no authentication.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://blog.nintechnet.com/critical-vulnerability-fixed-in-wordpress-automatic-plugin/\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13872",
              "tech": [
                "go"
              ],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13865",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-09T04:01:40.622Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:40.622Z",
            "created_at": "2025-11-09T04:01:40.622Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13865",
              "status": "open",
              "type": "issue",
              "number": 13865,
              "title": "CVE-2023-26134 - git-commit-info - Command Injection ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13865",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2023-26134 - git-commit-info - Command Injection ",
                  "body": "\n### Description: \n> git-commit-info contains a command injection caused by unsanitized commit parameter in gitCommitInfo(), letting attackers inject malicious commands if they control the hash content, exploit requires control over commit hash.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/JPeer264/node-git-commit-info/issues/24\n- https://security.snyk.io/vuln/SNYK-JS-GITCOMMITINFO-5740174\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13865"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13865",
              "body": "\n### Description: \n> git-commit-info contains a command injection caused by unsanitized commit parameter in gitCommitInfo(), letting attackers inject malicious commands if they control the hash content, exploit requires control over commit hash.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/JPeer264/node-git-commit-info/issues/24\n- https://security.snyk.io/vuln/SNYK-JS-GITCOMMITINFO-5740174\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13865",
              "tech": [
                "go"
              ],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13862",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-09T04:01:40.733Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:40.733Z",
            "created_at": "2025-11-09T04:01:40.733Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13862",
              "status": "open",
              "type": "issue",
              "number": 13862,
              "title": "CVE-2023-34478 - Apache Shiro - Authentication Bypass ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13862",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2023-34478 - Apache Shiro - Authentication Bypass ",
                  "body": "\n### Description: \n> Apache Shiro before 1.12.0 or 2.0.0-alpha-3 contains a path traversal caused by request routing issues with non-normalized requests, letting attackers bypass authentication, exploit requires use with specific web frameworks or APIs.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/shoucheng3/apache__shiro_CVE-2023-34478_1-11-0\n\n### KEV: True\n\n### Shodan Query: `http.title:\"apache shiro quickstart\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13862"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13862",
              "body": "\n### Description: \n> Apache Shiro before 1.12.0 or 2.0.0-alpha-3 contains a path traversal caused by request routing issues with non-normalized requests, letting attackers bypass authentication, exploit requires use with specific web frameworks or APIs.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/shoucheng3/apache__shiro_CVE-2023-34478_1-11-0\n\n### KEV: True\n\n### Shodan Query: `http.title:\"apache shiro quickstart\"`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13862",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13820",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-09T04:01:40.830Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:40.830Z",
            "created_at": "2025-11-09T04:01:40.830Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13820",
              "status": "open",
              "type": "issue",
              "number": 13820,
              "title": "CVE-2025-11833 - Post SMTP WordPress Plugin - Broken Access Control ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13820",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2025-11833 - Post SMTP WordPress Plugin - Broken Access Control ",
                  "body": "\n### Description: \n> Post SMTP WordPress plugin <= 3.6.0 contains an unauthorized data access vulnerability caused by missing capability check in __construct function, letting unauthenticated attackers read arbitrary logged emails, exploit requires no authentication.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/nullstatics/CVE-2025-11833\n- https://github.com/modhopmarrow1973/CVE-2025-11833-LAB\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13820"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13820",
              "body": "\n### Description: \n> Post SMTP WordPress plugin <= 3.6.0 contains an unauthorized data access vulnerability caused by missing capability check in __construct function, letting unauthenticated attackers read arbitrary logged emails, exploit requires no authentication.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/nullstatics/CVE-2025-11833\n- https://github.com/modhopmarrow1973/CVE-2025-11833-LAB\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13820",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13724",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-09T04:01:40.920Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:40.920Z",
            "created_at": "2025-11-09T04:01:40.920Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13724",
              "status": "open",
              "type": "issue",
              "number": 13724,
              "title": "CVE-2025-61932 - Lanscope Endpoint Manager - Remote Code Execution ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13724",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2025-61932 - Lanscope Endpoint Manager - Remote Code Execution ",
                  "body": "\n### Description: \n> Lanscope Endpoint Manager (On-Premises) contains a remote code execution vulnerability caused by improper verification of the origin of incoming requests, letting attackers execute arbitrary code remotely, exploit requires sending specially crafted packets.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/allinsthon/CVE-2025-61932\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13724"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13724",
              "body": "\n### Description: \n> Lanscope Endpoint Manager (On-Premises) contains a remote code execution vulnerability caused by improper verification of the origin of incoming requests, letting attackers execute arbitrary code remotely, exploit requires sending specially crafted packets.\n\n#### Severity: `Critical`\n\n#### POC: \n- https://github.com/allinsthon/CVE-2025-61932\n\n### KEV: True\n\n### Shodan Query: `NA`\n\n> Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors are required to provide debug data(`-debug`) along with the template to help the triage team with validation or can also share a vulnerable environment like docker file. \n\n> Rewards will only be given once the template is fully validated by the team. Templates that are incomplete or invalid will not be accepted. Avoid adding code templates for CVEs that can be achieved using HTTP, TCP, or JavaScript. Such templates are blocked by default and wont produce results, so we prioritize creating templates with other protocols unless exceptions are made.\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/blob/main/Community-Rewards-FAQ.md).\n",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13724",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13435",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-09T04:01:41.034Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:41.034Z",
            "created_at": "2025-11-09T04:01:41.034Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13435",
              "status": "open",
              "type": "issue",
              "number": 13435,
              "title": "CVE-2023-27532 - Veeam Backup & Replication - Credential Disclosure ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13435",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2023-27532 - Veeam Backup & Replication - Credential Disclosure ",
                  "body": "### Description:\n> Veeam Backup & Replication allows encrypted credentials stored in the configuration database to be obtained by attackers who can access backup infrastructure hosts.\n\n#### Severity: `High` (CVSS: 7.5)\n\n#### Vulnerability Details:\n- **CVE ID**: CVE-2023-27532\n- **CWE**: CWE-306 (Missing Authentication for Critical Function)\n- **Affected Versions**: 11.0.1.1261 and 12.0.0.1420\n- **Attack Vector**: Network\n- **Authentication**: Requires access to configuration database\n- **Impact**: Information Disclosure, Privilege Escalation\n\n#### POC:\n- https://github.com/horizon3ai/CVE-2023-27532\n- https://github.com/sfewer-r7/CVE-2023-27532\n- https://github.com/puckiestyle/CVE-2023-27532-RCE-Only\n\n### KEV: True \n**CISA KEV**: Added 2023-08-22  \n**Known Ransomware Campaign**: Yes (Akira, Qilin, and multiple others)\n\n### EPSS Score: 0.87024 (99.406th percentile) \n\n### Shodan Query: `\"Veeam Backup\" http.title:\"Veeam Backup Enterprise Manager\"`\n\n---\n\n> **Acceptance Criteria:**\n> The template must include a complete POC and should not rely solely on version-based detection. Contributors must share vulnerable setup information or a testable instance by emailing templates@projectdiscovery.io. Providing a testable instance significantly reduces validation time and increases the chance of quicker rewards. Templates that are incomplete, invalid, or non-verifiable will not be accepted. Avoid submitting code templates for CVEs that can be detected using HTTP, TCP, or JavaScript only these are blocked by default and will not produce results. Exceptions may apply for certain cases. Do not submit AI-simulated vulnerable environments. To qualify for the bounty, the team must be able to fully validate the POC. If you have hosted a vulnerable environment for validation, send the details (IP or Docker setup) along with the PR number to templates[at]projectdiscovery.io\n\n> **Note**: This vulnerability has been **actively exploited** in multiple ransomware campaigns including Akira, Qilin, and others. **VERY HIGH PRIORITY** - EPSS score 0.87 (top 1%).\n\n---\n\n### References:\n- https://www.veeam.com/kb4424\n- https://github.com/horizon3ai/CVE-2023-27532\n- https://www.zscaler.com/resources/industry-reports/threatlabz-2025-ransomware-analysis.pdf\n- https://blog.qualys.com/vulnerabilities-threat-research/2025/06/18/qilin-ransomware-explained-threats-risks-defenses\n- https://services.google.com/fh/files/misc/m-trends-2025-en.pdf\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/discussions/9965)",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13435"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13435",
              "body": "### Description:\n> Veeam Backup & Replication allows encrypted credentials stored in the configuration database to be obtained by attackers who can access backup infrastructure hosts.\n\n#### Severity: `High` (CVSS: 7.5)\n\n#### Vulnerability Details:\n- **CVE ID**: CVE-2023-27532\n- **CWE**: CWE-306 (Missing Authentication for Critical Function)\n- **Affected Versions**: 11.0.1.1261 and 12.0.0.1420\n- **Attack Vector**: Network\n- **Authentication**: Requires access to configuration database\n- **Impact**: Information Disclosure, Privilege Escalation\n\n#### POC:\n- https://github.com/horizon3ai/CVE-2023-27532\n- https://github.com/sfewer-r7/CVE-2023-27532\n- https://github.com/puckiestyle/CVE-2023-27532-RCE-Only\n\n### KEV: True \n**CISA KEV**: Added 2023-08-22  \n**Known Ransomware Campaign**: Yes (Akira, Qilin, and multiple others)\n\n### EPSS Score: 0.87024 (99.406th percentile) \n\n### Shodan Query: `\"Veeam Backup\" http.title:\"Veeam Backup Enterprise Manager\"`\n\n---\n\n> **Acceptance Criteria:**\n> The template must include a complete POC and should not rely solely on version-based detection. Contributors must share vulnerable setup information or a testable instance by emailing templates@projectdiscovery.io. Providing a testable instance significantly reduces validation time and increases the chance of quicker rewards. Templates that are incomplete, invalid, or non-verifiable will not be accepted. Avoid submitting code templates for CVEs that can be detected using HTTP, TCP, or JavaScript only these are blocked by default and will not produce results. Exceptions may apply for certain cases. Do not submit AI-simulated vulnerable environments. To qualify for the bounty, the team must be able to fully validate the POC. If you have hosted a vulnerable environment for validation, send the details (IP or Docker setup) along with the PR number to templates[at]projectdiscovery.io\n\n> **Note**: This vulnerability has been **actively exploited** in multiple ransomware campaigns including Akira, Qilin, and others. **VERY HIGH PRIORITY** - EPSS score 0.87 (top 1%).\n\n---\n\n### References:\n- https://www.veeam.com/kb4424\n- https://github.com/horizon3ai/CVE-2023-27532\n- https://www.zscaler.com/resources/industry-reports/threatlabz-2025-ransomware-analysis.pdf\n- https://blog.qualys.com/vulnerabilities-threat-research/2025/06/18/qilin-ransomware-explained-threats-risks-defenses\n- https://services.google.com/fh/files/misc/m-trends-2025-en.pdf\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/discussions/9965)",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13435",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "projectdiscovery#13434",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "projectdiscovery",
              "id": "generated-projectdiscovery",
              "name": "Projectdiscovery",
              "description": "",
              "members": [],
              "display_name": "Projectdiscovery",
              "created_at": "2025-11-09T04:01:41.143Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/projectdiscovery?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "projectdiscovery",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-11-09T04:01:41.143Z",
            "created_at": "2025-11-09T04:01:41.143Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-projectdiscovery#13434",
              "status": "open",
              "type": "issue",
              "number": 13434,
              "title": "CVE-2022-26500 - Veeam Backup & Replication - Unrestricted File Upload ",
              "source": {
                "data": {
                  "id": "source-projectdiscovery#13434",
                  "user": {
                    "login": "princechaddha",
                    "id": 16654365,
                    "node_id": "MDQ6VXNlcjE2NjU0MzY1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/16654365?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/princechaddha",
                    "html_url": "https://github.com/princechaddha",
                    "followers_url": "https://api.github.com/users/princechaddha/followers",
                    "following_url": "https://api.github.com/users/princechaddha/following{/other_user}",
                    "gists_url": "https://api.github.com/users/princechaddha/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/princechaddha/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/princechaddha/subscriptions",
                    "organizations_url": "https://api.github.com/users/princechaddha/orgs",
                    "repos_url": "https://api.github.com/users/princechaddha/repos",
                    "events_url": "https://api.github.com/users/princechaddha/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/princechaddha/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "CVE-2022-26500 - Veeam Backup & Replication - Unrestricted File Upload ",
                  "body": "### Description:\n> Veeam Backup & Replication contains an improper limitation of path names caused by insufficient validation in internal API functions, letting remote authenticated users upload and execute arbitrary code.\n\n#### Severity: `High` (CVSS: 8.8)\n\n#### Vulnerability Details:\n- **CVE ID**: CVE-2022-26500\n- **CWE**: CWE-22 (Improper Limitation of a Pathname to a Restricted Directory)\n- **Affected Versions**: 9.5U3, 9.5U4, 10.x, and 11.x\n- **Attack Vector**: Network\n- **Authentication**: Required (logged_in)\n- **Impact**: Remote Code Execution\n\n#### POC:\n- https://cloudsek.com/threatintelligence/multiple-rce-vulnerabilities-affecting-veeam-backup-replication/\n- https://www.veeam.com/kb4288\n\n### KEV: True \n**CISA KEV**: Added 2022-12-13  \n**Known Ransomware Campaign**: Yes (Cuba, AvosLocker, LockBit)\n\n### EPSS Score: 0.25477 (96.037th percentile)\n\n### Shodan Query: `\"Veeam Backup\" http.title:\"Veeam Backup Enterprise Manager\"`\n\n---\n\n>  Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors must share vulnerable setup information or a testable instance by emailing templates@projectdiscovery.io. Providing a testable instance significantly reduces validation time and increases the chance of quicker rewards. Templates that are incomplete, invalid, or non-verifiable will not be accepted. Avoid submitting code templates for CVEs that can be detected using HTTP, TCP, or JavaScript only these are blocked by default and will not produce results. Exceptions may apply for certain cases. Do not submit AI-simulated vulnerable environments. To qualify for the bounty, the team must be able to fully validate the POC. If you have hosted a vulnerable environment for validation, send the details (IP or Docker setup) along with the PR number to templates[at]projectdiscovery.io\n\n---\n\n### References:\n- https://veeam.com\n- https://www.veeam.com/kb4288\n- https://securelist.com/cuba-ransomware/110533/\n- https://www.kroll.com/en/insights/publications/cyber/avoslocker-ransomware-update\n- https://blog.qualys.com/vulnerabilities-threat-research/2025/05/08/inside-lockbit-defense-lessons-from-the-leaked-lockbit-negotiations\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/discussions/9965)",
                  "html_url": "https://github.com/projectdiscovery/nuclei-templates/issues/13434"
                },
                "type": "github"
              },
              "hash": "projectdiscovery/nuclei-templates#13434",
              "body": "### Description:\n> Veeam Backup & Replication contains an improper limitation of path names caused by insufficient validation in internal API functions, letting remote authenticated users upload and execute arbitrary code.\n\n#### Severity: `High` (CVSS: 8.8)\n\n#### Vulnerability Details:\n- **CVE ID**: CVE-2022-26500\n- **CWE**: CWE-22 (Improper Limitation of a Pathname to a Restricted Directory)\n- **Affected Versions**: 9.5U3, 9.5U4, 10.x, and 11.x\n- **Attack Vector**: Network\n- **Authentication**: Required (logged_in)\n- **Impact**: Remote Code Execution\n\n#### POC:\n- https://cloudsek.com/threatintelligence/multiple-rce-vulnerabilities-affecting-veeam-backup-replication/\n- https://www.veeam.com/kb4288\n\n### KEV: True \n**CISA KEV**: Added 2022-12-13  \n**Known Ransomware Campaign**: Yes (Cuba, AvosLocker, LockBit)\n\n### EPSS Score: 0.25477 (96.037th percentile)\n\n### Shodan Query: `\"Veeam Backup\" http.title:\"Veeam Backup Enterprise Manager\"`\n\n---\n\n>  Acceptance Criteria: The template must include a complete POC and should not rely solely on version-based detection. Contributors must share vulnerable setup information or a testable instance by emailing templates@projectdiscovery.io. Providing a testable instance significantly reduces validation time and increases the chance of quicker rewards. Templates that are incomplete, invalid, or non-verifiable will not be accepted. Avoid submitting code templates for CVEs that can be detected using HTTP, TCP, or JavaScript only these are blocked by default and will not produce results. Exceptions may apply for certain cases. Do not submit AI-simulated vulnerable environments. To qualify for the bounty, the team must be able to fully validate the POC. If you have hosted a vulnerable environment for validation, send the details (IP or Docker setup) along with the PR number to templates[at]projectdiscovery.io\n\n---\n\n### References:\n- https://veeam.com\n- https://www.veeam.com/kb4288\n- https://securelist.com/cuba-ransomware/110533/\n- https://www.kroll.com/en/insights/publications/cyber/avoslocker-ransomware-update\n- https://blog.qualys.com/vulnerabilities-threat-research/2025/05/08/inside-lockbit-defense-lessons-from-the-leaked-lockbit-negotiations\n\nYou can check the FAQ for the Nuclei Templates Community Rewards Program [here](https://github.com/projectdiscovery/nuclei-templates/discussions/9965)",
              "url": "https://github.com/projectdiscovery/nuclei-templates/issues/13434",
              "tech": [],
              "repo_name": "nuclei-templates",
              "repo_owner": "projectdiscovery",
              "forge": "github"
            },
            "timeouts_disabled": false
          }
        ],
        "next_cursor": null
      }
    }
  }
}