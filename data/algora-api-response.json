{
  "result": {
    "data": {
      "json": {
        "items": [
          {
            "id": "omnigres#823",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "omnigres",
              "id": "generated-omnigres",
              "name": "Omnigres",
              "description": "",
              "members": [],
              "display_name": "Omnigres",
              "created_at": "2025-12-13T17:42:54.225Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/omnigres?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "omnigres",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-13T17:42:54.225Z",
            "created_at": "2025-12-13T17:42:54.225Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-omnigres#823",
              "status": "open",
              "type": "issue",
              "number": 823,
              "title": "Problem: omni_schema.dependency and omni_schema.acl views are slow",
              "source": {
                "data": {
                  "id": "source-omnigres#823",
                  "user": {
                    "login": "yrashk",
                    "id": 452,
                    "node_id": "MDQ6VXNlcjQ1Mg==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/452?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/yrashk",
                    "html_url": "https://github.com/yrashk",
                    "followers_url": "https://api.github.com/users/yrashk/followers",
                    "following_url": "https://api.github.com/users/yrashk/following{/other_user}",
                    "gists_url": "https://api.github.com/users/yrashk/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/yrashk/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/yrashk/subscriptions",
                    "organizations_url": "https://api.github.com/users/yrashk/orgs",
                    "repos_url": "https://api.github.com/users/yrashk/repos",
                    "events_url": "https://api.github.com/users/yrashk/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/yrashk/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Problem: omni_schema.dependency and omni_schema.acl views are slow",
                  "body": "This gravely impacts some of our functionality like schema diffing as we scan through all these views and `dependency` and `acl` views are the worst offenders.\n\nProposed solution: find a way to significantly optimize the queries\n\nOne thing is to see what else can be done for the queries themselves – at the very least in `dependency` and `acl` and maybe even other meta views. \n\nhttps://github.com/omnigres/omnigres/blob/master/extensions/omni_schema/src/meta/catalog.sql#L76\n",
                  "html_url": "https://github.com/omnigres/omnigres/issues/823"
                },
                "type": "github"
              },
              "hash": "omnigres/omnigres#823",
              "body": "This gravely impacts some of our functionality like schema diffing as we scan through all these views and `dependency` and `acl` views are the worst offenders.\n\nProposed solution: find a way to significantly optimize the queries\n\nOne thing is to see what else can be done for the queries themselves – at the very least in `dependency` and `acl` and maybe even other meta views. \n\nhttps://github.com/omnigres/omnigres/blob/master/extensions/omni_schema/src/meta/catalog.sql#L76\n",
              "url": "https://github.com/omnigres/omnigres/issues/823",
              "tech": [
                "go"
              ],
              "repo_name": "omnigres",
              "repo_owner": "omnigres",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "Mudlet#8030",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "Mudlet",
              "id": "generated-Mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2025-12-13T17:42:54.291Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/Mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-13T17:42:54.309Z",
            "created_at": "2025-12-13T17:42:54.309Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-Mudlet#8030",
              "status": "open",
              "type": "issue",
              "number": 8030,
              "title": "Split Mudlet up into `libmudlet` and a Qt front-end",
              "source": {
                "data": {
                  "id": "source-Mudlet#8030",
                  "user": {
                    "login": "vadi2",
                    "id": 110988,
                    "node_id": "MDQ6VXNlcjExMDk4OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/110988?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vadi2",
                    "html_url": "https://github.com/vadi2",
                    "followers_url": "https://api.github.com/users/vadi2/followers",
                    "following_url": "https://api.github.com/users/vadi2/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vadi2/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vadi2/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vadi2/subscriptions",
                    "organizations_url": "https://api.github.com/users/vadi2/orgs",
                    "repos_url": "https://api.github.com/users/vadi2/repos",
                    "events_url": "https://api.github.com/users/vadi2/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vadi2/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Split Mudlet up into `libmudlet` and a Qt front-end",
                  "body": "#### Description of requested feature:\nMudlet is a Qt Widgets based application, which works great for Linux/macOS/Windows, but not so great for running natively on Android or iPhone, which are popular feature requests.\n\nAkin to how VLC is split into libVLC and various front-ends, split Mudlet out into libmudlet (providing all of core functionality) and a Qt Widget frontend that makes use of all of the core functionality.\n\n**Prior to taking this issue up**, open a new github issue here and in there, provide (1) plan for how the library/frontend split will work on an architectural level, and (2) a plan for the migration strategy, since once mega PR will not work for this.\n\n#### Reasons for adding feature:\n\n1. allowing Mudlet to eventually have a mobile-native version\n\n#### Expected result of feature\nlibmudlet may use Qt Core classes (QObject, QTimer, QThread, QSettings, etc.) but must not depend on Qt Widgets, Qt GUI, or any UI-related Qt modules.\n\n Mudlet's functionality pre and post-split should be 100% the same, nothing should be lost in the transition:\n -  All existing automated tests must pass, plus:\n  - All menu items and dialogs function identically\n  - All Lua API functions return identical results\n  - All protocol features work (GMCP, MXP, etc.)\n  - All file formats (profiles, packages) remain compatible\n\nPerformance of the network/text display stack as well as the trigger engine should be comparable as well (no more than 10% lost). Measured in:\n\n  - Text display: X lines/second in main console (can be measured using [stressinator](https://packages.mudlet.org/packages#pkg-Stressinator))\n  - Network: Y MB/s processing throughput (needs to be measured)\n  - Memory: no more than 10% increase in base memory usage\n\n####\n\n",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/8030"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#8030",
              "body": "#### Description of requested feature:\nMudlet is a Qt Widgets based application, which works great for Linux/macOS/Windows, but not so great for running natively on Android or iPhone, which are popular feature requests.\n\nAkin to how VLC is split into libVLC and various front-ends, split Mudlet out into libmudlet (providing all of core functionality) and a Qt Widget frontend that makes use of all of the core functionality.\n\n**Prior to taking this issue up**, open a new github issue here and in there, provide (1) plan for how the library/frontend split will work on an architectural level, and (2) a plan for the migration strategy, since once mega PR will not work for this.\n\n#### Reasons for adding feature:\n\n1. allowing Mudlet to eventually have a mobile-native version\n\n#### Expected result of feature\nlibmudlet may use Qt Core classes (QObject, QTimer, QThread, QSettings, etc.) but must not depend on Qt Widgets, Qt GUI, or any UI-related Qt modules.\n\n Mudlet's functionality pre and post-split should be 100% the same, nothing should be lost in the transition:\n -  All existing automated tests must pass, plus:\n  - All menu items and dialogs function identically\n  - All Lua API functions return identical results\n  - All protocol features work (GMCP, MXP, etc.)\n  - All file formats (profiles, packages) remain compatible\n\nPerformance of the network/text display stack as well as the trigger engine should be comparable as well (no more than 10% lost). Measured in:\n\n  - Text display: X lines/second in main console (can be measured using [stressinator](https://packages.mudlet.org/packages#pkg-Stressinator))\n  - Network: Y MB/s processing throughput (needs to be measured)\n  - Memory: no more than 10% increase in base memory usage\n\n####\n\n",
              "url": "https://github.com/Mudlet/Mudlet/issues/8030",
              "tech": [
                "go"
              ],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "Mudlet#3172",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "Mudlet",
              "id": "generated-Mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2025-12-13T17:42:55.441Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/Mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-13T17:42:55.441Z",
            "created_at": "2025-12-13T17:42:55.441Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-Mudlet#3172",
              "status": "open",
              "type": "issue",
              "number": 3172,
              "title": "generic mapper: add video walkthrough on how to set it up",
              "source": {
                "data": {
                  "id": "source-Mudlet#3172",
                  "user": {
                    "login": "vadi2",
                    "id": 110988,
                    "node_id": "MDQ6VXNlcjExMDk4OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/110988?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vadi2",
                    "html_url": "https://github.com/vadi2",
                    "followers_url": "https://api.github.com/users/vadi2/followers",
                    "following_url": "https://api.github.com/users/vadi2/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vadi2/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vadi2/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vadi2/subscriptions",
                    "organizations_url": "https://api.github.com/users/vadi2/orgs",
                    "repos_url": "https://api.github.com/users/vadi2/repos",
                    "events_url": "https://api.github.com/users/vadi2/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vadi2/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "generic mapper: add video walkthrough on how to set it up",
                  "body": "#### Brief summary of issue / Description of requested feature:\r\nIt's been requested a few times, and it would be really handy to link people to a video explanation of how the generic mapper script should be setup.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1. \r\n2. \r\n3. \r\n\r\n#### Error output / Expected result of feature\r\n\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/3172"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#3172",
              "body": "#### Brief summary of issue / Description of requested feature:\r\nIt's been requested a few times, and it would be really handy to link people to a video explanation of how the generic mapper script should be setup.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1. \r\n2. \r\n3. \r\n\r\n#### Error output / Expected result of feature\r\n\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n",
              "url": "https://github.com/Mudlet/Mudlet/issues/3172",
              "tech": [
                "go"
              ],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "Mudlet#689",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "Mudlet",
              "id": "generated-Mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2025-12-13T17:42:59.255Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/Mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-13T17:42:59.255Z",
            "created_at": "2025-12-13T17:42:59.255Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-Mudlet#689",
              "status": "open",
              "type": "issue",
              "number": 689,
              "title": "Support telnet:// links",
              "source": {
                "data": {
                  "id": "source-Mudlet#689",
                  "user": {
                    "login": "vadi2",
                    "id": 110988,
                    "node_id": "MDQ6VXNlcjExMDk4OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/110988?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/vadi2",
                    "html_url": "https://github.com/vadi2",
                    "followers_url": "https://api.github.com/users/vadi2/followers",
                    "following_url": "https://api.github.com/users/vadi2/following{/other_user}",
                    "gists_url": "https://api.github.com/users/vadi2/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/vadi2/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/vadi2/subscriptions",
                    "organizations_url": "https://api.github.com/users/vadi2/orgs",
                    "repos_url": "https://api.github.com/users/vadi2/repos",
                    "events_url": "https://api.github.com/users/vadi2/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/vadi2/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Support telnet:// links",
                  "body": "Idea: MUDs should be able to provide an easy to use link with their connection info to spawn Mudlet and get it to connect to their game. Similar to apt://, steam:// and so forth links.\r\n\r\nI think Mudlet should support those types of links - it'd be a lot more convenient for players to try out new MUDs if they only have to click on a link, instead of copying the server and port, going to Mudlet, making a new profile and so on.\r\n\r\nAs for the naming of the link, we could either go with a custom one: mudlet:// or - use an already standard one (telnet://), which would be much better as some websites use it already (http://dmud.thebbs.org/lotflink.htm) and it would be compatible with other MUDs clients.\r\n\r\nI believe the latter option is better.\r\n\r\nTelnet links seem to work in the format of: telnet://<server>[:<optional port #>], see https://tools.ietf.org/html/rfc4248 for the actual spec.\r\n\r\nThe logic for this could be the following:\r\n\r\nWhen Mudlet is spawned via the telnet link, check to see if any profile(s) server matches server field of the link. If multiple profiles do, auto-load the latest profile used. If one matches, load that profile. If not profiles match...\r\n\r\nCreate a new profile with the given server and port data, and the profiles name will be the servers name as well. Auto-load this newly created profile.\r\n\r\n\r\nI think these cases sound plausible. There'll an issue with peoples already made profile using the server name vs IP address directly as webmasters might, but that's not something that could be easily avoided.\r\n\r\nLaunchpad Details: [#LP1187243](https://bugs.launchpad.net/bugs/1187243) Vadim Peretokin - 2013-06-04 04:47:05 +0000",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/689"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#689",
              "body": "Idea: MUDs should be able to provide an easy to use link with their connection info to spawn Mudlet and get it to connect to their game. Similar to apt://, steam:// and so forth links.\r\n\r\nI think Mudlet should support those types of links - it'd be a lot more convenient for players to try out new MUDs if they only have to click on a link, instead of copying the server and port, going to Mudlet, making a new profile and so on.\r\n\r\nAs for the naming of the link, we could either go with a custom one: mudlet:// or - use an already standard one (telnet://), which would be much better as some websites use it already (http://dmud.thebbs.org/lotflink.htm) and it would be compatible with other MUDs clients.\r\n\r\nI believe the latter option is better.\r\n\r\nTelnet links seem to work in the format of: telnet://<server>[:<optional port #>], see https://tools.ietf.org/html/rfc4248 for the actual spec.\r\n\r\nThe logic for this could be the following:\r\n\r\nWhen Mudlet is spawned via the telnet link, check to see if any profile(s) server matches server field of the link. If multiple profiles do, auto-load the latest profile used. If one matches, load that profile. If not profiles match...\r\n\r\nCreate a new profile with the given server and port data, and the profiles name will be the servers name as well. Auto-load this newly created profile.\r\n\r\n\r\nI think these cases sound plausible. There'll an issue with peoples already made profile using the server name vs IP address directly as webmasters might, but that's not something that could be easily avoided.\r\n\r\nLaunchpad Details: [#LP1187243](https://bugs.launchpad.net/bugs/1187243) Vadim Peretokin - 2013-06-04 04:47:05 +0000",
              "url": "https://github.com/Mudlet/Mudlet/issues/689",
              "tech": [],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "Mudlet#5310",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "Mudlet",
              "id": "generated-Mudlet",
              "name": "Mudlet",
              "description": "",
              "members": [],
              "display_name": "Mudlet",
              "created_at": "2025-12-13T17:43:03.278Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/Mudlet?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "Mudlet",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-13T17:43:03.278Z",
            "created_at": "2025-12-13T17:43:03.278Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-Mudlet#5310",
              "status": "open",
              "type": "issue",
              "number": 5310,
              "title": "Autocomplete steals window focus, prevents further typing",
              "source": {
                "data": {
                  "id": "source-Mudlet#5310",
                  "user": {
                    "login": "Matthew-Marsh",
                    "id": 79426017,
                    "node_id": "MDQ6VXNlcjc5NDI2MDE3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/79426017?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Matthew-Marsh",
                    "html_url": "https://github.com/Matthew-Marsh",
                    "followers_url": "https://api.github.com/users/Matthew-Marsh/followers",
                    "following_url": "https://api.github.com/users/Matthew-Marsh/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Matthew-Marsh/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Matthew-Marsh/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Matthew-Marsh/subscriptions",
                    "organizations_url": "https://api.github.com/users/Matthew-Marsh/orgs",
                    "repos_url": "https://api.github.com/users/Matthew-Marsh/repos",
                    "events_url": "https://api.github.com/users/Matthew-Marsh/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Matthew-Marsh/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Autocomplete steals window focus, prevents further typing",
                  "body": "#### Brief summary of issue / Description of requested feature:\r\n\r\nOccasionally encountering an issue where autocomplete pops up and prevents typing. Need to esc to remove the autocomplete, but will pop up again with another relevant letter.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1.  Unknown to why it begins.\r\n2.  Typing a letter that has a corresponding lua command in the autocomplete. \r\n\r\n#### Error output / Expected result of feature\r\n\r\nExpected result: Being able to continue typing outside of autocomplete.\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n\r\nMudlet version: 4.11.2\r\nWindows 10 Home\r\nVideo recording: https://youtu.be/qJF0h2MDWzg\r\n",
                  "html_url": "https://github.com/Mudlet/Mudlet/issues/5310"
                },
                "type": "github"
              },
              "hash": "Mudlet/Mudlet#5310",
              "body": "#### Brief summary of issue / Description of requested feature:\r\n\r\nOccasionally encountering an issue where autocomplete pops up and prevents typing. Need to esc to remove the autocomplete, but will pop up again with another relevant letter.\r\n\r\n#### Steps to reproduce the issue / Reasons for adding feature:\r\n\r\n1.  Unknown to why it begins.\r\n2.  Typing a letter that has a corresponding lua command in the autocomplete. \r\n\r\n#### Error output / Expected result of feature\r\n\r\nExpected result: Being able to continue typing outside of autocomplete.\r\n\r\n#### Extra information, such as Mudlet version, operating system and ideas for how to solve / implement:\r\n\r\nMudlet version: 4.11.2\r\nWindows 10 Home\r\nVideo recording: https://youtu.be/qJF0h2MDWzg\r\n",
              "url": "https://github.com/Mudlet/Mudlet/issues/5310",
              "tech": [],
              "repo_name": "Mudlet",
              "repo_owner": "Mudlet",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "onyx-dot-app#2807",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "onyx-dot-app",
              "id": "generated-onyx-dot-app",
              "name": "Onyx-dot-app",
              "description": "",
              "members": [],
              "display_name": "Onyx-dot-app",
              "created_at": "2025-12-13T17:43:17.238Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/onyx-dot-app?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "onyx-dot-app",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-13T17:43:17.238Z",
            "created_at": "2025-12-13T17:43:17.238Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-onyx-dot-app#2807",
              "status": "open",
              "type": "issue",
              "number": 2807,
              "title": "Feature Request: Add Coda.io Import Connector",
              "source": {
                "data": {
                  "id": "source-onyx-dot-app#2807",
                  "user": {
                    "login": "MagnusHL",
                    "id": 6343677,
                    "node_id": "MDQ6VXNlcjYzNDM2Nzc=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/6343677?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/MagnusHL",
                    "html_url": "https://github.com/MagnusHL",
                    "followers_url": "https://api.github.com/users/MagnusHL/followers",
                    "following_url": "https://api.github.com/users/MagnusHL/following{/other_user}",
                    "gists_url": "https://api.github.com/users/MagnusHL/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/MagnusHL/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/MagnusHL/subscriptions",
                    "organizations_url": "https://api.github.com/users/MagnusHL/orgs",
                    "repos_url": "https://api.github.com/users/MagnusHL/repos",
                    "events_url": "https://api.github.com/users/MagnusHL/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/MagnusHL/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Feature Request: Add Coda.io Import Connector",
                  "body": "Please add a connector to enable the import of data from Coda.io into Danswer-AI. Coda.io is a strong alternative to Notion and would provide valuable flexibility for users.\r\n\r\nBest regards, Magnus",
                  "html_url": "https://github.com/onyx-dot-app/onyx/issues/2807"
                },
                "type": "github"
              },
              "hash": "onyx-dot-app/onyx#2807",
              "body": "Please add a connector to enable the import of data from Coda.io into Danswer-AI. Coda.io is a strong alternative to Notion and would provide valuable flexibility for users.\r\n\r\nBest regards, Magnus",
              "url": "https://github.com/onyx-dot-app/onyx/issues/2807",
              "tech": [
                "go"
              ],
              "repo_name": "onyx",
              "repo_owner": "onyx-dot-app",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "onyx-dot-app#2281",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "onyx-dot-app",
              "id": "generated-onyx-dot-app",
              "name": "Onyx-dot-app",
              "description": "",
              "members": [],
              "display_name": "Onyx-dot-app",
              "created_at": "2025-12-13T17:43:17.524Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/onyx-dot-app?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "danswer-ai",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-13T17:43:17.524Z",
            "created_at": "2025-12-13T17:43:17.524Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-onyx-dot-app#2281",
              "status": "open",
              "type": "issue",
              "number": 2281,
              "title": "Jira Service Management Connector",
              "source": {
                "data": {
                  "id": "source-onyx-dot-app#2281",
                  "user": {
                    "login": "Weves",
                    "id": 25087905,
                    "node_id": "MDQ6VXNlcjI1MDg3OTA1",
                    "avatar_url": "https://avatars.githubusercontent.com/u/25087905?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Weves",
                    "html_url": "https://github.com/Weves",
                    "followers_url": "https://api.github.com/users/Weves/followers",
                    "following_url": "https://api.github.com/users/Weves/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Weves/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Weves/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Weves/subscriptions",
                    "organizations_url": "https://api.github.com/users/Weves/orgs",
                    "repos_url": "https://api.github.com/users/Weves/repos",
                    "events_url": "https://api.github.com/users/Weves/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Weves/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Jira Service Management Connector",
                  "body": "Pull in all tickets from a specified [Jira Service Management](https://www.atlassian.com/software/jira/service-management) project. \r\n\r\nCheckout the connector creation README here for more details on the best way to add new connectors: https://github.com/danswer-ai/danswer/blob/main/backend/danswer/connectors/README.md. ",
                  "html_url": "https://github.com/onyx-dot-app/onyx/issues/2281"
                },
                "type": "github"
              },
              "hash": "danswer-ai/danswer#2281",
              "body": "Pull in all tickets from a specified [Jira Service Management](https://www.atlassian.com/software/jira/service-management) project. \r\n\r\nCheckout the connector creation README here for more details on the best way to add new connectors: https://github.com/danswer-ai/danswer/blob/main/backend/danswer/connectors/README.md. ",
              "url": "https://github.com/onyx-dot-app/onyx/issues/2281",
              "tech": [],
              "repo_name": "danswer",
              "repo_owner": "danswer-ai",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#3531",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2025-12-13T17:43:21.438Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-13T17:43:21.438Z",
            "created_at": "2025-12-13T17:43:21.438Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3531",
              "status": "open",
              "type": "issue",
              "number": 3531,
              "title": "Better error response for wrong datetime format in REST filter",
              "source": {
                "data": {
                  "id": "source-qdrant#3531",
                  "user": {
                    "login": "timvisee",
                    "id": 856222,
                    "node_id": "MDQ6VXNlcjg1NjIyMg==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/856222?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/timvisee",
                    "html_url": "https://github.com/timvisee",
                    "followers_url": "https://api.github.com/users/timvisee/followers",
                    "following_url": "https://api.github.com/users/timvisee/following{/other_user}",
                    "gists_url": "https://api.github.com/users/timvisee/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/timvisee/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/timvisee/subscriptions",
                    "organizations_url": "https://api.github.com/users/timvisee/orgs",
                    "repos_url": "https://api.github.com/users/timvisee/repos",
                    "events_url": "https://api.github.com/users/timvisee/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/timvisee/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Better error response for wrong datetime format in REST filter",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\nWe recently merged <https://github.com/qdrant/qdrant/pull/3395> which adds a datetime payload index.\r\n\r\nCurrently, the datetime parser is very strict, only allowing [RFC 3339](https://www.rfc-editor.org/rfc/rfc3339) formats in our REST API. A common format such as `YYYY-MM-DD HH:MM:SS` is currently not accepted.\r\n\r\nIf you'd send the following request:\r\n\r\n```json\r\nPOST collections/test_collection/points/scroll\r\n{\r\n  \"limit\": 10,\r\n  \"filter\": {\r\n    \"must\": [\r\n      {\r\n        \"key\": \"updated\",\r\n        \"datetime_range\": {\r\n          \"gt\": \"2014-01-01T00:00:00\"\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nYou'd receive the following error:\r\n\r\n```\r\nFormat error in JSON body: data did not match any variant of untagged enum Condition at line 1 column 96\r\n```\r\n\r\nThis error is very confusing.\r\n\r\n**Describe the solution you'd like**\r\nWe'd strongly prefer a more descriptive error message instead.\r\n\r\nSomething like this would be a lot better:\r\n\r\n```\r\nFormat error in JSON body: '2014-01-01T00:00:00' does not match any accepted datetime format\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n_None_\r\n\r\n**Additional context**\r\nRelated issue: <https://github.com/qdrant/qdrant/issues/3529>",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3531"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3531",
              "body": "**Is your feature request related to a problem? Please describe.**\r\nWe recently merged <https://github.com/qdrant/qdrant/pull/3395> which adds a datetime payload index.\r\n\r\nCurrently, the datetime parser is very strict, only allowing [RFC 3339](https://www.rfc-editor.org/rfc/rfc3339) formats in our REST API. A common format such as `YYYY-MM-DD HH:MM:SS` is currently not accepted.\r\n\r\nIf you'd send the following request:\r\n\r\n```json\r\nPOST collections/test_collection/points/scroll\r\n{\r\n  \"limit\": 10,\r\n  \"filter\": {\r\n    \"must\": [\r\n      {\r\n        \"key\": \"updated\",\r\n        \"datetime_range\": {\r\n          \"gt\": \"2014-01-01T00:00:00\"\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nYou'd receive the following error:\r\n\r\n```\r\nFormat error in JSON body: data did not match any variant of untagged enum Condition at line 1 column 96\r\n```\r\n\r\nThis error is very confusing.\r\n\r\n**Describe the solution you'd like**\r\nWe'd strongly prefer a more descriptive error message instead.\r\n\r\nSomething like this would be a lot better:\r\n\r\n```\r\nFormat error in JSON body: '2014-01-01T00:00:00' does not match any accepted datetime format\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n_None_\r\n\r\n**Additional context**\r\nRelated issue: <https://github.com/qdrant/qdrant/issues/3529>",
              "url": "https://github.com/qdrant/qdrant/issues/3531",
              "tech": [
                "go"
              ],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "qdrant#3322",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "qdrant",
              "id": "generated-qdrant",
              "name": "Qdrant",
              "description": "",
              "members": [],
              "display_name": "Qdrant",
              "created_at": "2025-12-13T17:43:21.630Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/qdrant?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "qdrant",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-13T17:43:21.630Z",
            "created_at": "2025-12-13T17:43:21.630Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-qdrant#3322",
              "status": "open",
              "type": "issue",
              "number": 3322,
              "title": "Per-collection metrics for Prometheus",
              "source": {
                "data": {
                  "id": "source-qdrant#3322",
                  "user": {
                    "login": "generall",
                    "id": 1935623,
                    "node_id": "MDQ6VXNlcjE5MzU2MjM=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1935623?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/generall",
                    "html_url": "https://github.com/generall",
                    "followers_url": "https://api.github.com/users/generall/followers",
                    "following_url": "https://api.github.com/users/generall/following{/other_user}",
                    "gists_url": "https://api.github.com/users/generall/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/generall/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/generall/subscriptions",
                    "organizations_url": "https://api.github.com/users/generall/orgs",
                    "repos_url": "https://api.github.com/users/generall/repos",
                    "events_url": "https://api.github.com/users/generall/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/generall/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Per-collection metrics for Prometheus",
                  "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, all metrics in `/metrics` are global, meaning that it’s impossible to see differences per collection.\r\n\r\nIn addition to that, all our metrics should have per-collection granularity to allow better aggregation in Prometheus, including:\r\n\r\n- point/vector counts\r\n- REST/gRPC requests\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample:\r\n```\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\"} 0.000046\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection\"} 0.000049\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection-2\"} 0.000046\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreate dedicated endpoint for each collection `/collections/my-collecton/metrics`\r\nbut feedback from DevOps on this idea was negative.\r\n\r\n**Additional context**\r\n\r\nIt might be beneficial to allow users to disable per-collection output. It is especially relevant if there are a lot of collections and metric response could become huge. But this is a nice-to-have requirement.\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently\r\n\r\n",
                  "html_url": "https://github.com/qdrant/qdrant/issues/3322"
                },
                "type": "github"
              },
              "hash": "qdrant/qdrant#3322",
              "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, all metrics in `/metrics` are global, meaning that it’s impossible to see differences per collection.\r\n\r\nIn addition to that, all our metrics should have per-collection granularity to allow better aggregation in Prometheus, including:\r\n\r\n- point/vector counts\r\n- REST/gRPC requests\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample:\r\n```\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\"} 0.000046\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection\"} 0.000049\r\ngrpc_responses_min_duration_seconds{endpoint=\"/qdrant.Points/Upsert\",collection=\"my-collection-2\"} 0.000046\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreate dedicated endpoint for each collection `/collections/my-collecton/metrics`\r\nbut feedback from DevOps on this idea was negative.\r\n\r\n**Additional context**\r\n\r\nIt might be beneficial to allow users to disable per-collection output. It is especially relevant if there are a lot of collections and metric response could become huge. But this is a nice-to-have requirement.\r\n\r\n\r\n---\r\n\r\nNote for contributors: Please consider this as tracking issue. If you think that it would be beneficial to split the task into multiple smaller PRs, please you are welcome to do so. Bounty will be rewarded for each PR independently\r\n\r\n",
              "url": "https://github.com/qdrant/qdrant/issues/3322",
              "tech": [],
              "repo_name": "qdrant",
              "repo_owner": "qdrant",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "outerbase#59",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2025-12-13T17:43:24.422Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-13T17:43:24.422Z",
            "created_at": "2025-12-13T17:43:24.422Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [
              "go"
            ],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#59",
              "status": "open",
              "type": "issue",
              "number": 59,
              "title": "Database dumps do not work on large databases",
              "source": {
                "data": {
                  "id": "source-outerbase#59",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Database dumps do not work on large databases",
                  "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/59"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#59",
              "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
              "url": "https://github.com/outerbase/starbasedb/issues/59",
              "tech": [
                "go"
              ],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "outerbase#72",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2025-12-13T17:43:24.613Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2025-12-13T17:43:24.613Z",
            "created_at": "2025-12-13T17:43:24.613Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#72",
              "status": "open",
              "type": "issue",
              "number": 72,
              "title": "Replicate data from external source to internal source with a Plugin",
              "source": {
                "data": {
                  "id": "source-outerbase#72",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Replicate data from external source to internal source with a Plugin",
                  "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/72"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#72",
              "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
              "url": "https://github.com/outerbase/starbasedb/issues/72",
              "tech": [],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          }
        ],
        "next_cursor": null
      }
    }
  }
}