{
  "result": {
    "data": {
      "json": {
        "items": [
          {
            "id": "outerbase#59",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2026-01-31T09:50:42.428Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:50:42.428Z",
            "created_at": "2026-01-31T09:50:42.428Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#59",
              "status": "open",
              "type": "issue",
              "number": 59,
              "title": "Database dumps do not work on large databases",
              "source": {
                "data": {
                  "id": "source-outerbase#59",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Database dumps do not work on large databases",
                  "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/59"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#59",
              "body": "**Describe the bug**\nIf you try to use any of the database dump endpoints such as SQL, CSV or JSON the data is loaded into memory and then created as a dump file. To support any size database we should investigate enhancements to allow any sized database to be exported. Currently the size limitations are 1GB for Durable Objects with 10GB in the future. Operate under the assumption that we might be attempting to dump a 10GB database into a `.sql` file.\n\nAnother consideration to make is because Durable Objects execute synchronous operations we may need to allow for \"breathing intervals\". An example might be we allow our export operation to run for 5 seconds, and take 5 seconds off if other requests are in a queue, then it can pick up again. The goal here would be to prevent locking the database for long periods of time.\n\nBut then poses the questions: \n1. How do we continue operations that need more than 30 seconds to work?\n2. Where is the data stored as it's being created? (R2, S3, something else)?\n3. How do we deliver that dump information to the user after its completed?\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Hit the `/export/dump` endpoint on a large database\n2. Will eventually fail when the 30 second request response time window closes\n\nRun the following command in Terminal (replace the URL with yours) and if your operation exceeds 30 seconds you should see a failed network response instead of a dump file.\n```\ncurl --location 'https://starbasedb.YOUR-ID-HERE.workers.dev/export/dump' \\\n--header 'Authorization: Bearer ABC123' \\\n--output database_dump.sql\n```\n\nIf you can't create a large enough test database feel free to add code in to `sleep` for 29 seconds before proceeding with the `/export/dump` functional code and should also see the failure.\n\n**Expected behavior**\nAs a user I would expect any and all of the specified data to be dumped out without an error and without partial results. Where it ends up for the user to access if the operation takes more than 30 seconds is up for discussion. Ideally if shorter than 30 seconds it could be returned as our cURL above works today (downloads the file from the response of the origin request), but perhaps after the timeout it continues on uploads it to a destination source to access afterwards?\n\n**Proposed Solution:**\n1. For backups require an R2 binding\n2. Have a `.sql` file that gets created in R2 with the filename like `dump_20240101-170000.sql` where it represents `2024-01-01 17:00:00`\n3. Create the file and continuously append new chunks to it until reaching the end\n4. May need to utilize a DO alarm to continue the work after X time if a timeout occurs & mark where it currently is in the process in internal memory so it can pick up and continue.\n5. Provide a callback URL when the operation is finally completed so users can create custom logic to notify them (e.g. Email, Slack, etc)",
              "url": "https://github.com/outerbase/starbasedb/issues/59",
              "tech": [],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "outerbase#72",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "outerbase",
              "id": "generated-outerbase",
              "name": "Outerbase",
              "description": "",
              "members": [],
              "display_name": "Outerbase",
              "created_at": "2026-01-31T09:50:42.769Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/outerbase?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "outerbase",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:50:42.769Z",
            "created_at": "2026-01-31T09:50:42.769Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-outerbase#72",
              "status": "open",
              "type": "issue",
              "number": 72,
              "title": "Replicate data from external source to internal source with a Plugin",
              "source": {
                "data": {
                  "id": "source-outerbase#72",
                  "user": {
                    "login": "Brayden",
                    "id": 1066085,
                    "node_id": "MDQ6VXNlcjEwNjYwODU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1066085?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Brayden",
                    "html_url": "https://github.com/Brayden",
                    "followers_url": "https://api.github.com/users/Brayden/followers",
                    "following_url": "https://api.github.com/users/Brayden/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Brayden/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Brayden/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Brayden/subscriptions",
                    "organizations_url": "https://api.github.com/users/Brayden/orgs",
                    "repos_url": "https://api.github.com/users/Brayden/repos",
                    "events_url": "https://api.github.com/users/Brayden/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Brayden/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Replicate data from external source to internal source with a Plugin",
                  "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
                  "html_url": "https://github.com/outerbase/starbasedb/issues/72"
                },
                "type": "github"
              },
              "hash": "outerbase/starbasedb#72",
              "body": "**Is your feature request related to a problem? Please describe.**\nStarbaseDB instances support by default an internal database (SQLite offered by the Durable Object) as well as an optional external data source. External data sources can be powered in one of two ways, both by providing values in the `wrangler.toml` file of the project.\n\n- Outerbase API Key\n- Connection details of the database\n\n<img width=\"481\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485d4b88-a7f8-432d-9f29-d3239a6e6577\" />\n\n**Describe the solution you'd like**\nWhat would be beneficial for some use cases is the ability to bring in an external data source (e.g. a Postgres on Supabase) and have a pull mechanism where data can be brought into the internal DO SQLite so that the instance serves as a close-to-edge replica that can be queried alternatively to querying the Supabase Postgres instance.\n\n**Describe alternatives you've considered**\n- Considering the pull vs push mechanism. A pull mechanism seems to be a better global solution where a push mechanism would be required to live elsewhere on a per provider basis.\n\n**Additional context**\n- Might be beneficial for users to be able to define in the plugin what intervals data should be pulled at\n- Might be beneficial to allow users to define which tables should have data pulled into it (perhaps not all tables need replicated)\n- Likely need a way to know for each table what the last queried items were so you can do append-only type polling for new data. Does a user need to define a column to base this on (e.g. `id` or `created_at` columns perhaps)?\n",
              "url": "https://github.com/outerbase/starbasedb/issues/72",
              "tech": [],
              "repo_name": "starbasedb",
              "repo_owner": "outerbase",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#3960",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2026-01-31T09:50:54.589Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:50:54.589Z",
            "created_at": "2026-01-31T09:50:54.589Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3960",
              "status": "open",
              "type": "issue",
              "number": 3960,
              "title": "[ðŸ”Œ Provider]: Nagios Provider",
              "source": {
                "data": {
                  "id": "source-keephq#3960",
                  "user": {
                    "login": "talboren",
                    "id": 68807791,
                    "node_id": "MDQ6VXNlcjY4ODA3Nzkx",
                    "avatar_url": "https://avatars.githubusercontent.com/u/68807791?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/talboren",
                    "html_url": "https://github.com/talboren",
                    "followers_url": "https://api.github.com/users/talboren/followers",
                    "following_url": "https://api.github.com/users/talboren/following{/other_user}",
                    "gists_url": "https://api.github.com/users/talboren/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/talboren/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/talboren/subscriptions",
                    "organizations_url": "https://api.github.com/users/talboren/orgs",
                    "repos_url": "https://api.github.com/users/talboren/repos",
                    "events_url": "https://api.github.com/users/talboren/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/talboren/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[ðŸ”Œ Provider]: Nagios Provider",
                  "body": "https://www.nagios.org/",
                  "html_url": "https://github.com/keephq/keep/issues/3960"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3960",
              "body": "https://www.nagios.org/",
              "url": "https://github.com/keephq/keep/issues/3960",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#3526",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2026-01-31T09:50:54.813Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:50:54.813Z",
            "created_at": "2026-01-31T09:50:54.813Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3526",
              "status": "open",
              "type": "issue",
              "number": 3526,
              "title": "[ðŸ”Œ Provider]: Solarwinds",
              "source": {
                "data": {
                  "id": "source-keephq#3526",
                  "user": {
                    "login": "Matvey-Kuk",
                    "id": 3284841,
                    "node_id": "MDQ6VXNlcjMyODQ4NDE=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/3284841?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Matvey-Kuk",
                    "html_url": "https://github.com/Matvey-Kuk",
                    "followers_url": "https://api.github.com/users/Matvey-Kuk/followers",
                    "following_url": "https://api.github.com/users/Matvey-Kuk/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Matvey-Kuk/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Matvey-Kuk/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Matvey-Kuk/subscriptions",
                    "organizations_url": "https://api.github.com/users/Matvey-Kuk/orgs",
                    "repos_url": "https://api.github.com/users/Matvey-Kuk/repos",
                    "events_url": "https://api.github.com/users/Matvey-Kuk/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Matvey-Kuk/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[ðŸ”Œ Provider]: Solarwinds",
                  "body": "We're looking for a https://www.solarwinds.com/ provider for Keep.",
                  "html_url": "https://github.com/keephq/keep/issues/3526"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3526",
              "body": "We're looking for a https://www.solarwinds.com/ provider for Keep.",
              "url": "https://github.com/keephq/keep/issues/3526",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#3376",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2026-01-31T09:50:55.192Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:50:55.192Z",
            "created_at": "2026-01-31T09:50:55.192Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3376",
              "status": "open",
              "type": "issue",
              "number": 3376,
              "title": "[âž• Feature]: Add a way to validate Keep workflows from CI",
              "source": {
                "data": {
                  "id": "source-keephq#3376",
                  "user": {
                    "login": "shahargl",
                    "id": 12069200,
                    "node_id": "MDQ6VXNlcjEyMDY5MjAw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/12069200?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/shahargl",
                    "html_url": "https://github.com/shahargl",
                    "followers_url": "https://api.github.com/users/shahargl/followers",
                    "following_url": "https://api.github.com/users/shahargl/following{/other_user}",
                    "gists_url": "https://api.github.com/users/shahargl/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/shahargl/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/shahargl/subscriptions",
                    "organizations_url": "https://api.github.com/users/shahargl/orgs",
                    "repos_url": "https://api.github.com/users/shahargl/repos",
                    "events_url": "https://api.github.com/users/shahargl/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/shahargl/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[âž• Feature]: Add a way to validate Keep workflows from CI",
                  "body": "https://github.com/keephq/keep/pull/5149 https://github.com/keephq/keep/pull/4517 https://github.com/keephq/keep/pull/5499 https://github.com/keephq/keep/issues/3526 https://github.com/keephq/keep/pul",
                  "html_url": "https://github.com/keephq/keep/issues/3376"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3376",
              "body": "https://github.com/keephq/keep/pull/5149 https://github.com/keephq/keep/pull/4517 https://github.com/keephq/keep/pull/5499 https://github.com/keephq/keep/issues/3526 https://github.com/keephq/keep/pul",
              "url": "https://github.com/keephq/keep/issues/3376",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#3379",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2026-01-31T09:50:55.535Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:50:55.535Z",
            "created_at": "2026-01-31T09:50:55.535Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#3379",
              "status": "open",
              "type": "issue",
              "number": 3379,
              "title": "[ðŸ”Œ Provider]: ServiceNow pull activity from incidents into incidents",
              "source": {
                "data": {
                  "id": "source-keephq#3379",
                  "user": {
                    "login": "talboren",
                    "id": 68807791,
                    "node_id": "MDQ6VXNlcjY4ODA3Nzkx",
                    "avatar_url": "https://avatars.githubusercontent.com/u/68807791?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/talboren",
                    "html_url": "https://github.com/talboren",
                    "followers_url": "https://api.github.com/users/talboren/followers",
                    "following_url": "https://api.github.com/users/talboren/following{/other_user}",
                    "gists_url": "https://api.github.com/users/talboren/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/talboren/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/talboren/subscriptions",
                    "organizations_url": "https://api.github.com/users/talboren/orgs",
                    "repos_url": "https://api.github.com/users/talboren/repos",
                    "events_url": "https://api.github.com/users/talboren/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/talboren/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[ðŸ”Œ Provider]: ServiceNow pull activity from incidents into incidents",
                  "body": "As a user, I would like to pull activity from ServiceNow incident into my Keep incident and the other way around.",
                  "html_url": "https://github.com/keephq/keep/issues/3379"
                },
                "type": "github"
              },
              "hash": "keephq/keep#3379",
              "body": "As a user, I would like to pull activity from ServiceNow incident into my Keep incident and the other way around.",
              "url": "https://github.com/keephq/keep/issues/3379",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "keephq#2112",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "keephq",
              "id": "generated-keephq",
              "name": "Keephq",
              "description": "",
              "members": [],
              "display_name": "Keephq",
              "created_at": "2026-01-31T09:50:56.351Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/keephq?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "keephq",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:50:56.351Z",
            "created_at": "2026-01-31T09:50:56.351Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-keephq#2112",
              "status": "open",
              "type": "issue",
              "number": 2112,
              "title": "[ðŸ”Œ Provider]: SNMP provider",
              "source": {
                "data": {
                  "id": "source-keephq#2112",
                  "user": {
                    "login": "shahargl",
                    "id": 12069200,
                    "node_id": "MDQ6VXNlcjEyMDY5MjAw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/12069200?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/shahargl",
                    "html_url": "https://github.com/shahargl",
                    "followers_url": "https://api.github.com/users/shahargl/followers",
                    "following_url": "https://api.github.com/users/shahargl/following{/other_user}",
                    "gists_url": "https://api.github.com/users/shahargl/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/shahargl/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/shahargl/subscriptions",
                    "organizations_url": "https://api.github.com/users/shahargl/orgs",
                    "repos_url": "https://api.github.com/users/shahargl/repos",
                    "events_url": "https://api.github.com/users/shahargl/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/shahargl/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[ðŸ”Œ Provider]: SNMP provider",
                  "body": "Send SNMP traps/events into Keep as alerts",
                  "html_url": "https://github.com/keephq/keep/issues/2112"
                },
                "type": "github"
              },
              "hash": "keephq/keep#2112",
              "body": "Send SNMP traps/events into Keep as alerts",
              "url": "https://github.com/keephq/keep/issues/2112",
              "tech": [],
              "repo_name": "keep",
              "repo_owner": "keephq",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#8042",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-31T09:51:21.415Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:21.415Z",
            "created_at": "2026-01-31T09:51:21.415Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#8042",
              "status": "open",
              "type": "issue",
              "number": 8042,
              "title": "[Enhancement]: OAUTH only self registering.",
              "source": {
                "data": {
                  "id": "source-coollabsio#8042",
                  "user": {
                    "login": "kewynf",
                    "id": 47131740,
                    "node_id": "MDQ6VXNlcjQ3MTMxNzQw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/47131740?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kewynf",
                    "html_url": "https://github.com/kewynf",
                    "followers_url": "https://api.github.com/users/kewynf/followers",
                    "following_url": "https://api.github.com/users/kewynf/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kewynf/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kewynf/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kewynf/subscriptions",
                    "organizations_url": "https://api.github.com/users/kewynf/orgs",
                    "repos_url": "https://api.github.com/users/kewynf/repos",
                    "events_url": "https://api.github.com/users/kewynf/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kewynf/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: OAUTH only self registering.",
                  "body": "### Request Type\n\nImprovement\n\n### Description\n\nHi, there!\n\nToday users are only able to self-register with OAUTH2 when general self-register is enabled.\n\nThe improvement would be:\n- Allow users logging in with OAUTH2 accounts to self-register even when general self-registering is disabled;\n- Allow admins to restrict users to OAUTH2 only, blocking users from creating and using passwords if they are coming from an OAUTH2 provider (this would allow a single action to suspend users in multiple Coolify instances);\n\nThis would allow us to, for example, control who can and cannot login into a Coolify instance using a tool like Authentik (ex: only users within a certain organization).\n\nThe ideal world would be SCIM 2.0 or something like LDAP, but this is a good start to block access whenever someone leaves the team.\n\nThanks in advance.",
                  "html_url": "https://github.com/coollabsio/coolify/issues/8042"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#8042",
              "body": "### Request Type\n\nImprovement\n\n### Description\n\nHi, there!\n\nToday users are only able to self-register with OAUTH2 when general self-register is enabled.\n\nThe improvement would be:\n- Allow users logging in with OAUTH2 accounts to self-register even when general self-registering is disabled;\n- Allow admins to restrict users to OAUTH2 only, blocking users from creating and using passwords if they are coming from an OAUTH2 provider (this would allow a single action to suspend users in multiple Coolify instances);\n\nThis would allow us to, for example, control who can and cannot login into a Coolify instance using a tool like Authentik (ex: only users within a certain organization).\n\nThe ideal world would be SCIM 2.0 or something like LDAP, but this is a good start to block access whenever someone leaves the team.\n\nThanks in advance.",
              "url": "https://github.com/coollabsio/coolify/issues/8042",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7655",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-31T09:51:21.546Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:21.546Z",
            "created_at": "2026-01-31T09:51:21.546Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7655",
              "status": "open",
              "type": "issue",
              "number": 7655,
              "title": "[Improvement]: Do not share all environment variables across all containers in a Compose project",
              "source": {
                "data": {
                  "id": "source-coollabsio#7655",
                  "user": {
                    "login": "tadamcz",
                    "id": 43300673,
                    "node_id": "MDQ6VXNlcjQzMzAwNjcz",
                    "avatar_url": "https://avatars.githubusercontent.com/u/43300673?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/tadamcz",
                    "html_url": "https://github.com/tadamcz",
                    "followers_url": "https://api.github.com/users/tadamcz/followers",
                    "following_url": "https://api.github.com/users/tadamcz/following{/other_user}",
                    "gists_url": "https://api.github.com/users/tadamcz/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/tadamcz/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/tadamcz/subscriptions",
                    "organizations_url": "https://api.github.com/users/tadamcz/orgs",
                    "repos_url": "https://api.github.com/users/tadamcz/repos",
                    "events_url": "https://api.github.com/users/tadamcz/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/tadamcz/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Improvement]: Do not share all environment variables across all containers in a Compose project",
                  "body": "### Problem Description\n\nWhen deploying a Docker Compose project, Coolify injects all environment variables into every container, regardless of which container they were defined for.\n\nFrom inspecting the \"Raw Docker compose\" in the UI, I believe this happens like this:\n  1. A single `.env` file is created containing ALL environment variables from the entire Docker Compose project\n  2. This `.env` file is automatically added to every container's `env_file:` directive\n\n### Security Implications\n\nThis seems to be a serious security issue. \n\nAny container in a multi-container Docker Compose project can read the secrets/credentials of every other container.\n\nExamples:\n  - In a Next.js + PostgreSQL + Redis stack, the Redis container has access to POSTGRES_PASSWORD and the PostgreSQL container can see OPENAI_API_KEY meant only for the app\n  - In any multi-database setup, each database container can see the credentials of other databases\n  - If one container is compromised, an attacker gains credentials for all containers in the project\n\n###  Expected Behavior\n\n  Each container should only have access to:\n  - Variables explicitly defined in its `environment: ` section\n  - Variables from env files explicitly declared in its `env_file:` section\n  - Coolify metadata variables (`COOLIFY_*`, `SERVICE_URL_*`, etc.) as needed\n\nVariables specific to other containers (especially credentials) should NOT be accessible to unrelated containers.\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7655"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7655",
              "body": "### Problem Description\n\nWhen deploying a Docker Compose project, Coolify injects all environment variables into every container, regardless of which container they were defined for.\n\nFrom inspecting the \"Raw Docker compose\" in the UI, I believe this happens like this:\n  1. A single `.env` file is created containing ALL environment variables from the entire Docker Compose project\n  2. This `.env` file is automatically added to every container's `env_file:` directive\n\n### Security Implications\n\nThis seems to be a serious security issue. \n\nAny container in a multi-container Docker Compose project can read the secrets/credentials of every other container.\n\nExamples:\n  - In a Next.js + PostgreSQL + Redis stack, the Redis container has access to POSTGRES_PASSWORD and the PostgreSQL container can see OPENAI_API_KEY meant only for the app\n  - In any multi-database setup, each database container can see the credentials of other databases\n  - If one container is compromised, an attacker gains credentials for all containers in the project\n\n###  Expected Behavior\n\n  Each container should only have access to:\n  - Variables explicitly defined in its `environment: ` section\n  - Variables from env files explicitly declared in its `env_file:` section\n  - Coolify metadata variables (`COOLIFY_*`, `SERVICE_URL_*`, etc.) as needed\n\nVariables specific to other containers (especially credentials) should NOT be accessible to unrelated containers.\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n",
              "url": "https://github.com/coollabsio/coolify/issues/7655",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7743",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-31T09:51:21.696Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:21.696Z",
            "created_at": "2026-01-31T09:51:21.696Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7743",
              "status": "open",
              "type": "issue",
              "number": 7743,
              "title": "[Enhancement]: Don't timeout public database proxies after 10 min",
              "source": {
                "data": {
                  "id": "source-coollabsio#7743",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Don't timeout public database proxies after 10 min",
                  "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the TCP proxy in front of Postgres when you mark \"Expose publicly\" times out after about 10m. Switch this to have no timeout or to have a configurable timeout in the GUI.\n\nUse case: I sometimes have `SELECT *` statements that take a very long time (30m+) to download the results for. The connection timing out prevents that from being successful\n\nBounty: $100 USD once merged and live on Coolify Cloud.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com), a charity that supports teenagers who love coding and electronics! We previously funded database SSL support, backups API, and pgBackRest support for Postgres backups (in progress).",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7743"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7743",
              "body": "### Request Type\n\nImprovement\n\n### Description\n\nCurrently the TCP proxy in front of Postgres when you mark \"Expose publicly\" times out after about 10m. Switch this to have no timeout or to have a configurable timeout in the GUI.\n\nUse case: I sometimes have `SELECT *` statements that take a very long time (30m+) to download the results for. The connection timing out prevents that from being successful\n\nBounty: $100 USD once merged and live on Coolify Cloud.\n\n---\n\nThis bounty is funded by [Hack Club](https://hackclub.com), a charity that supports teenagers who love coding and electronics! We previously funded database SSL support, backups API, and pgBackRest support for Postgres backups (in progress).",
              "url": "https://github.com/coollabsio/coolify/issues/7743",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7738",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-31T09:51:21.845Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:21.845Z",
            "created_at": "2026-01-31T09:51:21.845Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7738",
              "status": "open",
              "type": "issue",
              "number": 7738,
              "title": "[Enhancement]: Environment variables for each server that can be made available to each application deployed on it",
              "source": {
                "data": {
                  "id": "source-coollabsio#7738",
                  "user": {
                    "login": "pkpio",
                    "id": 816666,
                    "node_id": "MDQ6VXNlcjgxNjY2Ng==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/816666?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/pkpio",
                    "html_url": "https://github.com/pkpio",
                    "followers_url": "https://api.github.com/users/pkpio/followers",
                    "following_url": "https://api.github.com/users/pkpio/following{/other_user}",
                    "gists_url": "https://api.github.com/users/pkpio/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/pkpio/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/pkpio/subscriptions",
                    "organizations_url": "https://api.github.com/users/pkpio/orgs",
                    "repos_url": "https://api.github.com/users/pkpio/repos",
                    "events_url": "https://api.github.com/users/pkpio/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/pkpio/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Environment variables for each server that can be made available to each application deployed on it",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\nWhen deploying a resource using the \"Multiple Servers\" option, currently there is no way to distinguish between the servers from within the application - because the container running on both servers get identical setup. \n\nThis makes debugging harder as application logs cannot identify which server deployment an issue happened - take for instance a failure due to network errors happening specifically on one server (randomly). \n\nA way to define Environment variables for each server and making them available for each application deployed on that server, will fix this limitation (and also generalised in a way for use cases beyond what I described here).",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7738"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7738",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\nWhen deploying a resource using the \"Multiple Servers\" option, currently there is no way to distinguish between the servers from within the application - because the container running on both servers get identical setup. \n\nThis makes debugging harder as application logs cannot identify which server deployment an issue happened - take for instance a failure due to network errors happening specifically on one server (randomly). \n\nA way to define Environment variables for each server and making them available for each application deployed on that server, will fix this limitation (and also generalised in a way for use cases beyond what I described here).",
              "url": "https://github.com/coollabsio/coolify/issues/7738",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7724",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-31T09:51:21.960Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:21.960Z",
            "created_at": "2026-01-31T09:51:21.960Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7724",
              "status": "open",
              "type": "issue",
              "number": 7724,
              "title": "[Bug]: Sporadic Permission denied (publickey,password).",
              "source": {
                "data": {
                  "id": "source-coollabsio#7724",
                  "user": {
                    "login": "zachlatta",
                    "id": 992248,
                    "node_id": "MDQ6VXNlcjk5MjI0OA==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/992248?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/zachlatta",
                    "html_url": "https://github.com/zachlatta",
                    "followers_url": "https://api.github.com/users/zachlatta/followers",
                    "following_url": "https://api.github.com/users/zachlatta/following{/other_user}",
                    "gists_url": "https://api.github.com/users/zachlatta/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/zachlatta/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/zachlatta/subscriptions",
                    "organizations_url": "https://api.github.com/users/zachlatta/orgs",
                    "repos_url": "https://api.github.com/users/zachlatta/repos",
                    "events_url": "https://api.github.com/users/zachlatta/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/zachlatta/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Sporadic Permission denied (publickey,password).",
                  "body": "### Error Message and Logs\n\n<img width=\"380\" height=\"129\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a615ea52-e26d-435d-8121-e01cd7d7f656\" />\n\nStarting maybe ~2 weeks ago we started getting this error constantly. Generating a new private SSH key and setting it up seems to stop it for a bit, then it starts happening again. I'm 99% sure something is causing Coolify to send the wrong SSH key. When I check server logs, it shows that logins are indeed failing. They are not being blocked by fail2ban or anything like that.\n\nI will pay $250 to anyone who can diagnose and fix this issue. It's causing major issues for us. Acceptance criteria: Fix is merged into Coolify Cloud.\n\n### Steps to Reproduce\n\nI'm sorry, I don't have good reproduction steps. It sporadically seems to happen.\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7724"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7724",
              "body": "### Error Message and Logs\n\n<img width=\"380\" height=\"129\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a615ea52-e26d-435d-8121-e01cd7d7f656\" />\n\nStarting maybe ~2 weeks ago we started getting this error constantly. Generating a new private SSH key and setting it up seems to stop it for a bit, then it starts happening again. I'm 99% sure something is causing Coolify to send the wrong SSH key. When I check server logs, it shows that logins are indeed failing. They are not being blocked by fail2ban or anything like that.\n\nI will pay $250 to anyone who can diagnose and fix this issue. It's causing major issues for us. Acceptance criteria: Fix is merged into Coolify Cloud.\n\n### Steps to Reproduce\n\nI'm sorry, I don't have good reproduction steps. It sporadically seems to happen.\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/7724",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7642",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-31T09:51:22.090Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:22.090Z",
            "created_at": "2026-01-31T09:51:22.090Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7642",
              "status": "open",
              "type": "issue",
              "number": 7642,
              "title": "[Enhancement]: Add surrealDB with and without TIKV",
              "source": {
                "data": {
                  "id": "source-coollabsio#7642",
                  "user": {
                    "login": "Jordan-Hall",
                    "id": 2092344,
                    "node_id": "MDQ6VXNlcjIwOTIzNDQ=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/2092344?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Jordan-Hall",
                    "html_url": "https://github.com/Jordan-Hall",
                    "followers_url": "https://api.github.com/users/Jordan-Hall/followers",
                    "following_url": "https://api.github.com/users/Jordan-Hall/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Jordan-Hall/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Jordan-Hall/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Jordan-Hall/subscriptions",
                    "organizations_url": "https://api.github.com/users/Jordan-Hall/orgs",
                    "repos_url": "https://api.github.com/users/Jordan-Hall/repos",
                    "events_url": "https://api.github.com/users/Jordan-Hall/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Jordan-Hall/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Add surrealDB with and without TIKV",
                  "body": "### Request Type\n\nNew Service\n\n### Description\n\nThey a couple of decussion around surrealdb as a database option but it be nice if it was bulit in with both TIKV and rockdb as an option\n\nhttps://github.com/coollabsio/coolify/discussions/3587\nhttps://github.com/coollabsio/coolify/discussions/4013 ",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7642"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7642",
              "body": "### Request Type\n\nNew Service\n\n### Description\n\nThey a couple of decussion around surrealdb as a database option but it be nice if it was bulit in with both TIKV and rockdb as an option\n\nhttps://github.com/coollabsio/coolify/discussions/3587\nhttps://github.com/coollabsio/coolify/discussions/4013 ",
              "url": "https://github.com/coollabsio/coolify/issues/7642",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7596",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-31T09:51:22.256Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:22.256Z",
            "created_at": "2026-01-31T09:51:22.256Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7596",
              "status": "open",
              "type": "issue",
              "number": 7596,
              "title": "[Enhancement]: new deployment page",
              "source": {
                "data": {
                  "id": "source-coollabsio#7596",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: new deployment page",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n- Add deployments to sidebar\n- Show past deployments (all of them)\n- Add a filter on the top:\n  - Filter by project\n  - Filter by server\n  - Filter by sources\n  - Filter by status (queued, pending, done)\n- Show live updates / refresh?\n- Hide filters if only 1 server / 1 source\n\n## Design inspiration\n\nVercel example:\n\n<img width=\"1362\" height=\"967\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e46d7470-fff1-46c5-8011-63ba82119db2\" />\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7596"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7596",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n- Add deployments to sidebar\n- Show past deployments (all of them)\n- Add a filter on the top:\n  - Filter by project\n  - Filter by server\n  - Filter by sources\n  - Filter by status (queued, pending, done)\n- Show live updates / refresh?\n- Hide filters if only 1 server / 1 source\n\n## Design inspiration\n\nVercel example:\n\n<img width=\"1362\" height=\"967\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e46d7470-fff1-46c5-8011-63ba82119db2\" />\n",
              "url": "https://github.com/coollabsio/coolify/issues/7596",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7528",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-31T09:51:22.443Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:22.443Z",
            "created_at": "2026-01-31T09:51:22.443Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7528",
              "status": "open",
              "type": "issue",
              "number": 7528,
              "title": "[Enhancement]: Enable database detection and backup support for Docker Compose deployments via GitHub App",
              "source": {
                "data": {
                  "id": "source-coollabsio#7528",
                  "user": {
                    "login": "Illyism",
                    "id": 304283,
                    "node_id": "MDQ6VXNlcjMwNDI4Mw==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/304283?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/Illyism",
                    "html_url": "https://github.com/Illyism",
                    "followers_url": "https://api.github.com/users/Illyism/followers",
                    "following_url": "https://api.github.com/users/Illyism/following{/other_user}",
                    "gists_url": "https://api.github.com/users/Illyism/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/Illyism/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/Illyism/subscriptions",
                    "organizations_url": "https://api.github.com/users/Illyism/orgs",
                    "repos_url": "https://api.github.com/users/Illyism/repos",
                    "events_url": "https://api.github.com/users/Illyism/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/Illyism/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Enhancement]: Enable database detection and backup support for Docker Compose deployments via GitHub App",
                  "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nWhen deploying a Docker Compose file via GitHub App (using the `dockercompose` buildpack), database services are not detected and `ServiceDatabase` records are not created. This means automated backups are not available for databases in these deployments.\n\nHowever, when using \"Empty Docker Compose\" or one-click services (like Supabase), database detection works correctly and backups are available.\n\n### Current Behavior\n\n| Deployment Method | Model | Creates ServiceDatabase | Backups Available |\n|---|---|---|---|\n| Empty Docker Compose | `Service` | âœ… Yes | âœ… Yes |\n| GitHub App (dockercompose buildpack) | `Application` | âŒ No | âŒ No |\n| One-click Services (e.g., Supabase) | `Service` | âœ… Yes | âœ… Yes |\n\n### Expected Behavior\n\nDatabase services in Docker Compose files deployed via GitHub App should be detected and have backup functionality available, similar to Empty Docker Compose deployments.\n\n### Technical Details\n\nThe issue is in `bootstrap/helpers/shared.php` in the `parseDockerComposeFile()` function:\n\n**Service model path (lines 1263-2025):**\n- Calls `isDatabaseImage()` to detect databases\n- Creates `ServiceDatabase` records for detected databases\n- These databases can have scheduled backups\n\n**Application model path (lines 2026-2767):**\n- Does NOT call `isDatabaseImage()`\n- Does NOT create `ServiceDatabase` records\n- All services are treated as application containers\n- No backup support\n\n### Proposed Solution\n\nAdd database detection logic to the Application model parsing path:\n\n1. In `parseDockerComposeFile()` for the Application model (around line 2066), add:\n   ```php\n   $isDatabase = isDatabaseImage($image, $service);\n   data_set($service, 'is_database', $isDatabase);\n   ```\n\n2. Create `ServiceDatabase` records for detected database services, similar to how it's done in the Service model path.\n\n3. Alternatively, consider refactoring to share the database detection logic between both paths.\n\n### Use Case\n\nUsers deploying full-stack applications via GitHub (e.g., Next.js app + PostgreSQL + pgbouncer in a single compose file) expect database backups to work the same way as standalone database deployments or one-click services.\n\n### Related Code\n\n- `bootstrap/helpers/shared.php` - `parseDockerComposeFile()` function\n- `bootstrap/helpers/docker.php` - `isDatabaseImage()` function\n- `app/Models/ServiceDatabase.php` - Database model with backup support\n- `app/Models/ScheduledDatabaseBackup.php` - Backup scheduling\n\n### Environment\n\n- Coolify version: latest\n- Deployment method: GitHub App with dockercompose buildpack\n",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7528"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7528",
              "body": "### Request Type\n\nNew Feature\n\n### Description\n\n\n### Description\n\nWhen deploying a Docker Compose file via GitHub App (using the `dockercompose` buildpack), database services are not detected and `ServiceDatabase` records are not created. This means automated backups are not available for databases in these deployments.\n\nHowever, when using \"Empty Docker Compose\" or one-click services (like Supabase), database detection works correctly and backups are available.\n\n### Current Behavior\n\n| Deployment Method | Model | Creates ServiceDatabase | Backups Available |\n|---|---|---|---|\n| Empty Docker Compose | `Service` | âœ… Yes | âœ… Yes |\n| GitHub App (dockercompose buildpack) | `Application` | âŒ No | âŒ No |\n| One-click Services (e.g., Supabase) | `Service` | âœ… Yes | âœ… Yes |\n\n### Expected Behavior\n\nDatabase services in Docker Compose files deployed via GitHub App should be detected and have backup functionality available, similar to Empty Docker Compose deployments.\n\n### Technical Details\n\nThe issue is in `bootstrap/helpers/shared.php` in the `parseDockerComposeFile()` function:\n\n**Service model path (lines 1263-2025):**\n- Calls `isDatabaseImage()` to detect databases\n- Creates `ServiceDatabase` records for detected databases\n- These databases can have scheduled backups\n\n**Application model path (lines 2026-2767):**\n- Does NOT call `isDatabaseImage()`\n- Does NOT create `ServiceDatabase` records\n- All services are treated as application containers\n- No backup support\n\n### Proposed Solution\n\nAdd database detection logic to the Application model parsing path:\n\n1. In `parseDockerComposeFile()` for the Application model (around line 2066), add:\n   ```php\n   $isDatabase = isDatabaseImage($image, $service);\n   data_set($service, 'is_database', $isDatabase);\n   ```\n\n2. Create `ServiceDatabase` records for detected database services, similar to how it's done in the Service model path.\n\n3. Alternatively, consider refactoring to share the database detection logic between both paths.\n\n### Use Case\n\nUsers deploying full-stack applications via GitHub (e.g., Next.js app + PostgreSQL + pgbouncer in a single compose file) expect database backups to work the same way as standalone database deployments or one-click services.\n\n### Related Code\n\n- `bootstrap/helpers/shared.php` - `parseDockerComposeFile()` function\n- `bootstrap/helpers/docker.php` - `isDatabaseImage()` function\n- `app/Models/ServiceDatabase.php` - Database model with backup support\n- `app/Models/ScheduledDatabaseBackup.php` - Backup scheduling\n\n### Environment\n\n- Coolify version: latest\n- Deployment method: GitHub App with dockercompose buildpack\n",
              "url": "https://github.com/coollabsio/coolify/issues/7528",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7473",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-31T09:51:22.567Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:22.567Z",
            "created_at": "2026-01-31T09:51:22.567Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7473",
              "status": "open",
              "type": "issue",
              "number": 7473,
              "title": "[Bug]: Database Backups won't use the custom timeout in ssh command (regression)",
              "source": {
                "data": {
                  "id": "source-coollabsio#7473",
                  "user": {
                    "login": "isokosan",
                    "id": 1430946,
                    "node_id": "MDQ6VXNlcjE0MzA5NDY=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/1430946?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/isokosan",
                    "html_url": "https://github.com/isokosan",
                    "followers_url": "https://api.github.com/users/isokosan/followers",
                    "following_url": "https://api.github.com/users/isokosan/following{/other_user}",
                    "gists_url": "https://api.github.com/users/isokosan/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/isokosan/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/isokosan/subscriptions",
                    "organizations_url": "https://api.github.com/users/isokosan/orgs",
                    "repos_url": "https://api.github.com/users/isokosan/repos",
                    "events_url": "https://api.github.com/users/isokosan/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/isokosan/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug]: Database Backups won't use the custom timeout in ssh command (regression)",
                  "body": "### Error Message and Logs\n\nWe had [this issue](https://github.com/coollabsio/coolify/issues/3325) with backups exceeding timeouts and we made a new feature where we can customize the timeout settings in the backups.\n\nThis was working but seems to have regressed as the timeout setting is not being passed to the backup ssh command, instead the default 3600 is being used I'm afraid:\n\nThe process \"timeout 3600 ssh -i /var/www/html/storage/app/ssh/keys/ssh_key@jgcwgggco80sc0occ88skg0s -o StrictHos... truncated ...FoM2ROejJRRmtjT1M0NXNt\" exceeded the timeout of 3600 seconds.\n\n@Cinzya commented that this is about the SSH command now and not the backup itself:\n> I believe this is actually the SSH process timing out and not the backup itself.\n> The SSH process has a hard timeout of 3600. The backup timeout is not really passed to the SSH process to increase that timeout as well. \n> This is either an oversight or there is a specific reason why a SSH process shouldn't linger more then 3600 seconds. \n> But yes, feel free to open a new issue about it. \n\n\n### Steps to Reproduce\n\n1. Configure a database and then backups.\n2. Use the Timeout option in the dashboard to set a custom timeout, eg 10800 (default 3600 seconds)\n3. Click on Backup Now\n4. Check the command that is run by coolify to see the timeout not being passed to the SSH command\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7473"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7473",
              "body": "### Error Message and Logs\n\nWe had [this issue](https://github.com/coollabsio/coolify/issues/3325) with backups exceeding timeouts and we made a new feature where we can customize the timeout settings in the backups.\n\nThis was working but seems to have regressed as the timeout setting is not being passed to the backup ssh command, instead the default 3600 is being used I'm afraid:\n\nThe process \"timeout 3600 ssh -i /var/www/html/storage/app/ssh/keys/ssh_key@jgcwgggco80sc0occ88skg0s -o StrictHos... truncated ...FoM2ROejJRRmtjT1M0NXNt\" exceeded the timeout of 3600 seconds.\n\n@Cinzya commented that this is about the SSH command now and not the backup itself:\n> I believe this is actually the SSH process timing out and not the backup itself.\n> The SSH process has a hard timeout of 3600. The backup timeout is not really passed to the SSH process to increase that timeout as well. \n> This is either an oversight or there is a specific reason why a SSH process shouldn't linger more then 3600 seconds. \n> But yes, feel free to open a new issue about it. \n\n\n### Steps to Reproduce\n\n1. Configure a database and then backups.\n2. Use the Timeout option in the dashboard to set a custom timeout, eg 10800 (default 3600 seconds)\n3. Click on Backup Now\n4. Check the command that is run by coolify to see the timeout not being passed to the SSH command\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nYes (Coolify Cloud)\n\n### Operating System and Version (self-hosted)\n\n_No response_\n\n### Additional Information\n\n_No response_",
              "url": "https://github.com/coollabsio/coolify/issues/7473",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "coollabsio#7458",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "coollabsio",
              "id": "generated-coollabsio",
              "name": "Coollabsio",
              "description": "",
              "members": [],
              "display_name": "Coollabsio",
              "created_at": "2026-01-31T09:51:22.701Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/coollabsio?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "coollabsio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:22.701Z",
            "created_at": "2026-01-31T09:51:22.701Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-coollabsio#7458",
              "status": "open",
              "type": "issue",
              "number": 7458,
              "title": "[Bug + Multiple Bounties]: Official Selfhosted Supabase MCP Setup hindered by Coolify AND Bounty List",
              "source": {
                "data": {
                  "id": "source-coollabsio#7458",
                  "user": {
                    "login": "rootacc3ss",
                    "id": 192549131,
                    "node_id": "U_kgDOC3oRCw",
                    "avatar_url": "https://avatars.githubusercontent.com/u/192549131?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/rootacc3ss",
                    "html_url": "https://github.com/rootacc3ss",
                    "followers_url": "https://api.github.com/users/rootacc3ss/followers",
                    "following_url": "https://api.github.com/users/rootacc3ss/following{/other_user}",
                    "gists_url": "https://api.github.com/users/rootacc3ss/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/rootacc3ss/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/rootacc3ss/subscriptions",
                    "organizations_url": "https://api.github.com/users/rootacc3ss/orgs",
                    "repos_url": "https://api.github.com/users/rootacc3ss/repos",
                    "events_url": "https://api.github.com/users/rootacc3ss/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/rootacc3ss/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "[Bug + Multiple Bounties]: Official Selfhosted Supabase MCP Setup hindered by Coolify AND Bounty List",
                  "body": "### Error Message and Logs\n\n**Bounty! $15.00 on Algora.io; will add ASAP, need to figure out how to use it.**\n\nWhen following these documents from Supabase pertaining to the latest selfhosted Supabase docker setup:\nhttps://supabase.com/docs/guides/self-hosting/enable-mcp\n_you will notice the following..._\n\n1. There is no configuration to turn this on or off with ease, or even commented out docker-compose, nor any notes.\n2. With how we expose Kong via URL by default, the approach in the document could be messy or unsafe\n3. It looks like additional configuration may be required if there are multiple Supabase instances on the same server with individual /mcp exposures as Traefik is handling the routing and everything is using the same ports, etc...\n\n**I am looking for a \"work around\" as the resolution for this bounty.** That is acceptable, but I will require **at minimum a tutorial below** that figures out how to get around this bug/issue and properly documents the following:\n\n- How to configure the MCP and use it on local network\n- How to setup Wireguard to properly allow for usage of this MCP\n- How to configure Cursor/Claude Code/Windsurf to use this MCP\n- **MOST IMPORTANTLY, HOW TO CONNECT TO DIFFERENT SUPABASE INSTANCES ON THE SAME COOLIFY INSTANCE (assuming all of them are running the default Service template)**\n\nCreating a fix within the system we have to spin up and manage a Supabase instance may be difficult due to the template system's restraints, but if you want to work on that complaint of mine and **earn much more than $15**, you can see the bottom of this post. I list off the other bounties I will be offering and putting up cash for upon clearing some wires and hopefully seeing someone (or a few people) dedicate time to it.\n\n### Steps to Reproduce\n\n1. Follow docs linked above\n2. Attempt to edit the docker and piece it all together as tutorial says\n3. ???\n\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nUbuntu 24.04.03\n\n### Additional Information\n\nI am starting this bounty small as I have no clue how this system works and if I will be able to add crypto or not. I want to list these other bounties here firstly to see if there is any immediate response for \n\n**If you claim the small bounty for this, I have a few more I am willing to put in to place -- just let me know if you're interested and make sure to clear whichever one you wish to do with me to I can post the bounty for it:**\n\n- **[$35]** Better Cloudflared/Cloudflare management tools (easy exclusions and inclusions by project, IP, etc... manage domains and subdomains via Cloudflare Zero Trust or DNS settings automatically -- or at least though a portal of some sort)\n- **[$15]** Improved Supabase template (easily configure MCP properly using some sort of fix from this thread, configure mail server for automated mail and OTP with ease, set up external S3 with ease, etc -- I can contribute what I have learned from messing with the template)\n- **[$25]** Working MailCow OR Stalwart+Roundcube \"Service\" template... It's time...\n- **[$XXX]** CoolifyAI -- add API key, get AI assistant w/ knowledge-base similar to the Supabase assistant, ideally with GitHub issue lookup and basic research capability  \n- **[$XXX - $X,XXX]** More proper, fleshed out \"Services\" template system WITH ability to add remote repositories outside of the official Coolify templates; setup scripting w/ select-able options, easily modify docker template or automations/commands with checkboxes, dropdowns and input fields and the works. Ideally, a system in which \"addons\" in these same repositories as the whole \"Services\" themselves can be added on to each individual service; I.e. for Cloudflared, my request above. Or for Supabase, an easy tool to help you visualize the parts missing from Selfhosted that are in Supabase SaaS/Cloud and perhaps an API to interface with it. **This would make Coolify the single self-hosted PaaS with scripting for templates, but also an extension system allowing new functionality.**\n\nIf you are interested in discussing, claiming or collaborating on one of these bounties, see the little repo I made to track this here:\nhttps://github.com/rootacc3ss/coolify-bounties/tree/main",
                  "html_url": "https://github.com/coollabsio/coolify/issues/7458"
                },
                "type": "github"
              },
              "hash": "coollabsio/coolify#7458",
              "body": "### Error Message and Logs\n\n**Bounty! $15.00 on Algora.io; will add ASAP, need to figure out how to use it.**\n\nWhen following these documents from Supabase pertaining to the latest selfhosted Supabase docker setup:\nhttps://supabase.com/docs/guides/self-hosting/enable-mcp\n_you will notice the following..._\n\n1. There is no configuration to turn this on or off with ease, or even commented out docker-compose, nor any notes.\n2. With how we expose Kong via URL by default, the approach in the document could be messy or unsafe\n3. It looks like additional configuration may be required if there are multiple Supabase instances on the same server with individual /mcp exposures as Traefik is handling the routing and everything is using the same ports, etc...\n\n**I am looking for a \"work around\" as the resolution for this bounty.** That is acceptable, but I will require **at minimum a tutorial below** that figures out how to get around this bug/issue and properly documents the following:\n\n- How to configure the MCP and use it on local network\n- How to setup Wireguard to properly allow for usage of this MCP\n- How to configure Cursor/Claude Code/Windsurf to use this MCP\n- **MOST IMPORTANTLY, HOW TO CONNECT TO DIFFERENT SUPABASE INSTANCES ON THE SAME COOLIFY INSTANCE (assuming all of them are running the default Service template)**\n\nCreating a fix within the system we have to spin up and manage a Supabase instance may be difficult due to the template system's restraints, but if you want to work on that complaint of mine and **earn much more than $15**, you can see the bottom of this post. I list off the other bounties I will be offering and putting up cash for upon clearing some wires and hopefully seeing someone (or a few people) dedicate time to it.\n\n### Steps to Reproduce\n\n1. Follow docs linked above\n2. Attempt to edit the docker and piece it all together as tutorial says\n3. ???\n\n\n\n### Example Repository URL\n\n_No response_\n\n### Coolify Version\n\nv4.0.0-beta.452\n\n### Are you using Coolify Cloud?\n\nNo (self-hosted)\n\n### Operating System and Version (self-hosted)\n\nUbuntu 24.04.03\n\n### Additional Information\n\nI am starting this bounty small as I have no clue how this system works and if I will be able to add crypto or not. I want to list these other bounties here firstly to see if there is any immediate response for \n\n**If you claim the small bounty for this, I have a few more I am willing to put in to place -- just let me know if you're interested and make sure to clear whichever one you wish to do with me to I can post the bounty for it:**\n\n- **[$35]** Better Cloudflared/Cloudflare management tools (easy exclusions and inclusions by project, IP, etc... manage domains and subdomains via Cloudflare Zero Trust or DNS settings automatically -- or at least though a portal of some sort)\n- **[$15]** Improved Supabase template (easily configure MCP properly using some sort of fix from this thread, configure mail server for automated mail and OTP with ease, set up external S3 with ease, etc -- I can contribute what I have learned from messing with the template)\n- **[$25]** Working MailCow OR Stalwart+Roundcube \"Service\" template... It's time...\n- **[$XXX]** CoolifyAI -- add API key, get AI assistant w/ knowledge-base similar to the Supabase assistant, ideally with GitHub issue lookup and basic research capability  \n- **[$XXX - $X,XXX]** More proper, fleshed out \"Services\" template system WITH ability to add remote repositories outside of the official Coolify templates; setup scripting w/ select-able options, easily modify docker template or automations/commands with checkboxes, dropdowns and input fields and the works. Ideally, a system in which \"addons\" in these same repositories as the whole \"Services\" themselves can be added on to each individual service; I.e. for Cloudflared, my request above. Or for Supabase, an easy tool to help you visualize the parts missing from Selfhosted that are in Supabase SaaS/Cloud and perhaps an API to interface with it. **This would make Coolify the single self-hosted PaaS with scripting for templates, but also an extension system allowing new functionality.**\n\nIf you are interested in discussing, claiming or collaborating on one of these bounties, see the little repo I made to track this here:\nhttps://github.com/rootacc3ss/coolify-bounties/tree/main",
              "url": "https://github.com/coollabsio/coolify/issues/7458",
              "tech": [],
              "repo_name": "coolify",
              "repo_owner": "coollabsio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#685",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-31T09:51:26.348Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:26.348Z",
            "created_at": "2026-01-31T09:51:26.348Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#685",
              "status": "open",
              "type": "issue",
              "number": 685,
              "title": "Add JsonPatch - Depends on #679",
              "source": {
                "data": {
                  "id": "source-ZIO#685",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Add JsonPatch - Depends on #679",
                  "body": "<html><head></head><body><h1>Add <code>JsonPatch</code> type for diffing and patching JSON values</h1>\n<h2>Summary</h2>\n<p>Implement a <code>JsonPatch</code> type that enables computing diffs between JSON values and applying patches to transform one JSON value into another. This type should mirror the existing <code>DynamicPatch</code> implementation, adapted for JSON's simpler data model.</p>\n<h2>Motivation</h2>\n<p><code>DynamicValue</code> has a well-designed <code>DynamicPatch</code> system with:</p>\n<ul>\n<li>Monoid composition (<code>++</code> with <code>empty</code> identity)</li>\n<li>LCS-based sequence diffing</li>\n<li>Primitive delta operations (numeric deltas, string edits)</li>\n<li>Comprehensive algebraic laws verified by property tests</li>\n</ul>\n<p>The proposed <code>Json</code> type (see #TBD) needs equivalent patching capabilities. Rather than converting <code>Json â†” DynamicValue</code> for every patch operation, a native <code>JsonPatch</code> provides:</p>\n<ul>\n<li>Type safety (no conversion errors for JSON-incompatible DynamicPatch operations)</li>\n<li>API consistency with the <code>Json</code> type</li>\n<li>Potential for JSON-specific optimizations</li>\n</ul>\n<h2>Design Sketch</h2>\n<p>A design sketch is available at <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala</code></a>. This sketch is <strong>a guide, not a specification</strong> â€” implementers should use judgment and deviate where appropriate.</p>\n<h3>Core Types</h3>\n<p>The design mirrors <code>DynamicPatch</code> with JSON-specific adaptations:</p>\n\nDynamicPatch | JsonPatch | Notes\n-- | -- | --\nDynamicPatch(Vector[DynamicPatchOp]) | JsonPatch(Vector[JsonPatchOp]) | Same structure\nOperation.Set | Op.Set | Same\nOperation.PrimitiveDelta | Op.PrimitiveDelta | Simplified for JSON types\nOperation.SequenceEdit | Op.ArrayEdit | Renamed\nOperation.MapEdit | Op.ObjectEdit | String keys only\nOperation.Patch | Op.Nested | Same\nSeqOp | ArrayOp | Same operations\nMapOp | ObjectOp | String keys only\nPrimitiveOp (14 variants) | PrimitiveOp (2 variants) | See below\n\n\n<h3>StringOp</h3>\n<p>Mirror <code>DynamicPatch.StringOp</code> exactly:</p>\n<ul>\n<li><code>Insert(index: Int, text: String)</code></li>\n<li><code>Delete(index: Int, length: Int)</code></li>\n<li><code>Append(text: String)</code></li>\n<li><code>Modify(index: Int, length: Int, text: String)</code></li>\n</ul>\n<h3>ArrayOp</h3>\n<p>Mirror <code>DynamicPatch.SeqOp</code>:</p>\n<ul>\n<li><code>Insert(index: Int, values: Vector[Json])</code></li>\n<li><code>Append(values: Vector[Json])</code></li>\n<li><code>Delete(index: Int, count: Int)</code></li>\n<li><code>Modify(index: Int, op: Op)</code></li>\n</ul>\n<h3>ObjectOp</h3>\n<p>Mirror <code>DynamicPatch.MapOp</code> with string keys:</p>\n<ul>\n<li><code>Add(key: String, value: Json)</code></li>\n<li><code>Remove(key: String)</code></li>\n<li><code>Modify(key: String, patch: JsonPatch)</code></li>\n</ul>\n<h2>Requirements</h2>\n<h3>Functional Requirements</h3>\n<ul>\n<li>[ ] <strong>F1</strong>: <code>JsonPatch.diff(source, target)</code> computes a patch transforming source to target</li>\n<li>[ ] <strong>F2</strong>: <code>patch.apply(json, mode)</code> applies a patch with configurable failure handling</li>\n<li>[ ] <strong>F3</strong>: <code>patch1 ++ patch2</code> composes patches (apply first, then second)</li>\n<li>[ ] <strong>F4</strong>: <code>JsonPatch.empty</code> is the identity element for composition</li>\n<li>[ ] <strong>F5</strong>: Support <code>JsonPatchMode.Strict</code>, <code>Lenient</code>, and <code>Clobber</code> modes</li>\n<li>[ ] <strong>F6</strong>: Bidirectional conversion: <code>toDynamicPatch</code> / <code>fromDynamicPatch</code></li>\n</ul>\n<h3>Algebraic Laws</h3>\n<p>All laws must be verified with property-based tests (see <code>PatchLawsSpec</code> for reference):</p>\n<ul>\n<li>[ ] <strong>L1</strong>: Left identity â€” <code>(empty ++ p)(j) == p(j)</code></li>\n<li>[ ] <strong>L2</strong>: Right identity â€” <code>(p ++ empty)(j) == p(j)</code></li>\n<li>[ ] <strong>L3</strong>: Associativity â€” <code>((p1 ++ p2) ++ p3)(j) == (p1 ++ (p2 ++ p3))(j)</code></li>\n<li>[ ] <strong>L4</strong>: Roundtrip â€” <code>diff(a, b)(a) == Right(b)</code></li>\n<li>[ ] <strong>L5</strong>: Identity diff â€” <code>diff(j, j).isEmpty</code></li>\n<li>[ ] <strong>L6</strong>: Diff composition â€” <code>(diff(a, b) ++ diff(b, c))(a) == Right(c)</code></li>\n<li>[ ] <strong>L7</strong>: Lenient subsumes Strict â€” if <code>p(j, Strict) == Right(r)</code> then <code>p(j, Lenient) == Right(r)</code></li>\n</ul>\n<h3>Testing Requirements</h3>\n<ul>\n<li>[ ] <strong>T1</strong>: Property-based tests for all algebraic laws (see <code>PatchLawsSpec</code>)</li>\n<li>[ ] <strong>T2</strong>: Test each operation type (<code>Set</code>, <code>PrimitiveDelta</code>, <code>ArrayEdit</code>, <code>ObjectEdit</code>, <code>Nested</code>)</li>\n<li>[ ] <strong>T3</strong>: Test each <code>ArrayOp</code> variant (<code>Insert</code>, <code>Append</code>, <code>Delete</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T4</strong>: Test each <code>ObjectOp</code> variant (<code>Add</code>, <code>Remove</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T5</strong>: Test each <code>StringOp</code> variant (<code>Insert</code>, <code>Delete</code>, <code>Append</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T6</strong>: Test <code>NumberDelta</code> with positive, negative, zero, and decimal deltas</li>\n<li>[ ] <strong>T7</strong>: Test all three <code>JsonPatchMode</code> behaviors</li>\n<li>[ ] <strong>T8</strong>: Test <code>toDynamicPatch</code> / <code>fromDynamicPatch</code> roundtrip</li>\n<li>[ ] <strong>T9</strong>: Test edge cases: empty arrays, empty objects, empty strings, nested structures</li>\n<li>[ ] <strong>T10</strong>: Test error cases: invalid paths, type mismatches, out-of-bounds indices</li>\n</ul>\n<h3>Documentation Requirements</h3>\n<ul>\n<li>[ ] <strong>D1</strong>: ScalaDoc for all public types and methods</li>\n<li>[ ] <strong>D2</strong>: Usage examples in ScalaDoc (see sketch for examples)</li>\n<li>[ ] <strong>D3</strong>: Document algebraic laws in type-level comments</li>\n<li>[ ] <strong>D4</strong>: Document relationship to <code>DynamicPatch</code></li>\n</ul>\n<h3>Implementation Notes</h3>\n<ol>\n<li>\n<p><strong>Follow <code>DynamicPatch</code> patterns</strong>: The implementation in <code>DynamicPatch.scala</code> is the reference. Study <code>Differ.scala</code> for diff algorithms (especially LCS for sequences and strings).</p>\n</li>\n<li>\n<p><strong>Reuse algorithms where possible</strong>: Consider whether <code>JsonPatch</code> can delegate to <code>DynamicPatch</code> internally, or share algorithm implementations.</p>\n</li>\n<li>\n<p><strong>Keep it minimal</strong>: Resist adding operations not present in <code>DynamicPatch</code>. The design is intentionally minimal and principled.</p>\n</li>\n<li>\n<p><strong>Performance considerations</strong>: The register-based design of ZIO Blocks prioritizes performance. Avoid unnecessary allocations in hot paths.</p>\n</li>\n</ol>\n<h2>Out of Scope</h2>\n<p>The following are explicitly <strong>not</strong> part of this issue:</p>\n<ul>\n<li>RFC 6902 JSON Patch serialization format (separate issue)</li>\n<li>Patch inversion / undo support (separate issue)</li>\n<li>Patch optimization / compaction (separate issue)</li>\n<li>Integration with <code>Json</code> type methods like <code>json.diff(other)</code> (depends on <code>Json</code> implementation)</li>\n</ul>\n<h2>Related</h2>\n<ul>\n<li><code>DynamicPatch</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala</code></a></li>\n<li><code>Differ</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala</code></a></li>\n<li><code>PatchLawsSpec</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala\"><code>schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala</code></a></li>\n<li><code>PatchMode</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala</code></a></li>\n</ul>\n<h2>Acceptance Criteria</h2>\n<ul>\n<li>[ ] All functional requirements (F1-F6) implemented</li>\n<li>[ ] All algebraic laws (L1-L7) pass property-based tests</li>\n<li>[ ] All testing requirements (T1-T10) have corresponding test cases</li>\n<li>[ ] All documentation requirements (D1-D4) complete</li>\n<li>[ ] Code reviewed and approved</li>\n<li>[ ] CI passing</li>\n</ul></body></html># Add `JsonPatch` type for diffing and patching JSON values\n\n## Summary\n\nImplement a `JsonPatch` type that enables computing diffs between JSON values and applying patches to transform one JSON value into another. This type should mirror the existing `DynamicPatch` implementation, adapted for JSON's simpler data model.\n\n## Motivation\n\n`DynamicValue` has a well-designed `DynamicPatch` system with:\n- Monoid composition (`++` with `empty` identity)\n- LCS-based sequence diffing\n- Primitive delta operations (numeric deltas, string edits)\n- Comprehensive algebraic laws verified by property tests\n\nThe proposed `Json` type (see #TBD) needs equivalent patching capabilities. Rather than converting `Json â†” DynamicValue` for every patch operation, a native `JsonPatch` provides:\n- Type safety (no conversion errors for JSON-incompatible DynamicPatch operations)\n- API consistency with the `Json` type\n- Potential for JSON-specific optimizations\n\n## Design Sketch\n\nA design sketch is available at [`[schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala). This sketch is **a guide, not a specification** â€” implementers should use judgment and deviate where appropriate.\n\n### Core Types\n\nThe design mirrors `DynamicPatch` with JSON-specific adaptations:\n\n| DynamicPatch | JsonPatch | Notes |\n|--------------|-----------|-------|\n| `DynamicPatch(Vector[DynamicPatchOp])` | `JsonPatch(Vector[JsonPatchOp])` | Same structure |\n| `Operation.Set` | `Op.Set` | Same |\n| `Operation.PrimitiveDelta` | `Op.PrimitiveDelta` | Simplified for JSON types |\n| `Operation.SequenceEdit` | `Op.ArrayEdit` | Renamed |\n| `Operation.MapEdit` | `Op.ObjectEdit` | String keys only |\n| `Operation.Patch` | `Op.Nested` | Same |\n| `SeqOp` | `ArrayOp` | Same operations |\n| `MapOp` | `ObjectOp` | String keys only |\n| `PrimitiveOp` (14 variants) | `PrimitiveOp` (2 variants) | See below |\n\n### Primitive Operations\n\nJSON has a simpler type system than `DynamicValue`:\n\n| JSON Type | Delta Operation | Notes |\n|-----------|-----------------|-------|\n| Number | `NumberDelta(BigDecimal)` | Unifies all numeric deltas |\n| String | `StringEdit(Vector[StringOp])` | Same as `DynamicPatch` |\n| Boolean | Use `Op.Set` | No delta (same as `DynamicPatch`) |\n| Null | Use `Op.Set` | No delta |\n\n### StringOp\n\nMirror `DynamicPatch.StringOp` exactly:\n- `Insert(index: Int, text: String)`\n- `Delete(index: Int, length: Int)`\n- `Append(text: String)`\n- `Modify(index: Int, length: Int, text: String)`\n\n### ArrayOp\n\nMirror `DynamicPatch.SeqOp`:\n- `Insert(index: Int, values: Vector[Json])`\n- `Append(values: Vector[Json])`\n- `Delete(index: Int, count: Int)`\n- `Modify(index: Int, op: Op)`\n\n### ObjectOp\n\nMirror `DynamicPatch.MapOp` with string keys:\n- `Add(key: String, value: Json)`\n- `Remove(key: String)`\n- `Modify(key: String, patch: JsonPatch)`\n\n## Requirements\n\n### Functional Requirements\n\n- [ ] **F1**: `JsonPatch.diff(source, target)` computes a patch transforming source to target\n- [ ] **F2**: `patch.apply(json, mode)` applies a patch with configurable failure handling\n- [ ] **F3**: `patch1 ++ patch2` composes patches (apply first, then second)\n- [ ] **F4**: `JsonPatch.empty` is the identity element for composition\n- [ ] **F5**: Support `JsonPatchMode.Strict`, `Lenient`, and `Clobber` modes\n- [ ] **F6**: Bidirectional conversion: `toDynamicPatch` / `fromDynamicPatch`\n\n### Algebraic Laws\n\nAll laws must be verified with property-based tests (see `PatchLawsSpec` for reference):\n\n- [ ] **L1**: Left identity â€” `(empty ++ p)(j) == p(j)`\n- [ ] **L2**: Right identity â€” `(p ++ empty)(j) == p(j)`\n- [ ] **L3**: Associativity â€” `((p1 ++ p2) ++ p3)(j) == (p1 ++ (p2 ++ p3))(j)`\n- [ ] **L4**: Roundtrip â€” `diff(a, b)(a) == Right(b)`\n- [ ] **L5**: Identity diff â€” `diff(j, j).isEmpty`\n- [ ] **L6**: Diff composition â€” `(diff(a, b) ++ diff(b, c))(a) == Right(c)`\n- [ ] **L7**: Lenient subsumes Strict â€” if `p(j, Strict) == Right(r)` then `p(j, Lenient) == Right(r)`\n\n### Testing Requirements\n\n- [ ] **T1**: Property-based tests for all algebraic laws (see `PatchLawsSpec`)\n- [ ] **T2**: Test each operation type (`Set`, `PrimitiveDelta`, `ArrayEdit`, `ObjectEdit`, `Nested`)\n- [ ] **T3**: Test each `ArrayOp` variant (`Insert`, `Append`, `Delete`, `Modify`)\n- [ ] **T4**: Test each `ObjectOp` variant (`Add`, `Remove`, `Modify`)\n- [ ] **T5**: Test each `StringOp` variant (`Insert`, `Delete`, `Append`, `Modify`)\n- [ ] **T6**: Test `NumberDelta` with positive, negative, zero, and decimal deltas\n- [ ] **T7**: Test all three `JsonPatchMode` behaviors\n- [ ] **T8**: Test `toDynamicPatch` / `fromDynamicPatch` roundtrip\n- [ ] **T9**: Test edge cases: empty arrays, empty objects, empty strings, nested structures\n- [ ] **T10**: Test error cases: invalid paths, type mismatches, out-of-bounds indices\n\n### Documentation Requirements\n\n- [ ] **D1**: ScalaDoc for all public types and methods\n- [ ] **D2**: Usage examples in ScalaDoc (see sketch for examples)\n- [ ] **D3**: Document algebraic laws in type-level comments\n- [ ] **D4**: Document relationship to `DynamicPatch`\n\n## Related\n\n- `DynamicPatch` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala)\n- `Differ` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala)\n- `PatchLawsSpec` â€” [`[schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala](https://claude.ai/chat/schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala)`](./schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala)\n- `PatchMode` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala)\n\n## Acceptance Criteria\n\n- [ ] All functional requirements (F1-F6) implemented\n- [ ] All algebraic laws (L1-L7) pass property-based tests\n- [ ] All testing requirements (T1-T10) have corresponding test cases\n- [ ] All documentation requirements (D1-D4) complete\n- [ ] Code reviewed and approved\n- [ ] CI passing\n\n# Sketch\n\n```scala\npackage zio.blocks.schema.json\n\nimport zio.blocks.schema.DynamicOptic\nimport zio.blocks.schema.patch.DynamicPatch\n\n// =============================================================================\n// JSON PATCH\n// =============================================================================\n\n/**\n * An untyped patch that operates on [[Json]] values.\n *\n * `JsonPatch` is the JSON-specific counterpart to [[DynamicPatch]]. It represents\n * a sequence of operations that transform one JSON value into another. Patches\n * are serializable and composable.\n *\n * ==Design==\n *\n * This type directly mirrors [[DynamicPatch]] but is specialized for JSON's\n * simpler data model:\n *  - JSON has 4 leaf types (String, Number, Boolean, Null) vs 30 PrimitiveValues\n *  - JSON objects have string keys only (no arbitrary-keyed maps)\n *  - JSON has no native Variant type\n *\n * ==Algebraic Laws==\n *\n * '''Monoid Laws''' (under `++` composition):\n * {{{\n * // 1. LEFT IDENTITY\n * âˆ€ p: JsonPatch, j: Json.\n *   (JsonPatch.empty ++ p)(j, mode) == p(j, mode)\n *\n * // 2. RIGHT IDENTITY\n * âˆ€ p: JsonPatch, j: Json.\n *   (p ++ JsonPatch.empty)(j, mode) == p(j, mode)\n *\n * // 3. ASSOCIATIVITY\n * âˆ€ p1, p2, p3: JsonPatch, j: Json.\n *   ((p1 ++ p2) ++ p3)(j, mode) == (p1 ++ (p2 ++ p3))(j, mode)\n * }}}\n *\n * '''Diff/Apply Laws''':\n * {{{\n * // 4. ROUNDTRIP\n * âˆ€ source, target: Json.\n *   JsonPatch.diff(source, target)(source, Strict) == Right(target)\n *\n * // 5. IDENTITY DIFF\n * âˆ€ j: Json.\n *   JsonPatch.diff(j, j).isEmpty == true\n *\n * // 6. DIFF COMPOSITION\n * âˆ€ a, b, c: Json.\n *   (JsonPatch.diff(a, b) ++ JsonPatch.diff(b, c))(a, Strict) == Right(c)\n * }}}\n *\n * '''PatchMode Laws''':\n * {{{\n * // 7. STRICT FAILS ON ERROR\n * // Strict mode fails on first precondition violation\n *\n * // 8. LENIENT SKIPS ERRORS\n * // Lenient mode skips failing operations, always returns Right\n *\n * // 9. LENIENT SUBSUMES STRICT\n * âˆ€ p: JsonPatch, j: Json.\n *   p(j, Strict) == Right(r) implies p(j, Lenient) == Right(r)\n *\n * // 10. CLOBBER FORCES SUCCESS\n * // Clobber mode creates missing paths, always returns Right\n * }}}\n *\n * @param ops The sequence of patch operations\n */\nfinal case class JsonPatch(ops: Vector[JsonPatch.JsonPatchOp]) {\n\n  /**\n   * Applies this patch to a JSON value.\n   *\n   * @param json The JSON value to patch\n   * @param mode The patch mode (default: Strict)\n   * @return Either an error or the patched value\n   */\n  def apply(json: Json, mode: JsonPatchMode = JsonPatchMode.Strict): Either[JsonError, Json]\n\n  /**\n   * Composes this patch with another. Applies this patch first, then `that`.\n   *\n   * This is the monoid `combine` operation.\n   */\n  def ++(that: JsonPatch): JsonPatch = JsonPatch(ops ++ that.ops)\n\n  /**\n   * Returns true if this patch contains no operations.\n   */\n  def isEmpty: Boolean = ops.isEmpty\n\n  /**\n   * Converts this JSON patch to a [[DynamicPatch]].\n   */\n  def toDynamicPatch: DynamicPatch\n}\n\nobject JsonPatch {\n\n  /**\n   * Empty patch â€” the identity element for `++` composition.\n   */\n  val empty: JsonPatch = JsonPatch(Vector.empty)\n\n  /**\n   * Creates a patch with a single operation at the root path.\n   */\n  def root(op: Op): JsonPatch =\n    JsonPatch(Vector(JsonPatchOp(DynamicOptic.root, op)))\n\n  /**\n   * Creates a patch with a single operation at the given path.\n   */\n  def apply(path: DynamicOptic, op: Op): JsonPatch =\n    JsonPatch(Vector(JsonPatchOp(path, op)))\n\n  /**\n   * Computes a patch that transforms `oldJson` into `newJson`.\n   *\n   * Law: `diff(old, new)(old, Strict) == Right(new)`\n   */\n  def diff(oldJson: Json, newJson: Json): JsonPatch\n\n  /**\n   * Creates a JSON patch from a [[DynamicPatch]].\n   *\n   * May fail if the DynamicPatch contains operations not representable in JSON\n   * (e.g., non-string map keys, temporal deltas, variant operations).\n   */\n  def fromDynamicPatch(patch: DynamicPatch): Either[JsonError, JsonPatch]\n\n  // ===========================================================================\n  // JsonPatchOp â€” a single operation at a path\n  // ===========================================================================\n\n  /**\n   * A single patch operation: a path and what to do there.\n   *\n   * Mirrors [[DynamicPatch.DynamicPatchOp]].\n   */\n  final case class JsonPatchOp(path: DynamicOptic, op: Op)\n\n  // ===========================================================================\n  // Op â€” the operation to perform at a path\n  // ===========================================================================\n\n  /**\n   * The operation to perform at a target location.\n   *\n   * Mirrors [[DynamicPatch.Operation]] but specialized for JSON.\n   */\n  sealed trait Op\n\n  object Op {\n\n    /**\n     * Set a value directly (replacement).\n     *\n     * Mirrors [[DynamicPatch.Operation.Set]].\n     */\n    final case class Set(value: Json) extends Op\n\n    /**\n     * Apply a primitive delta operation.\n     *\n     * Used for numeric deltas and string edits.\n     * Mirrors [[DynamicPatch.Operation.PrimitiveDelta]].\n     */\n    final case class PrimitiveDelta(op: PrimitiveOp) extends Op\n\n    /**\n     * Apply array edit operations.\n     *\n     * Used for inserting, appending, deleting, or modifying array elements.\n     * Mirrors [[DynamicPatch.Operation.SequenceEdit]].\n     */\n    final case class ArrayEdit(ops: Vector[ArrayOp]) extends Op\n\n    /**\n     * Apply object edit operations.\n     *\n     * Used for adding, removing, or modifying object fields.\n     * Mirrors [[DynamicPatch.Operation.MapEdit]] but with string keys.\n     */\n    final case class ObjectEdit(ops: Vector[ObjectOp]) extends Op\n\n    /**\n     * Apply a nested patch.\n     *\n     * Used to group operations sharing a common path prefix.\n     * Mirrors [[DynamicPatch.Operation.Patch]].\n     */\n    final case class Nested(patch: JsonPatch) extends Op\n  }\n\n  // ===========================================================================\n  // PrimitiveOp â€” delta operations for JSON primitives\n  // ===========================================================================\n\n  /**\n   * Delta operations for JSON primitive values.\n   *\n   * JSON has only one numeric type, so we use BigDecimal for deltas.\n   * Boolean has no delta (use Set to toggle).\n   * Null has no delta (use Set to change).\n   *\n   * Mirrors [[DynamicPatch.PrimitiveOp]] but simplified for JSON's type system.\n   */\n  sealed trait PrimitiveOp\n\n  object PrimitiveOp {\n\n    /**\n     * Add a delta to a JSON number.\n     *\n     * Applied by: `currentValue + delta`\n     *\n     * Mirrors the numeric delta operations in [[DynamicPatch.PrimitiveOp]]\n     * (IntDelta, LongDelta, DoubleDelta, etc.) unified into one type.\n     */\n    final case class NumberDelta(delta: BigDecimal) extends PrimitiveOp\n\n    /**\n     * Apply string edit operations.\n     *\n     * Mirrors [[DynamicPatch.PrimitiveOp.StringEdit]].\n     */\n    final case class StringEdit(ops: Vector[StringOp]) extends PrimitiveOp\n  }\n\n  // ===========================================================================\n  // StringOp â€” edit operations for strings\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON strings.\n   *\n   * Mirrors [[DynamicPatch.StringOp]] exactly.\n   */\n  sealed trait StringOp\n\n  object StringOp {\n\n    /**\n     * Insert text at the given index.\n     */\n    final case class Insert(index: Int, text: String) extends StringOp\n\n    /**\n     * Delete characters starting at the given index.\n     */\n    final case class Delete(index: Int, length: Int) extends StringOp\n\n    /**\n     * Append text to the end of the string.\n     */\n    final case class Append(text: String) extends StringOp\n\n    /**\n     * Replace characters starting at index with new text.\n     */\n    final case class Modify(index: Int, length: Int, text: String) extends StringOp\n  }\n\n  // ===========================================================================\n  // ArrayOp â€” edit operations for arrays\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON arrays.\n   *\n   * Mirrors [[DynamicPatch.SeqOp]] but with Json values.\n   */\n  sealed trait ArrayOp\n\n  object ArrayOp {\n\n    /**\n     * Insert values at the given index.\n     */\n    final case class Insert(index: Int, values: Vector[Json]) extends ArrayOp\n\n    /**\n     * Append values to the end of the array.\n     */\n    final case class Append(values: Vector[Json]) extends ArrayOp\n\n    /**\n     * Delete elements starting at the given index.\n     */\n    final case class Delete(index: Int, count: Int) extends ArrayOp\n\n    /**\n     * Modify the element at the given index with a nested operation.\n     */\n    final case class Modify(index: Int, op: Op) extends ArrayOp\n  }\n\n  // ===========================================================================\n  // ObjectOp â€” edit operations for objects\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON objects.\n   *\n   * Mirrors [[DynamicPatch.MapOp]] but with string keys (JSON constraint).\n   */\n  sealed trait ObjectOp\n\n  object ObjectOp {\n\n    /**\n     * Add a field to the object.\n     */\n    final case class Add(key: String, value: Json) extends ObjectOp\n\n    /**\n     * Remove a field from the object.\n     */\n    final case class Remove(key: String) extends ObjectOp\n\n    /**\n     * Modify a field's value with a nested patch.\n     */\n    final case class Modify(key: String, patch: JsonPatch) extends ObjectOp\n  }\n}\n\n// =============================================================================\n// PATCH MODE\n// =============================================================================\n\n/**\n * Controls how patch application handles failures.\n *\n * Mirrors [[zio.blocks.schema.patch.PatchMode]].\n */\nsealed trait JsonPatchMode\n\nobject JsonPatchMode {\n\n  /**\n   * Fail on precondition violations.\n   */\n  case object Strict extends JsonPatchMode\n\n  /**\n   * Skip operations that fail preconditions.\n   */\n  case object Lenient extends JsonPatchMode\n\n  /**\n   * Replace/overwrite on conflicts (create missing paths).\n   */\n  case object Clobber extends JsonPatchMode\n}\n\n// =============================================================================\n// USAGE EXAMPLES\n// =============================================================================\n\n/*\n * ==Example 1: Basic Patching==\n *\n * {{{\n * import zio.blocks.schema.json._\n *\n * val json = Json.Object(Vector(\n *   \"name\" -> Json.String(\"Alice\"),\n *   \"age\" -> Json.Number(\"30\")\n * ))\n *\n * // Replace name\n * val patch = JsonPatch.root(JsonPatch.Op.Set(Json.String(\"Bob\")))\n *   // Or at a specific path:\n *   // JsonPatch(DynamicOptic.root.field(\"name\"), JsonPatch.Op.Set(Json.String(\"Bob\")))\n *\n * val result = patch(json, JsonPatchMode.Strict)\n * }}}\n *\n * ==Example 2: Diff and Apply (Roundtrip Law)==\n *\n * {{{\n * val source = Json.Object(Vector(\"x\" -> Json.Number(\"1\")))\n * val target = Json.Object(Vector(\"x\" -> Json.Number(\"5\")))\n *\n * val patch = JsonPatch.diff(source, target)\n *\n * // Roundtrip law\n * assert(patch(source, JsonPatchMode.Strict) == Right(target))\n *\n * // Identity diff law\n * assert(JsonPatch.diff(source, source).isEmpty)\n * }}}\n *\n * ==Example 3: Monoid Laws==\n *\n * {{{\n * val p1 = JsonPatch.diff(a, b)\n * val p2 = JsonPatch.diff(b, c)\n * val p3 = JsonPatch.diff(c, d)\n *\n * // Left identity\n * assert((JsonPatch.empty ++ p1)(a, Strict) == p1(a, Strict))\n *\n * // Right identity\n * assert((p1 ++ JsonPatch.empty)(a, Strict) == p1(a, Strict))\n *\n * // Associativity\n * assert(((p1 ++ p2) ++ p3)(a, Strict) == (p1 ++ (p2 ++ p3))(a, Strict))\n * }}}\n *\n * ==Example 4: Numeric Delta==\n *\n * {{{\n * val json = Json.Number(\"10\")\n *\n * // Add 5 to the number (more efficient than Set for large structures)\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.PrimitiveDelta(JsonPatch.PrimitiveOp.NumberDelta(BigDecimal(5)))\n * )\n *\n * assert(patch(json, Strict) == Right(Json.Number(\"15\")))\n * }}}\n *\n * ==Example 5: String Edit==\n *\n * {{{\n * val json = Json.String(\"hello world\")\n *\n * // Change \"hello\" to \"hi\" using LCS-based edits\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.PrimitiveDelta(\n *     JsonPatch.PrimitiveOp.StringEdit(Vector(\n *       JsonPatch.StringOp.Delete(0, 5),\n *       JsonPatch.StringOp.Insert(0, \"hi\")\n *     ))\n *   )\n * )\n *\n * assert(patch(json, Strict) == Right(Json.String(\"hi world\")))\n * }}}\n *\n * ==Example 6: Array Edit==\n *\n * {{{\n * val json = Json.Array(Vector(Json.Number(\"1\"), Json.Number(\"2\"), Json.Number(\"3\")))\n *\n * // Delete element at index 1, append new element\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ArrayEdit(Vector(\n *     JsonPatch.ArrayOp.Delete(1, 1),\n *     JsonPatch.ArrayOp.Append(Vector(Json.Number(\"4\")))\n *   ))\n * )\n *\n * // Result: [1, 3, 4]\n * }}}\n *\n * ==Example 7: Object Edit==\n *\n * {{{\n * val json = Json.Object(Vector(\"a\" -> Json.Number(\"1\"), \"b\" -> Json.Number(\"2\")))\n *\n * // Remove field \"a\", add field \"c\"\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ObjectEdit(Vector(\n *     JsonPatch.ObjectOp.Remove(\"a\"),\n *     JsonPatch.ObjectOp.Add(\"c\", Json.Number(\"3\"))\n *   ))\n * )\n *\n * // Result: {\"b\": 2, \"c\": 3}\n * }}}\n *\n * ==Example 8: Nested Patch==\n *\n * {{{\n * val json = Json.Object(Vector(\n *   \"user\" -> Json.Object(Vector(\n *     \"name\" -> Json.String(\"Alice\"),\n *     \"age\" -> Json.Number(\"30\")\n *   ))\n * ))\n *\n * // Patch nested inside \"user\"\n * val innerPatch = JsonPatch(Vector(\n *   JsonPatch.JsonPatchOp(\n *     DynamicOptic.root.field(\"age\"),\n *     JsonPatch.Op.PrimitiveDelta(JsonPatch.PrimitiveOp.NumberDelta(BigDecimal(1)))\n *   )\n * ))\n *\n * val patch = JsonPatch(\n *   DynamicOptic.root.field(\"user\"),\n *   JsonPatch.Op.Nested(innerPatch)\n * )\n *\n * // Increments user.age by 1\n * }}}\n *\n * ==Example 9: Diff Composition Law==\n *\n * {{{\n * val a = Json.Number(\"1\")\n * val b = Json.Number(\"5\")\n * val c = Json.Number(\"10\")\n *\n * val p1 = JsonPatch.diff(a, b)  // delta +4\n * val p2 = JsonPatch.diff(b, c)  // delta +5\n *\n * // Composition law: applying composed patch equals applying sequentially\n * assert((p1 ++ p2)(a, Strict) == Right(c))\n * }}}\n *\n * ==Example 10: PatchMode Behavior==\n *\n * {{{\n * val json = Json.Object(Vector(\"a\" -> Json.Number(\"1\")))\n *\n * // Try to remove non-existent field\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ObjectEdit(Vector(JsonPatch.ObjectOp.Remove(\"nonexistent\")))\n * )\n *\n * // Strict: fails\n * assert(patch(json, JsonPatchMode.Strict).isLeft)\n *\n * // Lenient: skips, returns unchanged\n * assert(patch(json, JsonPatchMode.Lenient) == Right(json))\n *\n * // Clobber: skips (nothing to clobber), returns unchanged\n * assert(patch(json, JsonPatchMode.Clobber) == Right(json))\n * }}}\n */\n```",
                  "html_url": "https://github.com/zio/zio-blocks/issues/685"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#685",
              "body": "<html><head></head><body><h1>Add <code>JsonPatch</code> type for diffing and patching JSON values</h1>\n<h2>Summary</h2>\n<p>Implement a <code>JsonPatch</code> type that enables computing diffs between JSON values and applying patches to transform one JSON value into another. This type should mirror the existing <code>DynamicPatch</code> implementation, adapted for JSON's simpler data model.</p>\n<h2>Motivation</h2>\n<p><code>DynamicValue</code> has a well-designed <code>DynamicPatch</code> system with:</p>\n<ul>\n<li>Monoid composition (<code>++</code> with <code>empty</code> identity)</li>\n<li>LCS-based sequence diffing</li>\n<li>Primitive delta operations (numeric deltas, string edits)</li>\n<li>Comprehensive algebraic laws verified by property tests</li>\n</ul>\n<p>The proposed <code>Json</code> type (see #TBD) needs equivalent patching capabilities. Rather than converting <code>Json â†” DynamicValue</code> for every patch operation, a native <code>JsonPatch</code> provides:</p>\n<ul>\n<li>Type safety (no conversion errors for JSON-incompatible DynamicPatch operations)</li>\n<li>API consistency with the <code>Json</code> type</li>\n<li>Potential for JSON-specific optimizations</li>\n</ul>\n<h2>Design Sketch</h2>\n<p>A design sketch is available at <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala</code></a>. This sketch is <strong>a guide, not a specification</strong> â€” implementers should use judgment and deviate where appropriate.</p>\n<h3>Core Types</h3>\n<p>The design mirrors <code>DynamicPatch</code> with JSON-specific adaptations:</p>\n\nDynamicPatch | JsonPatch | Notes\n-- | -- | --\nDynamicPatch(Vector[DynamicPatchOp]) | JsonPatch(Vector[JsonPatchOp]) | Same structure\nOperation.Set | Op.Set | Same\nOperation.PrimitiveDelta | Op.PrimitiveDelta | Simplified for JSON types\nOperation.SequenceEdit | Op.ArrayEdit | Renamed\nOperation.MapEdit | Op.ObjectEdit | String keys only\nOperation.Patch | Op.Nested | Same\nSeqOp | ArrayOp | Same operations\nMapOp | ObjectOp | String keys only\nPrimitiveOp (14 variants) | PrimitiveOp (2 variants) | See below\n\n\n<h3>StringOp</h3>\n<p>Mirror <code>DynamicPatch.StringOp</code> exactly:</p>\n<ul>\n<li><code>Insert(index: Int, text: String)</code></li>\n<li><code>Delete(index: Int, length: Int)</code></li>\n<li><code>Append(text: String)</code></li>\n<li><code>Modify(index: Int, length: Int, text: String)</code></li>\n</ul>\n<h3>ArrayOp</h3>\n<p>Mirror <code>DynamicPatch.SeqOp</code>:</p>\n<ul>\n<li><code>Insert(index: Int, values: Vector[Json])</code></li>\n<li><code>Append(values: Vector[Json])</code></li>\n<li><code>Delete(index: Int, count: Int)</code></li>\n<li><code>Modify(index: Int, op: Op)</code></li>\n</ul>\n<h3>ObjectOp</h3>\n<p>Mirror <code>DynamicPatch.MapOp</code> with string keys:</p>\n<ul>\n<li><code>Add(key: String, value: Json)</code></li>\n<li><code>Remove(key: String)</code></li>\n<li><code>Modify(key: String, patch: JsonPatch)</code></li>\n</ul>\n<h2>Requirements</h2>\n<h3>Functional Requirements</h3>\n<ul>\n<li>[ ] <strong>F1</strong>: <code>JsonPatch.diff(source, target)</code> computes a patch transforming source to target</li>\n<li>[ ] <strong>F2</strong>: <code>patch.apply(json, mode)</code> applies a patch with configurable failure handling</li>\n<li>[ ] <strong>F3</strong>: <code>patch1 ++ patch2</code> composes patches (apply first, then second)</li>\n<li>[ ] <strong>F4</strong>: <code>JsonPatch.empty</code> is the identity element for composition</li>\n<li>[ ] <strong>F5</strong>: Support <code>JsonPatchMode.Strict</code>, <code>Lenient</code>, and <code>Clobber</code> modes</li>\n<li>[ ] <strong>F6</strong>: Bidirectional conversion: <code>toDynamicPatch</code> / <code>fromDynamicPatch</code></li>\n</ul>\n<h3>Algebraic Laws</h3>\n<p>All laws must be verified with property-based tests (see <code>PatchLawsSpec</code> for reference):</p>\n<ul>\n<li>[ ] <strong>L1</strong>: Left identity â€” <code>(empty ++ p)(j) == p(j)</code></li>\n<li>[ ] <strong>L2</strong>: Right identity â€” <code>(p ++ empty)(j) == p(j)</code></li>\n<li>[ ] <strong>L3</strong>: Associativity â€” <code>((p1 ++ p2) ++ p3)(j) == (p1 ++ (p2 ++ p3))(j)</code></li>\n<li>[ ] <strong>L4</strong>: Roundtrip â€” <code>diff(a, b)(a) == Right(b)</code></li>\n<li>[ ] <strong>L5</strong>: Identity diff â€” <code>diff(j, j).isEmpty</code></li>\n<li>[ ] <strong>L6</strong>: Diff composition â€” <code>(diff(a, b) ++ diff(b, c))(a) == Right(c)</code></li>\n<li>[ ] <strong>L7</strong>: Lenient subsumes Strict â€” if <code>p(j, Strict) == Right(r)</code> then <code>p(j, Lenient) == Right(r)</code></li>\n</ul>\n<h3>Testing Requirements</h3>\n<ul>\n<li>[ ] <strong>T1</strong>: Property-based tests for all algebraic laws (see <code>PatchLawsSpec</code>)</li>\n<li>[ ] <strong>T2</strong>: Test each operation type (<code>Set</code>, <code>PrimitiveDelta</code>, <code>ArrayEdit</code>, <code>ObjectEdit</code>, <code>Nested</code>)</li>\n<li>[ ] <strong>T3</strong>: Test each <code>ArrayOp</code> variant (<code>Insert</code>, <code>Append</code>, <code>Delete</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T4</strong>: Test each <code>ObjectOp</code> variant (<code>Add</code>, <code>Remove</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T5</strong>: Test each <code>StringOp</code> variant (<code>Insert</code>, <code>Delete</code>, <code>Append</code>, <code>Modify</code>)</li>\n<li>[ ] <strong>T6</strong>: Test <code>NumberDelta</code> with positive, negative, zero, and decimal deltas</li>\n<li>[ ] <strong>T7</strong>: Test all three <code>JsonPatchMode</code> behaviors</li>\n<li>[ ] <strong>T8</strong>: Test <code>toDynamicPatch</code> / <code>fromDynamicPatch</code> roundtrip</li>\n<li>[ ] <strong>T9</strong>: Test edge cases: empty arrays, empty objects, empty strings, nested structures</li>\n<li>[ ] <strong>T10</strong>: Test error cases: invalid paths, type mismatches, out-of-bounds indices</li>\n</ul>\n<h3>Documentation Requirements</h3>\n<ul>\n<li>[ ] <strong>D1</strong>: ScalaDoc for all public types and methods</li>\n<li>[ ] <strong>D2</strong>: Usage examples in ScalaDoc (see sketch for examples)</li>\n<li>[ ] <strong>D3</strong>: Document algebraic laws in type-level comments</li>\n<li>[ ] <strong>D4</strong>: Document relationship to <code>DynamicPatch</code></li>\n</ul>\n<h3>Implementation Notes</h3>\n<ol>\n<li>\n<p><strong>Follow <code>DynamicPatch</code> patterns</strong>: The implementation in <code>DynamicPatch.scala</code> is the reference. Study <code>Differ.scala</code> for diff algorithms (especially LCS for sequences and strings).</p>\n</li>\n<li>\n<p><strong>Reuse algorithms where possible</strong>: Consider whether <code>JsonPatch</code> can delegate to <code>DynamicPatch</code> internally, or share algorithm implementations.</p>\n</li>\n<li>\n<p><strong>Keep it minimal</strong>: Resist adding operations not present in <code>DynamicPatch</code>. The design is intentionally minimal and principled.</p>\n</li>\n<li>\n<p><strong>Performance considerations</strong>: The register-based design of ZIO Blocks prioritizes performance. Avoid unnecessary allocations in hot paths.</p>\n</li>\n</ol>\n<h2>Out of Scope</h2>\n<p>The following are explicitly <strong>not</strong> part of this issue:</p>\n<ul>\n<li>RFC 6902 JSON Patch serialization format (separate issue)</li>\n<li>Patch inversion / undo support (separate issue)</li>\n<li>Patch optimization / compaction (separate issue)</li>\n<li>Integration with <code>Json</code> type methods like <code>json.diff(other)</code> (depends on <code>Json</code> implementation)</li>\n</ul>\n<h2>Related</h2>\n<ul>\n<li><code>DynamicPatch</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala</code></a></li>\n<li><code>Differ</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala</code></a></li>\n<li><code>PatchLawsSpec</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala\"><code>schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala</code></a></li>\n<li><code>PatchMode</code> â€” <a href=\"https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala\"><code>schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala</code></a></li>\n</ul>\n<h2>Acceptance Criteria</h2>\n<ul>\n<li>[ ] All functional requirements (F1-F6) implemented</li>\n<li>[ ] All algebraic laws (L1-L7) pass property-based tests</li>\n<li>[ ] All testing requirements (T1-T10) have corresponding test cases</li>\n<li>[ ] All documentation requirements (D1-D4) complete</li>\n<li>[ ] Code reviewed and approved</li>\n<li>[ ] CI passing</li>\n</ul></body></html># Add `JsonPatch` type for diffing and patching JSON values\n\n## Summary\n\nImplement a `JsonPatch` type that enables computing diffs between JSON values and applying patches to transform one JSON value into another. This type should mirror the existing `DynamicPatch` implementation, adapted for JSON's simpler data model.\n\n## Motivation\n\n`DynamicValue` has a well-designed `DynamicPatch` system with:\n- Monoid composition (`++` with `empty` identity)\n- LCS-based sequence diffing\n- Primitive delta operations (numeric deltas, string edits)\n- Comprehensive algebraic laws verified by property tests\n\nThe proposed `Json` type (see #TBD) needs equivalent patching capabilities. Rather than converting `Json â†” DynamicValue` for every patch operation, a native `JsonPatch` provides:\n- Type safety (no conversion errors for JSON-incompatible DynamicPatch operations)\n- API consistency with the `Json` type\n- Potential for JSON-specific optimizations\n\n## Design Sketch\n\nA design sketch is available at [`[schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/json/JsonPatch.scala). This sketch is **a guide, not a specification** â€” implementers should use judgment and deviate where appropriate.\n\n### Core Types\n\nThe design mirrors `DynamicPatch` with JSON-specific adaptations:\n\n| DynamicPatch | JsonPatch | Notes |\n|--------------|-----------|-------|\n| `DynamicPatch(Vector[DynamicPatchOp])` | `JsonPatch(Vector[JsonPatchOp])` | Same structure |\n| `Operation.Set` | `Op.Set` | Same |\n| `Operation.PrimitiveDelta` | `Op.PrimitiveDelta` | Simplified for JSON types |\n| `Operation.SequenceEdit` | `Op.ArrayEdit` | Renamed |\n| `Operation.MapEdit` | `Op.ObjectEdit` | String keys only |\n| `Operation.Patch` | `Op.Nested` | Same |\n| `SeqOp` | `ArrayOp` | Same operations |\n| `MapOp` | `ObjectOp` | String keys only |\n| `PrimitiveOp` (14 variants) | `PrimitiveOp` (2 variants) | See below |\n\n### Primitive Operations\n\nJSON has a simpler type system than `DynamicValue`:\n\n| JSON Type | Delta Operation | Notes |\n|-----------|-----------------|-------|\n| Number | `NumberDelta(BigDecimal)` | Unifies all numeric deltas |\n| String | `StringEdit(Vector[StringOp])` | Same as `DynamicPatch` |\n| Boolean | Use `Op.Set` | No delta (same as `DynamicPatch`) |\n| Null | Use `Op.Set` | No delta |\n\n### StringOp\n\nMirror `DynamicPatch.StringOp` exactly:\n- `Insert(index: Int, text: String)`\n- `Delete(index: Int, length: Int)`\n- `Append(text: String)`\n- `Modify(index: Int, length: Int, text: String)`\n\n### ArrayOp\n\nMirror `DynamicPatch.SeqOp`:\n- `Insert(index: Int, values: Vector[Json])`\n- `Append(values: Vector[Json])`\n- `Delete(index: Int, count: Int)`\n- `Modify(index: Int, op: Op)`\n\n### ObjectOp\n\nMirror `DynamicPatch.MapOp` with string keys:\n- `Add(key: String, value: Json)`\n- `Remove(key: String)`\n- `Modify(key: String, patch: JsonPatch)`\n\n## Requirements\n\n### Functional Requirements\n\n- [ ] **F1**: `JsonPatch.diff(source, target)` computes a patch transforming source to target\n- [ ] **F2**: `patch.apply(json, mode)` applies a patch with configurable failure handling\n- [ ] **F3**: `patch1 ++ patch2` composes patches (apply first, then second)\n- [ ] **F4**: `JsonPatch.empty` is the identity element for composition\n- [ ] **F5**: Support `JsonPatchMode.Strict`, `Lenient`, and `Clobber` modes\n- [ ] **F6**: Bidirectional conversion: `toDynamicPatch` / `fromDynamicPatch`\n\n### Algebraic Laws\n\nAll laws must be verified with property-based tests (see `PatchLawsSpec` for reference):\n\n- [ ] **L1**: Left identity â€” `(empty ++ p)(j) == p(j)`\n- [ ] **L2**: Right identity â€” `(p ++ empty)(j) == p(j)`\n- [ ] **L3**: Associativity â€” `((p1 ++ p2) ++ p3)(j) == (p1 ++ (p2 ++ p3))(j)`\n- [ ] **L4**: Roundtrip â€” `diff(a, b)(a) == Right(b)`\n- [ ] **L5**: Identity diff â€” `diff(j, j).isEmpty`\n- [ ] **L6**: Diff composition â€” `(diff(a, b) ++ diff(b, c))(a) == Right(c)`\n- [ ] **L7**: Lenient subsumes Strict â€” if `p(j, Strict) == Right(r)` then `p(j, Lenient) == Right(r)`\n\n### Testing Requirements\n\n- [ ] **T1**: Property-based tests for all algebraic laws (see `PatchLawsSpec`)\n- [ ] **T2**: Test each operation type (`Set`, `PrimitiveDelta`, `ArrayEdit`, `ObjectEdit`, `Nested`)\n- [ ] **T3**: Test each `ArrayOp` variant (`Insert`, `Append`, `Delete`, `Modify`)\n- [ ] **T4**: Test each `ObjectOp` variant (`Add`, `Remove`, `Modify`)\n- [ ] **T5**: Test each `StringOp` variant (`Insert`, `Delete`, `Append`, `Modify`)\n- [ ] **T6**: Test `NumberDelta` with positive, negative, zero, and decimal deltas\n- [ ] **T7**: Test all three `JsonPatchMode` behaviors\n- [ ] **T8**: Test `toDynamicPatch` / `fromDynamicPatch` roundtrip\n- [ ] **T9**: Test edge cases: empty arrays, empty objects, empty strings, nested structures\n- [ ] **T10**: Test error cases: invalid paths, type mismatches, out-of-bounds indices\n\n### Documentation Requirements\n\n- [ ] **D1**: ScalaDoc for all public types and methods\n- [ ] **D2**: Usage examples in ScalaDoc (see sketch for examples)\n- [ ] **D3**: Document algebraic laws in type-level comments\n- [ ] **D4**: Document relationship to `DynamicPatch`\n\n## Related\n\n- `DynamicPatch` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/DynamicPatch.scala)\n- `Differ` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/Differ.scala)\n- `PatchLawsSpec` â€” [`[schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala](https://claude.ai/chat/schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala)`](./schema/shared/src/test/scala/zio/blocks/schema/patch/PatchLawsSpec.scala)\n- `PatchMode` â€” [`[schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala](https://claude.ai/chat/schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala)`](./schema/shared/src/main/scala/zio/blocks/schema/patch/PatchMode.scala)\n\n## Acceptance Criteria\n\n- [ ] All functional requirements (F1-F6) implemented\n- [ ] All algebraic laws (L1-L7) pass property-based tests\n- [ ] All testing requirements (T1-T10) have corresponding test cases\n- [ ] All documentation requirements (D1-D4) complete\n- [ ] Code reviewed and approved\n- [ ] CI passing\n\n# Sketch\n\n```scala\npackage zio.blocks.schema.json\n\nimport zio.blocks.schema.DynamicOptic\nimport zio.blocks.schema.patch.DynamicPatch\n\n// =============================================================================\n// JSON PATCH\n// =============================================================================\n\n/**\n * An untyped patch that operates on [[Json]] values.\n *\n * `JsonPatch` is the JSON-specific counterpart to [[DynamicPatch]]. It represents\n * a sequence of operations that transform one JSON value into another. Patches\n * are serializable and composable.\n *\n * ==Design==\n *\n * This type directly mirrors [[DynamicPatch]] but is specialized for JSON's\n * simpler data model:\n *  - JSON has 4 leaf types (String, Number, Boolean, Null) vs 30 PrimitiveValues\n *  - JSON objects have string keys only (no arbitrary-keyed maps)\n *  - JSON has no native Variant type\n *\n * ==Algebraic Laws==\n *\n * '''Monoid Laws''' (under `++` composition):\n * {{{\n * // 1. LEFT IDENTITY\n * âˆ€ p: JsonPatch, j: Json.\n *   (JsonPatch.empty ++ p)(j, mode) == p(j, mode)\n *\n * // 2. RIGHT IDENTITY\n * âˆ€ p: JsonPatch, j: Json.\n *   (p ++ JsonPatch.empty)(j, mode) == p(j, mode)\n *\n * // 3. ASSOCIATIVITY\n * âˆ€ p1, p2, p3: JsonPatch, j: Json.\n *   ((p1 ++ p2) ++ p3)(j, mode) == (p1 ++ (p2 ++ p3))(j, mode)\n * }}}\n *\n * '''Diff/Apply Laws''':\n * {{{\n * // 4. ROUNDTRIP\n * âˆ€ source, target: Json.\n *   JsonPatch.diff(source, target)(source, Strict) == Right(target)\n *\n * // 5. IDENTITY DIFF\n * âˆ€ j: Json.\n *   JsonPatch.diff(j, j).isEmpty == true\n *\n * // 6. DIFF COMPOSITION\n * âˆ€ a, b, c: Json.\n *   (JsonPatch.diff(a, b) ++ JsonPatch.diff(b, c))(a, Strict) == Right(c)\n * }}}\n *\n * '''PatchMode Laws''':\n * {{{\n * // 7. STRICT FAILS ON ERROR\n * // Strict mode fails on first precondition violation\n *\n * // 8. LENIENT SKIPS ERRORS\n * // Lenient mode skips failing operations, always returns Right\n *\n * // 9. LENIENT SUBSUMES STRICT\n * âˆ€ p: JsonPatch, j: Json.\n *   p(j, Strict) == Right(r) implies p(j, Lenient) == Right(r)\n *\n * // 10. CLOBBER FORCES SUCCESS\n * // Clobber mode creates missing paths, always returns Right\n * }}}\n *\n * @param ops The sequence of patch operations\n */\nfinal case class JsonPatch(ops: Vector[JsonPatch.JsonPatchOp]) {\n\n  /**\n   * Applies this patch to a JSON value.\n   *\n   * @param json The JSON value to patch\n   * @param mode The patch mode (default: Strict)\n   * @return Either an error or the patched value\n   */\n  def apply(json: Json, mode: JsonPatchMode = JsonPatchMode.Strict): Either[JsonError, Json]\n\n  /**\n   * Composes this patch with another. Applies this patch first, then `that`.\n   *\n   * This is the monoid `combine` operation.\n   */\n  def ++(that: JsonPatch): JsonPatch = JsonPatch(ops ++ that.ops)\n\n  /**\n   * Returns true if this patch contains no operations.\n   */\n  def isEmpty: Boolean = ops.isEmpty\n\n  /**\n   * Converts this JSON patch to a [[DynamicPatch]].\n   */\n  def toDynamicPatch: DynamicPatch\n}\n\nobject JsonPatch {\n\n  /**\n   * Empty patch â€” the identity element for `++` composition.\n   */\n  val empty: JsonPatch = JsonPatch(Vector.empty)\n\n  /**\n   * Creates a patch with a single operation at the root path.\n   */\n  def root(op: Op): JsonPatch =\n    JsonPatch(Vector(JsonPatchOp(DynamicOptic.root, op)))\n\n  /**\n   * Creates a patch with a single operation at the given path.\n   */\n  def apply(path: DynamicOptic, op: Op): JsonPatch =\n    JsonPatch(Vector(JsonPatchOp(path, op)))\n\n  /**\n   * Computes a patch that transforms `oldJson` into `newJson`.\n   *\n   * Law: `diff(old, new)(old, Strict) == Right(new)`\n   */\n  def diff(oldJson: Json, newJson: Json): JsonPatch\n\n  /**\n   * Creates a JSON patch from a [[DynamicPatch]].\n   *\n   * May fail if the DynamicPatch contains operations not representable in JSON\n   * (e.g., non-string map keys, temporal deltas, variant operations).\n   */\n  def fromDynamicPatch(patch: DynamicPatch): Either[JsonError, JsonPatch]\n\n  // ===========================================================================\n  // JsonPatchOp â€” a single operation at a path\n  // ===========================================================================\n\n  /**\n   * A single patch operation: a path and what to do there.\n   *\n   * Mirrors [[DynamicPatch.DynamicPatchOp]].\n   */\n  final case class JsonPatchOp(path: DynamicOptic, op: Op)\n\n  // ===========================================================================\n  // Op â€” the operation to perform at a path\n  // ===========================================================================\n\n  /**\n   * The operation to perform at a target location.\n   *\n   * Mirrors [[DynamicPatch.Operation]] but specialized for JSON.\n   */\n  sealed trait Op\n\n  object Op {\n\n    /**\n     * Set a value directly (replacement).\n     *\n     * Mirrors [[DynamicPatch.Operation.Set]].\n     */\n    final case class Set(value: Json) extends Op\n\n    /**\n     * Apply a primitive delta operation.\n     *\n     * Used for numeric deltas and string edits.\n     * Mirrors [[DynamicPatch.Operation.PrimitiveDelta]].\n     */\n    final case class PrimitiveDelta(op: PrimitiveOp) extends Op\n\n    /**\n     * Apply array edit operations.\n     *\n     * Used for inserting, appending, deleting, or modifying array elements.\n     * Mirrors [[DynamicPatch.Operation.SequenceEdit]].\n     */\n    final case class ArrayEdit(ops: Vector[ArrayOp]) extends Op\n\n    /**\n     * Apply object edit operations.\n     *\n     * Used for adding, removing, or modifying object fields.\n     * Mirrors [[DynamicPatch.Operation.MapEdit]] but with string keys.\n     */\n    final case class ObjectEdit(ops: Vector[ObjectOp]) extends Op\n\n    /**\n     * Apply a nested patch.\n     *\n     * Used to group operations sharing a common path prefix.\n     * Mirrors [[DynamicPatch.Operation.Patch]].\n     */\n    final case class Nested(patch: JsonPatch) extends Op\n  }\n\n  // ===========================================================================\n  // PrimitiveOp â€” delta operations for JSON primitives\n  // ===========================================================================\n\n  /**\n   * Delta operations for JSON primitive values.\n   *\n   * JSON has only one numeric type, so we use BigDecimal for deltas.\n   * Boolean has no delta (use Set to toggle).\n   * Null has no delta (use Set to change).\n   *\n   * Mirrors [[DynamicPatch.PrimitiveOp]] but simplified for JSON's type system.\n   */\n  sealed trait PrimitiveOp\n\n  object PrimitiveOp {\n\n    /**\n     * Add a delta to a JSON number.\n     *\n     * Applied by: `currentValue + delta`\n     *\n     * Mirrors the numeric delta operations in [[DynamicPatch.PrimitiveOp]]\n     * (IntDelta, LongDelta, DoubleDelta, etc.) unified into one type.\n     */\n    final case class NumberDelta(delta: BigDecimal) extends PrimitiveOp\n\n    /**\n     * Apply string edit operations.\n     *\n     * Mirrors [[DynamicPatch.PrimitiveOp.StringEdit]].\n     */\n    final case class StringEdit(ops: Vector[StringOp]) extends PrimitiveOp\n  }\n\n  // ===========================================================================\n  // StringOp â€” edit operations for strings\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON strings.\n   *\n   * Mirrors [[DynamicPatch.StringOp]] exactly.\n   */\n  sealed trait StringOp\n\n  object StringOp {\n\n    /**\n     * Insert text at the given index.\n     */\n    final case class Insert(index: Int, text: String) extends StringOp\n\n    /**\n     * Delete characters starting at the given index.\n     */\n    final case class Delete(index: Int, length: Int) extends StringOp\n\n    /**\n     * Append text to the end of the string.\n     */\n    final case class Append(text: String) extends StringOp\n\n    /**\n     * Replace characters starting at index with new text.\n     */\n    final case class Modify(index: Int, length: Int, text: String) extends StringOp\n  }\n\n  // ===========================================================================\n  // ArrayOp â€” edit operations for arrays\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON arrays.\n   *\n   * Mirrors [[DynamicPatch.SeqOp]] but with Json values.\n   */\n  sealed trait ArrayOp\n\n  object ArrayOp {\n\n    /**\n     * Insert values at the given index.\n     */\n    final case class Insert(index: Int, values: Vector[Json]) extends ArrayOp\n\n    /**\n     * Append values to the end of the array.\n     */\n    final case class Append(values: Vector[Json]) extends ArrayOp\n\n    /**\n     * Delete elements starting at the given index.\n     */\n    final case class Delete(index: Int, count: Int) extends ArrayOp\n\n    /**\n     * Modify the element at the given index with a nested operation.\n     */\n    final case class Modify(index: Int, op: Op) extends ArrayOp\n  }\n\n  // ===========================================================================\n  // ObjectOp â€” edit operations for objects\n  // ===========================================================================\n\n  /**\n   * Edit operations for JSON objects.\n   *\n   * Mirrors [[DynamicPatch.MapOp]] but with string keys (JSON constraint).\n   */\n  sealed trait ObjectOp\n\n  object ObjectOp {\n\n    /**\n     * Add a field to the object.\n     */\n    final case class Add(key: String, value: Json) extends ObjectOp\n\n    /**\n     * Remove a field from the object.\n     */\n    final case class Remove(key: String) extends ObjectOp\n\n    /**\n     * Modify a field's value with a nested patch.\n     */\n    final case class Modify(key: String, patch: JsonPatch) extends ObjectOp\n  }\n}\n\n// =============================================================================\n// PATCH MODE\n// =============================================================================\n\n/**\n * Controls how patch application handles failures.\n *\n * Mirrors [[zio.blocks.schema.patch.PatchMode]].\n */\nsealed trait JsonPatchMode\n\nobject JsonPatchMode {\n\n  /**\n   * Fail on precondition violations.\n   */\n  case object Strict extends JsonPatchMode\n\n  /**\n   * Skip operations that fail preconditions.\n   */\n  case object Lenient extends JsonPatchMode\n\n  /**\n   * Replace/overwrite on conflicts (create missing paths).\n   */\n  case object Clobber extends JsonPatchMode\n}\n\n// =============================================================================\n// USAGE EXAMPLES\n// =============================================================================\n\n/*\n * ==Example 1: Basic Patching==\n *\n * {{{\n * import zio.blocks.schema.json._\n *\n * val json = Json.Object(Vector(\n *   \"name\" -> Json.String(\"Alice\"),\n *   \"age\" -> Json.Number(\"30\")\n * ))\n *\n * // Replace name\n * val patch = JsonPatch.root(JsonPatch.Op.Set(Json.String(\"Bob\")))\n *   // Or at a specific path:\n *   // JsonPatch(DynamicOptic.root.field(\"name\"), JsonPatch.Op.Set(Json.String(\"Bob\")))\n *\n * val result = patch(json, JsonPatchMode.Strict)\n * }}}\n *\n * ==Example 2: Diff and Apply (Roundtrip Law)==\n *\n * {{{\n * val source = Json.Object(Vector(\"x\" -> Json.Number(\"1\")))\n * val target = Json.Object(Vector(\"x\" -> Json.Number(\"5\")))\n *\n * val patch = JsonPatch.diff(source, target)\n *\n * // Roundtrip law\n * assert(patch(source, JsonPatchMode.Strict) == Right(target))\n *\n * // Identity diff law\n * assert(JsonPatch.diff(source, source).isEmpty)\n * }}}\n *\n * ==Example 3: Monoid Laws==\n *\n * {{{\n * val p1 = JsonPatch.diff(a, b)\n * val p2 = JsonPatch.diff(b, c)\n * val p3 = JsonPatch.diff(c, d)\n *\n * // Left identity\n * assert((JsonPatch.empty ++ p1)(a, Strict) == p1(a, Strict))\n *\n * // Right identity\n * assert((p1 ++ JsonPatch.empty)(a, Strict) == p1(a, Strict))\n *\n * // Associativity\n * assert(((p1 ++ p2) ++ p3)(a, Strict) == (p1 ++ (p2 ++ p3))(a, Strict))\n * }}}\n *\n * ==Example 4: Numeric Delta==\n *\n * {{{\n * val json = Json.Number(\"10\")\n *\n * // Add 5 to the number (more efficient than Set for large structures)\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.PrimitiveDelta(JsonPatch.PrimitiveOp.NumberDelta(BigDecimal(5)))\n * )\n *\n * assert(patch(json, Strict) == Right(Json.Number(\"15\")))\n * }}}\n *\n * ==Example 5: String Edit==\n *\n * {{{\n * val json = Json.String(\"hello world\")\n *\n * // Change \"hello\" to \"hi\" using LCS-based edits\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.PrimitiveDelta(\n *     JsonPatch.PrimitiveOp.StringEdit(Vector(\n *       JsonPatch.StringOp.Delete(0, 5),\n *       JsonPatch.StringOp.Insert(0, \"hi\")\n *     ))\n *   )\n * )\n *\n * assert(patch(json, Strict) == Right(Json.String(\"hi world\")))\n * }}}\n *\n * ==Example 6: Array Edit==\n *\n * {{{\n * val json = Json.Array(Vector(Json.Number(\"1\"), Json.Number(\"2\"), Json.Number(\"3\")))\n *\n * // Delete element at index 1, append new element\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ArrayEdit(Vector(\n *     JsonPatch.ArrayOp.Delete(1, 1),\n *     JsonPatch.ArrayOp.Append(Vector(Json.Number(\"4\")))\n *   ))\n * )\n *\n * // Result: [1, 3, 4]\n * }}}\n *\n * ==Example 7: Object Edit==\n *\n * {{{\n * val json = Json.Object(Vector(\"a\" -> Json.Number(\"1\"), \"b\" -> Json.Number(\"2\")))\n *\n * // Remove field \"a\", add field \"c\"\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ObjectEdit(Vector(\n *     JsonPatch.ObjectOp.Remove(\"a\"),\n *     JsonPatch.ObjectOp.Add(\"c\", Json.Number(\"3\"))\n *   ))\n * )\n *\n * // Result: {\"b\": 2, \"c\": 3}\n * }}}\n *\n * ==Example 8: Nested Patch==\n *\n * {{{\n * val json = Json.Object(Vector(\n *   \"user\" -> Json.Object(Vector(\n *     \"name\" -> Json.String(\"Alice\"),\n *     \"age\" -> Json.Number(\"30\")\n *   ))\n * ))\n *\n * // Patch nested inside \"user\"\n * val innerPatch = JsonPatch(Vector(\n *   JsonPatch.JsonPatchOp(\n *     DynamicOptic.root.field(\"age\"),\n *     JsonPatch.Op.PrimitiveDelta(JsonPatch.PrimitiveOp.NumberDelta(BigDecimal(1)))\n *   )\n * ))\n *\n * val patch = JsonPatch(\n *   DynamicOptic.root.field(\"user\"),\n *   JsonPatch.Op.Nested(innerPatch)\n * )\n *\n * // Increments user.age by 1\n * }}}\n *\n * ==Example 9: Diff Composition Law==\n *\n * {{{\n * val a = Json.Number(\"1\")\n * val b = Json.Number(\"5\")\n * val c = Json.Number(\"10\")\n *\n * val p1 = JsonPatch.diff(a, b)  // delta +4\n * val p2 = JsonPatch.diff(b, c)  // delta +5\n *\n * // Composition law: applying composed patch equals applying sequentially\n * assert((p1 ++ p2)(a, Strict) == Right(c))\n * }}}\n *\n * ==Example 10: PatchMode Behavior==\n *\n * {{{\n * val json = Json.Object(Vector(\"a\" -> Json.Number(\"1\")))\n *\n * // Try to remove non-existent field\n * val patch = JsonPatch.root(\n *   JsonPatch.Op.ObjectEdit(Vector(JsonPatch.ObjectOp.Remove(\"nonexistent\")))\n * )\n *\n * // Strict: fails\n * assert(patch(json, JsonPatchMode.Strict).isLeft)\n *\n * // Lenient: skips, returns unchanged\n * assert(patch(json, JsonPatchMode.Lenient) == Right(json))\n *\n * // Clobber: skips (nothing to clobber), returns unchanged\n * assert(patch(json, JsonPatchMode.Clobber) == Right(json))\n * }}}\n */\n```",
              "url": "https://github.com/zio/zio-blocks/issues/685",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#519",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-31T09:51:26.516Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:26.516Z",
            "created_at": "2026-01-31T09:51:26.516Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#519",
              "status": "open",
              "type": "issue",
              "number": 519,
              "title": "Schema Migration System for ZIO Schema 2",
              "source": {
                "data": {
                  "id": "source-ZIO#519",
                  "user": {
                    "login": "jdegoes",
                    "id": 156745,
                    "node_id": "MDQ6VXNlcjE1Njc0NQ==",
                    "avatar_url": "https://avatars.githubusercontent.com/u/156745?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/jdegoes",
                    "html_url": "https://github.com/jdegoes",
                    "followers_url": "https://api.github.com/users/jdegoes/followers",
                    "following_url": "https://api.github.com/users/jdegoes/following{/other_user}",
                    "gists_url": "https://api.github.com/users/jdegoes/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/jdegoes/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/jdegoes/subscriptions",
                    "organizations_url": "https://api.github.com/users/jdegoes/orgs",
                    "repos_url": "https://api.github.com/users/jdegoes/repos",
                    "events_url": "https://api.github.com/users/jdegoes/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/jdegoes/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Schema Migration System for ZIO Schema 2",
                  "body": "## Overview\n\nImplement a **pure, algebraic migration system** for ZIO Schema 2 that represents **structural transformations between schema versions** as first-class, serializable data.\n\nA migration describes how to transform data from one schema version to another, enabling:\n\n* schema evolution\n* backward / forward compatibility\n* data versioning\n* offline migrations (JSON, SQL, data lakes, registries, etc.)\n\nThe system provides a **typed, macro-validated user API** (`Migration[A, B]`) built on a **pure, serializable core** (`DynamicMigration`) that operates on `DynamicValue`. \n\nThe ADT is fully introspectable and can be used to generate DDL, etc.\n\n## Motivation & Big Picture\n\n### Why structural types?\n\nWhen evolving schemas over time, **older versions of data types should not require runtime representations**.\n\nIn this design:\n\n* **Current versions** are represented by real case classes / enums\n* **Past versions** are represented using:\n\n  * **structural types** for records\n  * **abstract types + intersection types** for sum types\n\nThese types:\n\n* exist **only at compile time**\n* have **no runtime representation**\n* introduce **zero runtime overhead**\n* do **not require optics or instances to be kept around**\n\nThis allows you to describe arbitrarily old versions of data *without polluting your runtime or codebase*.\n\n#### Typical Workflow\n\nA typical workflow looks like:\n\n1. You have a current type:\n\n   ```scala\n   @schema\n   case class Person(name: String, age: Int)\n   ```\n\n2. You derive and copy its structural shape:\n\n   ```scala\n   type PersonV1 = { def name: String; def age: Int }\n   ```\n\n3. You evolve the real type:\n\n   ```scala\n   @schema\n   case class Person(fullName: String, age: Int, country: String)\n   ```\n\n4. You keep only:\n\n   * the **current** runtime type\n   * the **structural type** for the old version\n   * a **pure migration** between them\n\nNo old case classes. No old optics. No runtime baggage.\n\nNote there is no requirement that the \"current\" type actually be a real case class, enum, etc.--so you can work purely with structural types, allowing you to define migrations for data types that are never materialized as runtime structures.\n\n---\n\n### Why pure data migrations?\n\nMigrations are represented entirely as **pure data**:\n\n* no user functions\n* no closures\n* no reflection\n* no runtime code generation\n\nAs a result:\n\n* migrations can be **serialized**\n* stored in **registries**\n* applied **dynamically**\n* inspected and transformed\n* used to generate:\n\n  * upgraders\n  * downgraders\n  * SQL DDL / DML\n  * offline data transforms\n\nWhile code generation is **out of scope for this ticket**, this explains many design decisions (invertibility, path-based actions, no functions).\n\n---\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed migration (user-facing API)\ncase class Migration[A, B](\n  dynamicMigration: DynamicMigration,\n  sourceSchema: Schema[A], // These are structural schemas!!!\n  targetSchema: Schema[B] // These are structural schemas!!!\n) {\n  /** Apply migration to transform A to B */\n  def apply(value: A): Either[MigrationError, B]\n\n  /** Compose migrations sequentially */\n  def ++[C](that: Migration[B, C]): Migration[A, C]\n\n  /** Alias for ++ */\n  def andThen[C](that: Migration[B, C]): Migration[A, C] = this ++ that\n\n  /** Reverse migration (structural inverse; runtime is best-effort) */\n  def reverse: Migration[B, A]\n}\n```\n\n```scala\n// Untyped migration (pure data, fully serializable)\ncase class DynamicMigration(\n  actions: Vector[MigrationAction]\n) {\n  def apply(value: DynamicValue): Either[MigrationError, DynamicValue]\n  def ++(that: DynamicMigration): DynamicMigration\n  def reverse: DynamicMigration\n}\n```\n\n* `Migration[A, B]` is introspectable, but not pure data due to bindings inside schemas\n* `DynamicMigration` is **fully serializable**\n\n---\n\n## User-Facing API: Selector Expressions\n\n### Selectors, not optics\n\nThe user-facing API **does not expose optics**.\n\nInstead, all locations are specified using **selector expressions**:\n\n```scala\nS => A\n```\n\nExamples:\n\n```scala\n_.name\n_.address.street\n_.addresses.each.streetNumber\n_.country.when[UK]\n```\n\nTo see the syntax, one can look at the `optic` macro, which utilizes the same selector syntax for optic creation (e.g. `optic(_.address.street)`, etc.).\n\n### Macro extraction\n\nAll builder methods that accept selectors are **implemented via macros** (or via a macro-generated type class such as `ToDynamicOptic`).\n\nThe macro:\n\n1. Inspects the selector expression\n2. Validates it is a supported projection\n3. Converts it into a `DynamicOptic`\n4. Stores that optic in the migration action\n\nSupported projections include:\n\n* field access (`_.foo.bar`)\n* case selection (`_.country.when[UK]`)\n* collection traversal (`_.items.each`)\n* (future) key access, wrappers, etc.\n\n`DynamicOptic` is **never exposed publicly**.\n\n---\n\n## Migration Builder\n\nAll selector-accepting methods are implemented via macros. For simplicity, these are shown as functions (e.g. `A => Any`), but this is NOT the way to implement them. Either all these functions need to be macros, or a macro needs to be used to generate an implicit / given at each call site. Macros may do additional validation to constrain the validity of these different types of transformations.\n\n```scala\nclass MigrationBuilder[A, B](\n  sourceSchema: Schema[A],\n  targetSchema: Schema[B],\n  actions: Vector[MigrationAction]\n) {\n\n  // ----- Record operations -----\n\n  def addField(\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def dropField(\n    source: A => Any,\n    defaultForReverse: SchemaExpr[B, ?] = SchemaExpr.DefaultValue\n  ): MigrationBuilder[A, B]\n\n  def renameField(\n    from: A => Any,\n    to: B => Any\n  ): MigrationBuilder[A, B]\n\n  def transformField(\n    from: A => Any,\n    to: B => Any,\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def mandateField(\n    source: A => Option[?],\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def optionalizeField(\n    source: A => Any,\n    target: B => Option[?]\n  ): MigrationBuilder[A, B]\n\n  def changeFieldType(\n    source: A => Any,\n    target: B => Any,\n    converter: SchemaExpr[A, ?]  // primitive-to-primitive only\n  ): MigrationBuilder[A, B]\n\n  // ----- Enum operations (limited) -----\n\n  def renameCase[SumA, SumB](\n    from: String,\n    to: String\n  ): MigrationBuilder[A, B]\n\n  def transformCase[SumA, CaseA, SumB, CaseB](\n    caseMigration: MigrationBuilder[CaseA, CaseB] => MigrationBuilder[CaseA, CaseB]\n  ): MigrationBuilder[A, B]\n\n  // ----- Collections -----\n\n  def transformElements(\n    at: A => Vector[?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  // ----- Maps -----\n\n  def transformKeys(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def transformValues(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  /** Build migration with full macro validation */\n  def build: Migration[A, B]\n\n  /** Build migration without full validation */\n  def buildPartial: Migration[A, B]\n}\n```\n\n---\n\n## Migration Actions (Untyped Core)\n\nAll actions operate at a **path**, represented by `DynamicOptic`.\n\n```scala\nsealed trait MigrationAction {\n  def at: DynamicOptic\n  def reverse: MigrationAction\n}\n```\n\n### Record Actions\n\n```scala\ncase class AddField(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class DropField(\n  at: DynamicOptic,\n  defaultForReverse: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Rename(\n  at: DynamicOptic,\n  to: String\n) extends MigrationAction\n\ncase class TransformValue(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Mandate(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Optionalize(\n  at: DynamicOptic\n) extends MigrationAction\n\ncase class Join(\n  at: DynamicOptic,\n  sourcePaths: Vector[DynamicOptic],\n  combiner: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Split(\n  at: DynamicOptic,\n  targetPaths: Vector[DynamicOptic],\n  splitter: SchemaExpr[?]\n) extends MigrationAction\n\ncase class ChangeType(\n  at: DynamicOptic,\n  converter: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n### Enum Actions (Supported)\n\n```scala\ncase class RenameCase(\n  at: DynamicOptic,\n  from: String,\n  to: String\n) extends MigrationAction\n\ncase class TransformCase(\n  at: DynamicOptic,\n  actions: Vector[MigrationAction]\n) extends MigrationAction\n```\n\n> Enum case addition / removal is **out of scope** for this ticket\n> (requires composite value construction).\n\n---\n\n### Collection / Map Actions\n\n```scala\ncase class TransformElements(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformKeys(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformValues(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n## SchemaExpr Integration\n\n* Used for all value-level transformations\n* **Constraints for this ticket**:\n\n  * primitive â†’ primitive only\n  * joins / splits must produce primitives\n  * no record / enum construction\n\n### `SchemaExpr.DefaultValue`\n\nA special expression that:\n\n1. uses the macro-captured field schema\n2. calls `schema.defaultValue`\n3. converts the value to `DynamicValue`\n4. is stored for reverse migrations\n\n---\n\n## Type Modeling\n\n### Records (Structural Types)\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\ntype PersonV1 = { val fullName: String; val age: Int }\n\nimplicit val v0Schema: Schema[PersonV0] = Schema.structural[PersonV0]\nimplicit val v1Schema: Schema[PersonV1] = Schema.structural[PersonV1]\n```\n\n---\n\n### Enums (Union of Structural Types with Tags)\n\nEnums are encoded into structural types by using union types, together with singleton types (string literals, which represent the name of the case of the enum).\n\nIn structural types, the names of the type aliases shown below are not relevant, nor are they used.\n\n```scala\ntype OldCreditCard =\n  { type Tag = \"CreditCard\"; def number: String; def exp: String }\ntype OldWireTransfer =\n  { type Tag = \"WireTransfer\"; def account: String; def routing: String }\ntype OldPaymentMethod = OldCreditCard | OldWireTransfer\n```\n\nMacros extract:\n\n* refinement type â†’ structure of the case\n* type `Tag` with singleton type â†’ case tag\n\n---\n\n## Laws\n\n### Identity\n\n```scala\nMigration.identity[A].apply(a) == Right(a)\n```\n\n### Associativity\n\n```scala\n(m1 ++ m2) ++ m3 == m1 ++ (m2 ++ m3)\n```\n\n### Structural Reverse\n\n```scala\nm.reverse.reverse == m\n```\n\n### Best-Effort Semantic Inverse\n\n```scala\nm.apply(a) == Right(b) â‡’ m.reverse.apply(b) == Right(a)\n```\n\n(when sufficient information exists)\n\n---\n\n## Error Handling\n\n* All runtime errors return `MigrationError`\n* Errors must capture **path information** (`DynamicOptic`)\n* Enables diagnostics such as:\n\n> â€œFailed to apply TransformValue at `.addresses.each.streetNumber`â€\n\n---\n\n## Example\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\n\n@schema\ncase class Person(fullName: String, age: Int)\n\nval migration =\n  Migration.newBuilder[PersonV0, Person]\n    .addField(_.age, 0)\n    .build\n\nval old =\n  new { val firstName = \"John\"; val lastName = \"Doe\" }\n\nmigration(old)\n// Right(Person(\"John Doe\", 0))\n```\n\n---\n\n## Success Criteria\n\n* [ ] `DynamicMigration` fully serializable\n* [ ] `Migration[A, B]` wraps schemas and actions\n* [ ] All actions path-based via `DynamicOptic`\n* [ ] User API uses selector functions (`S => A`) for \"optics\" on old and new types\n* [ ] Macro validation in `.build` to confirm \"old\" has been migrated to \"new\"\n* [ ] `.buildPartial` supported\n* [ ] Structural reverse implemented\n* [ ] Identity & associativity laws hold\n* [ ] Enum rename / transform supported\n* [ ] Errors include path information\n* [ ] Comprehensive tests\n* [ ] Scala 2.13 and Scala 3.5+ supported\n",
                  "html_url": "https://github.com/zio/zio-blocks/issues/519"
                },
                "type": "github"
              },
              "hash": "zio/zio-blocks#519",
              "body": "## Overview\n\nImplement a **pure, algebraic migration system** for ZIO Schema 2 that represents **structural transformations between schema versions** as first-class, serializable data.\n\nA migration describes how to transform data from one schema version to another, enabling:\n\n* schema evolution\n* backward / forward compatibility\n* data versioning\n* offline migrations (JSON, SQL, data lakes, registries, etc.)\n\nThe system provides a **typed, macro-validated user API** (`Migration[A, B]`) built on a **pure, serializable core** (`DynamicMigration`) that operates on `DynamicValue`. \n\nThe ADT is fully introspectable and can be used to generate DDL, etc.\n\n## Motivation & Big Picture\n\n### Why structural types?\n\nWhen evolving schemas over time, **older versions of data types should not require runtime representations**.\n\nIn this design:\n\n* **Current versions** are represented by real case classes / enums\n* **Past versions** are represented using:\n\n  * **structural types** for records\n  * **abstract types + intersection types** for sum types\n\nThese types:\n\n* exist **only at compile time**\n* have **no runtime representation**\n* introduce **zero runtime overhead**\n* do **not require optics or instances to be kept around**\n\nThis allows you to describe arbitrarily old versions of data *without polluting your runtime or codebase*.\n\n#### Typical Workflow\n\nA typical workflow looks like:\n\n1. You have a current type:\n\n   ```scala\n   @schema\n   case class Person(name: String, age: Int)\n   ```\n\n2. You derive and copy its structural shape:\n\n   ```scala\n   type PersonV1 = { def name: String; def age: Int }\n   ```\n\n3. You evolve the real type:\n\n   ```scala\n   @schema\n   case class Person(fullName: String, age: Int, country: String)\n   ```\n\n4. You keep only:\n\n   * the **current** runtime type\n   * the **structural type** for the old version\n   * a **pure migration** between them\n\nNo old case classes. No old optics. No runtime baggage.\n\nNote there is no requirement that the \"current\" type actually be a real case class, enum, etc.--so you can work purely with structural types, allowing you to define migrations for data types that are never materialized as runtime structures.\n\n---\n\n### Why pure data migrations?\n\nMigrations are represented entirely as **pure data**:\n\n* no user functions\n* no closures\n* no reflection\n* no runtime code generation\n\nAs a result:\n\n* migrations can be **serialized**\n* stored in **registries**\n* applied **dynamically**\n* inspected and transformed\n* used to generate:\n\n  * upgraders\n  * downgraders\n  * SQL DDL / DML\n  * offline data transforms\n\nWhile code generation is **out of scope for this ticket**, this explains many design decisions (invertibility, path-based actions, no functions).\n\n---\n\n## Core Architecture\n\n### Type Hierarchy\n\n```scala\n// Typed migration (user-facing API)\ncase class Migration[A, B](\n  dynamicMigration: DynamicMigration,\n  sourceSchema: Schema[A], // These are structural schemas!!!\n  targetSchema: Schema[B] // These are structural schemas!!!\n) {\n  /** Apply migration to transform A to B */\n  def apply(value: A): Either[MigrationError, B]\n\n  /** Compose migrations sequentially */\n  def ++[C](that: Migration[B, C]): Migration[A, C]\n\n  /** Alias for ++ */\n  def andThen[C](that: Migration[B, C]): Migration[A, C] = this ++ that\n\n  /** Reverse migration (structural inverse; runtime is best-effort) */\n  def reverse: Migration[B, A]\n}\n```\n\n```scala\n// Untyped migration (pure data, fully serializable)\ncase class DynamicMigration(\n  actions: Vector[MigrationAction]\n) {\n  def apply(value: DynamicValue): Either[MigrationError, DynamicValue]\n  def ++(that: DynamicMigration): DynamicMigration\n  def reverse: DynamicMigration\n}\n```\n\n* `Migration[A, B]` is introspectable, but not pure data due to bindings inside schemas\n* `DynamicMigration` is **fully serializable**\n\n---\n\n## User-Facing API: Selector Expressions\n\n### Selectors, not optics\n\nThe user-facing API **does not expose optics**.\n\nInstead, all locations are specified using **selector expressions**:\n\n```scala\nS => A\n```\n\nExamples:\n\n```scala\n_.name\n_.address.street\n_.addresses.each.streetNumber\n_.country.when[UK]\n```\n\nTo see the syntax, one can look at the `optic` macro, which utilizes the same selector syntax for optic creation (e.g. `optic(_.address.street)`, etc.).\n\n### Macro extraction\n\nAll builder methods that accept selectors are **implemented via macros** (or via a macro-generated type class such as `ToDynamicOptic`).\n\nThe macro:\n\n1. Inspects the selector expression\n2. Validates it is a supported projection\n3. Converts it into a `DynamicOptic`\n4. Stores that optic in the migration action\n\nSupported projections include:\n\n* field access (`_.foo.bar`)\n* case selection (`_.country.when[UK]`)\n* collection traversal (`_.items.each`)\n* (future) key access, wrappers, etc.\n\n`DynamicOptic` is **never exposed publicly**.\n\n---\n\n## Migration Builder\n\nAll selector-accepting methods are implemented via macros. For simplicity, these are shown as functions (e.g. `A => Any`), but this is NOT the way to implement them. Either all these functions need to be macros, or a macro needs to be used to generate an implicit / given at each call site. Macros may do additional validation to constrain the validity of these different types of transformations.\n\n```scala\nclass MigrationBuilder[A, B](\n  sourceSchema: Schema[A],\n  targetSchema: Schema[B],\n  actions: Vector[MigrationAction]\n) {\n\n  // ----- Record operations -----\n\n  def addField(\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def dropField(\n    source: A => Any,\n    defaultForReverse: SchemaExpr[B, ?] = SchemaExpr.DefaultValue\n  ): MigrationBuilder[A, B]\n\n  def renameField(\n    from: A => Any,\n    to: B => Any\n  ): MigrationBuilder[A, B]\n\n  def transformField(\n    from: A => Any,\n    to: B => Any,\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def mandateField(\n    source: A => Option[?],\n    target: B => Any,\n    default: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def optionalizeField(\n    source: A => Any,\n    target: B => Option[?]\n  ): MigrationBuilder[A, B]\n\n  def changeFieldType(\n    source: A => Any,\n    target: B => Any,\n    converter: SchemaExpr[A, ?]  // primitive-to-primitive only\n  ): MigrationBuilder[A, B]\n\n  // ----- Enum operations (limited) -----\n\n  def renameCase[SumA, SumB](\n    from: String,\n    to: String\n  ): MigrationBuilder[A, B]\n\n  def transformCase[SumA, CaseA, SumB, CaseB](\n    caseMigration: MigrationBuilder[CaseA, CaseB] => MigrationBuilder[CaseA, CaseB]\n  ): MigrationBuilder[A, B]\n\n  // ----- Collections -----\n\n  def transformElements(\n    at: A => Vector[?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  // ----- Maps -----\n\n  def transformKeys(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  def transformValues(\n    at: A => Map[?, ?],\n    transform: SchemaExpr[A, ?]\n  ): MigrationBuilder[A, B]\n\n  /** Build migration with full macro validation */\n  def build: Migration[A, B]\n\n  /** Build migration without full validation */\n  def buildPartial: Migration[A, B]\n}\n```\n\n---\n\n## Migration Actions (Untyped Core)\n\nAll actions operate at a **path**, represented by `DynamicOptic`.\n\n```scala\nsealed trait MigrationAction {\n  def at: DynamicOptic\n  def reverse: MigrationAction\n}\n```\n\n### Record Actions\n\n```scala\ncase class AddField(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class DropField(\n  at: DynamicOptic,\n  defaultForReverse: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Rename(\n  at: DynamicOptic,\n  to: String\n) extends MigrationAction\n\ncase class TransformValue(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Mandate(\n  at: DynamicOptic,\n  default: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Optionalize(\n  at: DynamicOptic\n) extends MigrationAction\n\ncase class Join(\n  at: DynamicOptic,\n  sourcePaths: Vector[DynamicOptic],\n  combiner: SchemaExpr[?]\n) extends MigrationAction\n\ncase class Split(\n  at: DynamicOptic,\n  targetPaths: Vector[DynamicOptic],\n  splitter: SchemaExpr[?]\n) extends MigrationAction\n\ncase class ChangeType(\n  at: DynamicOptic,\n  converter: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n### Enum Actions (Supported)\n\n```scala\ncase class RenameCase(\n  at: DynamicOptic,\n  from: String,\n  to: String\n) extends MigrationAction\n\ncase class TransformCase(\n  at: DynamicOptic,\n  actions: Vector[MigrationAction]\n) extends MigrationAction\n```\n\n> Enum case addition / removal is **out of scope** for this ticket\n> (requires composite value construction).\n\n---\n\n### Collection / Map Actions\n\n```scala\ncase class TransformElements(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformKeys(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n\ncase class TransformValues(\n  at: DynamicOptic,\n  transform: SchemaExpr[?]\n) extends MigrationAction\n```\n\n---\n\n## SchemaExpr Integration\n\n* Used for all value-level transformations\n* **Constraints for this ticket**:\n\n  * primitive â†’ primitive only\n  * joins / splits must produce primitives\n  * no record / enum construction\n\n### `SchemaExpr.DefaultValue`\n\nA special expression that:\n\n1. uses the macro-captured field schema\n2. calls `schema.defaultValue`\n3. converts the value to `DynamicValue`\n4. is stored for reverse migrations\n\n---\n\n## Type Modeling\n\n### Records (Structural Types)\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\ntype PersonV1 = { val fullName: String; val age: Int }\n\nimplicit val v0Schema: Schema[PersonV0] = Schema.structural[PersonV0]\nimplicit val v1Schema: Schema[PersonV1] = Schema.structural[PersonV1]\n```\n\n---\n\n### Enums (Union of Structural Types with Tags)\n\nEnums are encoded into structural types by using union types, together with singleton types (string literals, which represent the name of the case of the enum).\n\nIn structural types, the names of the type aliases shown below are not relevant, nor are they used.\n\n```scala\ntype OldCreditCard =\n  { type Tag = \"CreditCard\"; def number: String; def exp: String }\ntype OldWireTransfer =\n  { type Tag = \"WireTransfer\"; def account: String; def routing: String }\ntype OldPaymentMethod = OldCreditCard | OldWireTransfer\n```\n\nMacros extract:\n\n* refinement type â†’ structure of the case\n* type `Tag` with singleton type â†’ case tag\n\n---\n\n## Laws\n\n### Identity\n\n```scala\nMigration.identity[A].apply(a) == Right(a)\n```\n\n### Associativity\n\n```scala\n(m1 ++ m2) ++ m3 == m1 ++ (m2 ++ m3)\n```\n\n### Structural Reverse\n\n```scala\nm.reverse.reverse == m\n```\n\n### Best-Effort Semantic Inverse\n\n```scala\nm.apply(a) == Right(b) â‡’ m.reverse.apply(b) == Right(a)\n```\n\n(when sufficient information exists)\n\n---\n\n## Error Handling\n\n* All runtime errors return `MigrationError`\n* Errors must capture **path information** (`DynamicOptic`)\n* Enables diagnostics such as:\n\n> â€œFailed to apply TransformValue at `.addresses.each.streetNumber`â€\n\n---\n\n## Example\n\n```scala\ntype PersonV0 = { val firstName: String; val lastName: String }\n\n@schema\ncase class Person(fullName: String, age: Int)\n\nval migration =\n  Migration.newBuilder[PersonV0, Person]\n    .addField(_.age, 0)\n    .build\n\nval old =\n  new { val firstName = \"John\"; val lastName = \"Doe\" }\n\nmigration(old)\n// Right(Person(\"John Doe\", 0))\n```\n\n---\n\n## Success Criteria\n\n* [ ] `DynamicMigration` fully serializable\n* [ ] `Migration[A, B]` wraps schemas and actions\n* [ ] All actions path-based via `DynamicOptic`\n* [ ] User API uses selector functions (`S => A`) for \"optics\" on old and new types\n* [ ] Macro validation in `.build` to confirm \"old\" has been migrated to \"new\"\n* [ ] `.buildPartial` supported\n* [ ] Structural reverse implemented\n* [ ] Identity & associativity laws hold\n* [ ] Enum rename / transform supported\n* [ ] Errors include path information\n* [ ] Comprehensive tests\n* [ ] Scala 2.13 and Scala 3.5+ supported\n",
              "url": "https://github.com/zio/zio-blocks/issues/519",
              "tech": [],
              "repo_name": "zio-blocks",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#3472",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-31T09:51:26.676Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:26.676Z",
            "created_at": "2026-01-31T09:51:26.676Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#3472",
              "status": "open",
              "type": "issue",
              "number": 3472,
              "title": "Split into multiple modules",
              "source": {
                "data": {
                  "id": "source-ZIO#3472",
                  "user": {
                    "login": "987Nabil",
                    "id": 7283535,
                    "node_id": "MDQ6VXNlcjcyODM1MzU=",
                    "avatar_url": "https://avatars.githubusercontent.com/u/7283535?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/987Nabil",
                    "html_url": "https://github.com/987Nabil",
                    "followers_url": "https://api.github.com/users/987Nabil/followers",
                    "following_url": "https://api.github.com/users/987Nabil/following{/other_user}",
                    "gists_url": "https://api.github.com/users/987Nabil/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/987Nabil/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/987Nabil/subscriptions",
                    "organizations_url": "https://api.github.com/users/987Nabil/orgs",
                    "repos_url": "https://api.github.com/users/987Nabil/repos",
                    "events_url": "https://api.github.com/users/987Nabil/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/987Nabil/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Split into multiple modules",
                  "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
                  "html_url": "https://github.com/zio/zio-http/issues/3472"
                },
                "type": "github"
              },
              "hash": "zio/zio-http#3472",
              "body": "Currently, the zio-http artifact contains a lot of different parts of zio-http exclusively. They are not separate maven artifacts.\n\nWe want to change this, to support future changes/features.\n\nThere should be at least these modules that are published into maven. \n\n1. core\n2. endpoint\n3. netty\n\nShould we have client and server in different modules?",
              "url": "https://github.com/zio/zio-http/issues/3472",
              "tech": [],
              "repo_name": "zio-http",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9810",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-31T09:51:26.819Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:26.819Z",
            "created_at": "2026-01-31T09:51:26.819Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9810",
              "status": "open",
              "type": "issue",
              "number": 9810,
              "title": "ZStreams buffer(1) is buffering 2.",
              "source": {
                "data": {
                  "id": "source-ZIO#9810",
                  "user": {
                    "login": "douglasthomsen",
                    "id": 88000378,
                    "node_id": "MDQ6VXNlcjg4MDAwMzc4",
                    "avatar_url": "https://avatars.githubusercontent.com/u/88000378?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/douglasthomsen",
                    "html_url": "https://github.com/douglasthomsen",
                    "followers_url": "https://api.github.com/users/douglasthomsen/followers",
                    "following_url": "https://api.github.com/users/douglasthomsen/following{/other_user}",
                    "gists_url": "https://api.github.com/users/douglasthomsen/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/douglasthomsen/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/douglasthomsen/subscriptions",
                    "organizations_url": "https://api.github.com/users/douglasthomsen/orgs",
                    "repos_url": "https://api.github.com/users/douglasthomsen/repos",
                    "events_url": "https://api.github.com/users/douglasthomsen/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/douglasthomsen/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZStreams buffer(1) is buffering 2.",
                  "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
                  "html_url": "https://github.com/zio/zio/issues/9810"
                },
                "type": "github"
              },
              "hash": "zio/zio#9810",
              "body": "I am using zio 2.1.17. When I run the following code:\n\n```scala\ndef fakeNetworkCall(n: Int): ZIO[Any, Throwable, String] = {\n  for {\n    _ <- Console.printLine(s\"Starting request $n\")\n    _ <- ZIO.sleep(1.second)\n    _ <- Console.printLine(s\"Completed request $n\")\n  } yield s\"Response for $n\"\n}\n\nval program: ZIO[Any, Throwable, Unit] =\n  ZStream\n    .fromIterator(Iterator.from(1))\n    .mapZIO(fakeNetworkCall)\n    .buffer(1)\n    .runForeach { response =>\n      for {\n        _ <- Console.printLine(s\"Press Enter to process $response...\")\n        _ <- ZIO.sleep(100.minutes)\n        _ <- Console.printLine(s\"Processing response $response\")\n        _ <- ZIO.sleep(1.second)\n        _ <- Console.printLine(s\"Done processing $response\")\n      } yield ()\n    }\n```\nThe full code is [here](https://scastie.scala-lang.org/douglasthomsen/kvRuhoAGRjarj9djF53N0g/10).\n\nWhen i get to the `_ <- ZIO.sleep(100.minutes)` line I would expect the output to be like this:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\n```\n\nbut I am getting the following:\n```\nStarting request 1\nCompleted request 1\nStarting request 2\nPress Enter to process Response for 1...\nCompleted request 2\nStarting request 3\nCompleted request 3\n```\n\nMy goal is to only buffer one call to `fakeNetworkCall` at time. Right now it looks like it is buffering two. I am I doing something wrong or is this a bug?",
              "url": "https://github.com/zio/zio/issues/9810",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9844",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-31T09:51:27.476Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:27.476Z",
            "created_at": "2026-01-31T09:51:27.476Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9844",
              "status": "open",
              "type": "issue",
              "number": 9844,
              "title": "improved `Queue` shutdown functionality",
              "source": {
                "data": {
                  "id": "source-ZIO#9844",
                  "user": {
                    "login": "mberndt123",
                    "id": 11650737,
                    "node_id": "MDQ6VXNlcjExNjUwNzM3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/11650737?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/mberndt123",
                    "html_url": "https://github.com/mberndt123",
                    "followers_url": "https://api.github.com/users/mberndt123/followers",
                    "following_url": "https://api.github.com/users/mberndt123/following{/other_user}",
                    "gists_url": "https://api.github.com/users/mberndt123/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/mberndt123/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/mberndt123/subscriptions",
                    "organizations_url": "https://api.github.com/users/mberndt123/orgs",
                    "repos_url": "https://api.github.com/users/mberndt123/repos",
                    "events_url": "https://api.github.com/users/mberndt123/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/mberndt123/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "improved `Queue` shutdown functionality",
                  "body": "Hey, I've recently proposed something on Discord, and since feedback has been rather positive, I'm making a ticket to track the idea.\n\nI've been working with Queues recently, and I've been having some issues around `shutdown` that I would like to address.\n\nSpecifically, I find it a common pattern that I send some kind of request object through a queue because I want another fiber to perform some action on my behalf. Along with the request, I send a `Promise` to have that fiber communicate the outcome of that action to me. By and large this works fine. The issue arises when the fiber that I'm sending requests to fails. In that case, I would like it to communicate the cause of the failure back to the other fibers. This is easy enough for the requests that I've already pulled out of the queue: I simply fail those promises.\nBut I also need to deal with other cases: fibers currently blocked in an `offer` call, future attempts to `offer` to the queue, and I also need to deal with requests that have been submitted to the queue but not yet retrieved.\n\nSo my idea is as follows:\n - add an `E` type parameter to `Queue`\n - add a `shutdownCause` method that takes a type parameter of type `Cause[E]`\n - `shutdownCause` would also return the items currently buffered in the queue in order to dispose of them\n - after `shutdownCause` has been called, any attempt to interact with the queue will fail with the cause\n - methods like `take, offer` etc. should indicate errors of type `E`\n - streams created with `ZStream.fromQueue` would also fail with this cause\n - `shutdownCause` should be atomic: when multiple fibers call it at the same time, one of them wins and the others fail with the cause supplied by the winner\n\nAfaik, adding a new method is a binary compatible change, as is adding a new type parameter. Hence I think this is a source incompatible but binary compatible change. @ghostdogpr therefore suggested it could be added in a ZIO 2.2 release.\n",
                  "html_url": "https://github.com/zio/zio/issues/9844"
                },
                "type": "github"
              },
              "hash": "zio/zio#9844",
              "body": "Hey, I've recently proposed something on Discord, and since feedback has been rather positive, I'm making a ticket to track the idea.\n\nI've been working with Queues recently, and I've been having some issues around `shutdown` that I would like to address.\n\nSpecifically, I find it a common pattern that I send some kind of request object through a queue because I want another fiber to perform some action on my behalf. Along with the request, I send a `Promise` to have that fiber communicate the outcome of that action to me. By and large this works fine. The issue arises when the fiber that I'm sending requests to fails. In that case, I would like it to communicate the cause of the failure back to the other fibers. This is easy enough for the requests that I've already pulled out of the queue: I simply fail those promises.\nBut I also need to deal with other cases: fibers currently blocked in an `offer` call, future attempts to `offer` to the queue, and I also need to deal with requests that have been submitted to the queue but not yet retrieved.\n\nSo my idea is as follows:\n - add an `E` type parameter to `Queue`\n - add a `shutdownCause` method that takes a type parameter of type `Cause[E]`\n - `shutdownCause` would also return the items currently buffered in the queue in order to dispose of them\n - after `shutdownCause` has been called, any attempt to interact with the queue will fail with the cause\n - methods like `take, offer` etc. should indicate errors of type `E`\n - streams created with `ZStream.fromQueue` would also fail with this cause\n - `shutdownCause` should be atomic: when multiple fibers call it at the same time, one of them wins and the others fail with the cause supplied by the winner\n\nAfaik, adding a new method is a binary compatible change, as is adding a new type parameter. Hence I think this is a source incompatible but binary compatible change. @ghostdogpr therefore suggested it could be added in a ZIO 2.2 release.\n",
              "url": "https://github.com/zio/zio/issues/9844",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9878",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-31T09:51:27.609Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:27.609Z",
            "created_at": "2026-01-31T09:51:27.609Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9878",
              "status": "open",
              "type": "issue",
              "number": 9878,
              "title": "ZScheduler parks+unparks workers too frequently",
              "source": {
                "data": {
                  "id": "source-ZIO#9878",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "ZScheduler parks+unparks workers too frequently",
                  "body": "Unparking workers is slow and invoked in the hotpath too often. I think we may need to trade some fairness for aggression to avoid excessive cycling.\n\n`maybeUnparkWorker` (obviously `LockSupport.unpark(worker)`) is very expensive: https://github.com/zio/zio/blob/series/2.x/core/jvm-native/src/main/scala/zio/internal/ZScheduler.scala#L443-L454",
                  "html_url": "https://github.com/zio/zio/issues/9878"
                },
                "type": "github"
              },
              "hash": "zio/zio#9878",
              "body": "Unparking workers is slow and invoked in the hotpath too often. I think we may need to trade some fairness for aggression to avoid excessive cycling.\n\n`maybeUnparkWorker` (obviously `LockSupport.unpark(worker)`) is very expensive: https://github.com/zio/zio/blob/series/2.x/core/jvm-native/src/main/scala/zio/internal/ZScheduler.scala#L443-L454",
              "url": "https://github.com/zio/zio/issues/9878",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9877",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-31T09:51:27.732Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:27.732Z",
            "created_at": "2026-01-31T09:51:27.732Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9877",
              "status": "open",
              "type": "issue",
              "number": 9877,
              "title": "Can Fiber(Runtime) and Promise be merged?",
              "source": {
                "data": {
                  "id": "source-ZIO#9877",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Can Fiber(Runtime) and Promise be merged?",
                  "body": "A Promise awaiting completion is essentially a Fiber parked awaiting an async callback. When a Fiber is forking work (which will eventually complete a promise), then awaiting a Promise, we end up with unnecessary allocations + indirection.\n\nit would be useful to have `Promise.become` or similar to link fibers/promises.",
                  "html_url": "https://github.com/zio/zio/issues/9877"
                },
                "type": "github"
              },
              "hash": "zio/zio#9877",
              "body": "A Promise awaiting completion is essentially a Fiber parked awaiting an async callback. When a Fiber is forking work (which will eventually complete a promise), then awaiting a Promise, we end up with unnecessary allocations + indirection.\n\nit would be useful to have `Promise.become` or similar to link fibers/promises.",
              "url": "https://github.com/zio/zio/issues/9877",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9874",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-31T09:51:27.873Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:27.873Z",
            "created_at": "2026-01-31T09:51:27.873Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9874",
              "status": "open",
              "type": "issue",
              "number": 9874,
              "title": "Handling errors allows recovering from defects",
              "source": {
                "data": {
                  "id": "source-ZIO#9874",
                  "user": {
                    "login": "kyri-petrou",
                    "id": 67301607,
                    "node_id": "MDQ6VXNlcjY3MzAxNjA3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/67301607?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kyri-petrou",
                    "html_url": "https://github.com/kyri-petrou",
                    "followers_url": "https://api.github.com/users/kyri-petrou/followers",
                    "following_url": "https://api.github.com/users/kyri-petrou/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kyri-petrou/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kyri-petrou/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kyri-petrou/subscriptions",
                    "organizations_url": "https://api.github.com/users/kyri-petrou/orgs",
                    "repos_url": "https://api.github.com/users/kyri-petrou/repos",
                    "events_url": "https://api.github.com/users/kyri-petrou/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kyri-petrou/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Handling errors allows recovering from defects",
                  "body": "Sigh... Well, this is annoying. When a Cause contains both a failure and a defect (i.e., Fail & Die), failure handling assumes that the Cause does not contain any defects and therefor silently ignores them.\n\nRepro:\n\n```scala\nimport zio.*\n\nobject Foo extends ZIOAppDefault {\n  val dieCause: Cause[String] = Cause.die(new RuntimeException(\"boom\"))\n  val combinedCause = dieCause && Cause.fail(\"boom\")\n\n  def run = ZIO.failCause(combinedCause).catchAll { e =>\n    ZIO.debug(e)\n  } *> ZIO.debug(\"Success\")\n}\n```\nprints:\n```\nhandled: boom\nSuccess\n```\n\nHowever if we substituted `ZIO.failCause(combinedCause)` with `ZIO.failCause(dieCause)`:\n\n```\ntimestamp=2025-05-20T16:31:09.291104Z level=ERROR thread=#zio-fiber-1707930317 message=\"\" cause=\"java.lang.RuntimeException: boom\n\tat Foo$.<clinit>(Foo.scala:4)\n\tat Foo.main(Foo.scala)\n\tat <empty>.Foo.run(Foo.scala:7)\n\tat <empty>.Foo.run(Foo.scala:9)\n\"\n```\n\nWith both of these causes, the outcome should be the same as defects should always be prioritised over failures. This gets even worse when interruption is involved, because the failure handling will be prioritised over it.\n\nHaving said that, this has the potential to massively alter applications so I'm too scared to fix it.\n@ghostdogpr @jdegoes  @hearnadam @guizmaii I summon you all for some wisdom",
                  "html_url": "https://github.com/zio/zio/issues/9874"
                },
                "type": "github"
              },
              "hash": "zio/zio#9874",
              "body": "Sigh... Well, this is annoying. When a Cause contains both a failure and a defect (i.e., Fail & Die), failure handling assumes that the Cause does not contain any defects and therefor silently ignores them.\n\nRepro:\n\n```scala\nimport zio.*\n\nobject Foo extends ZIOAppDefault {\n  val dieCause: Cause[String] = Cause.die(new RuntimeException(\"boom\"))\n  val combinedCause = dieCause && Cause.fail(\"boom\")\n\n  def run = ZIO.failCause(combinedCause).catchAll { e =>\n    ZIO.debug(e)\n  } *> ZIO.debug(\"Success\")\n}\n```\nprints:\n```\nhandled: boom\nSuccess\n```\n\nHowever if we substituted `ZIO.failCause(combinedCause)` with `ZIO.failCause(dieCause)`:\n\n```\ntimestamp=2025-05-20T16:31:09.291104Z level=ERROR thread=#zio-fiber-1707930317 message=\"\" cause=\"java.lang.RuntimeException: boom\n\tat Foo$.<clinit>(Foo.scala:4)\n\tat Foo.main(Foo.scala)\n\tat <empty>.Foo.run(Foo.scala:7)\n\tat <empty>.Foo.run(Foo.scala:9)\n\"\n```\n\nWith both of these causes, the outcome should be the same as defects should always be prioritised over failures. This gets even worse when interruption is involved, because the failure handling will be prioritised over it.\n\nHaving said that, this has the potential to massively alter applications so I'm too scared to fix it.\n@ghostdogpr @jdegoes  @hearnadam @guizmaii I summon you all for some wisdom",
              "url": "https://github.com/zio/zio/issues/9874",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9681",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-31T09:51:28.011Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:28.011Z",
            "created_at": "2026-01-31T09:51:28.011Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9681",
              "status": "open",
              "type": "issue",
              "number": 9681,
              "title": "Scala Native `WeakConcurrentBag` NPE when forking 10K fibers",
              "source": {
                "data": {
                  "id": "source-ZIO#9681",
                  "user": {
                    "login": "hearnadam",
                    "id": 22334119,
                    "node_id": "MDQ6VXNlcjIyMzM0MTE5",
                    "avatar_url": "https://avatars.githubusercontent.com/u/22334119?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/hearnadam",
                    "html_url": "https://github.com/hearnadam",
                    "followers_url": "https://api.github.com/users/hearnadam/followers",
                    "following_url": "https://api.github.com/users/hearnadam/following{/other_user}",
                    "gists_url": "https://api.github.com/users/hearnadam/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/hearnadam/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/hearnadam/subscriptions",
                    "organizations_url": "https://api.github.com/users/hearnadam/orgs",
                    "repos_url": "https://api.github.com/users/hearnadam/repos",
                    "events_url": "https://api.github.com/users/hearnadam/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/hearnadam/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Scala Native `WeakConcurrentBag` NPE when forking 10K fibers",
                  "body": "```\n[info]   - PromiseSpec - waiter stack safety\n[info]     Exception in thread \"zio-fiber-931\" java.lang.NullPointerException: null\n[info]     \tat scala.scalanative.runtime.package$.throwNullPointer(Unknown Source)\n[info]     \tat <none>.(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.treeifyBin(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.putVal(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap$KeySetView.add(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.addToLongTermStorage(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.add(Unknown Source)\n[info]     \tat zio.internal.FiberScope$global$.add(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.makeChildFiber(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.fork(Unknown Source)\n[info]     \tat zio.ZIO.$anonfun$forkWithScopeOverride$2(Unknown Source)\n[info]     \tat zio.ZIO$$Lambda$280.apply(Unknown Source)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:127)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:124)\n```\nI introduced a new test in #9569 which resulted in this strange failure on Native.",
                  "html_url": "https://github.com/zio/zio/issues/9681"
                },
                "type": "github"
              },
              "hash": "zio/zio#9681",
              "body": "```\n[info]   - PromiseSpec - waiter stack safety\n[info]     Exception in thread \"zio-fiber-931\" java.lang.NullPointerException: null\n[info]     \tat scala.scalanative.runtime.package$.throwNullPointer(Unknown Source)\n[info]     \tat <none>.(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.treeifyBin(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap.putVal(Unknown Source)\n[info]     \tat java.util.concurrent.ConcurrentHashMap$KeySetView.add(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.addToLongTermStorage(Unknown Source)\n[info]     \tat zio.internal.WeakConcurrentBag.add(Unknown Source)\n[info]     \tat zio.internal.FiberScope$global$.add(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.makeChildFiber(Unknown Source)\n[info]     \tat zio.ZIO$unsafe$.fork(Unknown Source)\n[info]     \tat zio.ZIO.$anonfun$forkWithScopeOverride$2(Unknown Source)\n[info]     \tat zio.ZIO$$Lambda$280.apply(Unknown Source)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:127)\n[info]     \tat zio.PromiseSpec.spec(PromiseSpec.scala:124)\n```\nI introduced a new test in #9569 which resulted in this strange failure on Native.",
              "url": "https://github.com/zio/zio/issues/9681",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          },
          {
            "id": "ZIO#9909",
            "status": "open",
            "type": "standard",
            "kind": "dev",
            "org": {
              "handle": "ZIO",
              "id": "generated-ZIO",
              "name": "ZIO",
              "description": "",
              "members": [],
              "display_name": "ZIO",
              "created_at": "2026-01-31T09:51:28.192Z",
              "website_url": "",
              "avatar_url": "https://avatars.githubusercontent.com/u/ZIO?v=4",
              "discord_url": "",
              "slack_url": "",
              "stargazers_count": 0,
              "twitter_url": "",
              "youtube_url": "",
              "tech": [],
              "github_handle": "zio",
              "accepts_sponsorships": false,
              "days_until_timeout": null,
              "enabled_expert_recs": false,
              "enabled_private_bounties": false
            },
            "updated_at": "2026-01-31T09:51:28.192Z",
            "created_at": "2026-01-31T09:51:28.192Z",
            "visibility": "public",
            "autopay_disabled": false,
            "tech": [],
            "bids": [],
            "is_external": false,
            "manual_assignments": false,
            "point_reward": null,
            "reward": {
              "currency": "USD",
              "amount": 10000
            },
            "reward_formatted": "$100",
            "reward_tiers": [],
            "reward_type": "cash",
            "task": {
              "id": "task-ZIO#9909",
              "status": "open",
              "type": "issue",
              "number": 9909,
              "title": "Create test suite that tests the correct behaviour of `ZIOApp`",
              "source": {
                "data": {
                  "id": "source-ZIO#9909",
                  "user": {
                    "login": "kyri-petrou",
                    "id": 67301607,
                    "node_id": "MDQ6VXNlcjY3MzAxNjA3",
                    "avatar_url": "https://avatars.githubusercontent.com/u/67301607?v=4",
                    "gravatar_id": "",
                    "url": "https://api.github.com/users/kyri-petrou",
                    "html_url": "https://github.com/kyri-petrou",
                    "followers_url": "https://api.github.com/users/kyri-petrou/followers",
                    "following_url": "https://api.github.com/users/kyri-petrou/following{/other_user}",
                    "gists_url": "https://api.github.com/users/kyri-petrou/gists{/gist_id}",
                    "starred_url": "https://api.github.com/users/kyri-petrou/starred{/owner}{/repo}",
                    "subscriptions_url": "https://api.github.com/users/kyri-petrou/subscriptions",
                    "organizations_url": "https://api.github.com/users/kyri-petrou/orgs",
                    "repos_url": "https://api.github.com/users/kyri-petrou/repos",
                    "events_url": "https://api.github.com/users/kyri-petrou/events{/privacy}",
                    "received_events_url": "https://api.github.com/users/kyri-petrou/received_events",
                    "type": "User",
                    "user_view_type": "public",
                    "site_admin": false
                  },
                  "title": "Create test suite that tests the correct behaviour of `ZIOApp`",
                  "body": "The test suite needs to run during CI and test the behaviour of `ZIOApp` when:\n1. The app completes on its own (either via failure or success)\n2. The app completes due to an external signal (e.g., SIGINT)\n\nWhat needs to be tested:\n1. Correct error code is emitted\n2. Application finalizers are run (except for catastrophic failures)\n3. Shutdown sequence doesn't hang\n4. `gracefulShutdownTimeout` is respected\n5. A lot of use-cases from past issues:\ni. #9901 \nii. #9807\niii. #9240\niv. (I'll add others as I find them)",
                  "html_url": "https://github.com/zio/zio/issues/9909"
                },
                "type": "github"
              },
              "hash": "zio/zio#9909",
              "body": "The test suite needs to run during CI and test the behaviour of `ZIOApp` when:\n1. The app completes on its own (either via failure or success)\n2. The app completes due to an external signal (e.g., SIGINT)\n\nWhat needs to be tested:\n1. Correct error code is emitted\n2. Application finalizers are run (except for catastrophic failures)\n3. Shutdown sequence doesn't hang\n4. `gracefulShutdownTimeout` is respected\n5. A lot of use-cases from past issues:\ni. #9901 \nii. #9807\niii. #9240\niv. (I'll add others as I find them)",
              "url": "https://github.com/zio/zio/issues/9909",
              "tech": [],
              "repo_name": "zio",
              "repo_owner": "zio",
              "forge": "github"
            },
            "timeouts_disabled": false
          }
        ],
        "next_cursor": null
      }
    }
  }
}