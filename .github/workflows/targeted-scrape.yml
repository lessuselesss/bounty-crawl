name: ðŸŽ¯ Targeted Bounty Scrape

on:
  # Triggered by changedetection.io via Cloudflare Worker webhook
  repository_dispatch:
    types: [bounty_changed]

  # Allow manual triggering with specific organizations
  workflow_dispatch:
    inputs:
      organizations:
        description: 'Comma-separated list of organization handles to scrape'
        required: true
        type: string
      force_commit:
        description: 'Force commit even if no changes detected'
        required: false
        default: false
        type: boolean

env:
  NIX_CONFIG: "experimental-features = nix-command flakes"
  SOPS_AGE_KEY: ${{ secrets.SOPS_AGE_KEY }}
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  FIRECRAWL_API_KEY: ${{ secrets.FIRECRAWL_API_KEY }}

jobs:
  targeted-scrape:
    name: Scrape Changed Organizations
    runs-on: ubuntu-latest

    permissions:
      contents: write
      actions: read

    steps:
      - name: ðŸ“¥ Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: ðŸ¦• Install latest Deno
        run: |
          curl -fsSL https://deno.land/install.sh | sh
          echo "$HOME/.deno/bin" >> $GITHUB_PATH

      - name: ðŸ”‘ Setup SOPS
        continue-on-error: true
        run: |
          # Install SOPS and age
          curl -LO https://github.com/mozilla/sops/releases/download/v3.7.3/sops-v3.7.3.linux
          sudo mv sops-v3.7.3.linux /usr/local/bin/sops
          sudo chmod +x /usr/local/bin/sops

          curl -LO https://github.com/FiloSottile/age/releases/download/v1.1.1/age-v1.1.1-linux-amd64.tar.gz
          tar -xzf age-v1.1.1-linux-amd64.tar.gz
          sudo mv age/age* /usr/local/bin/

          # Create age key file for SOPS
          echo "$SOPS_AGE_KEY" > .age-key
          chmod 600 .age-key
          export SOPS_AGE_KEY_FILE="$PWD/.age-key"
          echo "SOPS_AGE_KEY_FILE=$PWD/.age-key" >> "$GITHUB_ENV"

          # Decrypt secrets if they exist
          if [ -f "secrets/github-token.yaml" ]; then
            echo "ðŸ”“ Decrypting secrets..."
            if sops -d secrets/github-token.yaml > /tmp/secrets.json 2>/tmp/sops_error.log; then
              if jq empty /tmp/secrets.json 2>/dev/null; then
                echo "âœ… Successfully decrypted secrets"
                GITHUB_API_TOKEN=$(jq -r '.github_token // empty' /tmp/secrets.json 2>/dev/null || echo "")
                ALGORA_SESSION=$(jq -r '.algora_session // empty' /tmp/secrets.json 2>/dev/null || echo "")

                echo "GITHUB_API_TOKEN=$GITHUB_API_TOKEN" >> "$GITHUB_ENV"
                echo "ALGORA_SESSION=$ALGORA_SESSION" >> "$GITHUB_ENV"
              fi
              rm -f /tmp/secrets.json
            fi
            rm -f /tmp/sops_error.log
          fi

      - name: ðŸ“¦ Cache Deno dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/deno
            .deno
            .cache
          key: deno-${{ hashFiles('deno.lock') }}
          restore-keys: |
            deno-

      - name: ðŸŽ¯ Parse target organizations
        id: parse-orgs
        run: |
          # Parse organizations from repository_dispatch or workflow_dispatch
          if [ "${{ github.event_name }}" = "repository_dispatch" ]; then
            # Extract from repository_dispatch client_payload
            CHANGED_ORGS='${{ toJSON(github.event.client_payload.changed_orgs) }}'
            ORGS_CSV=$(echo "$CHANGED_ORGS" | jq -r 'join(",")')
            BATCH_SIZE='${{ github.event.client_payload.batch_size }}'
            TIMESTAMP='${{ github.event.client_payload.timestamp }}'

            echo "orgs=$ORGS_CSV" >> "$GITHUB_OUTPUT"
            echo "batch_size=$BATCH_SIZE" >> "$GITHUB_OUTPUT"
            echo "timestamp=$TIMESTAMP" >> "$GITHUB_OUTPUT"
            echo "trigger=changedetection.io" >> "$GITHUB_OUTPUT"

            echo "ðŸ”” Triggered by changedetection.io webhook"
            echo "ðŸ“Š Batch size: $BATCH_SIZE organizations"
            echo "ðŸ•’ Change detected at: $TIMESTAMP"
            echo "ðŸŽ¯ Organizations: $ORGS_CSV"
          else
            # Extract from manual workflow_dispatch
            ORGS_CSV='${{ github.event.inputs.organizations }}'
            ORG_COUNT=$(echo "$ORGS_CSV" | tr ',' '\n' | wc -l)

            echo "orgs=$ORGS_CSV" >> "$GITHUB_OUTPUT"
            echo "batch_size=$ORG_COUNT" >> "$GITHUB_OUTPUT"
            echo "timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> "$GITHUB_OUTPUT"
            echo "trigger=manual" >> "$GITHUB_OUTPUT"

            echo "ðŸ‘¤ Manual trigger"
            echo "ðŸ“Š Organizations: $ORG_COUNT"
            echo "ðŸŽ¯ Organizations: $ORGS_CSV"
          fi

      - name: ðŸ” Run targeted scraper
        id: scrape
        run: |
          # Configure git for automated commits
          git config --local user.email "scraper@algora-bounty-scraper.com"
          git config --local user.name "Algora Bounty Scraper"
          git config --local commit.gpgsign false

          # Ensure data directory exists
          mkdir -p data/archive logs

          ORGS="${{ steps.parse-orgs.outputs.orgs }}"

          if [ -z "$ORGS" ]; then
            echo "âŒ No organizations to scrape"
            exit 1
          fi

          echo "ðŸš€ Running targeted scraper for: $ORGS"

          # Run the production scraper with targeted organizations
          if ! deno run --allow-all --no-lock scripts/production-scraper.ts --orgs "$ORGS"; then
            echo "âŒ Scraper failed, checking logs..."
            if [ -d logs ]; then
              echo "Available log files:"
              ls -la logs/
              echo "Latest log content:"
              find logs -name "*.log" -type f -exec tail -50 {} \;
            fi
            exit 1
          fi

          # Check if there are changes to commit
          if git diff --staged --quiet && git diff --quiet; then
            echo "changes_detected=false" >> "$GITHUB_OUTPUT"
            echo "â„¹ï¸  No changes detected"
          else
            echo "changes_detected=true" >> "$GITHUB_OUTPUT"
            echo "âœ… Changes detected"

            # Get summary of changes
            CHANGES_SUMMARY=$(git diff --name-only --staged | tr '\n' ' ')
            echo "changes_summary=$CHANGES_SUMMARY" >> "$GITHUB_OUTPUT"
          fi

      - name: ðŸ“Š Generate summary report
        if: success()
        run: |
          echo "## ðŸŽ¯ Targeted Scraping Report" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "### ðŸ“¡ Trigger Information" >> $GITHUB_STEP_SUMMARY
          echo "- **Trigger**: ${{ steps.parse-orgs.outputs.trigger }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: ${{ steps.parse-orgs.outputs.timestamp }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Organizations**: ${{ steps.parse-orgs.outputs.batch_size }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Org List**: \`${{ steps.parse-orgs.outputs.orgs }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f "data/bounty-index.json" ]; then
            TOTAL_ORGS=$(jq -r '.total_organizations' data/bounty-index.json)
            TOTAL_BOUNTIES=$(jq -r '.total_bounties' data/bounty-index.json)
            TOTAL_VALUE=$(jq -r '.total_value_usd' data/bounty-index.json)
            GENERATED_AT=$(jq -r '.generated_at' data/bounty-index.json)

            echo "### ðŸ“ˆ Current Statistics" >> $GITHUB_STEP_SUMMARY
            echo "- **Total Organizations**: $TOTAL_ORGS" >> $GITHUB_STEP_SUMMARY
            echo "- **Total Bounties**: $TOTAL_BOUNTIES" >> $GITHUB_STEP_SUMMARY
            echo "- **Total Value**: \$$(echo $TOTAL_VALUE | numfmt --format=%.0f --grouping)" >> $GITHUB_STEP_SUMMARY
            echo "- **Updated**: $GENERATED_AT" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Changes
            if [ "${{ steps.scrape.outputs.changes_detected }}" = "true" ]; then
              echo "### ðŸ”„ Changes Detected" >> $GITHUB_STEP_SUMMARY
              echo "- Modified files: ${{ steps.scrape.outputs.changes_summary }}" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "âœ… **Event-driven scraping working as expected!**" >> $GITHUB_STEP_SUMMARY
            else
              echo "### âœ… No Changes" >> $GITHUB_STEP_SUMMARY
              echo "No bounty changes detected for the monitored organizations." >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "âŒ No bounty index generated" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "*This was a targeted scrape - only the changed organizations were processed.*" >> $GITHUB_STEP_SUMMARY
          echo "*Full scrapes run daily to ensure data integrity.*" >> $GITHUB_STEP_SUMMARY

      - name: ðŸ“¤ Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: targeted-scraping-artifacts-${{ github.run_id }}
          path: |
            data/bounty-index.json
            data/algora-api-response.json
            data/archive/
            logs/
          retention-days: 7

      - name: ðŸ”” Notify on failure
        if: failure()
        run: |
          echo "## âŒ Targeted Scraping Failed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The targeted scraping workflow encountered an error." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Trigger**: ${{ steps.parse-orgs.outputs.trigger }}" >> $GITHUB_STEP_SUMMARY
          echo "**Organizations**: ${{ steps.parse-orgs.outputs.orgs }}" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow**: ${{ github.workflow }}" >> $GITHUB_STEP_SUMMARY
          echo "**Run ID**: ${{ github.run_id }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "*Note: Full scrape will pick up these changes tomorrow.*" >> $GITHUB_STEP_SUMMARY
